"{\"title\":\"\",\"courses\":[{\"course_title\":\"PyTorch Essential Training: Deep Learning\",\"course_admin_id\":2706322,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":2706322,\"Project ID\":null,\"Course Name\":\"PyTorch Essential Training: Deep Learning\",\"Course Name EN\":\"PyTorch Essential Training: Deep Learning\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"&lt;p&gt;PyTorch is the most flexible and expressive library for deep learning, and offers simple Python API, GPU support, and flexibility. It\u00e2\u20ac\u2122s designed to load data, apply transforms, and build deep learning models with just a few lines of code. Many machine learning developers and researchers use PyTorch to accelerate deep learning research, experimentation, and prototyping. In this course, software developer Terezija Semenski teaches you the important features of PyTorch with a hands-on approach to help you develop the skills you need to dive into your deep learning projects.&lt;/p&gt;&lt;p&gt;This course includes Code Challenges powered by CoderPad. Code Challenges are interactive coding exercises with real-time feedback, so you can get hands-on coding practice alongside the course content to advance your programming skills.&lt;/p&gt;\",\"Course Short Description\":\"Explore the basics of deep learning using PyTorch and test your knowledge with hands-on challenges.\",\"Content Type\":\"TOOLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":20533014,\"Instructor Name\":\"Terezija  Semenski\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"Software Developer, Mathematician, Writer, and Learner\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2024-04-15T00:00:00\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"No\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/pytorch-essential-training-deep-learning-23753149,https://www.linkedin.com/learning/pytorch-essential-training-deep-learning-revision-q1-2024-coderpad\",\"Series\":\"Essential Training\",\"Limited Series\":null,\"Manager Level\":\"Individual Contributor\",\"LI Level\":\"Intermediate\",\"LI Level EN\":\"Intermediate\",\"Sensitivity\":null,\"Internal Library\":\"Technology\",\"Internal Subject\":\"Artificial Intelligence for Technology\",\"Primary Software\":\"PyTorch\",\"Media Type\":\"Interactive\",\"Has CEU\":\"No\",\"Has Exercise Files\":\"No\",\"Visible Duration\":4902.0,\"Visible Video Count\":29.0,\"Contract Type\":\"PERPETUAL\"},\"sections\":[{\"duration\":296,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3890261\",\"duration\":31,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Deep learning with PyTorch\",\"fileName\":\"2706322_en_US_00_01_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"Storyboard + WSC\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":false,\"rawDurationSeconds\":129,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Take a closer look at the advantages of PyTorch and explore the goals of this course.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1981176,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- PyTorch is one of the most popular deep learning\\nframeworks that allows us\\nto implement neural networks more efficiently.\\nIt is designed to load data, apply transforms,\\nand build deep learning models\\nwith just a few lines of code.\\nJoin me to learn the foundations of PyTorch\\nwith the hands-on approach for the skills you need\\nto dive into Deep Learning Project.\\nHi, I'm Terezija Semenski.\\nI'm a software developer, mathematician,\\nand a teacher with a passion for AI and machine learning.\\nLet's get started.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3886261\",\"duration\":77,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"What you should know\",\"fileName\":\"2706322_en_US_00_02_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"Overlay - colab.research.google.com Please mask sign in to Google account\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":86,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Before starting this course, explore what skills and knowledge you need to have to be successful in this course. This video also lists all installation requirements you need to set up before you proceed.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2591273,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Before starting this course,\\nlet's explore what skills and knowledge you will need.\\nTo truly be successful in this course,\\nit will be helpful\\nto have a basic Python programming knowledge.\\nI assume you're familiar\\nwith the concepts and technologies behind deep learning,\\nbut you don't need any experience building models\\nusing neural networks, or NNs.\\nIn order to run our code,\\nwe will be using the Google Colaboratory environment,\\ncommonly known as Google Colab,\\nwhich is available at colab.research.google.com.\\n\\nGoogle Colab, or short, Colab, is a free computing service\\nthat provides Jupyter Notebook instances\\nthat run on the cloud.\\nThe great thing is that notebooks can be saved\\non Google Drive or GitHub.\\nConveniently, all you need to start writing code\\nis a Google account.\\nGoogle provides free access to GPUs,\\nor graphical processing units,\\nwhich we will use for training our models.\\nThere are some limits on GPU usage,\\nbut it will be sufficient for our course.\\n\\nAnd that's about it.\\nSo let's get ready to jump into PyTorch in depth.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3888262\",\"duration\":188,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Tour of CoderPad\",\"fileName\":\"2706322_en_US_00_03_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"Use callouts to highlight areas covered by the [in]structor.\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":236,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5703994,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] This course includes\\nautomated code challenges\\nthat appear when you click on the Challenge links\\nin the course's Table of Contents.\\nEach challenge includes instructions\\nand a couple of code editors\\nyou can use to create and test\\nyour own solutions to the challenge.\\nThese challenges are hosted by CoderPad,\\nand they appear in the same area of the course page\\nwhere you watch the course's videos.\\nWe recommend using a desktop browser\\nfor the best experience with the code challenges,\\nbut you can use the LinkedIn Learning mobile app\\nif you prefer.\\n\\nThe Code Challenges has four areas:\\ninstructions in the top left,\\na code editor for your answer in the top right,\\nanother code editor where you can see how your code is used\\nin the bottom right,\\nand a console for output in the bottom left.\\nYou can use these rectangles to allocate space as you like.\\nTo get even more horizontal space for the code editors,\\nyou can collapse the course's Table of Contents on the left.\\n\\nEach challenge has instructions\\nthat include a description of the challenge\\nand the challenge's parameters and desired result.\\nParameters are values that are passed into your code,\\nand they have to be of a particular data type.\\nThe return value also has to be of a particular type,\\nand you'll also see that noted in instructions.\\nThe Constraints section has useful information\\nabout the parameters that will be passed in.\\nThe examples show different parameter values\\nand what results would be returned\\nfor each of those test cases.\\n\\nCreate your answer in the top right code editor.\\nThere are comments in the starting code\\nshowing where to put your solution.\\nWhen you click Test My Code,\\nyou'll see a message\\nindicating whether your code returned a correct result.\\nCreate your answer in the top right code editor.\\nThere are comments in the starting code\\nshowing where to put your solution.\\nWhen you click Test My Code,\\nyou'll see a message\\nindicating whether your code returned a correct result.\\n\\nIf your code isn't successful, you can ask for help.\\nThe show_expected_result and show_hints variables\\ndetermine whether you see the expected outputs\\nand any hints.\\nChange them to a value of True to control the output.\\nThe code editor in the lower right\\nshows you how your solution is used.\\nYou can change that code\\nto experiment with different test cases.\\nRegardless of whether your answer is successful,\\nyou'll see messages in the console output in the lower left.\\n\\nIf any messages are too long to fit in that area,\\nyou can scroll sideways to see all of the text.\\nWhen you finish each code challenge,\\nreturn to the course's Table of Contents\\nand click the next window to see my solution.\\n\"}],\"name\":\"Introduction\",\"size\":10230942,\"urn\":\"urn:li:learningContentChapter:3891288\"},{\"duration\":588,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3885248\",\"duration\":260,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Introduction to deep learning\",\"fileName\":\"2706322_en_US_01_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"01:03 - audio only pickup to replace the missing word \\\"the\\\"\\nB-roll (seen on screen starting the video off is in Collected Assets\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":348,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":true},\"description\":\"Learn what deep learning is, and how it is different from ML and AI, and explore examples of its applications in real-life scenarios.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9170693,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Neural networks used to be\\na cool theoretical concept just a few decades ago,\\nand now they're part of our everyday lives\\ncarried around in our smartphones.\\nWe can use them to enhance their pictures,\\nreceive contact-sensitive email replies,\\nand have our voices recognized.\\nSmart speakers are a common household item\\nand self-driving cars are reality,\\nbut what is behind them?\\nIn the last few years,\\nartificial intelligence, or AI,\\nmachine learning, or ML,\\nand deep learning, or DL, have been buzzwords.\\n\\nEverybody talks about them,\\nbut only a limited number of people understand the meaning\\nand difference between them.\\nSo, is ML the same as AI, or is it different from it?\\nWhat about the DL?\\nWhere does it fit into picture?\\nFirst, artificial intelligence, or short, AI,\\nis challenging to define,\\nand there is no clear agreement among AI professionals.\\nSo, how can we define what AI is?\\nIn AI, the goal is to simulate human learning\\nso that application can adapt\\nto uncertain or unexpected conditions.\\n\\nArtificial intelligence is a concept of creating machines\\nthat can perform tasks requiring human cognitive functions\\nsuch as discovering, finding new information,\\nlearning, reasoning, problem solving, perception,\\nand language Understanding.\\nAI has many subsets,\\nsuch as machine learning, expert systems,\\nnatural language processing, or short, NLP, and robotics.\\n\\nMachine learning, or ML,\\nis just one of several subsets of AI.\\nTo build any learning system,\\nyou need three essential components, input data,\\nprocessing and output layer.\\nWhen we have a learning system\\nwith improved performance over time\\nby learning from a new examples or data,\\nwe call it machine learning, or ML.\\nML is a set of multiple techniques\\nthat enable a computer to learn from data\\nand use what it learns to provide an answer,\\noften in form of a prediction.\\n\\nWhen they have a huge data sets,\\nit is time consuming for ML algorithms\\nto process large scale matrix computations.\\nIn this case, deep learning or DL is more applicable.\\nWe can represent the relationship\\nbetween the AI, ML and DL\\nwith a simple Venn diagram like this.\\nSo, ML is a subset of AI,\\nand deep learning is a subset of ML.\\n\\nWait, but what is the difference\\nbetween machine learning and deep learning?\\nDeep learning is a subset of machine learning\\nthat uses multiple and numerous layers\\nof non-linear transforms\\nto progressively extract features from row input.\\nWait, what?\\nDeep learning is called deep\\nbecause it uses multiple layers of neural networks.\\nEvery layer is trained by algorithms.\\n\\nIt takes its inputs from previous layers\\nand progressively refines them in order\\nto minimize their errors and improve accuracy.\\nSo, machine learning is usually used\\nfor all dimensional data and for small volumes of data.\\nOn the other side,\\ndeep learning is used when the data dimension is huge\\nand the training data is also high in volume.\\nFinally, you may wonder where we can apply deep learning.\\n\\nThere are numerous use cases,\\nsome of them are speech recognition,\\nanomaly detection from videos,\\nmachine translation,\\nspeech to text conversion.\\nThis introduction leaves us with a good starting point\\nto discover why we should choose PyTorch for deep learning,\\nso let's discover that next.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3885247\",\"duration\":121,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Why should you use PyTorch\",\"fileName\":\"2706322_en_US_01_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"Overlay -  https://github.com/pytorch/pytorch/blob/main/LICENSE\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":130,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"PyTorch provides Python with easily run array-based calculations, allows the building of dynamic neural networks, and performs auto differentiation with strong graphics processing unit (GPU) acceleration. All the above are the most important features required for deep learning development.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3693987,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] PyTorch is a Python library\\nthat facilitates building deep learning projects.\\nPyTorch provides Python\\nwith easily run array-based calculations,\\nallowing it to build dynamic neural networks\\nand perform auto differentiation\\nwith a strong graphics processing unit or GPU acceleration.\\nThese are the most important features required\\nfor deep learning development.\\nPyTorch was developed by researchers and engineers\\nfrom the Facebook AI Research, FAIR division,\\nto process large-scale image analysis,\\nincluding object detection,\\nsegmentation, and classification.\\n\\nIt was written using Python and C++ languages.\\nPyTorch was initially released in September, 2016,\\nand its free and open-source under the modified BSD license,\\nso its development involves many contributions\\nfrom the community.\\nBut what makes PyTorch useful to us?\\nPyTorch is the world's fastest growing deep learning library\\nfor three main reasons,\\nits simplicity, flexibility, and Python interface.\\n\\nThis is what makes PyTorch powerful.\\nIt is supported by all major cloud platforms,\\nsuch as Amazon Web Services, Google Cloud Platform,\\nand Microsoft Azure.\\nIt is mature and stable since it's regularly maintained.\\nIt supports CPU, GPU, TPU, and parallel processing.\\nIt supports distributed training,\\nmeaning you can train neural networks or multiple GPUs\\non multiple machines.\\n\\nNow that you're familiar with PyTorch,\\nlet's jump in and discover Google Colab.\\nIt is super easy for beginners\\nas you can run PyTorch code in a browser\\nwithout installation or configuration.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3890260\",\"duration\":207,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Google Colaboratory basics\",\"fileName\":\"2706322_en_US_01_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":287,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"In this video, explore Google Colab which allows you to write and execute Python and PyTorch code in your browser.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5374245,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Let's explore Google Collaboratory,\\nknown as Google Colab,\\nthat allows us to write and execute\\nPython and PyTorch code in our browser.\\nLet's take a look at where we'll be writing\\nand running our code.\\nTo get started, let's head on to colab.research.google.com.\\nTo use Colab, you only need to have a Google account.\\nIf you haven't signed into your Google account,\\nyou'll be prompted to sign in or to create one.\\n\\nIn case you already signed into your Google account,\\nyou'll see a default screen,\\nand it gives you a good set\\nof beginner-friendly instructions on how to use it.\\nThe very first thing you're going to do\\nis to create a new notebook.\\nClick on File, New notebook,\\nand it creates an empty blank template.\\nAnd we can rename it to 0103.\\nColab is great for beginners\\nor anyone who wants to start playing\\nwith machine learning and deep learning models,\\nbecause it allows us to have a GPU for absolutely free.\\n\\nWell, there are limits in GPU usage per week,\\nbut it will be sufficient for our needs.\\nTo verify our configuration,\\nyou're going to import the PyTorch library,\\nprint the installed version,\\nand lastly, check to see if you're using a GPU.\\nWe got false, as by default,\\nour Colab notebook does not use the GPU.\\n\\nWe are going to change the runtime type\\nso that we use a hardware accelerator.\\nWe want to run this code using GPUs,\\nbecause if you just use CPUs, it will consume too much time.\\nNow, let's get our environment set up.\\nTo change CPU to GPU, Let's select Runtime.\\nAnd under it change runtime type.\\nThen select T4 GPU\\nfrom the hardware accelerator dropdown menu, and click Save.\\n\\nLet's run the cell again by selecting the cell\\nand pressing Shift + Enter.\\nNow we have a true as the output. Great.\\nWe have verified that PyTorch is installed\\nand we have a GPU available.\\nOne more thing I want to set up\\nis line numbers for each code\\nso you can easily follow along.\\nClick on Tools, click on Settings,\\nand select the Editor tab.\\nThere is an option, right, that says Show line numbers.\\n\\nLet's select that option and click on Save.\\nThere are some other options like font and indentation\\nthat you can customize later if you want.\\nSome may wonder why we don't run PyTorch locally\\nor in the cloud.\\nSetting up your local machine or your cloud environment\\nis beyond the scope of this course,\\nand it would require much more time and even money\\nas GPU instances or cloud platforms like AWS, GCP,\\nor Azure have additional costs.\\n\\nNow that we have our playground ready,\\nlet's get to know tensors.\\n\"}],\"name\":\"1. PyTorch Overview and Introduction to Google Colaboratory\",\"size\":16664192,\"urn\":\"urn:li:learningContentChapter:3888263\"},{\"duration\":548,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3890259\",\"duration\":204,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Introduction to tensors\",\"fileName\":\"2706322_en_US_02_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":245,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"In this video, learn the fundamental data structure used in PyTorch called the tensors. It allows you to understand how PyTorch handles and stores the data.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6158463,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] A neural network knows how to deal with data\\nstored as floating-point numbers.\\nInputs are real-world data in many forms.\\nLet's take for example, image recognition.\\nA deep neural network takes images\\nand codes them in a digestible way\\nand then decodes them back to some output,\\nfor example, text.\\nIt happens in multiple stages,\\nand partially transformed data between stages\\nis a sequence of intermediate representations.\\n\\nIn our case, for images,\\nlet's think of a picture of a person.\\nEarly representation can be edge detection.\\nIntermediate representation can capture ears, nose, or eyes.\\nEach intermediate representation\\nis a collection of a floating-point numbers\\nresulting from multiplying the input\\nwith the previous layer's weights.\\nTo handle and store the data\\nin all stages of deep learning,\\nPyTorch uses an essential data structure called a tensor.\\n\\nSo inputs, intermediate representations, and outputs\\nare all stored as tensors.\\nBut what is a tensor?\\nFrom mathematics, we can look at tensors\\nas generalizations of scalars, vectors, and matrices\\nto any dimension.\\nSo we can define the scalar as a zero dimensional,\\nor 0-d tensor,\\na vector as one dimensional, or 1-d tensor,\\na matrix as a 2-d tensor,\\nand a matrix stack in a third dimension,\\nfor example, when you need to process data\\nthat has a time element as 3-d tensor.\\n\\nGenerally, tensors can have an arbitrary number\\nof dimensions.\\nIn PyTorch, a tensor is a multi-dimensional array\\ncontaining elements of a single data type.\\nIf you have worked with a NumPy library,\\nthen tensor reminds you of the fundamental object in NumPy\\ncalled ndarray, which is defined as an n-dimensional array,\\nhomogenous array of fixed-size items.\\nYou may wonder,\\nwhat is the difference between tensor and ndarray?\\nTensors in PyTorch are similar to NumPy's ndarrays.\\n\\nBut tensors have additional advantages\\nthat make them more suitable for deep learning calculations.\\nSome of those advantages are\\ntensor operations are performed significantly faster\\nusing graphical processing units, or GPUs.\\nTensors can be stored and manipulated at scale\\nusing distributed processing on multiple CPUs and GPUs\\nand across multiple servers.\\n\\nAnd tensors keep track of the graph of computation\\nthat created them.\\nWith all those mentioned,\\nyou can see that tensors are much more than a special sort\\nof multidimensional arrays.\\nTensors interact with each other\\nsuch that transforming tensors as a whole\\nmeans that each tensor\\nfollows a particular transformation rule.\\nWith that in mind, let's head on to practical examples\\nand learn how to create tensors.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3887273\",\"duration\":108,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Creating a tensor CPU example\",\"fileName\":\"2706322_en_US_02_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"01:18 - Pause 4 action mogrt\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":144,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn a CPU example of how to create a tensor and perform a tensor operation so you can use a built-in method on the tensor itself.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2925364,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Let's create our first tensors\\nusing the PyTorch library.\\nWe're going to open a Google Colab notebook named 02_02.\\nFirst, we're going to import the PyTorch library.\\nNext, we're going to create two tensors\\nfrom two-dimensional lists,\\nand let's call them first_tens and second_tens.\\nTensor data type will by default be derived\\nfrom the input data type,\\nand the tensor is allocated to the CPU device.\\n\\nNow, let's apply a simple arithmetic operation.\\nIn our case, addition.\\nWe can do that using the plus operator\\nand store the result in the third tensor,\\nwhich we'll call add_tens.\\nLet's print the new tensor, add_tens, and print its size.\\nAs you can see,\\nit's the sum of tensors first_tens and second_tens,\\nand you can see its dimensions are two by four.\\nNow, let's try subtraction.\\n\\nHow would you calculate it?\\n(upbeat music)\\n(buzzer buzzing)\\nThat's right, by using the minus operator.\\nNow, let's do that and store the result in sub_tens.\\nFinally, let's print the latest tensor, sub_tens,\\nwhich we can see is the difference\\nof the first_tens and second_tens,\\nand we print the size of sub_tens.\\nAs you can see,\\nboth add_tens and sub_tens are tensor objects themselves,\\nand we can use size method to return its matrix dimensions,\\nnamely two by four.\\n\\nNow that we have seen how to create a tensor\\nthat is allocated to the CPU device,\\nwe'll explore the GPU example next.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3889244\",\"duration\":106,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Creating a tensor GPU example\",\"fileName\":\"2706322_en_US_02_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":113,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn a GPU example of how to create a tensor and perform a tensor operation so you can use a built-in method on the tensor itself.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2738242,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] GPUs were originally developed\\nfor rendering computer graphics.\\nSo when I was a kid, every gamer talked about them.\\nMeanwhile, with the need for speed\\nof computational processing involving neural networks,\\nthey now play a crucial role in deep learning.\\nIn PyTorch, we have the CUDA library\\nthat is instrumental in detecting, activating,\\nand harnessing the power of GPUs.\\nJust as for the CPU, we'll explore a simple example.\\n\\nFirst, before using CPUs,\\nwe are going to check if they are configured\\nand ready to use.\\nWe are going to import PyTorch\\nand print the PyTorch version.\\nNext, by calling the torch.cuda.is_available function,\\nwe'll move the tensors to the GPU device\\nif one is available.\\nSo, our device has a GPU support.\\nWe are going to create two tensors\\nand let's just call them tens_a and tens_b.\\n\\nNow let's apply a simple arithmetic operation,\\nin our case, multiplication.\\nWe can do that using the asterisk operator\\nand store the result in the third tensor,\\nwhich we'll call multi_tens.\\nNotice that the output tensor is also allocated to the GPU.\\nWhen we run the code,\\nwe get the output, in our case, device='cuda:0'\\nwhich indicates that the first GPU is being used.\\n\\nIn the case our device contains multiple GPUs,\\nthis way, we can control which GPU is being used.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3885246\",\"duration\":130,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Moving tensors between CPUs and GPUs\",\"fileName\":\"2706322_en_US_02_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":212,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Explore the torch.to() method that allows you to move an existing tensor from CPU to GPU device.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3628251,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] A few important reasons exist\\nfor moving the tenors between CPUs and GPUs.\\nLet's explore them and see how to transfer\\nthe data from the CPU to GPU.\\nBy default, in PyTorch, all the data are in the CPU.\\nIn case we are training neural network, which is huge,\\nwe prefer to use GPU for faster training.\\nFor example, if we have high dimensional tensors\\nthat represent images, their computation intents,\\nand take too much time if run over the CPU.\\n\\nSo we need to transfer the data from the CPU to the GPU.\\nAdditionally, after the training,\\nthe output tensors are produced in GPU.\\nSometimes the output data requires pre-processing.\\nSome pre-processing libraries don't support tensors,\\nand expect an NumPy array.\\nIn that case, NumPy supports only data in the CPU,\\nso there is a need to move the data from the CPU to the GPU.\\n\\nLuckily, tensors can be moved easily from the CPU\\nto GPU device with the torch to method.\\nWe can call this method in one of the three ways.\\nFirst way, tensor.cuda,\\nor second way, tensor to cuda,\\nor the third way, tensor to cuda 0.\\nWhen we need to move the tensors in the opposite direction\\nfrom the GPU to CPU, there are two possible cases.\\n\\nFirst one, tensor with required grad = false.\\nIn the first case, when required grad = false,\\nthen we use the methods tensor.cpu.\\nIn the second case, when required grad = true,\\nthen we use method, tensor.detach.cpu.\\nNow, that we have mastered methods to move the tensors,\\nlet's head on to explore how to create tensors.\\n\"}],\"name\":\"2. Tensors\",\"size\":15450320,\"urn\":\"urn:li:learningContentChapter:3887274\"},{\"duration\":941,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3884263\",\"duration\":219,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Different ways to create tensors\",\"fileName\":\"2706322_en_US_03_01_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"Overlay - https://pytorch.org/docs/stable/torch.html\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":250,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Sometimes you may want to construct tensors from preexisting data stored in array-like structures such as lists, tuples, scalars, serialized data files, or NumPy arrays. Learn how to achieve that.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7708833,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Sometimes we want\\nto construct tensors directly from Python objects\\nlike lists, tuples or NumPy arrays.\\nWe can also create tensors\\nby using different functions in case we want\\nto generate a particular type of tensor.\\nLet's first learn how\\nto create a tensor from a Python list and a tuple.\\nTo do that, open notebook 0301,\\nwe have already imported PyTorch and numpy as np.\\nI will create a tensor from a list\\nand call it tensor from list by using a torch.tensor method,\\nand this list will contain integers from one to five.\\n\\nThis method is used\\nto create a tensor from an existing data structure.\\nNow to create a tensor from a tuple.\\nTuples are lists that are immutable,\\nmeaning that once defined,\\nthe individual elements of a tuple cannot be changed.\\nYou can easily spot a difference between a tuple and a list\\nbecause a tuple is written in a sequence of numbers\\nand closed in the round parenthesis.\\nLet's call this tensor tensor_from_tuple.\\n\\nWe will call the same torch.tensor method,\\nbut this time we'll pass a tuple instead of a list.\\nGo ahead and display these two tensors.\\nNow to create a tensor from a NumPy array,\\nwe will call torch.tensor\\nand pass a NumPy array instead of a list or a tuple.\\nLet's display our tensor.\\nPyTorch also has different functions that we can use\\nto create an initialized tensors.\\n\\nThe most useful ones are torch.empty(), torch.ones()\\nand torch.zeros().\\nAs you can see, each one of them is used\\nwith a torch namespace.\\nThese functions take integers as the first two arguments,\\nwhich specified the size of a tensor.\\nYou can easily guess what they do from their name.\\nAs you can see in our example using the empty function,\\nwe create a tensor from uninitialized elements.\\nIf you use a torch.zero function, it creates a tensor\\nwith elements initialized with zeros\\nand torch.ones function creates a tensor\\nwith all elements initialized to ones.\\n\\nSometimes you want to initialize the tensor\\nwith random values,\\nand PyTorch has a few useful functions called torch.rand,\\ntorch.randn and torch.randint.\\nAs you can see in our code, the difference between them\\nis that the first one returns a tensor filled\\nwith random numbers from uniform distribution.\\nThe second one used normal distribution,\\nand the third one returns the tensor filled\\nwith random integers using uniform distributions.\\n\\nThese functions take integers as first two arguments,\\nwhich specify the size of a tensor.\\nWe can also pass in an optional arguments data type\\nor dtype and device.\\nOften we want to create tensors that have similar properties\\nto another tensor, including the dtype device\\nand layout properties to facilitate calculations.\\nFor example, torch.ones_like will create a tensor\\nwith all ones with a dtype device\\nand layout properties of tensor X.\\n\\nYou can learn more about additional functions used\\nfor tensor creation\\nat the official PyTorch documentation page.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3891286\",\"duration\":131,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Tensor attributes\",\"fileName\":\"2706322_en_US_03_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":233,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to effortlessly find information about tensors by accessing their attributes.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3786168,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Knowing attributes\\nsuch as device location, data type, dimension, and rank\\nis very important\\nwhen you're doing computations with tensors.\\nAs you have learned, a tensor is a container\\nwith a fixed size that has elements of the same type.\\nYou can think of a tensor as a multidimensional array.\\nWe have already imported PyTorch,\\nand now let's create our one-dimensional tensor\\ncalled first_tensor.\\nWe'll call the device function\\nto find out the tensor's device location,\\nmeaning the device on which the tensor is stored.\\n\\nHere we run the cell\\nand see that our tensor is on the CPU.\\nTo check its data type, we'll call the dtype function.\\nAnd when we ran the cell we got int64,\\nmeaning 64-bit integer.\\nWhen we want to find out the shape of the tensor,\\nwe can always call its shape function\\nand it gives us back the dimensions.\\nAnother useful function is ndim,\\nwhich gives us the number of tensors, dimension, or rank.\\n\\nLet's go ahead and run the code.\\nAnd we get one, as we have expected,\\nsince we have a one-dimensional tensor.\\nWhat if we create a two-dimensional tensor?\\nLet's create one and name it second_tensor.\\nNow we can check its attributes by running the cells.\\nAs you can see, when accessing object attributes,\\nwe don't include parenthesis as we do with the class method.\\nThere are many more variable functions to access attributes,\\nsuch as requires_grad,\\nwhich is used in automatic differentiation\\nor short autograd.\\n\\nYou can find out more\\nby heading onto the documentation page\\non the following link.\\nNow that we have learned the tensor attributes,\\nit's time to move to the next section\\nand explore tensor data types.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3885245\",\"duration\":196,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Tensor data types\",\"fileName\":\"2706322_en_US_03_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"01:48 - Pause4Action Mogrt\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":298,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"When creating tensors, you can specify the data type. It is also possible to cast a tensor to a new data type. In this video, explore how to achieve that.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6074139,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] What sets PyTorch apart from other libraries\\nis the usage of tensors, multidimensional arrays\\nthat can seamlessly perform fast operations on GPUs\\nand distribute operations on multiple machines\\nwhile keeping track of the graphic computations\\nthat created them.\\nLet's look at the various tensor data types\\nthat are used in computations happening in neural networks.\\nWe'll start by importing PyTorch\\nand creating a couple of tensor objects.\\n\\nWe are going to create our first one-dimensional tensor\\nand call it int_tensor,\\nand specify the data type by using dtype as an argument\\nto the constructor.\\nWe want all tensor elements to be integer type\\nof eight-bit size,\\nso we'll type dtype=torch.int8.\\nLet's displace data type using dtype function.\\n\\nNow let's create a second one-dimensional tensor\\nand call it float_tensor.\\nWe want all tensor elements to be 32 floating points,\\nso we'll type dtype=torch.float32\\nand just display the data type.\\nWhat if we want to create a one-dimensional tensor\\nwith an integer type of 16 bits?\\nHow would you do it?\\n(light music)\\nThat's right, by specifying the data type\\nas dtype=torch.int16.\\n\\nAnd let's go ahead and create one.\\nSometimes we need to cast the tensor to new data type.\\nIt can be done in two different ways\\nby using the corresponding casting function\\nwhich is named after the data type you want to convert to.\\nFor example, in case you want to convert\\nint_tensor to float,\\nwe can do that by calling the float function.\\n\\nAnd when we display the data type,\\nwe can see that our short tensor\\nis the same type as the float tensor.\\nAnother way to cast a tensor to a new data type\\nis using two function; for example,\\nto cast short tensor from int 16 to int 8\\nand assign it to a new tensor called last_tensor,\\nwe'll type last_tensor = short_tensor.to(dtype=torch.int8).\\n\\nThe important thing to remember\\nis that when we are doing operations\\non and between tensors that have different data types,\\nPyTorch will automatically cast tensors\\nto a larger data type.\\nIt would be best if you always were mindful\\non which data type to choose.\\nThis can have a huge effect\\non memory consumption and precision,\\nwhich is especially relevant in deep learning algorithms.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3888261\",\"duration\":161,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Creating tensors from random samples\",\"fileName\":\"2706322_en_US_03_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":193,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Often, you need to initialize weights to random values or create random inputs with specified distributions. Learn functions that you can apply to create tensors from random data.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5108856,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] In deep learning,\\nwe often need to initialize weights to random values\\nor create random inputs with specified distributions.\\nPyTorch provides valuable functions\\nthat we can use for random sampling.\\nWith the power of these functions,\\nwe can generate values by drawing randomly\\nfor probability distributions, like normal distribution\\nand uniform distribution.\\nLet's explore the most useful ones.\\nWe have already imported PyTorch.\\n\\nLet's go ahead and create the two-dimensional tensors\\nusing the torch.rand function.\\nIt will create a tensor filled with random values\\nfrom a uniform distribution on the interval zero to one.\\nIt's going to be 3 by 3 shape,\\nwhich we define by passing it as an argument\\nto rand function and displaying it.\\nNow, if we rerun our code, you can see that, as expected,\\nwe get a different result each time.\\n\\nHowever, sometimes we want the same result.\\nTo achieve this, we can just call manual_seed function\\nbefore creating our tensor.\\nLet's add the line before.\\nGreat, now when we rerun the code,\\nwe obtain the same result.\\nIf we want to select random values\\nfrom a standard normal distribution\\nwith zero mean unit variance,\\nwe can use the torch.rand function.\\n\\nLet's create a 4 by 4 shape tensor using rand function.\\nWe use torch.randint function to create a tensor\\nfilled with random integers generated uniformly\\nbetween specified low and high values.\\nIt accepts three values as parameters.\\nThe first parameter is the lowest inclusive value,\\nthe second parameter is the highest exclusive value,\\nand the third parameter will pass the shape.\\nLet's provide the parameters minus 1, 10,\\nand it's going to be 3 by 3 shape.\\n\\nwhen creating tensors using sampling functions,\\nyou can also specify dtype and device and other parameters.\\nWhen creating tensors using sampling functions,\\nyou can also specify dtype and device and other parameters\\nin the case of using the more advanced distributions\\nlike multinomial or exponential distributions.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3887272\",\"duration\":125,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Creating tensors like other tensors\",\"fileName\":\"2706322_en_US_03_05_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":144,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn similarity functions so you can create\u2009and\u2009initialize\u2009a\u2009tensor\u2009that has similar properties to the existing tensor.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3751344,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Sometimes there is a need to create a tensor\\nthat has the same device, size, data type,\\nand layout properties as another preference tensor.\\nPyTorch has special functions that allow to achieve this.\\nYou can easily spot and memorize those functions\\nas they have the postfix like\\nas a part of the function name.\\nWe have explored the tensor creation functions,\\nempty, zero, ones, rand and rand int.\\nAnd all these functions have similar function,\\nwhich we call similarity functions with postfix like.\\n\\nSo empty has its pair empty like,\\nzeroes have a pair zeroes like and so on.\\nWe have already imported PyTorch.\\nWe'll start by creating a tensor using zeroes function,\\ncall it starting tensor and display it.\\nWe'll create a tensor with the same size\\nfilled with random values using torch.rand like function.\\n\\nNotice we are using manual seed\\nto have the same numbers generated\\neach time we rerun our code.\\nLet's create another two dimensional tensor.\\nThis time we want to have the same shape as starting tensor,\\nbut filled with ones.\\nWe will use ones like function.\\nAnd we get a tensor filled with ones.\\nNow, imagine you want to create a tensor\\nwith the same shape,\\nbut this time you want all elements\\nto be of a specific value.\\n\\nThis time we'll use a full like function.\\nProvide an input tensor\\nand pass number seven as a fill value.\\nGreat, now that we know what tensors are\\nand have seen different ways to create tensors,\\nlet's jump right into some practice\\nin a coder pad environment.\\nGive the challenge a go\\nand then come back to see how I solved it.\\nGood luck.\\n\"},{\"urn\":\"urn:li:learningContentAssessment:6605e3623450c8a8f9db62b3\",\"duration\":600,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"</> Code challenge: Create tensors\",\"externalAsset\":{\"coderPadCampaign\":\"urn:li:coderPadCampaign:1006782\"},\"coderPadCampaign\":null},{\"urn\":\"urn:li:learningContentVideo:3890262\",\"duration\":109,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Create tensors\",\"fileName\":\"2706322_en_US_03_07_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":124,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"In this video, learn a solution for creating tensors from different data structures.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4100885,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"(bright music)\\n- [Instructor] All right, so for this challenge,\\nwe needed to create four functions that return four tensors,\\nthe first two using the already provided Python list\\nand NumPy array,\\nand the next two by using PyTorch functions.\\nSo, here is how to solve this challenge.\\nSince Torch is not supported by CoderPad environment,\\nI have created a mock tensor class\\nthat has all required functions to solve this challenge.\\n\\nSo we have our first function,\\nwhich takes input list as parameter.\\nTo convert a Python list to a tensor,\\nwe'll use a built-in function\\nfrom the Torch Library called torch.tensor.\\nThis function creates a tensor\\nwith elements in the same data type as the Python list.\\nIn our case, integers.\\nNext, for a second function,\\nwhich takes an input array\\nand needs to return a two-dimensional tensor,\\nwe'll again use the torch.tensor function\\nand pass in an input array as a parameter.\\n\\nTo create a tensor of a shape three by four,\\nwith all its elements being one,\\nwe'll use torch.once function.\\nWe'll pass a tuple {3, 4} as a parameter.\\nFor the last task\\nwhere we need to create a shape four by five\\nwith all elements being five,\\nwe'll call full function.\\nWe use it by passing a tuple {4, 5} as a parameter\\nand 5 as a default value.\\nNow, go ahead and click on test my code.\\n\\nWe got the right answer,\\nand you can see a printout of all of our four tensors.\\n\"}],\"name\":\"3. Creating Tensors\",\"size\":30530225,\"urn\":\"urn:li:learningContentChapter:3886262\"},{\"duration\":1205,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3885244\",\"duration\":275,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Tensor operations\",\"fileName\":\"2706322_en_US_04_01_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"Start with WSC, PUWSC - video and audio are on separate files. PU replaces content at 02:45 and start with WSC, separate audiofile\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":false,\"rawDurationSeconds\":939,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"In this video explore a set of tensor operations that allow you to access and transform your tensor data.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9202498,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Managing and transforming large data sets in deep learning\\ncan be frustrating.\\nYou're likely wasting time and computational power\\nif your tensor operations aren't optimized,\\nmaking the task of handling data\\ncumbersome and less effective.\\nLet's learn to efficiently split, combine,\\nand manipulate tensors,\\nwhich lead to more robust and scalable deep learning models.\\nLet's perform indexing and slicing on tensors.\\nIf you have used NumPy, I have great news.\\n\\nIndexing and slicing of tensors\\nis done the same way as per NumPy arrays.\\nIf you're new to this, don't worry.\\nIndexing means accessing a single element of a tensor,\\nand slicing means accessing a range of elements.\\nNow let's create a one-dimensional tensor,\\ncall it 1-dim-tensor.\\nIf we want to access and display\\na third element of our tensor,\\nwe just have to type print 1-dim-tensor two.\\nWhen we run the cell, notice we got tensor three.\\n\\nIn PyTorch, when we are passing the tensor element\\nto a function like print, we first have to convert it\\nto a Python value by calling the item function.\\nLet's do that and rerun our code.\\nAnd you can see, we got the value as a number.\\nNext, let's see how slicing is done.\\nThere is a format that we use start column and column step.\\nWe need to specify a start index\\nand the end index separated by column.\\n\\nThe step is optional,\\nand it defines the number of indexes to move forward\\nwhile slicing an object.\\nIf the step is not indicated,\\nit means moving without skipping any index.\\nThe output tensor will contain all the elements\\nfrom the starting index including,\\nto the ending index excluding.\\nSo, let's say we want to get elements\\nbetween the first and the fourth element.\\nWe will type 1-dim-tensor, one column four.\\n\\nNext, let's see how to do indexing and slicing\\non a two-dimensional tensor.\\nWe'll create a four by six tensor called 2-dim tensor.\\nTo access the fourth element of the second array,\\nwe'll type:\\n2-dim tensor one three.\\nIn the case when we want to access two or more elements\\nat the same time, we'll perform slicing.\\nLet's say we want to access\\nthe first three elements of the first row,\\nand the first four elements of the second row.\\n\\nWe'll type print first three elements on the first row,\\n2-dim tensor, zero zero three.\\nAnd we'll print first four elements of the second row,\\n2-dim tensor one zero four.\\nSometimes we want to use indexing\\nto extract the data that meets some criteria.\\nFor example, if we would like to keep only elements\\nthat are less than 10, we would type 2-dim tensor,\\n2-dim tensor less than 11, and display it.\\n\\nPyTorch has many different built-in functions\\nthat we can use to access, combine, and split tensors.\\nLet's use the two most common ones in our example.\\nIf we want to combine tensors,\\nthere is a function called torch stack.\\nIt concatenates a sequence of tensors along a new dimension.\\nLet's create a new tensor called combined tensor.\\nLet's combine our two-dimensional tensor\\nusing torch stack function.\\n\\nThe second useful function is for splitting tensors,\\nand it is called torch and bind.\\nIf we want to split our two-dimensional tensor\\ninto four tensors, let's call them first tensor,\\nsecond tensor, and so on.\\nWe will type: first tensor, second tensor, third tensor,\\nfourth tensor equals torch unbind, 2-dim tensor.\\nAnd display it.\\nAs you can see, torch and bind function splits the tensor\\naccordingly to the number of rows,\\nbut we can select along which dimension we want it to work.\\n\\nNow, if we put dim equals one,\\nwhich corresponds to the column dimension,\\nthe tensor will split into six smaller tensors,\\nwith the corresponding values of each column.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3891287\",\"duration\":216,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Mathematical functions\",\"fileName\":\"2706322_en_US_04_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":259,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn a set of built-in math functions. It is extremely important to know them as deep learning is based on mathematical computations.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6007871,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Mathematical functions\\nare one of the most useful functions in PyTorch.\\nLet's explore five types of built-in math functions,\\npointwise operations, reduction functions,\\ncomparison functions, linear algebra operations,\\nand spectral and other math computations.\\nDon't be overwhelmed with these fancy names.\\nLet's figure them out together.\\nPointwise operations are named after their function\\nas they perform an operation\\non each point in the tensor individually\\nand return a new tensor.\\n\\nSome commonly used pointwise operation\\ninclude some basic math functions,\\nadd(), mul(), div(), neg(), and true_divide(),\\nfunctions for truncation,\\nceil(), clamp(), floor(), et cetera,\\nlogical functions, trigonometry functions, and so on.\\nThe second type of mathematical functions\\nare reduction operations.\\nThey're also named after their role\\nas they reduce numbers down to a single number\\nor a smaller set of numbers\\nthat results in reducing the dimensionality\\nor rank of the tensor.\\n\\nReduction operations include statistical functions\\nsuch as mean, median, mode.\\nComparison functions, as the name suggests,\\ncompare all the values between the tensor\\nor compare values of two different tensors.\\nThey also include functions\\nto find the minimum or maximum value, sort tensor values,\\ntest sensor status or condition, or similar.\\nLinear algebra functions enable matrix operations\\nand are essential for deep-learning computations.\\n\\nThese include functions for matrix computations\\nand tensor computations.\\nThe last type of mathematical function\\nis a spectral and other math operations.\\nThese functions are useful\\nfor data transformations or analysis.\\nAs there are so many math functions for different purposes,\\nwe won't be covering all of them with code examples.\\nLet's explore some of them\\nby heading on to the Colab notebook.\\nWe have already imported PyTorch.\\n\\nLet's create two one-dimensional tensors\\nand call them a and b.\\nWe are going to add, multiply,\\nand divide tensor a with tensor b\\nby using add(), mul(), div() functions,\\nand display the results.\\nNext, let's see the most useful reduction functions.\\nThese are torch.mean(), torch.median(),\\ntorch.mode(), and torch.std().\\nAs their name suggests,\\nthey're used for calculating the mean, the median, the mode,\\nand the standard deviations\\nof all elements between the tensor.\\n\\nLet's create a tensor c that contains floating points.\\nWe are using floating points\\nas torch.mean() accepts only tensors\\nwith floating points data type.\\nNext, let's calculate these reduction functions\\nand display them.\\nAs you can see when we run the code,\\ntorch.mode() function returns a namedtuple\\ncontaining mode values and indices,\\nrepresenting the index occurrence of mode in each row.\\n\\nKeep in mind,\\nwe have only scratched the surface of math functions\\nas there are many more valuable functions.\\nYou can discover them later on your own.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3887271\",\"duration\":236,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Linear algebra operations\",\"fileName\":\"2706322_en_US_04_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"00:35 - Overlay - https://pytorch.org/docs/stable/linalg.html\\n01:04 - overlay - NumPy Essential Training\\n02:39 - PAUSE4ACTION\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":288,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Many computations, including optimization algorithms and gradient descent, use linear algebra to implement the calculations. Explore the most important built-in linear algebra operations which you can use.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7828922,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Linear algebra is used heavily\\nin deep learning computations,\\nfrom different optimization algorithms to gradient descent.\\nLet's explore the most important ones.\\nPyTorch has a module called torch lineal that contains a set\\nof built-in linear algebra functions\\nthat are mostly based on the basic linear algebra,\\nsubprograms or Blast and Linear algebra package\\nor APEC standardized libraries.\\nYou can find a complete list\\nof functions on the following PyTorch linear algebra\\ndocumentation page.\\n\\nIf you have already mastered Numpy,\\nyou will quickly learn these functions as most\\nof the functions from Numpy's linear algebra module are\\nthe same, but they're extended with accelerator\\nand L2 grad support.\\nOnly a few of the functions will be completely new.\\nIf you haven't explored the linear algebra capabilities\\nof Numpy, you can take my course, Numpy Essential Training.\\nWe have already imported PyTorch.\\n\\nThe first useful function performs matrix products\\nof two tensors, and it's called Torch Matmul.\\nWe'll create two tensors,\\nand then compute the dot product\\nof them using torch matmul and display it.\\nWhen we run our code, we see\\nthat the result is a zero dimensional tensor or scaler.\\nFor the next example, let's compute a product of two,\\ntwo dimensional tensors or matrix matrix products.\\n\\nLet's create a first tensor that has a shape, two by three\\nand a second tensor that has a shape three by two,\\nand after we perform a matrix product\\nand display the output, you can see we got a two\\nby two two dimensional tensor or matrix.\\nWhen performing matrix multiplication, it is important\\nthat matrices have compatible dimensions.\\nThis means that the number\\nof columns in the first matrix is the same as the number\\nof rows in the second matrix, so in our case,\\nwe multiplied two by three with three by two matrix\\nand got two by two matrix.\\n\\nWe could have also multiplied the two by three matrix\\nwith a three by five matrix.\\nWhat would be the dimension\\nof the result matrix in this case?\\n(upbeat music)\\nYou are right.\\nThe result matrix would be two by five matrix.\\nThere is a second function\\nfor calculating the matrix product of two tensors,\\ncalled torch mm.\\nUnlike torch matmul, it doesn't support broadcasting.\\n\\nIn deep learning, we often have\\nto calculate the matrix product\\nof in two dimensional tensors.\\nTo do that, we can use torch.linalg.multi_dot function.\\nLet's create five two dimensional tensors using torch render\\nand then call torch linalg.multi_dot function.\\nWhen we run our code, we see we got two by seven matrix\\nas a result.\\nOne of the most useful types\\nof matrix decompositions in deep learning is the eigen\\ncomposition, which decomposes a square matrix into eigen\\nvectors and eigen values.\\n\\nComputing eigen values\\nand eigen vectors is simply done\\nby calling the torch ike function.\\nLet's create a four by four square matrix A,\\ndisplayed and compute the Eigen values\\nand eigen vectors of the matrix.\\nNow that you have a basic foundation on tensors,\\nlet's head on to explore how to use them\\nto perform deep learning development.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3890258\",\"duration\":365,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Automatic differentiation (Autograd)\",\"fileName\":\"2706322_en_US_04_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"01:55. - Overlay - Machine Learning Foundations: Calculus\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":472,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn the backward() function. It is important because it is used to differentiate and compute gradients of tensors based on the Chain rule.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10276293,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] When we train a neural network,\\nwe follow two simple steps: forward propagation\\nand backward propagation.\\nIn forward propagation, we input data into the network.\\nIt runs the input data through each of these functions\\nand makes the best guess about the correct output.\\nThen we compare the predicted output with the actual output.\\nWe calculate the lowest function to determine the difference\\nbetween the predicted output and actual output.\\nIn the next step called backward propagation,\\nthe neural network adjusts its parameters\\nproportionate to the error in its guess.\\n\\nSo after we find the loss function,\\nwe take the derivative of the loss function\\nin terms of the parameters of our neural network.\\nLastly, we iteratively update\\nthe weight parameters accordingly\\nso that the loss function\\nreturns the smallest possible loss.\\nWe call this step iterative optimization\\nas we use an optimizer to perform the update\\nof the parameters.\\nWe call this process gradient-based optimization.\\nAutomatic differentiation, or auto diff,\\nis a set of techniques that allows to compute gradients\\nfor arbitrary complex loss functions efficiently.\\n\\nIf this sounds terrifying,\\nremember, we are just calculating partial derivatives.\\nIf you still need help with the concept of derivatives,\\nI highly recommend\\nthe Machine Learning Foundation calculus course.\\nWe can calculate derivatives in a few different ways.\\nThe first one is numerical differentiation,\\nwhich follows the definition of a derivative.\\nA derivative of Y with respect to X\\ndefines the rate of change of Y with respect to X.\\n\\nWe can write it down using the following formula.\\nThe cons are the computation costs,\\nwhich increase as we increase the number of parameters\\nin the loss function, the truncation errors,\\nand the round-off errors.\\nAnother method is symbolic differentiation\\nwhich is done in calculus.\\nBasically, we are using a set of rules,\\nmeaning a set of formulas that we can apply\\nto the loss function to get the gradients.\\n\\nFor example, if we want to calculate\\nthe derivative of a function, f of x equals 3x squared\\nminus 4x plus 5.\\nWhen we apply the symbolic rules,\\nwe get derivative of f equals 6x minus 4.\\nThe cons are it is limited\\nto the already defined symbolic differentiation rules,\\nso it cannot be used\\nfor differentiating a given computational procedure\\nand the computation costs,\\nas it can lead to an explosion of symbolic terms.\\n\\nThe way to avoid the above issues\\nis to use automatic differentiation.\\nEvery complex function that we want to differentiate\\ncan be expressed as a composition of elementary functions.\\nFor those elementary functions,\\nwe could apply symbolic differentiation,\\nwhich would mean storing and manipulating\\nsymbolic forms of derivatives.\\nBy using automatic differentiation,\\nwe don't have to go through the tedious process\\nof simplifying the expressions.\\n\\nInstead, we can just evaluate a given set of values.\\nAnother benefit of automatic differentiation\\nis that our function can contain if-else statements,\\nfor loops, or recursion.\\nTo understand automatic differentiation,\\nwe can represent the flow using a computational graph.\\nIt's a directed graph,\\nand nodes represent mathematical operations.\\nFor example, if you have a function f of x, y, z\\nequals x minus y multiplied by z,\\nand the variables x, y, and z are x equals 2,\\ny equals 1, and z equals 5.\\n\\nOn our graph, we can label an intermediate variable 'a'\\nthat will store the computed value of x minus y,\\nand final variable f which will store the final value:\\nx minus y multiply by z.\\nAutograd package provides automatic differentiation\\nfor all operations on tensors.\\nWhen we want to train or optimize the neural network,\\nthis requires computing the gradient.\\nIn the forward pass step, we substitute the variables\\nand get the final value f:\\n2 minus 1 multiplied by 5 equals 5.\\n\\nIn the next step, using automatic differentiation,\\nwe find gradients of f with regards to the input variables.\\nWe'll calculate gradients of the loss function\\nwith respect to the weights by using chain rule.\\nNow, enough math.\\nLet's see this simple implementation\\nof automatic differentiation using autograd package.\\nPyTorch autograd package can automatically differentiate\\nall tensor operations.\\nIt's super helpful for backpropagation computations\\nbetween our neural networks.\\n\\nPlus, we can easily access individual gradients\\nthrough a variables grad attribute.\\nLet's head on to Colab notebook.\\nWe'll define tensors and set the required gradient\\nequal to true to enable gradients to be computed.\\nWe can do that by assigning the keyword\\nfor requires grad as true.\\nNow we are computing the intermediate variable 'a'\\nthat is equal to x minus y,\\nand then computing to function f.\\n\\nNext, let's go ahead and call backward function,\\nand then the module computes\\nall the backpropagation gradients automatically.\\nAnd finally, let's print gradients\\nby accessing them using a variables grad attribute.\\n\"},{\"urn\":\"urn:li:learningContentAssessment:6605e382498e6fccaed114c3\",\"duration\":600,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"</> Code challenge: Split tensors to form new tensors\",\"externalAsset\":{\"coderPadCampaign\":\"urn:li:coderPadCampaign:1006784\"},\"coderPadCampaign\":null},{\"urn\":\"urn:li:learningContentVideo:3888259\",\"duration\":113,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Split tensors to form new tensors\",\"fileName\":\"2706322_en_US_04_06_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":145,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"In this video, learn one solution for splitting tensors to form new tensors.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4212748,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"(upbeat music)\\n- [Lecturer] For this challenge,\\nwe need to implement four functions\\nusing PyTorch building functions.\\nHere is how we solve this challenge.\\nOur task involves splitting two tensors, x and y,\\nusing PyTorch chunk and split functions.\\nWe use the chunk function when we want to divide the tensor\\ninto specified number of smaller tensors.\\nIt attempts to divide them as evenly as possible.\\n\\nFor the first implementation, I have called chunk function\\nwith parameter four and a dimension value equal to zero.\\nThis means we are dividing tensor x\\ninto four smaller tensors along the first dimension or rows.\\nYou can think of it as splitting the matrix\\ninto four smaller matrices,\\neach with roughly the same number of rows.\\nFor the second task, I've used chunk four,\\nwhich splits one dimensional tensor y\\ninto four smaller 1d tensors.\\n\\nSince y has 16 elements, each chunk will have four elements.\\nFor third task, we use split\\nsince we need more control over the sizes\\nof the resulting tensors.\\nIn this case, we specified the exact size of each chunk.\\nWe split x into two parts, the first with five rows\\nand second with three rows along first dimension.\\nLastly, we split y into three chunks\\nwith the specified lengths.\\n\\nThe first chunk has four elements\\nand the next two have six elements each.\\nFinally, if you go ahead and click on Test My Code,\\nyou can see that that is the right answer,\\nand we can scroll through\\nand see all of our modified tensors.\\n\"}],\"name\":\"4. Manipulate Tensors\",\"size\":37528332,\"urn\":\"urn:li:learningContentChapter:3885249\"},{\"duration\":1280,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3887270\",\"duration\":151,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Introduction to the DL training process\",\"fileName\":\"2706322_en_US_05_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"Append root with part 2\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":178,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"In this video, explore the basic pipeline used to train, test, and deploy your deep learning models.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4345518,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] There are different ways\\nto build your deep learning model.\\nYou can achieve it using supervised learning,\\nunsupervised learning, or semi-supervised learning.\\nEither way, you decide you're going to use the same pipeline\\nto train, test, and deploy your deep learning model.\\nThe process begins with the data preparation stage.\\nAs it's name suggests, we load the generic data,\\nwhich can be in many different formats,\\nsuch as text, images, videos, audio files, et cetera,\\nfrom an external source,\\nand we convert it to numeric values\\nsuitable for model training.\\n\\nThese numeric values are in form of tensors.\\nThen tensors need to be pre-processed during transforms,\\nand we group them with batches\\nthat can be passed into the model.\\nThe second stage is the model development stage\\nthat consists of three parts,\\ndesigning the model,\\ntraining the model using training data,\\nand testing its performance.\\nWe take the data set and split it into three data sets,\\ntraining data, validation data, and testing data.\\n\\nWhen we design the model,\\nwe use training data to train its parameters.\\nThe next step is the testing step\\nwhen we perform back propagation\\nand validate the model by passing invalidation data,\\nmeaning we measure model's performance against unseen data\\nand tune in hyperparameters.\\nBut what is the difference\\nbetween training data and validation data?\\nOne of the common problems in deep learning is overfitting.\\nBasically, model becomes really good\\nat recognizing what it has been trained on,\\nbut cannot recognize examples it hasn't seen.\\n\\nIn order to prevent that, we use the validation set.\\nValidation is a crucial step\\nin measuring your model's performance.\\nDuring this process,\\nyou can evaluate training data against validation data\\nthat has never been used.\\nIn the last step called model deployment,\\nyou can save the model to the file\\nor deploy the model to a product or service.\\nThe model is usually deployed to a production environment\\non a cloud server or to an edge device.\\n\\nNow that we are familiar with the deep learning process,\\nwe can expand on the data preparation step in the next video\\nand see how it's done on a simple network.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3889243\",\"duration\":97,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Data preparation\",\"fileName\":\"2706322_en_US_05_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":111,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn the steps of data preparations and why they are important.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2701886,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Data preparation is the first step\\nin developing a deep learning model.\\nThis step consists of loading the data, applying transforms,\\nand batching the data using PyTorch built-in capabilities.\\nWe won't carry how to generate a good dataset,\\nas we use an existing popular academic dataset\\ncalled CIFAR-10, developed by researchers from the Canadian\\nInstitute for Advanced Research, or short, CIFAR.\\n\\nCIFAR-10 dataset is a subset\\nof a much larger dataset with 80 million images in it.\\nIt consists of 60,000 small color photographs of objects\\nfrom 10 classes divided into 50,000 training images\\nand 10,000 test images.\\nHere is the table with class labels\\nand their associated integer values.\\nWe use a Python library called Torchvision,\\nas it has classes that support computer vision.\\n\\nThe Torchvision datasets module provides several\\nsubclasses to load image data from standard data sets,\\nsuch as our CIFAR-10 dataset.\\nTo create a training dataset using the existing CIFAR-10\\ndataset we'll import the torch and then import the CIFAR-10\\ndataset by typing from Torchvision dataset import CIFAR-10.\\nI'll show you how to load, summarize,\\nand display the training and testing dataset.\\n\\nSo let's dive into a mini deep learning project.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3888260\",\"duration\":157,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Data loading\",\"fileName\":\"2706322_en_US_05_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"Append with PU\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":false,\"rawDurationSeconds\":201,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Explore built-in classes and utilities for loading various types of data and learn how to apply them to pull the data from its source and create dataset objects.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4792123,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] We can load and convert different types\\nof data into format that are ready for training\\nand if it's often the most time consuming task.\\nLuckily, PyTorch has two important standard conventions\\nfor interacting with data called datasets and data loaders.\\nA dataset is a Python class that stores the samples\\nand their corresponding labels,\\nand the data loader feeds the data from the dataset\\ninto the network.\\nLet's take a look at our dataset\\ncalled the CIFAR-10 dataset.\\n\\nAs our first baby steps into deep learning,\\nwe'll run a deep neural network\\nthat was pre-trained on the object recognition task,\\nmeaning we'll be using it\\nto recognize the subject of an image.\\nWe have imported PyTorch as well as our dataset\\nin Matplotlib.\\nWe are going to use Matplotlib\\nto display some of the images.\\nHere is an example of how to load the training\\nand test data sets and print their shape.\\n\\nWhen we run the code, you can see\\nthat we have 50,000 images in the training set\\nand 10,000 images in the testing set,\\nand their dimensions are only 32 by 32 pixels,\\nso we have very small images.\\nNow, we also want to display the first few images,\\nso we'll do that by plotting the first 16 images.\\nHere we iterate over them and then call pyplot,\\nimshow and show functions.\\nFinally, let's go ahead and run our code.\\n\\nWe can see Matplotlib has created a plot\\nwith the first 16 images,\\nwhich are 32 by 32 pixel color images.\\nNumber three in our tensors output represents\\nthat the color image has three channels, RGB,\\nwhich represent red, green, and blue color.\\nOne more thing that we would like\\nis to examine the training data set.\\nWhen we print this shape,\\nwe see we have 50,000 images divided into 10 classes\\nand corresponding labels.\\n\\nThe label is an integer value\\nthat represents the class of the image.\\nFor example, airplane zero, automobile one, birds two, etc.\\nTo check the class labels,\\nwe literate over the pictures.\\nWhen we run the code,\\nwe see that on the first photo is a frog,\\non the second two is a truck, and on the fourth is a deer.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3886260\",\"duration\":160,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Data transforms\",\"fileName\":\"2706322_en_US_05_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":262,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Data often needs to be adjusted before it is passed into the model for training and testing. Learn different ways to adjust the data by applying transforms.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5242735,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Before passing the data into the model,\\nwe usually need to adjust it.\\nFor instance, data values need to be converted\\nfrom one type of object to a tensor.\\nAnother example of adjustment is data values\\nthat may be augmented to create a larger dataset.\\nWe can achieve this adjustment by applying transforms.\\nPyTorch has a torchvision library\\nthat supports common computer vision transformations\\nin the torchvision.transforms\\nand torchvision.transforms.v2 models.\\n\\nTransforms are common image transformations\\nthat we can use to transform or augment data\\nfor training or inference of different tasks.\\nFor example, image classification, detection, segmentation,\\nand video classification.\\nHere we have important transforms from torchvision.\\nWe'll then define a list of transforms\\nusing transforms.Compose function,\\nwhich composes several transforms together.\\nWe'll scale image data to 64 by 64 resolution,\\nthen turn it into a tensor and normalize the tensor\\naround the specific set of mean\\nand standard deviation points.\\n\\nYou may wonder where do these values\\nfor mean and standard deviation come from?\\nYou can calculate these statistics yourself\\nby iterating through the training set\\nand computing the mean and standard deviation\\nof each channel across all images.\\nHowever, since these values are standard for CIFAR-10,\\nthey're often provided in tutorials, documentation,\\nor widely used libraries like torchvision\\nto simplify the pre-processing step for users.\\nWithout normalization, these values would typically range\\nfrom zero to 255 for each channel,\\nrepresenting the intensity of RGB component of each pixel.\\n\\nAs the input passes through the layers of the network,\\nthere is a lot of multiplication,\\nso maintaining values between zero and one\\nprevents these values from increasing\\nduring the testing phase,\\nwhich is called the exploding gradient problem.\\nFinally, we use transforms\\nto create a training data dataset.\\nTo take a look at the transforms,\\nwe can simply print the training dataset\\nfor the first image.\\nOne more thing to add\\nis that we can also define a different set of transforms\\nfor testing dataset and apply them to our test data.\\n\\nLet's do that.\\nFor example, we may not want to resize;\\nwe want to convert the image to tensors and normalize them,\\nas you can see here in our code.\\nLet's go ahead and display it.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3890256\",\"duration\":175,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Data batching\",\"fileName\":\"2706322_en_US_05_05_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"Append with PU\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":true,\"rawDurationSeconds\":260,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"In the process of model training data is passed in small batches at each iteration. That way training is more efficient training and accelerated.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5953046,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] A data loader feeds the data\\nfrom the dataset into the neural network.\\nAt the core of PyTorch data loading utility\\nis a torch.utils.data.DataLoader class.\\nIt represents a Python iterable over a dataset,\\nwith support for map-style and iterable-style datasets,\\ncustomizing data loading order, automatic batching,\\nand single and multi-process data loading.\\nYou can find more about it\\non the PyTorch documentation page here.\\n\\nThe neural network trains best with batches of data,\\nmeaning rather than using the complete dataset\\nin one training pass,\\nwe've used mini batches,\\nusually 64 or 128 samples.\\n(upbeat music)\\n(buzzer buzzing)\\nThat's right.\\nSmaller batches require less memory than the entire dataset,\\nand it results in more efficient and accelerated training.\\nDataLoader has, by default, a batch_size of one,\\nso we will want to change that.\\n\\nSo DataLoader has a parameter called batch_size\\nwhich represents a number of images\\nthat go through the network before we train and update it.\\nNow, let's head on to the Colab notebook.\\nWe are using the same example and introducing DataLoader.\\nOne more thing we have to do\\nis import DataLoader from torch.utils.data.\\nAs we can see in our code, we have two dataset.\\nThe training set,\\nwhich is used in the training pass to update the model,\\nand the testing set,\\nwhich is the final dataset that we use\\nto evaluate the model's performance.\\n\\nTo build our data loaders,\\nwe'll set the batch_size to 16\\nand create training_data_loader and test_data_loader\\nby calling DataLoader and passing two parameters,\\ntraining_data or test_data and batch_size.\\nThe most commonly used parameters\\nare the dataset, batch_size, shuffle, sample,\\nand num_workers parameters.\\nNow in our example,\\nwe could also pass in the third parameter called shuffle\\nand set it to true if we want to shuffle our dataset,\\nso the data loader returns a random sample of data.\\n\\nLet's go ahead and do that for the training_data dataset.\\nAnd for the test data_dataset,\\nwe'll set it to false\\nas we want to have repeatable test results.\\nNow in our example,\\nwe could also pass in the third parameter called shuffle\\nand set it to true if we want to shuffle our dataset\\nso the data loader returns a random sample of data.\\nLet's go ahead and do that for the training_data dataset\\nand for the test_data dataset, we'll set it to false\\nas we want to have repeatable test results.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3884260\",\"duration\":286,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Model development and training\",\"fileName\":\"2706322_en_US_05_06_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"Append with PU\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":false,\"rawDurationSeconds\":382,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn different steps of model development and importance of the each step. Explore fundamental processes used for training models.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9549213,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] After taking care of preparing data sets,\\nwe can finally explore model development.\\nIt consists of a few steps,\\nmodel design, training, validation, and testing.\\nIn the model design step,\\nwe can design one or more model architectures\\nand initialize weights and biases.\\nUsually we take an existing design and modify it.\\nWe won't be covering this step in more detail\\nas we are taking care to understand the basics.\\nIn model training, we feed the training data into the model,\\ncalculate the error, and then adjust the parameters\\nto improve the model's performance.\\n\\nAfter the training, in the validation step,\\nwe measure the model's performance\\nagainst the data that wasn't used in training.\\nLet's explore how to build our first neural network.\\nWe have already imported libraries and data set.\\nHere we define the neural network and we call it net.\\nThen we fill out the init and forward functions.\\nIn init, we are adding layers to our network.\\nYou can think of them as filters and lenses\\nthat help our model to focus\\non important parts of the image.\\n\\nFor example, the first layer called self.conv1\\nis the first convolutional layer.\\nIt takes three input channels for free channel color images,\\noutputs six channels and uses five by five kernel.\\nSelf pool is the max pooling layer\\nwith two by two window and a stride of two.\\nIt is used to reduce the spatial dimensions of the output\\nfrom the convolutional layers.\\nSelf.conv2 is the second convolutional layer.\\n\\nIt takes the six output channels from conv1 as input\\nand output 16 channels.\\nSelf.fc1 is the first fully connected layer.\\nThe input size is 16 by 5 by 5,\\nwhich is derived from the output dimensions\\nof the last convolutional layer.\\nSelf.fc2, as the name suggests,\\nis the second fully connected layer\\nand self.fc3 is the final fully connected layer\\nthat outputs 10 channels,\\nwhich correspond to the 10 classes in our cipher 10 dataset.\\n\\nThe forward function defines\\nhow data flows through the network\\nin both training and making predictions.\\nIt takes two parameters, self and x.\\nX is passed through these layers sequentially.\\nHere we have a view function which reshapes the tensor\\nbefore feeding it to fully connected layers,\\nand F.relu,\\nwhich for example, when applied to the output of conv1\\nresults in the tensor where all negative values\\nare set to zero and positive values are left unchanged.\\n\\nNext, we instantiate the model\\nby setting up the necessary tools\\nfor training the network, loss function and optimizer,\\nas you can see in the code.\\nThen we load and transform the data.\\nAnd finally, in the training step,\\nour model learns by adjusting its weights\\nbased on the computed loss and gradients.\\nIt involves iterating over a data set multiple times,\\nwhich we call epochs.\\nIn our case, we are looping 10 times.\\nNow we initialize a variable\\nto accumulate the loss over each batch.\\n\\nThis inner loop iterates over the training data set\\nand the train loader provides batches of data,\\nmeaning images and labels.\\nThen we unpack the data into images\\nand their corresponding labels.\\nHere we use the optimizer to zero all the gradients\\nfrom weights and biases.\\nThis prevents the accumulation of gradients\\nfrom multiple passes.\\nAfter we pass the input data through the network\\nto get outputs, we compute the loss\\nby comparing the model's outputs with the actual labels.\\n\\nBy calling loss.backward function,\\nwe perform a backward pass\\nto compute the gradient of the loss\\nwith respect to the network parameters.\\nFinally, we update the weights\\nbased on the computed gradients\\nand accumulate the loss over the batches for reporting.\\nIn the if statement, we use print inside it\\nto log the average loss every 2000 mini batches\\nso we can monitor the training.\\nI have already executed this upfront\\nas usually it takes around 10 minutes\\nfor this code to finish execution.\\n\\nOnce training is finished,\\nwe can see finished training message,\\nwhich we will use to indicate\\nthe end of the training process.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3884259\",\"duration\":250,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Validation and testing\",\"fileName\":\"2706322_en_US_05_07_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"Append with PU\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":true,\"graphicsIncluded\":false,\"rawDurationSeconds\":295,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Validation and testing are important parts of model development as they take care that overfitting does not occur and that the model performs well against unseen data. Learn the key steps of each of them.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10043035,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Validation and testing are important parts\\nof model development as they take care\\nthat overfitting does not occur\\nand that the model performs well against unseen data.\\nLearn the key steps of each of them.\\nIn the validation step, we use a separate set of data,\\nwhich we haven't used previously in training\\nand call this set validation set.\\nThe main goal is tuning hip parameters such as learning rate\\nor number of epochs,\\nso we can provide an early indication\\nof how our model is performing.\\n\\nWe have already imported libraries and dataset.\\nNext, we define a neural network with init\\nand forward function.\\nAfter that, we instantiate the model\\nand define the loss function and optimizer.\\nTo load and transform the data,\\nwe will create transformations for the training data.\\nWe'll create validation set from our training data\\nby using torch.utils.data.randomsplit,\\nwhich splits the training data into the training set\\nof 40,000 images and validation set of 10,000 images.\\n\\nThen we set up loaders for the training set\\nand validation set with 16 images per batch\\nand enable shuffling.\\nA data loader for the test set is created\\nwith a batch size of four,\\nand we don't use shuffling.\\nAt the end of each epoch,\\nwe are going to evaluate our model on the validation set.\\nWe will usually check the loss and accuracy.\\nThe testing step is crucial\\nfor evaluating the model's performance on unseen data.\\nThe test set is a separate data set\\nthat the model has never seen during training.\\n\\nIt provides us with a final evaluation\\nof the model's performance.\\nWe are looping 10 times to train the model\\nas we have 10 epochs.\\nWe switch the model net to training mode.\\nThen we initialize the running loss to zero.\\nIn this inner loop,\\nwe iterate over our training data loader.\\nTrain loader batches the training data and enumerate,\\nwill give us the index and the data for each iteration.\\nThe data table is unpacked into inputs\\nthat represent features and labels.\\n\\nThen we zero out any gradients from the previous batch\\nbefore calculating the gradients.\\nThe input passes through the network\\nand it performs forward pass and returns the outputs.\\nLastly, we calculate the loss\\nusing the loss function criterion.\\nWe compare the network outputs with labels\\nand compute the gradient of the loss.\\nThen the optimizer updates the models parameters,\\nand we add the loss for this batch to running loss\\nso we can keep track of the total loss of epoch.\\n\\nAfter each training epoch, the model is switched\\nto evaluation mode using net.eval function,\\nwhich deactivates dropout\\nand normalizes batch normalization layers\\nfor consistent behavior during inference.\\nThen we iterate over the validation data set,\\nand for each batch of data, it computes the model's output\\nwithout updating the model's weights\\nas gradients are not needed for validation.\\n\\nWe calculate accuracy and loss on this validation data,\\nproviding insight into how well the model performs\\non data it hasn't been trained on.\\nAfter looping through all test data,\\nwe calculate the overall accuracy by dividing the number\\nof correct predictions by the total number\\nof samples in the test set.\\nAt the end of the epoch, we print the average training loss,\\nthe average validation loss,\\nand the validation accuracy percentage.\\n\\nThese averages are calculated by dividing the total loss\\nby the number of batches in the loader.\\nFor example, for average training loss,\\nwe divide the training loss by the number\\nof batches in the train loader.\\n\"}],\"name\":\"5. Developing a Deep Learning Model\",\"size\":42732224,\"urn\":\"urn:li:learningContentChapter:3890263\"},{\"duration\":48,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3890257\",\"duration\":48,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Next steps\",\"fileName\":\"2706322_en_US_06_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"editingNotes\":\"Twitter handle @Tsemenski\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":true,\"rawDurationSeconds\":50,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video explains where to go from here.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1493818,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Terezija] Congratulations on completing this course.\\nNow that you have seen the basics of using PyTorch,\\nyou can try applying it to your own projects.\\nI encourage you to play around with the different datasets\\nthat you can find on Kaggle.\\nYou can look for more PyTorch courses\\ncoming from me in the future.\\nYou can also search our library\\nfor more deep learning courses to continue your journey.\\nI want to wrap up by saying thank you.\\nYou have devoted time to learning this material with me,\\nand I want you to know that I don't take that for granted.\\n\\nI really do appreciate your engagement\\nas well as your feedback on this course.\\nIf you have any questions, please feel free\\nto get in touch on LinkedIn and on Twitter.\\nIf you enjoyed this course, I'd love to know.\\n\"}],\"name\":\"Conclusion\",\"size\":1475670,\"urn\":\"urn:li:learningContentChapter:3885250\"}],\"size\":154611905,\"duration\":4906,\"zeroBased\":false},{\"course_title\":\"Hands-On PyTorch Machine Learning\",\"course_admin_id\":2884016,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":2884016,\"Project ID\":null,\"Course Name\":\"Hands-On PyTorch Machine Learning\",\"Course Name EN\":\"Hands-On PyTorch Machine Learning\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"Many of the world\u00e2\u20ac\u2122s most exciting and innovative new tech projects leverage the power of machine learning. But if you want to set yourself apart as a data scientist or machine learning engineer, you need to stay up to date with the current tools and best practices for creating effective, predictable models.&lt;br&gt;&lt;br&gt;In this course, instructor Helen Sun shows you how to get up and running with PyTorch, the open-source machine learning framework known for its simplicity, performance, and APIs. Explore the basic concepts of PyTorch, including tensors, operators, and conversion to and from NumPy, as well as how to utilize autograd, which tracks the history of every computation recorded by the framework. By the end of this course, you\u00e2\u20ac\u2122ll also be equipped with a new set of skills to get the most out of Torchvision, Torchaudio, and Torchtext.\",\"Course Short Description\":\"Discover the fundamentals of creating machine learning models with PyTorch, the open-source machine learning framework.\",\"Content Type\":\"TOOLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":1992748775,\"Instructor Name\":\"Helen Sun\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"Technology Strategist and Thought Leader\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2022-12-13T00:00:00\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"Yes\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/hands-on-pytorch-machine-learning\",\"Series\":\"One-Off\",\"Limited Series\":null,\"Manager Level\":\"Individual Contributor\",\"LI Level\":\"Intermediate\",\"LI Level EN\":\"Intermediate\",\"Sensitivity\":null,\"Internal Library\":\"Technology\",\"Internal Subject\":\"Artificial Intelligence for Technology\",\"Primary Software\":\"PyTorch\",\"Media Type\":\"Video\",\"Has CEU\":\"No\",\"Has Exercise Files\":\"Yes\",\"Visible Duration\":3412.0,\"Visible Video Count\":17.0,\"Contract Type\":\"PERPETUAL\"},\"sections\":[{\"duration\":51,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2615032\",\"duration\":51,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Explore the capabilities of PyTorch\",\"fileName\":\"2884016_en_US_00_01_WX30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1591138,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Dr. Sun] PyTorch is one  \\n of the most widely adapted ML frameworks.  \\n If you know TansorFlow, learning PyTorch is essential  \\n to establish a foundation in AI and ML.  \\n And if you are just starting,  \\n PyTorch is an excellent place to start learning.  \\n Working the field of AI and ML,  \\n understanding the basics of PyTorch is imperative.  \\n In this course, I'll teach you the basics  \\n of computer vision, natural language processing,  \\n and audio processing through some hands-on experiences.  \\n Hello, I'm Dr. Helen Sun  \\n and I'm a senior engineering leader at Meta,  \\n working in the AI and ML space.  \\n Join me in this course to learn about the PyTorch platform  \\n that is used worldwide  \\n to support the work of AI research scientists  \\n and ML engineers.  \\n \\n\\n\"}],\"name\":\"Introduction\",\"size\":1591138,\"urn\":\"urn:li:learningContentChapter:2621017\"},{\"duration\":879,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2622022\",\"duration\":253,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"PyTorch overview\",\"fileName\":\"2884016_en_US_01_01_XR30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"In this video, learn about PyTorch\u2019s tensor library and neural networks at a high level. This is a context-setting video and an overview of key concepts for the remainder of the videos.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7767736,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] PyTorch is one of the most popular  \\n deep learning frameworks,  \\n and it continues to gain adoption  \\n in both research communities and enterprises.  \\n It is an open source machine learning framework  \\n developed and maintained by Meta.  \\n The key benefits of PyTorch include  \\n quick iteration for research,  \\n seamless eager graph mode transition with TorchScript,  \\n and production ready with TorchServe.  \\n It has a backend called Torch.Distributed,  \\n which enables scalable distributed training  \\n and optimization.  \\n PyTorch also has a rich ecosystem of tools and libraries  \\n that extends development in computer vision,  \\n natural language processing, and more.  \\n Some featured projects in this ecosystem include Captum  \\n for model interpretability,  \\n geometric deep learning for irregular input data,  \\n such as graphs and Point Cloud,  \\n and Skorch that enables psychic learn compatibility.  \\n In this course, I'll be using PyTorch 1.10,  \\n and cover some of its top features,  \\n including tensors, autograd, APIs, and libraries.  \\n A PyTorch tensor is a multi-dimensional container of data.  \\n It is similar to a NumPy array.  \\n Torch defines 10 tensor types with CPU and GPU variants,  \\n including boolean, 8, 16, 32, 64 bit integer,  \\n 16, 32 and 64 bit floating point,  \\n 32, 64, and 128 bit complex.  \\n There are many ways to create a tensor,  \\n such as with pre-existing data.  \\n There are also many tensor operations in PyTorch,  \\n but they can be grouped into two categories,  \\n including slice and math.  \\n Autograd is what earns PyTorch it's popularity  \\n for fast and flexible iteration.  \\n PyTorch traces the computation dynamically at runtime  \\n to get correct gradients to drive learning.  \\n The key for model training is to minimize the loss  \\n through adjusting the model's learning weights.  \\n The gradients over the learning weights tells us  \\n what direction to change each weight  \\n to reduce the loss function.  \\n With deep learning, the number of derivatives  \\n goes up exponentially.  \\n Autograd tracks the history of every computation,  \\n and as a result, greatly speeds  \\n the local derivative computation.  \\n The primary API to PyTorch is Python.  \\n These APIs allow you to interact with PyTorch  \\n through tensors, views, CUDA, autograd,  \\n quantization, and storage.  \\n PyTorch also provides you with a C++ interface  \\n with access to PyTorch functionalities,  \\n including tensor and autograd, serializing PyTorch models,  \\n and building C++ extensions through TorchScript.  \\n The C++ APIs can also be used  \\n to write compact, performance-sensitive code  \\n with deep learning capabilities  \\n to perform ML inference on mobile platforms.  \\n There are five main PyTorch libraries.  \\n The first is Torchaudio for audio signal processing.  \\n Next, we have Torchtext containing data processing utilities  \\n and data sets for natural language processing.  \\n The third library, Torchvision  \\n with computer vision data sets, model architecture  \\n and common image transformation.  \\n Fourth is Torchserve, a highly performant and flexible  \\n serving tool for PyTorch eager modes and models.  \\n And finally, Torch_xla that runs PyTorch  \\n on xla devices such as TPU.  \\n Now that you have a high level overview,  \\n let's dig deep into the top features of PyTorch.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2617029\",\"duration\":230,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"PyTorch environment setup\",\"fileName\":\"2884016_en_US_01_02_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to install PyTorch and configure the environment. Get the environment set up so that you can start to work on the use cases.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9006947,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] To set up the PyTorch environment,  \\n we first download the PyTorch library  \\n from the PyTorch website.  \\n Click on the Install button here.  \\n And use the default tab here, Start Locally.  \\n Scroll down to go to the selection grid.  \\n You first select the build.  \\n You'll then choose the OS.  \\n The options are Mac, Windows, and Linux.  \\n And we'll choose Mac.  \\n For the package manager, we'll choose Pip.  \\n You can also select Conda, LibTorch,  \\n or build it using the source code from GitHub.  \\n There are two language options,  \\n Python and C++/Java.  \\n We'll choose Python.  \\n The compute platform is default here  \\n because we're using the Mac OS.  \\n Once you make all of the selections,  \\n the site will give you a command to install PyTorch:  \\n pip3 install torch torchvision torchaudio.  \\n And you just run this command to install PyTorch  \\n if you prefer to use the most recent stable version.  \\n The previous versions of PyTorch  \\n are available here on this website.  \\n Just click on this Previous PyTorch Versions tab.  \\n I'll be using the 1.10.1 for this course.  \\n And you copy and paste this command and run it in iTerm.  \\n So here is the command,  \\n I'll run it here,  \\n but I also added an optional parameter  \\n to suppress warnings here.  \\n So it says, \\\"no warning script location.\\\"  \\n If you receive a message saying \\\"Command Not Found,\\\"  \\n this is probably because you don't have  \\n Pip3 environment set up properly.  \\n You need to use a package manager on Mac OS called Homebrew  \\n to install Pip3.  \\n So here's the command.  \\n Now your first command to run PyTorch installation  \\n can be resumed right here.  \\n With this installation,  \\n it includes numpy, pillow, torch,  \\n torchaudio, torchvision, and typing-extensions.  \\n We'll use these packages in our later modules.  \\n Once you see your screen saying,  \\n \\\"Successfully installed those packages\\\"  \\n or \\\"These requirements already satisfied,\\\"  \\n then you're ready to go.  \\n A few other module installations  \\n that are useful for this course include:  \\n Matplotlib and Jupyter Notebook.  \\n To install Matplotlib,  \\n I'll use the command  \\n pip3  \\n install  \\n matplotlib.  \\n This command will install Matplotlib  \\n along with a number of packages, including:  \\n Pyparsing,  \\n python-dateutil,  \\n Packaging,  \\n Kiwisolver,  \\n Fonttools,  \\n and cycler.  \\n Once it is all and completed,  \\n you'll receive the following message here.  \\n To install the Jupyter Notebook,  \\n you can either use Anaconda or Pip3.  \\n Similar to installing PyTorch,  \\n we'll use Pip3 as follows.  \\n To verify the installation,  \\n try the following command:  \\n python3 -m notebook.  \\n You should see the console launching  \\n the Notebook environment in the browser here.  \\n There will be additional environmental setup  \\n in later modules,  \\n but this concludes the general setup.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2621016\",\"duration\":143,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"PyTorch use case description\",\"fileName\":\"2884016_en_US_01_03_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn about the use case, objectives, and problem space. This is an important context for model development and learning.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4163598,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] The use case I'll be using  \\n throughout this course is based on a project called Piraeus.  \\n The overall objective of Project Piraeus  \\n is to democratize knowledge.  \\n Piraeus is a portal that brings together learners and tutors  \\n in a digital portal.  \\n It then leverages machine learning and AI  \\n to find the best tutors for every learner  \\n and to help tutors and learners  \\n to devise a customized learning plan.  \\n Many students struggle in rigid linear learning systems.  \\n Education and learning is personal.  \\n Unfortunately, one-on-one learning, private tutoring,  \\n and custom-designed learning paths are just too expensive  \\n for many students and communities to access.  \\n AI may be able to help.  \\n Artificial intelligence, AI, can play a key role  \\n to achieve this objective and vision.  \\n AI provides the capability to mimic human judgment.  \\n In this case, it'll mimic the judgment  \\n of a tutor or a teacher with dedicated attention  \\n to a student's unique learning needs.  \\n The focus of our use case is to develop AI models  \\n to better match tutors with learners  \\n based on learning, characteristics, and learning objectives.  \\n We look to generate a guided learning path,  \\n select learning material,  \\n weave in checkpoints and assessment  \\n through feedback along the way,  \\n and continue to refine and adapt the next set of milestones.  \\n In this course, I'll demonstrate how to develop  \\n and train the machine-learning models,  \\n using as inputs the characteristics  \\n of the learners and tutors,  \\n the performance of the learner,  \\n along with the metrics associated with the tutoring sessions  \\n including number of sessions, duration of sessions,  \\n time between sessions.  \\n The inputs to the models  \\n and predictive methods must be consistently monitored  \\n to determine the most critical inputs  \\n that produce the best possible outcome  \\n for both learners and tutors.  \\n This type of rapid iteration of exploration,  \\n experimentation, and productization  \\n makes PyTorch the ideal choice for the AI and ML framework.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2615033\",\"duration\":253,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"PyTorch data exploration\",\"fileName\":\"2884016_en_US_01_04_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn about the dataset for this use case. Understanding the dimensionality, categories, and distributions of the data is fundamental to developing ML algorithms.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8855054,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - PyTorch can be used to explore a dataset  \\n for model development.  \\n PyTorch provides two data primitives  \\n DataLoader and Dataset.  \\n The Dataset class stores the samples  \\n and the corresponding annotation labels.  \\n The DataLoader class wraps in iterable around  \\n the Dataset class to enable easy access to the samples.  \\n These two classes allow you to use preloaded data sets  \\n and upload your own data.  \\n PyTorch comes with a set of domain libraries  \\n that provide many preloaded data sets.  \\n They are subclasses of torch utils: data, dataset.  \\n These libraries and subclasses implement  \\n specific functions to the particular data.  \\n One great example is Fashion MNIST  \\n which we will explore later.  \\n These preloaded data sets and functions  \\n enable ML engineers to prototype and benchmark their models.  \\n You can find these data sets and functions  \\n on the PyTorch website  \\n with the links included in this slide.  \\n For example, for image dataset  \\n go to pytorch.org/vision/stable/datasets.html.  \\n For text datasets  \\n go to pytorch.org/text/stable/datasets.html.  \\n And lastly, for audio data sets  \\n go to pytorch.org/audio/stable/datasets.html.  \\n Now let's take a look at the Fashion MNIST dataset.  \\n I'll first import the needed libraries here.  \\n I'll then create two data sets  \\n one for training  \\n and one for testing.  \\n The only difference is to set the parameter of train to true  \\n for training data set  \\n and false for testing data set.  \\n Next, I'll create a validation sample  \\n from the training data set.  \\n Next, I'll create three DataLoaders  \\n one for training, one for validation, and one for testing.  \\n Next, I'll create a data iterator  \\n to populate the image and label tensors.  \\n Lastly, I'll use the mat plot lib to plot the data.  \\n Next, let's upload and look at our own dataset.  \\n We'll go through four steps to load our data set.  \\n Step one, import all necessary libraries  \\n for loading our data.  \\n We will be uploading a CSV file that contains tutor's data.  \\n For that, we need to import the following libraries.  \\n Step two, find the file path.  \\n For this exercise  \\n I'll just upload our CSV file from a local drive.  \\n And here is the file path, here in the documents folder.  \\n And we'll put this path into a variable called data path.  \\n Step three, loading the data.  \\n We'll load the data using the pandas library  \\n we imported in step one.  \\n If you don't have pandas installed  \\n just run the following command: pip3 install pandas.  \\n Here we created a pandas dataframe called df  \\n to store the dataset.  \\n Now let's visualize the data  \\n using the pandas function display.  \\n And this is our dataset.  \\n Step four, convert a pandas dataframe into a PyTorch tensor.  \\n In order to use the data set and PyTorch for model training  \\n we'll need to convert it into a PyTorch tensor.  \\n Here's the code to do that.  \\n And we also printed out the tensor in this format.  \\n Now this wraps up our overview chapter.  \\n In the next chapters we'll dig into the details  \\n of the PyTorch libraries.  \\n \\n\\n\"}],\"name\":\"1. Preparation\",\"size\":29793335,\"urn\":\"urn:li:learningContentChapter:2615034\"},{\"duration\":891,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2622023\",\"duration\":213,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Understand PyTorch tensors\",\"fileName\":\"2884016_en_US_02_01_XR30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"In this video, learn about the basic concepts of PyTorch tensors. Explore basic constructs that you are using for the rest of the use case implementation in PyTorch.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6395064,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Tensors are the building blocks  \\n of a neural network.  \\n A PyTorch tensor is the central data abstraction  \\n as a generalized form of arrays in n dimensions  \\n to run arbitrary computations.  \\n A tensor can be of any dimension.  \\n For example, zero dimensional tensors  \\n are a scale numbers like 0, 10, 100, et cetera.  \\n One dimensional tensors are array of numbers  \\n like an array of 9, 8, 7,  \\n or an array of 50, 30 10, et cetera.  \\n Tensors can also be two-dimensional.  \\n They are matrix of numbers like in 2x3 matrix  \\n with a two element array of an array.  \\n So for example, an array of 1, 2, 3 and a 7, 5, 3.  \\n So now let's create some tensors  \\n by importing torch and using the torch.Tensor methods.  \\n Here's our notebook, and here we are.  \\n We're creating some torch.Tensors,  \\n and here is the output of those tensors.  \\n The simplest way to set the underlying data type of a tensor  \\n is with an optional argument at creation time.  \\n Here is an example.  \\n We're setting the torch data type,  \\n the tensor data type, to be int16.  \\n There are 10 data types available.  \\n I have listed here boolean int8, uint8, int16, int32,  \\n int64, half, float, double, or bfloat.  \\n While training the model,  \\n you'll deal with higher dimensions.  \\n The neural network only accepts the dimension  \\n which is defined at the input layer  \\n while architecting the model.  \\n The dimension basically tells whether the tensor  \\n is zero-dimension, or one-dimension, or two-dimension,  \\n or even higher than that.  \\n Dimension of the tensor is also called  \\n the rank of the tensor.  \\n To get the size, you can use tensor.size method,  \\n or tensor.shape property,  \\n and to get the dimension of the tensor,  \\n use tensor.ndimension method, or tensor.ndim property.  \\n Let's take a look.  \\n There you have it.  \\n These are the examples.  \\n Sometimes working with a neural network,  \\n you need to change the dimension of the tensor.  \\n This can be done by using  \\n the tensor.view nrows, ncols method of the tensor.  \\n PyTorch tensor also provides flexibilities,  \\n such as in-place alterations, tensor copying,  \\n and changing the shape of the tensor,  \\n such as altering the dimensions of the tensor.  \\n One of the major advantages of PyTorch  \\n is its robust acceleration on CUDA-compatible NIVIDIA GPUs.  \\n CUDA stands for compute-unified device architecture,  \\n which is NIVIDIA's platform for parallel computing.  \\n By default, new tensors are created on the CPU,  \\n so we have to specify when we want to create our tensor  \\n on the GPU with the optional device argument.  \\n If you have an existing tensor living on one device,  \\n you can move it to another with a to method.  \\n It is important to know that,  \\n in order to do computation involving two or more tensors,  \\n all of the tensors must be on the same device.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2616025\",\"duration\":173,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Understand PyTorch basic operations\",\"fileName\":\"2884016_en_US_02_02_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn about the basic concepts of PyTorch operators. Explore basic constructs that you are using for the rest of the use case implementation in PyTorch.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5702499,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] PyTorch Tensors allow you to apply  \\n arithmetics on your tensors.  \\n PyTorch Tensors have over 300 operations  \\n that can be performed on them.  \\n You can apply these operations on Scala  \\n and multiple dimensions of tensors.  \\n The very basic operations on tensors are additions,  \\n subtractions, multiplications, and divisions.  \\n Here's an example for addition and subtraction.  \\n So we have two tensors  \\n and we are performing some additions and subtractions here,  \\n and you'll get those output.  \\n The major categories of operations  \\n include common functions such as abs, ceil, floor, clamp,  \\n trigonometric functions and their inverses  \\n such as pi, sin, asin, bitwise operations, comparisons,  \\n reductions such as max, min, standard, prod,  \\n unique, vector/matrices, and linear algebra operations.  \\n Now let's go over some more examples.  \\n First, here are some common functions  \\n like abs, ceil, floor, and clamp, and these are the output.  \\n Next, let's try a reduction function  \\n using the mean operator,  \\n and there you have the output.  \\n Finding maximum or minimum values in the Tensor  \\n can also be done by using tensor.max  \\n and tensor.min respectively.  \\n The expected output is right there.  \\n Now let's take a look at the trigonometric functions  \\n and their inverses.  \\n Supposed you have a tensor containing various values of pi  \\n and you want to apply the sine and cosine function on it.  \\n You can use the torch.sin tensor  \\n and torch.cos tensor as follows.  \\n And we import NumPy here as well.  \\n You can expect the output here.  \\n Sometimes you have to get an evenly spaced  \\n list of numbers between a range.  \\n You can use torch.linspace, start, end, and step to do that.  \\n Let's make it more interactive  \\n by plotting the sin minus pi to sin pi  \\n and cos minus pi to cos pi,  \\n making the dataset first here.  \\n Here we have the dataset.  \\n And last but not least,  \\n let's use Matplotlib to create the graph.  \\n Here you see the plotted output.  \\n The basic PyTorch operators offer a lot of functionalities  \\n and here is an example of that  \\n and hope you get the opportunity of exploring more.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2620024\",\"duration\":213,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Understand PyTorch NumPy Bridge\",\"fileName\":\"2884016_en_US_02_03_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to convert NumPy arrays to PyTorch tensors and vice versa. Explore the basic constructs that you are using for the rest of the use case implementation in PyTorch.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6786744,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Broadcasting is a way to perform an operation  \\n between tensors that have similarities in their shapes.  \\n This is an important operation in deep learning.  \\n The common example  \\n is multiplying a tensor of learning weights  \\n by a batch of input tensors,  \\n applying the operation to each instance  \\n in the batch separately  \\n and running a tester of identical shape.  \\n Here's an example with two by four  \\n multiplying one by four returns a tester of shape two,  \\n with dimension of one, with values of two and 16.  \\n If you're familiar with broadcasting semantics  \\n and NumPy ndarrays,  \\n you'll find the same rules apply with PyTorch.  \\n The exception to the same shape rule  \\n is tensor broadcasting.  \\n The rules for broadcastings are,  \\n one, each tensors must have at least one dimension,  \\n no empty tensors.  \\n Comparing the dimension sizes of two tensors,  \\n going from last to first, each dimension must be equal  \\n or one of the dimensions must be of size one  \\n or the dimension does not exist in one of the tensors.  \\n Tensors of identical shape,  \\n of course, are trivially broadcastable,  \\n as you saw earlier.  \\n Here are some examples of situations  \\n that honor the rules and allow broadcasting.  \\n We first have tensor A  \\n and tensor B, here, has the third and second dimensions  \\n identical to tensor A, with dimension one absent.  \\n Tensor C has third dimension equals to one,  \\n second dimension identical to A  \\n and first dimension empty.  \\n Tensor D has third dimension identical to A,  \\n second dimension equals to one  \\n and first dimension empty, and it is broadcastable as well.  \\n PyTorch's broadcast semantics are compatible with NumPy's,  \\n but the connection between PyTorch and NumPy  \\n goes even deeper than that.  \\n If you have existing ML or scientific code  \\n with data stored in NumPy ndarrays,  \\n you may wish to express the same data as PyTorch tensors.  \\n Whether to take advantage of PyTorch's GPU acceleration  \\n or its efficient abstractions for building ML models.  \\n It's easy to switch between ndarrays and PyTorch tensors.  \\n Let's take a look at some examples.  \\n Here's a conversion and here is the expected output.  \\n PyTorch creates a tensor of the same shape  \\n and containing the same data as NumPy array, going as far as  \\n to keep NumPy's default 64 bit float data type.  \\n The conversion can just as easily go the other way, here,  \\n as the example of a version.  \\n And the expected outcomes are here.  \\n It's also important to know that these converted objects  \\n are using the same underlying memory  \\n as their source objects,  \\n meaning that changes to one are reflected in the other.  \\n And here's an example,  \\n and the expected output is shown here.  \\n And this concludes the Intro to PyTorch NumPy Bridge.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2619025\",\"duration\":170,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Understand PyTorch autograd\",\"fileName\":\"2884016_en_US_02_04_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to use autograd to automate the computation of backward passes in neural networks. Explore the basic component within PyTorch and the important-to-implement neural networks for the rest of the use cases.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5241187,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Narrator] Automatic differentiation is a building block  \\n of every deep learning library out there.  \\n PyTorch's automatic differentiation engine called Autograd  \\n is a tool to understand how automatic differentiation works.  \\n Modern neural network architectures  \\n can have millions of learnable parameters.  \\n From a computational point of view,  \\n training a neural network consists of two phases.  \\n The forward pass computes the value of the loss function.  \\n In forward prop, the neural network makes its best guess  \\n about the correct output.  \\n It runs the input data through each of its functions  \\n to make this guess.  \\n The backward pass computes the gradients  \\n of the learnable parameters.  \\n In backdrop, the neural network adjusts its parameters  \\n proportionate to the error and its guesses.  \\n It does this through three steps.  \\n First, it traverses backwards from the output,  \\n then it collects the derivatives of the error  \\n with respect to the parameters of the functions,  \\n aka gradients.  \\n And lastly, it optimizes the parameters  \\n using gradient dissent.  \\n The forward pass is pretty straightforward.  \\n The output of one layer  \\n is the input to the next and so forth.  \\n Backward pass is a bit more complicated  \\n since it requires us to use the chain rule  \\n to compute the gradients of the weights  \\n to the loss function.  \\n It is impractical to calculate gradients  \\n of such large composite functions  \\n by solving mathematical equations,  \\n especially because these curves exist  \\n in a large number of dimensions  \\n and are impossible to fathom.  \\n This is where PyTorch's Autograd comes in.  \\n It abstracts complicated mathematics  \\n and helps us magically calculate gradients  \\n of high-dimensional curves with only a few lines of code.  \\n Let's run through an example.  \\n First, we need to import the libraries  \\n using Torch and Torch Autograd.  \\n Next, we'll use the Autograd variable function  \\n to create a variable.  \\n Let's now perform an operation of the variable.  \\n Y was created as a result of an operation,  \\n so it has a grad function.  \\n Next, let's perform more operations on y.  \\n Time to calculate the gradients now.  \\n Let's back prop now using out.backward  \\n which is equivalent to doing the following.  \\n And once we print, you should have got a matrix of 4.5.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2620025\",\"duration\":122,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Advanced PyTorch autograd\",\"fileName\":\"2884016_en_US_02_05_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to use autograd to automate the computation of backward passes in neural networks. Explore an advanced component within PyTorch an important-to-implement neural network for the rest of the use cases.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3771747,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] There's a lot more to AutoGrad and PyTorch.  \\n Let's try something more complex.  \\n In this first example,  \\n we first generate three random numbers,  \\n assign them to a variable called X,  \\n and we require, in this case, gradients for X.  \\n We then provide some operations on X  \\n to generate a new variable called Y,  \\n which will have a gradient function attached to it.  \\n Now, let's print out the gradient for X.  \\n So in your Neural Network,  \\n parameters that don't compute gradients  \\n are usually called frozen parameters.  \\n It is useful to freeze part of your model  \\n if you know in advance  \\n that you won't need the gradients of those parameters.  \\n This offers some performance benefits  \\n by reducing AutoGrad computations.  \\n Let's walk through a small example to demonstrate this.  \\n We'll first import some libraries,  \\n including torchvision, in this case.  \\n We load a pre-trained resnet18 model, in this case,  \\n and then freeze all of the parameters.  \\n Assume we want to fine tune the model  \\n on a new dataset with 10 labels.  \\n In ResNet, the classifier is the last linear layer,  \\n model.fc.  \\n We can simply replace it with a new linear layer,  \\n unfrozen by default,  \\n that acts as our classifier.  \\n Now, all parameters in this model,  \\n except for the parameters of model.fc, are frozen.  \\n The only parameters that compute gradients  \\n are the weights and bias of model.fc.  \\n Notice that although we register all the parameters  \\n in the optimizer,  \\n the only parameters that are computing gradients  \\n and hence, updated in the gradient descent,  \\n are the weights and the bias of the classifier.  \\n The same exclusionary functionality  \\n is available as a context manager in torch.no_grad.  \\n \\n\\n\"}],\"name\":\"2. PyTorch Basics\",\"size\":27897241,\"urn\":\"urn:li:learningContentChapter:2617031\"},{\"duration\":603,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2617030\",\"duration\":521,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Torchvision introduction\",\"fileName\":\"2884016_en_US_03_01_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to install Torchvision and understand the basic usage and implementation of the package. Understanding the basics of Torchvision helps you to further implement the use case in future sections.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":15422991,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] TorchVision is a library within PyTorch  \\n for image and video processing,  \\n it contains a number of important and useful data sets,  \\n model architecture,  \\n as well as models and transformation operations  \\n that are commonly used for computer vision projects.  \\n There are seven main packages for the TorchVision library:  \\n dataset, IO, models, feature extraction,  \\n ops, transforms, and utils.  \\n Let's look at each one of them.  \\n TorchVision dataset,  \\n this package, as the name suggests,  \\n contains some of the most popular computer vision data sets.  \\n All data sets are subset of torch.util.data.Dataset,  \\n they have getitem and lamp methods implemented,  \\n as a result, you can pass any of them  \\n to torch.utils.data.DataLoader,  \\n which can load multiple samples in parallel  \\n using multiple processing workers.  \\n We covered the PyTorch DataLoader in previous chapters.  \\n One thing to note is that all data sets  \\n have identical implementations and signatures.  \\n All of them have these two common arguments:  \\n transform, and target transform.  \\n The former will transform the input,  \\n and latter, to transform the target.  \\n Some of the most popular data sets are CalTech,  \\n which refers to the CalTech 101 project  \\n that contains pictures of objects  \\n belonging to 101 categories,  \\n each category has about 40 to 800 images.  \\n CIFAR.  \\n The CIFAR 10 and CIFAR 100 are labeled data sets  \\n of the 80 million TinyImage data set.  \\n Cityscapes.  \\n The Cityscapes data set focuses on semantic understanding  \\n of urban street scenes,  \\n with 50 cities across different seasons,  \\n with 5,000 images finely annotated,  \\n and 20,000 coarsely annotated.  \\n ImageNet contains 14,197,122 annotated images  \\n according to the WordNet hierarchy.  \\n Since 2010, the dataset is used  \\n in the ImageNet Large Scale Visual Recognition Challenge,  \\n a benchmark in image classification and object detection.  \\n Many of you have heard the MNIST dataset,  \\n which was developed by none other, Yann LeCun,  \\n the chief scientist at Meta  \\n who was dubbed as one of the god fathers of deep learning.  \\n The MNIST dataset has become a standard benchmark  \\n for learning, classification, and computer vision systems.  \\n Torch Vision Dataset also has a number of extended dataset  \\n from MNIST, including EMNIST,  \\n Extend MNIST that constitutes  \\n more challenging classification tasks  \\n involving letters and digits,  \\n and that shares the same image structure and parameters  \\n as the original MNIST tasks,  \\n allowing for direct compatibility  \\n with all existing classifiers and systems.  \\n Fashion-MNIST, consisting of a training set  \\n of 60,000 examples, and a test set of 10,000 examples.  \\n Each example is a 28 by 28 gray scale image  \\n associated with a label from 10 classes.  \\n KMNIST, it's a data set which is a replacement  \\n for the MNIST data set, 28 by 28 gray scale,  \\n with 70,000 images provided in the original MNIST format,  \\n as well as NumPy format.  \\n Torchvision.io,  \\n this package provides functions  \\n for performing IO operations,  \\n including reading and writing images and videos.  \\n Images, the Torch Vision IO read_image  \\n reads a JPEG or PNG image  \\n into a three-dimensional RGB tensor,  \\n optionally converts the image to the desired format.  \\n The values of the output tensor  \\n are unit 8, between 0 and 255.  \\n decode_image detects whether an image is a JPEG or PNG,  \\n and performs the appropriate operations  \\n to decode the image into a three-dimensional RGB tensor.  \\n encode_jpeg takes an input tensor and CHW layout,  \\n and returns a buffer with the content  \\n of its corresponding JPEG file.  \\n decode_jpeg decodes a JPEG image  \\n into a three-dimensional RGB tensor,  \\n optionally converts the image to the desired format.  \\n The value of the output tensor are unit 8  \\n between 0 and 255.  \\n write_jpeg takes an input tensor and CHW layout  \\n and saves it to a JPEG file.  \\n For each of the JPEG method above,  \\n there is an equivalent for PNG format.  \\n For videos,  \\n read_video reads a video from a file,  \\n returning both the video frames as well as the audio frames.  \\n read_video_timestamps list the video frames' timestamps.  \\n write_video writes a 4D tensor in THWC format,  \\n and a video file.  \\n VideoReader is a high performance, low-level API  \\n for more fine grain control video reading API,  \\n it supports frame by frame reading of various streams  \\n from a single video container.  \\n Models.  \\n The Models sub package contains definitions of models  \\n for addressing different tasks,  \\n including image classification,  \\n pixel-wise semantic segmentation,  \\n object detection, instant segmentation,  \\n person key point detection,  \\n and video classification.  \\n There are four model sub-packages,  \\n including Classification,  \\n Semantic segmentation,  \\n Object/keypoint detection,  \\n and Video classification.  \\n Operations.  \\n Feature extraction utilities enable ML engineers  \\n to access intermediate transformations of the model inputs.  \\n TorchVision provides great feature extractors  \\n for this purpose.  \\n The torch.fx.documentation  \\n provides a more general and detailed explanation  \\n of the above procedure  \\n and the inner workings of the symbolic tracing.  \\n TorchVision Ops,  \\n it implements operators  \\n that are specific for computer vision.  \\n Here are the key operators.  \\n batched_nms,  \\n it performs non-maximum suppression in a batched fashion.  \\n box_area, it computes the area of a set of bounding boxes.  \\n clip_boxes_to_image,  \\n clip boxes so that they lie inside an image of a size.  \\n mask_to_boxes,  \\n it computes the bounding boxes around the provided masks.  \\n remove_small_boxes,  \\n remove boxes which contain at least one size smaller  \\n than min size.  \\n sigmoid_focal_loss,  \\n loss used in retina net for dense detection.  \\n stochastic_depth implements the stochastic depth  \\n from deep networks  \\n with stochastic depth used  \\n for randomly dropping residual branches  \\n of residual architecture.  \\n Transforms, this library allows ML engineers  \\n to perform various transformation steps on images,  \\n including rotation, cropping, composing,  \\n adjusting color jitter, converting to gray scale,  \\n adjusting padding, resize,  \\n amongst many others.  \\n For details, check out the documentation in the link below.  \\n utils, this library provides  \\n a number of processing utilities for computer vision tasks,  \\n including making a grid of images,  \\n saving a tensor into an image file,  \\n and drawing segmentation masks on object detection.  \\n And the details and examples can be found  \\n at the PyTorch documentation site as well.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2620026\",\"duration\":82,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Torchvision for video and image understanding\",\"fileName\":\"2884016_en_US_03_02_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to use Torchvision to extract entities from various training and learning videos. Torchvision is a very powerful package to accomplish various computer vision tasks for object detection, entity extraction, and classification so similar training videos can be recommended.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3050507,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Now that you have a good understanding  \\n of the TorchVision library,  \\n let's walk through a lab,  \\n continuing with the use case of Piraeus.  \\n When presenting a set of tutors to a student for selection,  \\n it'll be helpful to include some photos  \\n of the instructions in the lectures.  \\n We'll use the TorchVision image library  \\n and try a few transformation actions.  \\n First, we have to import some libraries.  \\n We then define a function to display images, here,  \\n called show.  \\n Say this is a Padre class.  \\n We'll load the images and show them here.  \\n Now, we define a function to plot various images  \\n through transformation,  \\n and the function is called plot,  \\n right here.  \\n Most transforms natively support tensors  \\n on top of the PIL images.  \\n Let's add some paddings to the image.  \\n We then try a few image transformations  \\n such as random crop,  \\n color jitter,  \\n random perspectives.  \\n And finally, let's crop to the center  \\n and find the best centered image.  \\n \\n\\n\"}],\"name\":\"3. Torchvision\",\"size\":18473498,\"urn\":\"urn:li:learningContentChapter:2617032\"},{\"duration\":448,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2616026\",\"duration\":205,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Torchaudio introduction\",\"fileName\":\"2884016_en_US_04_01_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to set up the environment and implement a basic model for audio processing using Torchaudio. Understanding the basics of Torchaudio helps you further implement the use case in the next section.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6476643,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] TorchAudio is a library  \\n for audio and signal processing with PyTorch.  \\n It provides IO, signal, and data processing functions,  \\n datasets, model implementations, and application components.  \\n TorchAudio offers a set of APIs,  \\n including backend, functional, transforms,  \\n datasets, models, pipelines,  \\n sox_effects, compliance.kaldi, kaldi_io, and utils.  \\n Similar to TorchVision,  \\n TorchAudio also provides a number of popular datasets  \\n out of the box.  \\n Examples include CMUDict,  \\n CMU pronouncing dictionary,  \\n Common Voice,  \\n GTZAN, which is music genre classification of audio signals,  \\n speech commands,  \\n and VCTK, which is speech data uttered  \\n by 110 English speakers with various accents.  \\n Details of these datasets can be found  \\n at PyTorch dataset documentation.  \\n Audio I/O package allow you to query audio file metadata,  \\n loading audio data into a tensor,  \\n and saving audio to files.  \\n Audio resampling.  \\n To resample an audio wave form  \\n from one frequency to another,  \\n you can use transforms.Resample or functional.resample.  \\n transforms.Resample pre-computes  \\n and caches the kernel used for resampling,  \\n while functional.resample computes it on the fly.  \\n TorchAudio's resample function can be used  \\n to produce results similar to that of Librosa,  \\n which is resampy's kaiser window resampling,  \\n with some noise.  \\n TorchAudio provides a variety of ways  \\n to augment audio data.  \\n TorchAudio SoX effects allows for directly applying filters,  \\n similar to those variables in SoX to tensor objects,  \\n and file object audio sources.  \\n Convolution reverb is a technique  \\n that's used to make clean audio sound  \\n as though it has been produced in a different environment.  \\n Using room impulse response, RIR, for instance,  \\n we can make a clean speech sound  \\n as though it has been uttered in a conference room.  \\n To add background noise to audio data,  \\n you can simply add a noise tensor  \\n to the tensor representing the audio data.  \\n A common method to adjust the intensity of noise  \\n is changing the signal-to-noise ratio.  \\n torchaudio.functional.apply_codec can apply codecs  \\n to a tensor object.  \\n Combining all of the above techniques,  \\n TorchAudio can simulate audio.  \\n that sounds like a person talking over a phone  \\n in an echoey room with people talking in the background.  \\n Similar to TorchVision,  \\n TorchAudio implements feature extractions  \\n commonly used in the audio domain.  \\n They are available in torchaudio.functional  \\n and torchaudio.transforms.  \\n There are also augmentation techniques available  \\n in TorchAudio, including TimeStretch, TimeMasking,  \\n and FrequencyMasking.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2620027\",\"duration\":243,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Torchaudio for audio understanding\",\"fileName\":\"2884016_en_US_04_02_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to implement audio characteristics of the training tutorials in this use case. Knowing how to extract language, intonation, and other audio characteristics of the video files can be a useful technique to generate more metadata for training material recommendations.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8727736,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Now let's continue with a pyrees use case.  \\n We would like to transcribe the audio  \\n and video lectures into scripts.  \\n We'll go through an example using Pie Torch's  \\n Torch Audio Library to transcribe some audio speech.  \\n This example is provided by Hiro Moto and can be found  \\n at the Pie Torch website will be using pre-trained models  \\n from web to back 2.0 through Torch Audio.  \\n The high level steps  \\n of this pipeline includes extract the acoustic features  \\n from audio waveform and then estimate the class  \\n of the acoustic features framed by frame  \\n and then generate hypothesis  \\n from the sequence of the class probabilities.  \\n Torch audio provides an easy access  \\n to the pre-trained weights and associated information such  \\n as the expected sample rate and class labels.  \\n They're bundled together and available  \\n under the Torch Audio dot pipelines module.  \\n First, we import map plot lib.  \\n Next, we'll create a Wave two VAC two model  \\n that performs the feature extraction and the classification.  \\n We will use the torch audio dot pipelines  \\n dot wave two VAC two, ASR Base nine 60 H here.  \\n The bundle object provides the interface  \\n to instantiate model and other information.  \\n Sampling rate and the class labels  \\n are also found as follows.  \\n We'll create a model  \\n through automatically fetching the pre-trained weights  \\n and loaded into the Model.  \\n Importing S S L module is important to set the context  \\n so that the model can be downloaded  \\n through HTTPS via the secure sake layer.  \\n Next, we load data.  \\n We use the speech data from Voices dataset  \\n which is licensed under Creative Commons by 4.0.  \\n Let's listen to the output here.  \\n - [Male Computer Voice] I had that curiosity beside me  \\n at this moment.  \\n - Next, let's load the data into the model  \\n and run the resample if necessary  \\n for efficiency and performance.  \\n Next, we extract acoustic features frame by frame.  \\n The returned features is a set of tensors.  \\n Each tensor is the output of a transformer layer.  \\n Now let's visualize these features.  \\n All right. The result is back.  \\n As you can see, there are a total of 12 layers.  \\n Next, we'll classify these features into categories.  \\n Wave two, VAC two model provides method  \\n to perform the feature extraction  \\n and classification in one step.  \\n Let's visualize the classification.  \\n It's in the form of logics instead of probabilities.  \\n Next, we'll generate the transcript  \\n using a greedy decoding algorithm,  \\n meaning we'll simply pick up the best hypothesis  \\n at each timestamp  \\n and do not require external resources such as a dictionary.  \\n Now we will create the decoder object  \\n and decode the transcript.  \\n Lastly, let's check the result, and this is the output.  \\n I had that curiosity beside me at this moment.  \\n Let's listen to the audio  \\n and see if the transcription is correct.  \\n - [Male Computer Voice] I had that curiosity beside me  \\n at this moment.  \\n - Yes, it is correct.  \\n That wraps up the Torch Audio Lab.  \\n \\n\\n\"}],\"name\":\"4. Torchaudio\",\"size\":15204379,\"urn\":\"urn:li:learningContentChapter:2622024\"},{\"duration\":467,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2619026\",\"duration\":219,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Torchtext introduction\",\"fileName\":\"2884016_en_US_05_01_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to set up the environment and implement a basic model for text processing using Torchtext. Understanding the basics of Torchtext helps you to further implement the use case in the next section.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7261880,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - TorchText is PyTorch's Library  \\n for Natural Language Processing.  \\n It consists of data processing, utilities,  \\n and useful data sets for natural language processing.  \\n It also comes with pre-trained word embedding, dataset API.  \\n Iterator API ought to be used  \\n for training models with PyTorch.  \\n TorchText comes equipped with some popular data sets  \\n for text classification, language modeling,  \\n machine translation, sequence tagging, question and answers,  \\n and also unsupervised learning.  \\n Please note that these are actually data pipes  \\n from the Torch Data Project, which is still in beta status.  \\n So, be aware that APIs might change.  \\n Couple of recommendations while using these data sets.  \\n Use data loader for shuffling the data pipe.  \\n Use the built-in worker n-net function  \\n for multi-processing.  \\n And use drop last equals to true, to ensure that  \\n all batch sizes are equal.  \\n In addition to popular data sets,  \\n TorchText package also provides utilities  \\n for text data processing for training.  \\n Functional. The TorchText data functional module  \\n contains the following set of utilities.  \\n Generate SP model for training a sentence piece tokenizer.  \\n Load SP model for loading a sentence piece model for file.  \\n Sentence piece numericalizer is a sentence piece model  \\n that numericalizes a text sentence into a generator  \\n over the IDs.  \\n Sentence piece tokenizer is a sentence piece model to  \\n tokenize a text sentence into a generator over the tokens.  \\n Custom replace converts text strings.  \\n Simple space split splits text strings by spaces.  \\n Mericalize tokens from literator yields a list  \\n of IDs from a token iterator with a vocab.  \\n Filter Wikipedia XML filters Wikipedia XML lines.  \\n To map style dataset converts iterable style dataset  \\n to map style dataset.  \\n The metrics modules with blue score computes the blue score  \\n between a candidate translation corpus  \\n and a reference translation corpus.  \\n The data utils module contains get tokenizer function  \\n that generates tokenizer function for a string sentence.  \\n TorchText offers some common text transforms,  \\n including a few tokenizers, such as  \\n a sentence piece tokenizer, clip tokenizer,  \\n bert tokenizer, vocab transform,  \\n ToTnesor, label index, truncate, add token,  \\n sequential, pad transform, and string to int transform.  \\n They can also be trained together using  \\n torch.nn, sequential,  \\n or using TorchText, transforms, sequential  \\n to support torch's credibility.  \\n TorchText also contains a number  \\n of pre-trained models, including Roberta,  \\n that iterates on bert's pre-training procedure,  \\n including training the model longer  \\n with bigger batches over more data,  \\n removing the next sentence, prediction objective,  \\n training on longer sequences, and dynamically changing  \\n the masking pattern applied to the training data.  \\n We'll go through an example next.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2619027\",\"duration\":248,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Torchtext for translation\",\"fileName\":\"2884016_en_US_05_02_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to implement text transcription and translation from the video files. You need to understand how to use Torchtext for translation to make more learning content available to users.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9220109,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this lab,  \\n we continue with the Piraeus use case.  \\n I'll walk you through the tutorial  \\n called \\\"Classifying Names with a Character-Level RNN\\\"  \\n by Sean Robertson.  \\n We will be building a text classifier  \\n to identify the language used in the course by the tutor.  \\n The character-level RNN  \\n reads words as a series of characters,  \\n outputting a prediction and hidden state at each step,  \\n feeding its previous hidden state into each next step.  \\n We take the final prediction to be the output,  \\n which class the word belongs to.  \\n Specifically, we'll train on a few thousand surnames  \\n from 18 languages of origin  \\n and predict which language a name is from,  \\n based on the spelling.  \\n First, we import the matplotlib.  \\n We then load the data files from the directory  \\n and build our category lines.  \\n Now we have category lines,  \\n a dictionary mapping each category, which is the language,  \\n to a list of lines, which are names.  \\n We also kept track of all categories,  \\n just a list of languages,  \\n and categories for later references.  \\n Let's print the first five lines of the Italian category.  \\n Now we have all the names organized.  \\n We need to turn them into tensors  \\n to make any use of them in our model.  \\n Next, let's create the network.  \\n To run a step of this network, we need to pass an input,  \\n in our case, the tensor for the current letter,  \\n and a previous hidden state,  \\n which we initialize as zeros at first.  \\n We'll get back the output probability of each language  \\n and a next hidden state, which we keep for the next step.  \\n We will use the lineToTensor  \\n to avoid creating a new tensor every step.  \\n This is more efficient.  \\n Before doing our training,  \\n let's create a few helper functions.  \\n First one is to get category from output.  \\n The second helper function  \\n is to quickly get training example.  \\n We will train the network using NLLLoss function.  \\n We set the learning rate accordingly,  \\n and define a function, train the model.  \\n Now we'll run the train function  \\n that we defined in the previous step with some examples.  \\n This will take a while.  \\n So after the training is done,  \\n we will plot the learning results.  \\n We are almost halfway through.  \\n Okay, now let's plot the learning results.  \\n Here we go.  \\n Next step, we will evaluate the results.  \\n We create a confusion matrix in order to do that,  \\n which indicate for every actual language, which are rows,  \\n which language the network guesses and predicts,  \\n which are the columns.  \\n To calculate the confusion matrix,  \\n a bunch of samples are run through the network  \\n with the evaluate function,  \\n which is the same as the train function  \\n is set for minusing the backprop.  \\n This is the evaluate function.  \\n As you can see, the rows are the actual language  \\n and the columns are what the model predicts.  \\n Lastly, let's see how the model work  \\n by giving it some examples through a predict function.  \\n We're giving it four examples towards the end,  \\n and this is the prediction.  \\n \\n\\n\"}],\"name\":\"5. Torchtext\",\"size\":16481989,\"urn\":\"urn:li:learningContentChapter:2618025\"},{\"duration\":73,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2616027\",\"duration\":73,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Continuing your PyTorch learning process\",\"fileName\":\"2884016_en_US_06_01_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, get a summary of the key concepts covered in this training and get ready to select the next set of learning from the available resources. This is a very elementary introduction to PyTorch. There are greater details that you need to delve into in order to be more proficient with the framework.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2076513,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Thanks for watching.  \\n Understanding the basics of computer vision,  \\n natural language processing, and audio processing  \\n through PyTorch can be a lot to get your head around.  \\n So if you need to go back  \\n and rewatch videos until you get it.  \\n It's very common for new learners to take a couple of passes  \\n through this material before it really sinks in.  \\n If you want to keep learning about PyTorch  \\n or Machine Learning, the next step is to dive  \\n into the documentation and build something,  \\n create an implementation for an idea you have.  \\n And if you want to learn more about AI,  \\n there is a 10 course learning series  \\n on LinkedIn called Master The Fundamentals of AI  \\n and Machine Learning.  \\n Courses such as Artificial Intelligence Foundations  \\n Neural Networks with Doug Rose,  \\n or AI Algorithms for Gaming with Eduardo Corpeno  \\n will both be super informative and fun.  \\n If you want to keep in touch with me,  \\n please follow me on Twitter or LinkedIn  \\n or look me up on Facebook and Instagram.  \\n Thank you and bye.  \\n \\n\\n\"}],\"name\":\"Conclusion\",\"size\":2076513,\"urn\":\"urn:li:learningContentChapter:2617033\"}],\"size\":111518093,\"duration\":3412,\"zeroBased\":false},{\"course_title\":\"Natural Language Processing with PyTorch\",\"course_admin_id\":3004335,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":3004335,\"Project ID\":null,\"Course Name\":\"Natural Language Processing with PyTorch\",\"Course Name EN\":\"Natural Language Processing with PyTorch\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"Learn about natural language processing with PyTorch, the popular deep learning tool used by tech giants like OpenAI and Microsoft. In this course, Zhongyu Pan guides you through the basics of using PyTorch in natural language processing (NLP). She explains how to transform text into datasets that you can feed into deep learning models. Zhongyu walks you through a text classification project with two frequently used deep learning models for NLP: RNN and CNN. She also shows you how to tune hyperparameters and construct model layers to get more robust and accurate results, as well as the differences between the two models for NLP tasks.\",\"Course Short Description\":\"Learn the basics of using PyTorch, a powerful deep learning tool, for natural language processing.\",\"Content Type\":\"TOOLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":20160017,\"Instructor Name\":\"Zhongyu Pan\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"Content Creator at LinkedIn\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2022-04-15T00:00:00\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"Yes\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/natural-language-processing-with-pytorch\",\"Series\":\"One-Off\",\"Limited Series\":null,\"Manager Level\":\"Individual Contributor\",\"LI Level\":\"Intermediate\",\"LI Level EN\":\"Intermediate\",\"Sensitivity\":null,\"Internal Library\":\"Technology\",\"Internal Subject\":\"Artificial Intelligence for Technology\",\"Primary Software\":\"PyTorch\",\"Media Type\":\"Video\",\"Has CEU\":\"No\",\"Has Exercise Files\":\"Yes\",\"Visible Duration\":2464.0,\"Visible Video Count\":12.0,\"Contract Type\":\"PERPETUAL\"},\"sections\":[{\"duration\":161,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3070068\",\"duration\":77,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Natural language processing\",\"fileName\":\"3004335_en_US_00_01_WX30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"In this video, explore the course overview and learn the prerequisites for the course.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2854751,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Pan] We interact with machines  \\n most commonly through natural languages  \\n like English, Chinese, or Spanish, you name it.  \\n We ask our smartphones to open our favorite playlist  \\n on the music app.  \\n We type a sentence in Google Translate  \\n to be able to communicate with people  \\n from a different culture.  \\n Natural language processing, or NLP for short,  \\n gives machines the ability to understand human languages  \\n that we use in daily life accurately and efficiently.  \\n It has also undergone a massive transformation  \\n with the introduction of Deep Learning.  \\n PyTorch, which is one of the most popular  \\n Deep Learning libraries, developed by Meta,  \\n makes NLP even easier to learn and work with.  \\n Hi, my name is Pan Zhongyu.  \\n I work as a data scientist and software developer.  \\n I have built NLP-related systems  \\n for companies with knowledge of Deep Learning.  \\n Join me on my LinkedIn Learning course  \\n as we explore the exciting field  \\n of natural language processing with PyTorch.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3068059\",\"duration\":84,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"What you should know\",\"fileName\":\"3004335_en_US_00_02_XR30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"In this video, learn about the benefits of PyTorch and whether it is the best fit for you.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2810381,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this course,  \\n I will be giving you brief introductions  \\n to natural language processing, deep learning and PyTorch.  \\n You will learn how to pre-process  \\n and transform the text data into numeric datasets  \\n that can be fed into deep learning models.  \\n Then, you will be guided through  \\n a text classification project  \\n where you build and train a deep learning model  \\n for classification predictions.  \\n If you have never worked  \\n with natural language processing before, don't worry.  \\n This course is designed for anyone  \\n with a basic Python programming background  \\n who wants to dive into NLP  \\n with the powerful tool of PyTorch.  \\n You will need to have knowledge of key concepts in Python,  \\n like variables, functions, classes and so on.  \\n It will also help if you are familiar  \\n with the use of Python packages,  \\n like Numpy, pandas, NLTK.  \\n We assume that you have some deep learning exposure,  \\n you understand the basics of neural networks  \\n so that when we are introducing the PyTorch way  \\n of building neural nets,  \\n it will be easier for you to follow.  \\n We are going to use Google Colab throughout the coding part  \\n and I will help you set this tool up before we start coding.  \\n Let's dive right in.  \\n \\n\\n\"}],\"name\":\"Introduction\",\"size\":5665132,\"urn\":\"urn:li:learningContentChapter:3069059\"},{\"duration\":353,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3068060\",\"duration\":134,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Popular topics in NLP\",\"fileName\":\"3004335_en_US_01_01_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn the basic definition of NPL, its popular fields, and why you should learn it.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4490083,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] So, what is natural language processing?  \\n There can be multiple interpretations,  \\n but one way of defining it  \\n is that natural language processing  \\n is a subfield of artificial intelligence  \\n that helps machines better understand  \\n or generate human languages.  \\n NLP is therefore divided into two major components,  \\n natural language understanding  \\n and natural language generation.  \\n As the names imply, natural language understanding  \\n enables machines to understand the meaning of the text  \\n while natural language generation instead  \\n produces text responses based on specific text input.  \\n We will mainly focus on natural language understanding  \\n in this course.  \\n Let's take a look at some popular applications of NLP.  \\n One of the most important applications  \\n is sentiment analysis.  \\n It is a type of text classification task  \\n and it has been largely implemented by enterprises  \\n for understanding customer feedback,  \\n monitoring social media,  \\n conducting market research, et cetera.  \\n The second application is chatbot,  \\n which has been usually applied as a tool of customer support  \\n by various companies that need to interact with customers.  \\n It is also used for marketing or sales purposes.  \\n Speech recognition allows us to communicate  \\n with Apple's Siri or Amazon's Alexa  \\n just like the way we talk to a real assistant.  \\n Machine translation is also a common use case of NLP.  \\n One popular application is Google Translate,  \\n which translates one language to another  \\n in a very short period of time.  \\n One of the coolest applications is advertisement matching,  \\n which you can see probably every day on YouTube.  \\n The most relevant ads are displayed  \\n based on your personal preferences.  \\n The NLP application we're going to build in this course  \\n is text classification, stay tuned.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3073044\",\"duration\":219,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Introducing deep learning\",\"fileName\":\"3004335_en_US_01_02_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to describe deep learning at a high level and intuitively explain how deep learning works under NLP concepts.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7773368,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Deep learning is a subset  \\n of machine learning,  \\n and machine learning is a subset of artificial intelligence.  \\n In this video, we are going to introduce three types  \\n of deep learning models:  \\n artificial neural networks,  \\n convolutional neural networks,  \\n and recurrent neural networks,  \\n about how they work at a high level  \\n and compare their differences.  \\n Note that CNN and RNN are both ANN models.  \\n Let's first look at artificial neural networks  \\n or ANN for short.  \\n It normally has one input layer,  \\n one or more hidden layers  \\n and one output layer.  \\n The data is fed into the input layer,  \\n then calculated and extracted by hidden layers.  \\n And finally, the output layer delivers the result  \\n based on the information simplified  \\n by previous layers.  \\n However, regular ANN does not work so well  \\n in natural language processing or image processing tasks.  \\n So let's look at convolutional neural networks, or CNN,  \\n which performs better in both tasks.  \\n But why does CNN work better?  \\n Because it works spatially along the data  \\n and it focuses more on the feature  \\n rather than on the position of the data.  \\n The unique layer structures of CNN  \\n are convolutional layers and pooling layers,  \\n compared with a regular ANN.  \\n The world convole refers to the filtering process.  \\n This filtering process simplifies the information included  \\n within each layer  \\n so that it is easier for the next layer  \\n to process the output as shown in the picture below.  \\n This way it is convenient  \\n to find important features and ignore the trivial ones  \\n so that we get more solid results.  \\n CNN is also the deep learning model we're going to build  \\n for solving a natural language processing task  \\n in this course.  \\n Another major type of deep learning model  \\n is called recurrent neural networks or RNN.  \\n The structure of RNN is similar to a regular ANN,  \\n which contains one input layer,  \\n one or more hidden layers  \\n and one output layer.  \\n The difference between RNN and CNN  \\n is that RNN not only passes data forward  \\n throughout the layers  \\n but also feeds the data back into itself  \\n while CNN passes data only one way forward.  \\n That means RNN can remember the context before  \\n and after the current word in a sentence.  \\n An RNN is therefore well-suited for sequential data,  \\n such as text or audio.  \\n Another thing to keep in mind  \\n is that CNN is on average faster than RNN  \\n in processing text data.  \\n I hope you now have a general understanding  \\n of how these deep learning models work differently.  \\n In the next chapter,  \\n we're going to get our hands dirty  \\n by writing code and we will introduce PyTorch,  \\n the essential framework  \\n for learning natural language processing.  \\n So you in the next chapter.  \\n \\n\\n\"}],\"name\":\"1. NLP with Deep Learning Introduction\",\"size\":12263451,\"urn\":\"urn:li:learningContentChapter:3071047\"},{\"duration\":390,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3067062\",\"duration\":102,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Why PyTorch?\",\"fileName\":\"3004335_en_US_02_01_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, explore which tech giants are using PyTorch for NLP and its most popular uses and functionalities within the tech sector.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3747172,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Speaking of deep learning,  \\n PyTorch, developed by Meta,  \\n and TensorFlow, developed by Google Brain,  \\n are two open source Python libraries  \\n that are extensively used nowadays  \\n and they do share some similar features.  \\n So why do we use PyTorch instead of TensorFlow  \\n in this course?  \\n PyTorch has a reputation for being more applied  \\n in research than in production  \\n and most of the top AI papers use PyTorch  \\n as their deep learning framework  \\n while TensorFlow is widely used in industry  \\n by tech companies for deploying AI products.  \\n But for people who are just getting started with NLP,  \\n it is recommended to learn it with PyTorch.  \\n The reasons are;  \\n first, PyTorch was created to make  \\n the models easier to write.  \\n The code in PyTorch is relatively more concise,  \\n which makes it beginner-friendly.  \\n Second, the statements in PyTorch are designed  \\n to mimic the ones in Python.  \\n So if you have previous working knowledge of Python,  \\n you will feel pretty natural coding in PyTorch.  \\n Third, although PyTorch is more geared toward research,  \\n it has been used by large enterprises  \\n for building NLP-related services.  \\n For instance, Airbnb used to build dialogue assistant  \\n using PyTorch for improving the customer service experience.  \\n PyTorch has also been used by Microsoft  \\n for its language modeling service.  \\n Without further ado, let's start coding.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3073045\",\"duration\":288,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"PyTorch tensor\",\"fileName\":\"3004335_en_US_02_02_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn what a PyTorch tensor is and how to implement the basic calculations and functions of PyTorch Tensor.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10976137,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this video,  \\n we will introduce the PyTorch tensor  \\n and the common methods of tensors  \\n but before that, let's first set up Google Colab.  \\n Make sure you have a Google account  \\n and you're able to access your Google Drive.  \\n Then visit colab.research.google.com.  \\n There is this documentation of welcome to Colab.  \\n You can read it briefly if you're interested  \\n but we will cover everything you need to know  \\n for learning this course.  \\n Now please open your exercise file  \\n of this video in Google Colab  \\n and code along with me.  \\n We can think of a tensor as a data container  \\n or data structure  \\n that carries arrays of numbers in PyTorch.  \\n Let's first look at how to create a PyTorch tensor.  \\n If you don't have Torch library yet,  \\n type pip install torch  \\n and run the cell to install the package.  \\n I have already installed the package,  \\n so it says requirement already satisfied.  \\n We then import Torch library and NumPy.  \\n Now, let's create a PyTorch tensor with an array.  \\n We already had an array here.  \\n So we type torch.tensor array  \\n and name it tensor0.  \\n And then we print out tensor0  \\n as well as its data structure type,  \\n which is torch.tensor,  \\n and data type, which is the type  \\n of the data carried by the tensor.  \\n In this case, it's integer.  \\n We also printed out the shape of the tensor  \\n where the first number in the case, the number of rows  \\n and second number in the case, the number of columns.  \\n Another way of constructing a tensor  \\n is from a NumPy array.  \\n This is basically the same as what we just did  \\n but instead of a regular array,  \\n we put a NumPy array  \\n inside of torch.tensor container, like this.  \\n Now let's take a look at some common methods in PyTorch.  \\n The first one is slicing.  \\n Slicing of tensors is basically the same  \\n as the slicing of NumPy arrays.  \\n We have tensorA and B here.  \\n And we can slice the first two rows of tensorA like this  \\n where index one is inclusive  \\n and index two exclusive.  \\n If we want to slice the first two columns,  \\n we will need to first take all the rows  \\n and then select from columns, just like before.  \\n The second common method is concatenation.  \\n Concatenation is extremely useful  \\n when we're building deep learning models.  \\n By using torch.cat method,  \\n we can concatenate two tensors vertically  \\n when both tensors have the same amount of columns.  \\n Don't forget to wrap the two tensors in one array.  \\n We can also concatenate them horizontally  \\n and specify dimension as one.  \\n Let's print out the results  \\n to see what the concatenated tensors look like.  \\n Okay, the first one is the vertical concatenation  \\n of the two tensors  \\n and the second one is the horizontal concatenation.  \\n Those are exactly what we want.  \\n One thing to point out is that torch.cat performs  \\n vertical concatenation by default.  \\n So if you want to apply horizontal concatenation,  \\n you will need to add an argument.  \\n Then equals one to get the desired tensor.  \\n Congratulations, you just finished learning the basics  \\n of PyTorch tensor.  \\n In the next chapter, we will start our guided project  \\n by building a convolutional neural network  \\n for solving a tax classification task.  \\n See you in the next chapter.  \\n \\n\\n\"}],\"name\":\"2. PyTorch Basics\",\"size\":14723309,\"urn\":\"urn:li:learningContentChapter:3068062\"},{\"duration\":1513,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3073046\",\"duration\":557,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Preprocessing text dataset\",\"fileName\":\"3004335_en_US_03_01_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to preprocess text data by learning how to load and transform text into a format that can be fed into a DL model. Explore different ways of preprocessing and learn the difference between them.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":17603256,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] From now on,  \\n we will be working on the guided project  \\n which is text classification  \\n using convolutional neural networks.  \\n The first step of the project  \\n is to pre-process text dataset,  \\n which is the goal of this video.  \\n Please download the exercise file of this video  \\n and open it in Google CoLab.  \\n Before we start coding,  \\n let's change runtime type to GPU  \\n to ensure the code runs as fast as possible.  \\n Simply click on Runtime.  \\n Then change the runtime type to GPU.  \\n Please keep in mind that when you change runtime type,  \\n your Jupyter Notebook will be restarted,  \\n and you will have to rerun all the code.  \\n So make sure you change runtime type  \\n before you start typing any code.  \\n Let's first import the required libraries.  \\n Here we import torch from torchtext dot legacy,  \\n import data and datasets.  \\n Lastly, we import random.  \\n Then in the second cell at line number two,  \\n we call torch dot manual seed here  \\n to set the seed of the random number generator,  \\n so the random values generated by torch  \\n will be reproducible the next time we run the code.  \\n You can also set the seed value  \\n to any number you want.  \\n To check if you actually switched your runtime type  \\n to GPU successfully,  \\n you can run line number four and five  \\n to print out your current device.  \\n If it prints out cuda,  \\n then congratulations.  \\n That means you have your GPU ready.  \\n If not,  \\n it means you are still using CPU,  \\n which will make your model run slower.  \\n But don't worry.  \\n Even with CPU,  \\n you can still complete our project,  \\n since CNN is by itself a lot faster  \\n than most of the deep learning models.  \\n Now let's define the fields,  \\n text field and label field.  \\n We are using data dot Field and data dot LabelField here.  \\n And you can read more about them in this documentation.  \\n So field and label field are basically the same things,  \\n except that label field doesn't take sequential data  \\n like text,  \\n which is reasonable,  \\n since label field takes in classification labels  \\n rather than the text.  \\n And for field,  \\n it basically models our text data  \\n to numerical representations carried by tensors.  \\n We set tokenize method to spacy.  \\n And we will lowercase all the text.  \\n Now you must be wondering,  \\n what does the data actually look like?  \\n Let me show you.  \\n PyTorch has some built-in datasets  \\n that we can import directly.  \\n And the datasets we are using here  \\n is called Text Retrieval Conference or TREC dataset.  \\n It's question classification dataset.  \\n So each piece of text in this dataset is a question.  \\n And each question is labeled as one of the six categories.  \\n The table here gives us an idea  \\n of what the TREC dataset actually looks like.  \\n Each data example in a dataset  \\n contains a question and a label.  \\n Each question in the first column of the table  \\n is labeled as one of the six categories,  \\n which are in the second column.  \\n And the third column is just the full name of those labels.  \\n The six categories are abbreviation,  \\n numeric, human, entity, description and location.  \\n These names are pretty self-explanatory.  \\n Let's take a look at a few examples here.  \\n The answer to the question,  \\n what is the date of boxing day,  \\n is clearly a date,  \\n so this question is labeled as numeric.  \\n If the question is asking about the city's name,  \\n like what is California's capital,  \\n then it is labeled as location.  \\n As we mentioned,  \\n the text or the question  \\n might be labeled as any of the six categories,  \\n so our task is to build a CNN model  \\n to successfully predict the labels of input questions.  \\n For example, if I feed the question,  \\n who discovered electricity,  \\n into the model,  \\n since the answer to it must be a human name,  \\n we would expect the model to output the correct label,  \\n which is human.  \\n I hope the mission of this project is now clear to you.  \\n Let's split TREC dataset into train and test datasets.  \\n We are passing the text and label fields we just built  \\n here at line number one.  \\n Now we got our train and test data ready,  \\n but we also need a validation dataset  \\n for the sake of evaluation.  \\n So let's split a part of the training data  \\n as validation dataset.  \\n And don't forget to save a random seed here as well  \\n to save the randomness here at line number two.  \\n Now we can run this line of code  \\n to check a sample of the training data.  \\n The text or the question is  \\n how fast does the fastest car go?  \\n And the label is categorized as numeric.  \\n That makes sense.  \\n Since our data is ready,  \\n we can start building vocabulary for text and label fields.  \\n To reduce the number of unique words in our vocab object,  \\n we set the minimum frequency to two.  \\n That means a word has to appear at least twice  \\n in a train data  \\n to be included in a vocab object of the text field.  \\n Please also notice that we are building vocabularies  \\n based on only training data,  \\n so make sure you split train validation and test datasets  \\n before you build vocab.  \\n Let's print out the vocab object of label field.  \\n We can see the six labels  \\n as well as their numerical representations.  \\n Similarly, in a vocab object of text field,  \\n we also have words with their numerical representations.  \\n Now let's check how big those vocabs are.  \\n There are 2,679 words in text field,  \\n and of course, six words in label field,  \\n which represent the six categories.  \\n Amazing.  \\n We just got our train validation and test set  \\n and successfully built the vocabs  \\n with their numerical representations.  \\n We only have one thing left to do,  \\n which is to construct the iterators  \\n for each set in the last cell.  \\n But why do we need iterators?  \\n The bucket iterator transforms  \\n the train validation and test datasets into batches  \\n at line number two.  \\n The batch size is set to 64 at line number three,  \\n which means the number of training examples  \\n in one batch is 64.  \\n Then in a sort key argument at line number four,  \\n we are sorting based on the length of each sentence,  \\n which means it batches the text of length together.  \\n Finally, we set the device to GPU  \\n for an even faster training process at line number five.  \\n That's all for pre-proccessing the text dataset  \\n with PyTorch.  \\n See you in the next video  \\n where we are going to build a CNN model.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3067063\",\"duration\":386,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Building a simple CNN model\",\"fileName\":\"3004335_en_US_03_02_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to build a basic deep learning model using PyTorch, as well as how to fine-tune model parameters and make the model more solid.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":14679394,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] I hope you are excited.  \\n In this video,  \\n we are building CNN model using PyTorch.  \\n What we are building is a very simple CNN  \\n that helps you consolidate your understanding  \\n of CNN architecture.  \\n We first import required libraries in the first cell.  \\n Then in a second cell,  \\n we define the class called CNN at line number one,  \\n and pass in nn.Module.  \\n All the PyTorch models  \\n inherit from the subclass of nn.Module.  \\n As you can see here, we are going to define  \\n init and forward functions,  \\n which are two of the most essential functions  \\n in a neural network model.  \\n Init is the constructor where we define the model layers.  \\n And when you instantiate a model object,  \\n init will be called.  \\n Forward method is where we actually add layers to the model  \\n and build the model architecture.  \\n In the init function,  \\n we are passing in the parameters we need  \\n for the constructor.  \\n There are vocabulary size, embedding size,  \\n number of kernels, kernel sizes,  \\n output size, and dropout rate.  \\n We use super.init to call the entire nn.Module class.  \\n Then we define the embedding layer  \\n with the required arguments.  \\n And then, the convolutional layers.  \\n Now, the dropout layer.  \\n And finally, the fully connected layer.  \\n Please notice there are actually three convolutional layers  \\n with three different kernel sizes we are going to define,  \\n namely, two, three, and four.  \\n The number of convolutional layers is the same  \\n as the number of different kernel sizes.  \\n I will leave you a little task here.  \\n Please try searching for the name of those nn. layers online  \\n and figure out what those layers do,  \\n as well as what their arguments mean.  \\n For example,  \\n when searching for nn.Embedding layer at line number five,  \\n take a look at the meanings of arguments,  \\n vocabulary size, and embedding size.  \\n Keep doing this until you understand all the layers  \\n and their arguments in the CNN model.  \\n I ensure this will help you a lot  \\n with understanding any CNN model  \\n you are going to work with in the future.  \\n Now, it's time to move on to the forward function.  \\n The forward function  \\n is where we build the model's architecture  \\n using the layers we defined in the init function.  \\n As we mentioned earlier in the course,  \\n the forward function should take in a piece of text  \\n and output the prediction of one of the six categories.  \\n We need to first permute the size of the text  \\n so that our embedding layer can properly carry the data.  \\n nn.Embedding will automatically build  \\n the embedding of the text.  \\n Then we pass the result to convolutional layers,  \\n max pooling layers, and dropout layer.  \\n By the way,  \\n the purpose of using dropout is to prevent overfitting.  \\n And finally, we return the result  \\n of the fully connected layer.  \\n The architecture looks the same  \\n as what we discussed in theory,  \\n but the shape of the output of each layer  \\n needs to be taken care of  \\n to be able to fit in the next layer.  \\n That is also why we are using  \\n functions permute, unsqueeze, and squeeze  \\n in a forward function.  \\n I encourage you to print out  \\n the shape of the output of each layer  \\n and think about why we use those functions  \\n to modify the shape of the data  \\n when we are passing them through different layers in CNN.  \\n After building the model,  \\n we need to instantiate it.  \\n And to do that,  \\n we will need to pass in all the arguments of the model  \\n from the init function.  \\n We give each argument a value,  \\n but you can play with those parameters  \\n to see if you can get a better result.  \\n This is actually one way of building a more solid model  \\n to achieve better accuracy.  \\n Now that the model is instantiated,  \\n we can print the model out  \\n to see if it has the architecture we wanted.  \\n We see an embedding layer,  \\n three convolution layers  \\n with kernel sizes two, three, and four,  \\n then a dropout layer, and a fully connected layer.  \\n Exactly what we wanted.  \\n Finally, in the last cell,  \\n let's move our model to GPU  \\n so we can train a lot faster.  \\n We say model.to(device)  \\n where our device is cuda, or cpu.  \\n That's it for building the CNN model.  \\n Our next step is to complete  \\n the train and evaluate functions for the training process.  \\n See you very soon.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3069057\",\"duration\":226,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Train and evaluate functions\",\"fileName\":\"3004335_en_US_03_03_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn about CNN at a high level, how CNN works in text classification, and how CNN and RNN perform different text classification tasks.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8297142,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] For a complete training process,  \\n we need to have a train function  \\n and evaluate function.  \\n The train function makes predictions based  \\n on training data  \\n and calculates how inaccurate the predictions are  \\n by comparing them with true labels  \\n of the training dataset.  \\n The train function then updates the parameters  \\n of the network to minimize the error  \\n or we call it minimizing the loss.  \\n So the model performs better.  \\n The evaluate function acts very similarly  \\n to the train function.  \\n It makes predictions based on validation data  \\n or test data and calculates  \\n how inaccurate the predictions are by comparing them  \\n to true labels of the dataset.  \\n But it doesn't update the parameters of the model.  \\n It simply evaluates the model based  \\n on the model's current state.  \\n Let's code the train function together.  \\n There are three essential parameters we need to define  \\n for the training process:  \\n the accuracy, the criterion and the optimizer.  \\n For criterion, we simply use a loss function  \\n call CrossEntropyLoss.  \\n We also move the criterion to GPU  \\n for a faster training process.  \\n You can check out PyTorch documentation  \\n and change the loss function as needed.  \\n For the optimizer,  \\n we are using Adam optimizer here  \\n and passing in the model's parameters.  \\n You can experiment with different optimizers as well.  \\n For accuracy, we prepared a function  \\n to calculate it in the second cell.  \\n As you can see here,  \\n it is basically calculating the percentage  \\n of correct predictions out of all the true labels.  \\n We also prepared the train function.  \\n As we mentioned before,  \\n we iterate through batches in the iterator.  \\n The optimizer helps us update the parameters  \\n of the model to minimize the loss.  \\n We use the model to make predictions  \\n of the text data  \\n and calculate the loss and accuracy.  \\n Then we add in total the loss  \\n and accuracy of each batch for the loss  \\n and accuracy of the entire epoch at line number 20 and 21.  \\n Finally, we return average loss and accuracy  \\n at line number 23.  \\n The length of the iterator is just the number  \\n of data examples in the iterator.  \\n In the evaluate function,  \\n we are doing something similar to the train function  \\n where we use the model to make predictions,  \\n then calculate and return the average loss and accuracy.  \\n The only thing we didn't do in evaluate function  \\n is that we didn't update model parameters  \\n based on the loss of each batch.  \\n We have pre-processed text data,  \\n built CNN model,  \\n completed train and evaluate functions,  \\n it is time to train the model.  \\n I am going to make it a challenge for you  \\n so you can work on it on your own  \\n but don't worry, in the next video,  \\n you will get enough hints  \\n on how to solve the challenge.  \\n Let's jump right into the challenge.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3068061\",\"duration\":108,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Challenge: Training process\",\"fileName\":\"3004335_en_US_03_04_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to clean text data as the first essential step in building a model.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4570464,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (upbeat music)  \\n - [Instructor] Welcome to the challenge.  \\n This is also the last section of our guided project  \\n which is the model training process.  \\n When you open the exercise file of this video,  \\n you can see that we wrap up everything we did together  \\n in one file,  \\n including text preprocessing,  \\n model building,  \\n train and evaluate functions.  \\n You can take your time to review the above sections,  \\n but we will go to the training section right now.  \\n The challenge for you is to fill in all the code  \\n under the Python comments,  \\n where it asks you to write code.  \\n As you can see,  \\n there are only three lines of code you need to fill in  \\n at line number eight, number 10, and number 14.  \\n For line number eight and 10,  \\n you need to figure out how to calculate  \\n the training loss, training accuracy,  \\n validation loss, and validation accuracy  \\n using the functions we built in previous sections  \\n and passing the correct arguments.  \\n The purpose of the code at line number 14  \\n is to update the best accuracy  \\n which we initialized to negative infinity  \\n at the beginning of the training process  \\n here at line number three.  \\n Try to complete the code on your own  \\n and please do review the code in the previous sections  \\n as it does help with solving this challenge.  \\n See you in the solution video.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3069058\",\"duration\":236,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Training process\",\"fileName\":\"3004335_en_US_03_05_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, explore the solution to Challenge: Training process.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9207649,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (upbeat music)  \\n - [Instructor] Let's complete the training process together.  \\n First, we define the number of epochs we want to train  \\n at line number one.  \\n You can change 20 to a smaller or bigger number  \\n to get the desired accuracy and loss.  \\n Then we loop through each epoch.  \\n And for each epoch, we calculate accuracy and loss  \\n for the training and validation set  \\n using the train and evaluate functions  \\n at line number 8 and 10.  \\n Like this, we can easily pass in the model, train,  \\n or validation iterator, optimizer, and criterion.  \\n I hope you got the answer right.  \\n Now, let's look at how we can update the best accuracy.  \\n When we find that the validation accuracy  \\n is larger than the best accuracy,  \\n that is, of course, a good thing,  \\n because we just found a better model.  \\n This is the time when we should update the best accuracy.  \\n As it is so far the best model,  \\n we will save it at this epoch at line number 15.  \\n And finally, we print out the accuracies and losses  \\n for each epoch from line 17 to line 19.  \\n Let's start training right now.  \\n We can see that both training and validation accuracies  \\n are going up.  \\n Our training set might have overfitting issues  \\n since it has quite a bit of difference  \\n compared to the validation accuracies.  \\n But we are training a very small CNN model,  \\n so we will ignore that for now.  \\n After the training, we need to test the actual performance  \\n of the model when it takes in real data.  \\n We load the best model,  \\n which has the highest accuracy at line number one  \\n and evaluate the model using our test set  \\n at line number three.  \\n This is also the last step in the project,  \\n which is to get the final test accuracy.  \\n The accuracy is around 85%,  \\n which is pretty decent for a CNN model sample like this.  \\n As we mentioned before, we can play with the parameters  \\n that we passed into the model  \\n to get hopefully a better accuracy.  \\n Just make sure to change only one parameter at a time  \\n if you want to explore the impact  \\n of one particular parameter on model accuracy.  \\n Let me show you how to do it.  \\n Let's change the dropout_rate to 0.6.  \\n Rerun this cell as well as all the cells after it  \\n and wait for the test accuracy to be calculated  \\n at the end of the file.  \\n We can see that the test accuracy  \\n is lower than last time,  \\n which means playing with the parameters  \\n can actually influence the model accuracy.  \\n I encourage you to keep exploring  \\n using this Jupyter Notebook.  \\n Congratulations, you just completed the entire project  \\n on text classification with PyTorch.  \\n You have successfully preprocessed text data,  \\n built a CNN model,  \\n trained and evaluate the model.  \\n I hope you find this project informative,  \\n and see you in the last chapter.  \\n \\n\\n\"}],\"name\":\"3. Guided Project: CNN Text Classification with PyTorch\",\"size\":54357905,\"urn\":\"urn:li:learningContentChapter:3066067\"},{\"duration\":47,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3073047\",\"duration\":47,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Keep learning and connect\",\"fileName\":\"3004335_en_US_04_01_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"This video celebrates you for completing the course and encourages you to keep learning through more advanced courses on NLP using PyTorch.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1610716,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Zhongyu] We've reached the end of the course.  \\n At this point, you have successfully built  \\n and trained a deep learning model  \\n for solving a tax classification task  \\n using the popular framework, PyTorch,  \\n but this isn't the end.  \\n I encourage you to learn more about deep learning models  \\n and natural language processing related tasks  \\n and continue to expand your knowledge of NLP,  \\n as we were only able to scratch the surface of it.  \\n Don't forget to connect with me on LinkedIn  \\n and check back often, as we are adding more advanced courses  \\n on NLP with PyTorch soon.  \\n I hope you enjoyed learning my course.  \\n Until next time, my name is Pan Zhongyu  \\n and thank you for watching.  \\n \\n\\n\"}],\"name\":\"Conclusion\",\"size\":1610716,\"urn\":\"urn:li:learningContentChapter:3066068\"}],\"size\":88620513,\"duration\":2464,\"zeroBased\":false},{\"course_title\":\"Deep Learning: Model Optimization and Tuning\",\"course_admin_id\":3003617,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":3003617,\"Project ID\":null,\"Course Name\":\"Deep Learning: Model Optimization and Tuning\",\"Course Name EN\":\"Deep Learning: Model Optimization and Tuning\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"Deep Learning as a technology has grown leaps and bounds in the last few years. More and more AI solutions use Deep Learning as their foundational technology. Studying this technology, however, presents several challenges. IT professionals from varying backgrounds need a simplified resource to learn the concepts and build models quickly. In this course, instructor Kumaran Ponnambalam provides a simplified path to understand various optimization and tuning options available for deep learning models and shows you how to use these options to improve models. He begins by reviewing Deep Learning, including artificial neural networks and architectures. Next, Kumaran discusses the process of hyper parameter tuning. He examines the building blocks of neural networks and the levers available to tune them. Kumaran offers recommendations and best practices. Then he concludes with an end-to-end tuning example.\",\"Course Short Description\":\"Learn about various optimization and tuning options available for deep learning models and use them to improve models.\",\"Content Type\":\"TOOLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":9427389,\"Instructor Name\":\"Kumaran Ponnambalam\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"Working with data for 20+ years\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2022-02-01T00:00:00\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"Yes\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/deep-learning-model-optimization-and-tuning\",\"Series\":\"Deep Dive (X:Y)\",\"Limited Series\":null,\"Manager Level\":\"General\",\"LI Level\":\"Advanced\",\"LI Level EN\":\"Advanced\",\"Sensitivity\":null,\"Internal Library\":\"Technology\",\"Internal Subject\":\"Artificial Intelligence for Technology\",\"Primary Software\":\"Python\",\"Media Type\":\"Video\",\"Has CEU\":\"No\",\"Has Exercise Files\":\"Yes\",\"Visible Duration\":3262.0,\"Visible Video Count\":33.0,\"Contract Type\":\"PERPETUAL\"},\"sections\":[{\"duration\":326,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3056008\",\"duration\":49,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Optimizing neural networks\",\"fileName\":\"3003617_en_US_00_01_WX30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Neural network models need to be fine-tuned to improve accuracy and decrease costs. In this video, learn how this course can help you gain an understanding of tuning neural networks.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2440717,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Kumaran] Deep learning has revolutionized  \\n how humans interact with machines today.  \\n However, building deep learning models is not easy.  \\n Data scientists spend weeks trying to tune their models  \\n to get desired accuracy and cost effectiveness.  \\n Knowledge of the parameters available for tuning,  \\n the tuning process and best practices are essential  \\n for building effective models in agile timeframes.  \\n My name is Kumaran Ponnambalam.  \\n In this course, I will start off by exploring the process  \\n of model optimization.  \\n Then, I will discuss various hyperparameters available  \\n and how to tune them.  \\n An end-to-end exercise project will help students  \\n to fine tune a model by applying the learnings  \\n in the course.  \\n Let's now start building optimized, deep learning models.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3055007\",\"duration\":136,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Prerequisites for the course\",\"fileName\":\"3003617_en_US_00_02_XR30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"This course requires prior familiarity with concepts around machine learning and Python programming. In this video, explore the list of prerequisites for effective learning for this course.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4559545,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Before we begin the course,  \\n let's go through the course objectives,  \\n scope and prerequisites.  \\n Deep Learning is a vast domain  \\n with a variety of tools and technologies.  \\n This tool set is evolving rapidly.  \\n Multiple courses exist that cover  \\n various aspects of Deep Learning,  \\n including concepts, libraries,  \\n tools and implementations.  \\n One of the key components of Deep Learning  \\n is the math involved in it.  \\n Some courses covered this math in-depth,  \\n and some ignore them as tools take care  \\n of the implementation.  \\n The same place to various tools use  \\n for Deep Learning as they take  \\n care of the implementation  \\n of algorithms and techniques.  \\n So what does this course cover?  \\n The goal of this course  \\n is to educate the students  \\n about the Deep Learning hyper parameters,  \\n and how to run experiments to tune them.  \\n It focuses on the tuning process,  \\n and best practices.  \\n We will use the Keras toolkit for our examples.  \\n Keras takes care of a lot of the heavy-lifting  \\n involved in Deep Learning,  \\n and helps in quickly building robust models.  \\n We also do not cover the math  \\n behind the hyper parameters.  \\n We have omitted deeper topics  \\n for ease of learning.  \\n We also have some simple examples  \\n for getting started  \\n in Deep Learning optimization.  \\n Our goal is to introduce  \\n Deep Learning optimization in a simple fashion,  \\n and help students move forward  \\n with additional advanced learning.  \\n What are the prerequisites for the course?  \\n Students are expected to be familiar  \\n with machine learning concepts and technologies.  \\n Hands-on experience is preferred.  \\n They should also be familiar  \\n with Deep Learning concepts.  \\n They should be familiar with Python programming,  \\n and using Jupiter Notebooks.  \\n We do not cover the usage of Keras  \\n and TensorFlow.  \\n So it is recommended to compliment this course  \\n with those focusing on the use of Keras.  \\n Familiarity with other tools like scikit-learn  \\n are also preferred.  \\n Here is a list of recommended  \\n complementary courses  \\n that would help the students in coding skills  \\n with Deep Learning.  \\n They are Deep Learning Getting Started.  \\n Building and Deploying Applications  \\n with TensorFlow.  \\n And Building Deep Learning Applications  \\n with Keras 2.0.  \\n Let's now get started  \\n with optimizing Deep Learning models.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3053008\",\"duration\":141,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Setting up exercise files\",\"fileName\":\"3003617_en_US_00_03_XR30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"The course requires an environment and exercise files to be set up before they can be used. In this video, explore the course setup.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4685326,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this video,  \\n we will set up the exercise files  \\n and the environment to use in this course.  \\n All course exercises are built using Python 3.8.  \\n We will be using Anaconda and Jupyter Notebooks,  \\n for these exercises.  \\n You can download and install Anaconda  \\n from the website anaconda.com/products/individual  \\n for your specific operating system.  \\n Once downloaded, we will go to the Anaconda UI.  \\n Here, we will create a new virtual environment  \\n called deep learning.  \\n By clicking the create button at the bottom  \\n and providing the name of the environment.  \\n The package we will use is Python 3.8.  \\n This may take some time to set up.  \\n The deep learning environment is set up now.  \\n We will now go back to home.  \\n Choose the deep learning environment on the top,  \\n and then install Jupyter Notebook for that environment.  \\n Jupyter Notebook is installed now  \\n for the deep learning environment.  \\n Open the command prompt window.  \\n Please note that if you're on Windows,  \\n you would want to use the Anaconda command prompt  \\n for the same.  \\n The exercise files for this course have been downloaded  \\n to the folders users, LinkedIn, documents, exercise files.  \\n Please download exercise files on your computer  \\n on a similar folder.  \\n Navigate to this folder on the command prompt,  \\n we can explore these files from the command prompt.  \\n Now let's activate the new virtual environment we created  \\n using the command conda activate deep learning.  \\n Then, we can start the Jupyter Notebook server  \\n using the command Jupyter Notebook.  \\n Please make sure that you are in the same folder  \\n as the exercise files are before using the command.  \\n This command then opens up the Jupyter Notebook  \\n in your browser.  \\n The exercise files and the data files can be seen  \\n in the root directory.  \\n You will use these files in the later exercises.  \\n In the next chapter,  \\n we will discuss the basics of deep learning optimization.  \\n \\n\\n\"}],\"name\":\"Introduction\",\"size\":11685588,\"urn\":\"urn:li:learningContentChapter:3054011\"},{\"duration\":731,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3054005\",\"duration\":100,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"What is deep learning?\",\"fileName\":\"3003617_en_US_01_01_XR30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Deep learning is becoming a popular subset of machine learning. In this video, learn the unique characteristics of deep learning and how it helps in understanding complex behavior.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3284494,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Let's begin the course  \\n by reviewing the concept of deep learning.  \\n What is deep learning?  \\n Deep learning is a field within machine learning  \\n that deals with building and using neural network models.  \\n Neural networks with more than three layers  \\n are typically categorized as deep learning networks.  \\n Neural networks mimic the functioning of a human brain.  \\n They are organized similar to the brain cells  \\n and imitate how humans process data and make decisions.  \\n Deep learning is a field that has seen exponential growth  \\n in the last few years.  \\n While algorithms for neural networks  \\n have existed for some time,  \\n the advances in large scale data processing,  \\n as well as inference technologies, like GPUs,  \\n have spurred their popularity in real-world applications.  \\n Deep learning has been extremely popular  \\n in natural language processing,  \\n as the neural network architectures are ideal  \\n for dealing with unstructured data.  \\n For the same reason,  \\n they are also popular for speech recognition  \\n and synthesis applications.  \\n Image recognition is another domain  \\n where deep learning has made inroads.  \\n Self-driving cars is a leading-edge technology  \\n that is being powered by deep learning.  \\n Applications that require complex learning of behaviors  \\n are usually suited for deep learning.  \\n The applications of deep learning  \\n are getting wide popularity in varied domains,  \\n like customer experience, healthcare, and robotics.  \\n We will explore building optimized models  \\n for such applications in this course.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3053009\",\"duration\":150,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Review of artificial neural networks\",\"fileName\":\"3003617_en_US_01_02_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Neural networks are the key foundation for deep learning. In this video, learn the definition of and structure of a neural network.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5224240,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Before we get into optimization and tuning,  \\n let's review the basic concepts  \\n of Artificial Neural Networks in this video.  \\n An ANN is a network of perceptrons.  \\n We discussed earlier that a perceptron  \\n imitates the human brain cell.  \\n Similar to how a human brain is created  \\n with a network of cells, an ANN is created  \\n with a network of perceptrons.  \\n The perceptron is called a node in the neural network.  \\n We will use node as the term to represent perceptrons  \\n going forward in this course.  \\n Nodes are organized into multiple layers  \\n in a neural network.  \\n A deep neural network usually has three or more layers.  \\n Each node has its own weights,  \\n bias, and activation functions.  \\n Each node is connected to all the nodes  \\n in the next layer, forming a dense network.  \\n The node within a layer are not connected with each other.  \\n There are some exceptions to this  \\n in advanced use cases though.  \\n This diagram shows an example neural network.  \\n Each neural network has one input layer,  \\n one or more hidden layers, and one output layer.  \\n In the input layer, there is one node  \\n for each independent variable.  \\n In this example, there are three.  \\n The hidden layer has three layers for this example.  \\n Layer one has four nodes, layer two has five nodes,  \\n and layer three has three nodes.  \\n The number of layers, and the nodes in each layer,  \\n are determined by experience and trials,  \\n and it will vary from case to case.  \\n The number of nodes in the output layer  \\n will vary based on the type of predictions.  \\n The output layer, in this example, has two nodes.  \\n This arrangement of node represents  \\n the architecture of a given neural network.  \\n How does the ANN work for predictions?  \\n The inputs or independent variables  \\n are sent from the input layer to the network.  \\n Data may be pre-processed before using them.  \\n Inputs are passed on to the next layer.  \\n Each node is a perceptron containing weights,  \\n bias, and an activation function.  \\n The formula is applied on the weights  \\n and the outputs derived.  \\n This repeats for each node in the layer.  \\n The results from all the nodes in a layer  \\n are passed onto the next layer,  \\n and this process is repeated.  \\n As this process reaches the output layer,  \\n the final predictions will be derived.  \\n I highly recommend watching the deep learning  \\n getting started course to discuss these concepts further  \\n if you have already not done so.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3054006\",\"duration\":94,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"An ANN model\",\"fileName\":\"3003617_en_US_01_03_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn the components of an ANN model, parameters, and hyperparameters that are used in building models.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3211960,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] What is a neural network model  \\n and how do we build it?  \\n A neural network model is represented  \\n by a set of parameters and hyperparameters.  \\n The parameters include the weights of weights  \\n and biases for all the notes.  \\n The hyper-parameters includes a number of levers  \\n like layers,nodes in a layer, activation functions,  \\n cost functions, learning rate, and optimizers.  \\n Training An ANN Model means,  \\n determining the right values for these parameters,  \\n and hyperparameters such that it maximizes  \\n the accuracy of predictions for the given use case.  \\n In this course,  \\n we will look at ways to optimize these hyperparameters  \\n to achieve the best results.  \\n How do we train a model?  \\n We use training data like regular machine learning,  \\n where we know both dependent and independent variables.  \\n We will start with a network architecture by intuition.  \\n We also initialize weights and biases to random values.  \\n Then we repeat iterations of applying weights  \\n and biases to the inputs and computing the error.  \\n Based on the error found, we will adjust the weights  \\n and biases to reduce the error.  \\n We keep repeating the process of adjusting weights  \\n and biases until the error gets to an acceptable value.  \\n We will also fine tune the network hyper parameters  \\n to improve training speed and reduce iterations.  \\n Finally, we will save the model as represented  \\n by it's parameters and hyperparameters  \\n and use it for predictions.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3053010\",\"duration\":90,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Model optimization and tuning\",\"fileName\":\"3003617_en_US_01_04_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Hyperparameter tuning is a critical step in deep learning to build effective models. In this video, learn the goals for tuning for both training and inference\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3140791,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Let's start diving deeper  \\n into model optimization and tuning.  \\n We need to tune our models  \\n for both efficiency and effectiveness.  \\n Optimization can be focused on both inference  \\n and training goals.  \\n Let's begin with the inference goals.  \\n What are our goals for inference?  \\n We want better accuracy for our models.  \\n We focus on higher model metrics like F1 scores  \\n as well as avoid variance and bias.  \\n We want to lower inference costs.  \\n We want smaller model sizes  \\n so they can be effectively stored on disk  \\n and loaded into memory.  \\n We want to reduce the time taken for inference.  \\n We also want to lower the resources used during inference,  \\n namely CPU, memory and disks.  \\n Do note that the requirements for better accuracy  \\n and lower costs conflict with each other.  \\n Better accuracy would usually mean higher costs.  \\n So a balance needs to be achieved  \\n so that we get the desired outcomes  \\n at affordable costs for the solution to be cost-effective.  \\n In addition, we also want to optimize the training process.  \\n Training deep learning models  \\n with large amounts of data  \\n may take multiple iterations and long training times  \\n that may run for hours or days.  \\n We want to lower the time to train a model  \\n so we can run more experiments in less time.  \\n We also want to avoid various training pitfalls  \\n like vanishing gradients,  \\n exploding gradients and overfitting.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3053011\",\"duration\":174,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"The deep learning tuning process\",\"fileName\":\"3003617_en_US_01_05_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"A disciplined process is required for making steady progress in tuning models. In this video, learn the process and best practices for tuning deep learning models.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5881699,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Tuning a model should be executed  \\n through an organized process  \\n making sure that experiments are tracked  \\n and the results baselined.  \\n Ad hoc tuning will only lead to ineffective results  \\n in the long term.  \\n We first need to get ready for tuning.  \\n For this, the first step is to set clear goals  \\n on the outcomes.  \\n What are our accuracy or efficiency targets?  \\n Are those reasonable?  \\n We then need to select the training data  \\n and prepare it for experimentation.  \\n It is important to choose datasets  \\n that are balanced across various classes  \\n and cover a wide range of real-world samples.  \\n We should plan for testing and validation of models  \\n with independent data.  \\n Multiple real-life use cases should be covered  \\n and production-like scenarios should be used  \\n for measuring model performance.  \\n What are the key levers available in a deep learning model  \\n that can be experimented with?  \\n We have the network architecture levers  \\n like layers, nodes and weights.  \\n We have multiple activation functions  \\n that can be tried out.  \\n For training, we can control the epochs and batches  \\n to see how we can achieve the desired results  \\n with lower iterations.  \\n Normalization, regularization and optimization techniques  \\n can be tried out  \\n to achieve better model stability and performance.  \\n What are the best practices for running experiments?  \\n Choose one lever or hyperparameter at a time.  \\n Use your understanding, experience and team inputs  \\n to determine a set of values to experiment with.  \\n For example, for activation functions,  \\n you may choose a subset of activation functions  \\n that you find most appropriate to your use case.  \\n Run the experiment with each of the options  \\n and log the results.  \\n Review the results,  \\n and then choose the best options/value.  \\n Once you have experimented with individual levers  \\n and chosen the best options,  \\n try combining these options  \\n and see how the performance improves.  \\n This is an iterative back and forth process  \\n until the desired levels of performance are achieved.  \\n Validate the results with multiple independent datasets  \\n to make sure that you get consistent results.  \\n Before we jump into the various levers available,  \\n there are things we need to remember during experimentation.  \\n There is no one-size-fits-all best option.  \\n Each use case is unique  \\n and different models perform differently  \\n for the same option values.  \\n So if a given option works best for one use case,  \\n do not expect the same for another use case.  \\n The key for optimization is to keep experimenting.  \\n Experiment the first time  \\n when you are building the initial model.  \\n Experiment with multiple independent datasets  \\n to ensure consistency  \\n and repeat the experiments  \\n when new datasets become available  \\n to make sure that the model continues to perform well  \\n and there is no model drift.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3056009\",\"duration\":123,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Experiment setups for the course\",\"fileName\":\"3003617_en_US_01_06_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"A set of common methods are used across experiments in this course. In this video, learn about the common functions and how they help in running experiments.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5457251,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - In order to explore various tuning parameters  \\n and experiment with them,  \\n we have created an experiment setup.  \\n We start with a notebook called  \\n common experiment functions.  \\n In this notebook, we will use the same model  \\n for iris flower identification,  \\n that we explored in the deep learning  \\n getting started course.  \\n We first need to install the required packages  \\n for the exercises if we have already not done so.  \\n Please make sure to run this code,  \\n and check if all required dependencies are satisfied.  \\n Now let's explore the common functions  \\n that we will use throughout the course.  \\n The get data method will load up the data  \\n from iris.csv, pre-process it,  \\n extract the feature and target data sets and return them.  \\n The base model config method,  \\n initializes a set of model hyperparameters.  \\n These are the various parameters  \\n we will experiment with, in this course.  \\n For each parameter, a default value is set.  \\n During the experiment,  \\n we will change one or more of these values,  \\n build models and compare results.  \\n To create and run model method,  \\n we'll use the input model configuration,  \\n feature, and target variables  \\n to create a deep learning model, and build it.  \\n Various hyperparameters that are set up in the config  \\n are used to build the model.  \\n On execution it will collect the results from the epochs,  \\n and return them to the main function.  \\n Finally, the plot graph function  \\n takes in an array of accuracy measures,  \\n and plots them in a graph.  \\n Each experiment has a key and a set of values.  \\n The values are the accuracy measures for each epoch.  \\n The plot shows how the accuracy of the model improves  \\n with each epoch for the given experiment.  \\n Please explore more on these functions to understand  \\n what they do under the wraps.  \\n We will use them in our experiments  \\n in our upcoming chapters.  \\n \\n\\n\"}],\"name\":\"1. Introduction to Deep Learning Optimization\",\"size\":26200435,\"urn\":\"urn:li:learningContentChapter:3052007\"},{\"duration\":755,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3055008\",\"duration\":117,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Epoch and batch size tuning\",\"fileName\":\"3003617_en_US_02_01_XR30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Choosing the right batch size and number of epochs is essential to maintain a balance between model accuracy and performance. In this video, learn best practices for choosing the batch sizes and the number of epochs.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3631459,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Let us begin our optimization journey  \\n with the most common training parameters,  \\n namely batch sizes and epochs.  \\n The general format we will follow  \\n for optimization in this course  \\n would be a quick review of the hyper parameter,  \\n followed by an exercise to try out various values  \\n and see their relative performance.  \\n We will stay away from the background concepts informally.  \\n We recommend additional readings  \\n on these topics to learn more.  \\n What is a batch size?  \\n A batch size represents a set of samples  \\n sent through the ANN in a single pass.  \\n The input data is broken up into multiple batches  \\n and each batch is passed through the network  \\n to obtain predictions and update parameters.  \\n The maximum batch size is the size of the input data  \\n and batch sizes are usually configured in 2 power n values.  \\n If the batch sizes are higher,  \\n it would lead to better GPU utilization  \\n as the samples in a batch can be processed in parallel.  \\n It would also lead to lower training iterations  \\n and possible instability in the gradient descent.  \\n The recommendation is to experiment  \\n with the model to find the right size.  \\n A size of 32 has been found to be  \\n the most optimal for most use cases.  \\n We now look at epochs.  \\n Epochs are the number of times  \\n the entire training set is passed through the network.  \\n Epochs similar to batches will only control  \\n training progress, not inference.  \\n As epochs increase, the gains would taper off  \\n as the model gains accuracy.  \\n An increase can also trigger instability  \\n beyond a certain point.  \\n It is recommended to choose the earliest value  \\n when accuracy stabilizers during the training process.  \\n The recommendation is to figure out  \\n the right number of batches and epochs first,  \\n and then use that for further experimentation.  \\n In the next video,  \\n we will experiment with epochs and batch sizes.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3055009\",\"duration\":181,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Epoch and batch size experiment\",\"fileName\":\"3003617_en_US_02_02_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to run an experiment to compare various values for epochs and batch sizes and analyze how they impact the accuracy of the models.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7028579,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Narrator] Let's run some experiments now.  \\n The code for this chapter  \\n is available in the notebook code-02-XX,  \\n Tuning the Deep Learning Network.  \\n We first import the common experiments functions  \\n into this notebook.  \\n Please be aware  \\n that if you change the common experiments function notebook,  \\n you will have to save that notebook and import it again.  \\n The Epoch and Batch sizes exercise is in section 2.1.  \\n This code is a standard template for all our experiments.  \\n We first initialized the accuracy Mitchell's collection  \\n to empty.  \\n We've done experiments with Batch sizes  \\n ranging from 16 to 128 incrementing by 16.  \\n We'll get the base model configuration  \\n with the default setup for all the values  \\n from the common library.  \\n We will also load up the training data  \\n with the get data method.  \\n Now we set the Epochs to a value of 20.  \\n For all our experiments,  \\n we will anyway capture the output after each Epoch  \\n so we can see the trend for Epochs through this.  \\n We set the Batch size to the iterated value.  \\n We can also create a model name  \\n to use Astra Friends in our output and graphs.  \\n We then run the model  \\n and capture the accuracy performance after each Epoch.  \\n As we iterate for multiple Batch sizes,  \\n we captured the performance for these values.  \\n Let's review the model now.  \\n Looking at the model summary output,  \\n we see that the model remains the same  \\n irrespective of the Batch size chosen.  \\n Next we plot the captured results in a graph.  \\n Looking at the graph, we can see the trends.  \\n The x-axis has Epochs  \\n and the y-axis has accuracy found for that Epoch.  \\n Individual lines are plotted for each Batch size.  \\n Looking into the Epochs,  \\n we see that for lower Epochs  \\n the accuracy starts at a low value,  \\n but increases and stabilizes after a few Epochs.  \\n The value at which the stabilization happens  \\n will vary based on the specific use case  \\n and other model parameters.  \\n Now let's look at Batch size.  \\n For lower Batch size,  \\n we see that the accuracy starts at a much higher range.  \\n This is because there are more iterations  \\n within the Epoch for smaller Batch sizes.  \\n Again the accuracy stabilizes as the Epochs progress.  \\n For this specific use case,  \\n the accuracy range is higher for smaller Batch sizes.  \\n A warning not for all experiments in this course though.  \\n We are using a very small model  \\n with very little training data  \\n so repeating the same experiment  \\n may not provide consistent results.  \\n For real life use cases,  \\n It is recommended to use a good training data set  \\n that can provide repeatable results  \\n across multiple trends of the same experiment.  \\n Once we narrow down these parameters,  \\n we can fix them and use them  \\n for further downstream tuning with other parameters.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3056010\",\"duration\":117,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Hidden layers tuning\",\"fileName\":\"3003617_en_US_02_03_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"The number of layers in an ANN influence both the performance and accuracy characteristics of a model. In this video, learn how to choose the optimal number of layers in a network.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4286137,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Guide] One of the key model architecture hyperparameters  \\n is the number of hidden layers.  \\n Let's explore and experiment with this value in this video.  \\n A neural network can have one or more hidden layers  \\n that learns from training data and builds the model.  \\n As the number of layers increases,  \\n it increases the possibility  \\n of learning complex relationships  \\n between the feature and target variables,  \\n but it will also increase the cost and time needed  \\n for both training and inference.  \\n It also has the risk of overfitting the training set.  \\n A value of two has been found to be sufficient  \\n for simple problems.  \\n It is recommended to increase the number of layers  \\n only based on experimentation  \\n if the set accuracy levels are not achieved.  \\n Otherwise, additional layers will take resources and time  \\n without providing any additional value.  \\n Let's switch to the node book now and look at section 2.3.  \\n In this section, we keep the base model the same  \\n as the previous experiment  \\n and will only vary the number of layers.  \\n The logic is the same as the previous experiment.  \\n We experiment with layer counts of one to five.  \\n Each layer will have 32 nodes.  \\n We again get the base model and training data,  \\n but only chain the hidden nodes list.  \\n Once we create the model,  \\n we see that as the number of layers increases  \\n the number of parameters of the model also increases,  \\n which leads to more resource requirements  \\n to process and store the model.  \\n Let's plot the results and compare.  \\n With a count of one,  \\n the initial accuracies are pretty low,  \\n but they continue to improve as the training goes on.  \\n For a layer count of two,  \\n we see really high accuracy levels  \\n achieved within a few eBooks.  \\n But as the number of layers increases,  \\n accuracy actually starts dropping.  \\n A layer count of two seems optimal for this use case.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3051010\",\"duration\":119,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Determining nodes in a layer\",\"fileName\":\"3003617_en_US_02_04_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"The number of nodes in an ANN layer impacts the outcomes of a model. In this video, learn about characteristics and best practices for choosing the number of nodes in the layer.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4559373,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] We will experiment  \\n with nodes in a layer in this video.  \\n The nodes in a layer are associated  \\n with its corresponding weights and biases,  \\n which in turn represents the learning  \\n from the training data.  \\n As we increase the number of nodes in the layer,  \\n the model has better chances  \\n of learning more about the use case.  \\n It can model complex relationships better.  \\n However, similar to the number of layers,  \\n it will result in more training  \\n and inference resources and time.  \\n It also has the possibility of overfitting the training set.  \\n In general,  \\n between the number of nodes in the input  \\n and the number of nodes in the output.  \\n Do recollect that the number of nodes  \\n in the input layer equals the number  \\n of feature variables in the sample,  \\n and the node count in the output layer  \\n equals the number of classes in the target variable.  \\n Again, start with a low value like 32  \\n and increase it based on experimentation.  \\n Switching to the notebooks now.  \\n The experiment for the number of layers is in section 2.4.  \\n We will use the standard size of two hidden layers  \\n and vary the number of nodes from 8 to 32 in steps of 8.  \\n Once we build and run the model,  \\n we can review the model summary.  \\n From the model summary,  \\n we can see that the number of parameters increase  \\n as the number of nodes increase resulting in bigger models  \\n that would require more and more resources.  \\n Let's proceed to plot the results.  \\n As the number of nodes increase,  \\n there is a general tendency of increase in accuracy  \\n owing to more patterns being captured by additional nodes.  \\n A count of 16 nodes seem to provide  \\n the best accuracy for this use case.  \\n Once again, due to a small dataset,  \\n you may not see consistent results across multiple runs.  \\n For real life use cases do use a big balanced data set  \\n that is sufficient to ensure consistent results  \\n across multiple runs.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3050005\",\"duration\":118,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Choosing activation functions\",\"fileName\":\"3003617_en_US_02_05_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Activation functions determine how the output of a neuron is taken forward in a network. In this video, learn about different activation functions.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4450488,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Activation functions play a key role  \\n in building effective, deep learning networks.  \\n Let's explore the options available in this video.  \\n Activation functions are useful  \\n for both hidden layers and output layers.  \\n And the selection criteria for both is different.  \\n Let's start with hidden layers.  \\n The activation function for hidden layers  \\n depends upon the choice of the problem  \\n and the network architecture.  \\n The choice can also impact the stability  \\n and speed of the gradient descent.  \\n There are a number of algorithms available  \\n for activation functions.  \\n In general, rectified linear units work best  \\n for regular neural networks  \\n and convolutional neural networks.  \\n Sigmoid works best for RNNs.  \\n While these choices are default,  \\n experimentation is necessary to confirm them  \\n for a specific use case.  \\n When it comes to the output layer,  \\n the activation function choice depends upon  \\n the type of machine learning problem.  \\n For binary classification,  \\n sigmoid activation works best for the output layer.  \\n For multi-class classification, softmax is the ideal choice  \\n as it provides probabilities for each class.  \\n For regression problems,  \\n the linear activation function is sufficient.  \\n Let's not run an experiment  \\n for activation functions for the hidden layer.  \\n Code for this experiment is available in section 2.5.  \\n We will experiment with three activation functions,  \\n namely a ReLU, sigmoid, and tanh.  \\n We keep all other hyper-parameters as default.  \\n On reviewing the model summary,  \\n we notice that changing activation functions  \\n do not change the number of parameters.  \\n It actually impacts the values that are created inside them.  \\n On plotting the results,  \\n we see that ReLU and tanh activations  \\n seem to provide similar results in accuracy,  \\n while sigmoid activation lacks behind  \\n for this specific use case.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3054007\",\"duration\":103,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Initializing weights\",\"fileName\":\"3003617_en_US_02_06_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Weights initialization plays a key role in the efficiency and effectiveness of the model building. In this video, learn various options for weights initialization.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3827337,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] While building a model,  \\n the weights and biases of all the nodes  \\n need to be initialized to some value,  \\n and then gradient descent will update them  \\n to get closer to better accuracy.  \\n The initial values of the weights play a huge role  \\n in the speed of learning and the final accuracy achieved.  \\n Multiple initialization techniques exist.  \\n In random normal initialization,  \\n random values are drawn from a standard normal distribution  \\n and used to initialize the weights.  \\n Zeros will initialize all the parameters to zeros,  \\n and ones will initialize them  \\n to the same value of one.  \\n Random uniform will draw values  \\n from a random uniform distribution.  \\n The difference between a normal and a uniform distribution  \\n is that in the case of normal,  \\n more values will be closer to the mean,  \\n while in uniform distribution,  \\n they are evenly spread out.  \\n Overall, random normal works best  \\n for most use cases, and is almost never changed  \\n unless a special need arises.  \\n More advanced and custom initialization functions  \\n are also possible.  \\n Let's jump to the weights initialization experiment now.  \\n We use the initializer list  \\n to have the list of all four techniques.  \\n Keeping the base model settings,  \\n we only change the initialization technique  \\n and compare the results.  \\n On running the code, we can plot the graph and compare.  \\n Random normal and random uniform techniques do very well,  \\n while the ones and zeros have pretty bad results.  \\n This is expected since ones and zeros  \\n will take a much longer time to get closer to ideal values  \\n than starting off with random values.  \\n \\n\\n\"}],\"name\":\"2. Tuning the Deep Learning Network\",\"size\":27783373,\"urn\":\"urn:li:learningContentChapter:3052008\"},{\"duration\":554,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3052005\",\"duration\":143,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Vanishing and exploding gradients\",\"fileName\":\"3003617_en_US_03_01_XR30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Vanishing and exploding gradients impact the learning process during backpropagation. In this video, learn how to control these effects for efficient gradient descent.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4863331,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Building a stable and accurate deep learning model is  \\n reliant upon making steady progress during the  \\n backpropagation process, to achieve accurate results.  \\n In this chapter,  \\n we will explore various options to manage backpropagation.  \\n What problems are occurring backpropagation?  \\n Let's explore in this video.  \\n Let's review the gradient descent process to begin with.  \\n After forward propagation,  \\n we compute the error in prediction,  \\n between the estimated and actual target values.  \\n Then based on that error,  \\n we compute a Delta value and update the output layer.  \\n We then derive under the Delta value  \\n from this layer and update the previous layer.  \\n And this goes on until the first hidden layer.  \\n The values of the Delta's computed, should help adjust  \\n the weights and biases in such a way,  \\n so that additional iterations through the model will  \\n progressively reduce the error.  \\n There should allow for stable progression  \\n in gradient descent.  \\n If the values are too small,  \\n then there won't be any significant change in the rates,  \\n so subsequent forward propagation will end up  \\n with the same error and smaller Delta values.  \\n This causes decay and the gradient descent will stall.  \\n This is called vanishing gradients.  \\n On the other hand if the deltas are too big,  \\n it will cause significant change in the weights.  \\n This leads to a choppy gradient descent,  \\n and the added value will fluctuate, but will never converge.  \\n This is called exploding gradients.  \\n This graph illustrates the differences.  \\n The light green line is the target line.  \\n The blue line is a good gradient descent,  \\n which progressively gets closer to the target line.  \\n The yellow line decays,  \\n and does not get closer to the target at all.  \\n This is vanishing gradient.  \\n The dark green line shows exploding gradients,  \\n but it oscillates around the targets,  \\n but never gets closer to it.  \\n Vanishing and exploding gradients is an important problem  \\n to watch for and address during the deep learning process.  \\n The right weight initialization technique  \\n needs to be used for the problem,  \\n so the weight start with optimal values.  \\n Activation functions can impact gradient descent,  \\n so the right activation function  \\n needs to be chosen after experimentation.  \\n Finally, there is a technique of batch normalization  \\n that can be applied.  \\n We will discuss batch normalization in the next video.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3050006\",\"duration\":109,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Batch normalization\",\"fileName\":\"3003617_en_US_03_02_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Normalization helps to normalize the contribution of each input feature and reduces bias. In this video, learn how normalization works and how it helps in deep learning.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4612280,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Batch Normalization is an important technique  \\n to manage vanishing and exploiting gradients  \\n during gradient descent.  \\n In Batch Normalization,  \\n we normalize the inputs sent to each hidden layer.  \\n When we see normalize,  \\n we actually use the StandardScaler model  \\n to center and scale the weights and biases.  \\n For normalization,  \\n the values of the outputs of the hidden layer  \\n are considered for computing the mean  \\n and standard deviation.  \\n Even if the delta updates and activation function  \\n scale down or scale up the values,  \\n this step will normalize the inputs to be of the same scale.  \\n Batch Normalizations help achieve higher accuracies  \\n with lower epochs, hence is also an optimization technique.  \\n On the other hand,  \\n it can result in additional computations  \\n during training and inference  \\n and may increase resource utilization and execution times.  \\n The experiments for this chapter,  \\n are available in the notebook,  \\n 03_XX Tuning Back Propagation.  \\n Let's explore the Batch Normalization technique  \\n in section 3.2.  \\n Here, we use two Batch Normalization options,  \\n none and batch, and use that to run our experiments.  \\n Switching to the common experiments function notebook,  \\n we see that we add Batch Normalization as a layer  \\n between the hidden layers.  \\n Switching back, we build and run the model.  \\n If you look at the model summaries,  \\n we see that for the model with batch,  \\n an additional layer has been added for Batch Normalization.  \\n We then proceed to plot and examine the results.  \\n We see that for the model with Batch Normalization,  \\n higher accuracy levels are achieved with smaller epochs.  \\n This is because Batch Normalization  \\n controls the gradient descent  \\n and makes it move closer to the center.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3056011\",\"duration\":85,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Optimizers\",\"fileName\":\"3003617_en_US_03_03_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Optimizers update the weights in an ANN in order to minimize loss and lead it towards accurate predictions. In this video, learn about the role of optimizers in deep learning.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2726925,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Optimizers are key tools,  \\n that help gradient descent, achieve faster results.  \\n The regular gradient descent process, is painfully slow  \\n and takes a lot of time to achieve the desired results.  \\n Consider a situation, where the training dataset  \\n has hundreds of thousands of samples,  \\n and the model has multiple layers.  \\n Training would take hours to run  \\n and consume significant resources,  \\n especially ,if you are using GPUs in the cloud.  \\n Limited training data,  \\n will also impact the speed of descent.  \\n Optimizers are algorithms,  \\n that help speed up the training process.  \\n Introduced during back propagation,  \\n they will adjust the delta values in each step,  \\n such that it prevents vanishing and exploding descent  \\n while inching the parameter adjustments,  \\n closer to the desired states.  \\n There are a number of optimizers available  \\n in the deep learning world,  \\n and we can also write a custom optimizer.  \\n The most popular ones include SGD  \\n or stochastic gradient descent,  \\n RMSprop, Adam and Adagrad.  \\n We are not going to discuss the internals informally  \\n for each of these algorithms in this course,  \\n but it's recommended for additional reading.  \\n The deep learning libraries like Keras and TensorFlow,  \\n support these popular ones after the box.  \\n So, we simply need to provide the option  \\n during the training process.  \\n In the next video, we will run an experiment for optimizers.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3056012\",\"duration\":73,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Optimizer experiment\",\"fileName\":\"3003617_en_US_03_04_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to run an experiment with various optimizers to understand how they impact learning in an ANN, as well as plot results and compare the outcomes.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3018935,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Having learnt about optimizers  \\n in the previous video,  \\n let's run an experiment to compare  \\n the performance of various optimizers  \\n for the iris example.  \\n Here in the optimizer list,  \\n we have chosen 'agd', 'rmsprop', 'adam' and 'adagrad'.  \\n We build and run the model  \\n for each of these optimizer functions.  \\n Switching to the common experiment function notebook,  \\n there is a get_optimizer function  \\n that sets up the optimizer based on the option provider.  \\n A parameter called 'learning_rate' is also passed,  \\n which we will explore in the next video.  \\n When we compile the model.  \\n We provide the optimizer options  \\n to be used for training.  \\n Switching back to the experiment,  \\n let's run the experiment and review the results.  \\n The model definitions themselves don't change  \\n for different optimizers,  \\n but they merely impact the values  \\n of the parameters adjusted.  \\n When we run the graph,  \\n we see that for this use case,  \\n all optimizers except adagrad,  \\n perform reasonably well  \\n and provide good accuracy at lower ebooks.  \\n Again, the recommendation is to experiment  \\n and choose the right optimizer for the problem.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3051011\",\"duration\":71,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Learning rate\",\"fileName\":\"3003617_en_US_03_05_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Learning rate impacts the speed of learning in a neural network as well as helps control vanishing and exploding gradients. In this video, learn how the learning rate works with optimizers during backpropagation.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2368508,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Associated with the optimizers,  \\n is a hyper parameter called the learning rate.  \\n Learning rate is the rate at which the weights will change  \\n in response to the estimated error.  \\n It is the speed at which the model is expected to learn  \\n from the training data and adjust its weights.  \\n Learning rates work in conjunction with the optimizer.  \\n After computing the deltas,  \\n the optimizer will adjust the delta values  \\n based on the learning rates.  \\n Learning rates are numeric values in the sub decimal ranges.  \\n How do we select the right learning rate for the problem?  \\n If the learning rate value is large,  \\n it will adjust the values too fast.  \\n This means the model can learn faster with a few epochs.  \\n At the same time, there is the risk of exploding gradients,  \\n as big adjustments to the weights,  \\n will cause the gradient to be choppy.  \\n If the value is small, then the learning would be slower,  \\n but at a steady pace with minimal chopping.  \\n But if the value gets too small,  \\n it will result in vanishing gradients,  \\n as the deltas may not be big enough to reduce the error.  \\n Again, the value should be chosen based on experimentation  \\n for this specific use case.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3054008\",\"duration\":73,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Learning rate experiment\",\"fileName\":\"3003617_en_US_03_06_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to run an experiment to try various values for learning rates and compare how increasing learning rates impact the overall learning process.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2899979,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] We will now explore  \\n the learning rate experiment in the section 3.6  \\n of the notebook for Back Propagation.  \\n We are going to experiment with multiple values  \\n of learning rate, namely 0.001, 1.005, 0.01, 0.1 and 0.5.  \\n We will build the models for all these learning rates.  \\n Switching to the common experiment functions.  \\n The learning rate is passed as a parameter  \\n while initializing the optimizer for the model.  \\n Switching back let's build and run these models  \\n and plot the graphs to review  \\n the results for learning rates.  \\n For a low value of 0.001.  \\n We see that the model settles for a low accuracy value,  \\n increasing it to 0.005  \\n and 0.01 results in better accuracies,  \\n and this may be the ideal values for the model.  \\n Moving to 0.1 while the model gets near  \\n the previous accuracies,  \\n it is also choppy as it oscillates a lot.  \\n The value of 0.5 also results in oscillations,  \\n while the average accuracy is lower.  \\n We need to choose a learning rate  \\n that achieves higher accuracies  \\n while also making steady progress in accuracy across eBooks.  \\n \\n\\n\"}],\"name\":\"3. Tuning Back Propagation\",\"size\":20489958,\"urn\":\"urn:li:learningContentChapter:3056016\"},{\"duration\":327,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3052006\",\"duration\":109,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Overfitting in ANNs\",\"fileName\":\"3003617_en_US_04_01_XR30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Overfitting is a common problem in machine learning that needs to be addressed to build stable models. In this video, learn solutions for avoiding overfitting in neural networks.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3568949,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Overfitting is one of the main problems  \\n in building optimize models in machine learning.  \\n In this chapter,  \\n we will explore various options in controlling overfitting  \\n while building deep learning networks.  \\n What is overfitting?  \\n overfitting happens when a model adapts itself  \\n to suit this training data.  \\n It overfits the training data.  \\n When overfitting happens,  \\n a model will perform with very high accuracy  \\n when predicting against the training samples  \\n also known as in sample testing,  \\n but when predicting against independent data samples  \\n that are not in the training data,  \\n the accuracy levels would be low.  \\n Neural networks have a tendency to overfit  \\n when the models are too deep  \\n and have more than the required number of nodes.  \\n How do we take care of overfitting?  \\n A number of solutions are available.  \\n To begin with,  \\n we should focus on simpler models  \\n with smaller number of layers and nodes in a layer.  \\n It is highly recommended to start with small numbers  \\n and only increase them  \\n when accuracy against the best data is low.  \\n Also epochs and batch sizes should be controlled  \\n and the same recommendation of starting small  \\n and increasing as required holds good for them too.  \\n Another area to focus is on training data variety,  \\n the training data should have sufficient variety  \\n to cover a large number of real world occurrences.  \\n It should be sufficiently large for the model to learn.  \\n For a classification,  \\n there also needs to be a balance between various classes  \\n in the training data.  \\n Each class should be represented sufficiently  \\n in the training data set.  \\n In addition, there are two other techniques available,  \\n namely regularization and dropouts.  \\n We will discuss these two techniques in detail  \\n in the following videos.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3056013\",\"duration\":51,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Regularization\",\"fileName\":\"3003617_en_US_04_02_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Regularization helps avoid overfitting in deep learning models. In this video, learn its properties and applications in deep learning.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1696439,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Kumaran] Regularization is an important technique  \\n for managing overfitting in neural networks.  \\n Regularization controls overfitting during model training.  \\n How does it work?  \\n Regularization algorithms provide an adjustment  \\n to the model parameters after they are updated.  \\n The adjustment reduces the variance in the model  \\n by providing a penalty when overfitting increases.  \\n There are multiple algorithms available for regularization,  \\n the most popular being L1, L2, and L1 and L2 combined.  \\n We are not going to discuss these algorithms in detail,  \\n but I recommend it for additional reading.  \\n They are already implemented  \\n in popular machine learning libraries.  \\n We can specify a regularizer  \\n when creating a hidden layer in Keras.  \\n We will compare these options in the next video.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3056014\",\"duration\":51,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Regularization experiment\",\"fileName\":\"3003617_en_US_04_03_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to run an experiment to try various regularizers and compare how these choices help in avoiding the overfitting of the model.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1811468,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] The code for experiments in this chapter  \\n are available in the notebook,  \\n Code_04_XX Overfitting Management.  \\n The regularization experiment is in section 4.3.  \\n Here, we are going to compare three options,  \\n L1, L2, and L1_L2.  \\n We parse them as options  \\n when creating hidden layers in Keras.  \\n Note that we are comparing validation accuracy  \\n for overfitting experiments.  \\n Let's run the experiment and review the results.  \\n L2 seems to perform better than other algorithms  \\n for this use case.  \\n For the IDs dataset, the validation dataset is very small,  \\n so repeated runs may not have consistent results.  \\n In real world experiments,  \\n it is recommended to have a larger validation set  \\n to achieve consistent results across multiple runs.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3055010\",\"duration\":59,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Dropouts\",\"fileName\":\"3003617_en_US_04_04_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Dropouts are an interesting technique that helps manage overfitting during training. In this video, learn the principles behind dropouts during training.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1860109,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Another popular technique used  \\n to reduce over fitting is called dropouts.  \\n Dropout works during forward propagation.  \\n By default, during forward propagation,  \\n the output of each node in the layer is sent to every node  \\n in the next layer.  \\n When using dropout,  \\n the outputs of some of the nodes  \\n in the layer are dropped randomly.  \\n During training,  \\n we can provide a percentage value  \\n to control the number of nodes being dropped.  \\n Dropping nodes randomly tends to result  \\n in focusing on feature values  \\n that have a high influence on the outcomes.  \\n But dropouts can also negatively impact the model  \\n if they drop relevant nodes  \\n that model important features.  \\n Try dropouts if you see symptoms of over fitting  \\n and use a percentage that provides the similar accuracy  \\n for both training and test data.  \\n Sometimes having no dropouts  \\n may provide the best results too.  \\n In the next video,  \\n we will experiment with dropouts.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3055011\",\"duration\":57,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Dropout experiment\",\"fileName\":\"3003617_en_US_04_05_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to run an experiment to try various values for dropouts and about their impact on model accuracy and overfitting.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2309645,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] We will now run the exercise for dropouts  \\n in section 4.5 of the notebook.  \\n Here, we choose multiple dropout values.  \\n 0%, 10%, 20%, and 50%.  \\n We then build and run the models for each of them.  \\n Switching to the Common_Experiments_Function notebook,  \\n we see that a dropout layer will be added  \\n between hidden layers  \\n if a percentage is set.  \\n Switching back, let's run the models  \\n and compare the validation accuracies.  \\n Let's also plot the graph and examine the results.  \\n To begin with, when a dropout is added,  \\n we see a dropout layer in the model summary.  \\n Looking at the graph,  \\n a dropout percentage of 10% seemed  \\n to provide the best results for this specific use case.  \\n As discussed in the previous video,  \\n dropouts can help or hurt a model.  \\n In this case, a dropout of 10% seems to be the right value.  \\n \\n\\n\"}],\"name\":\"4. Overfitting Management\",\"size\":11246610,\"urn\":\"urn:li:learningContentChapter:3054012\"},{\"duration\":529,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3056015\",\"duration\":235,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Tuning exercise: Problem statement\",\"fileName\":\"3003617_en_US_05_01_XR30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"In this video, explore an end-to-end use case for deep learning optimization example and review the input data and desired outcomes.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8008078,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Having now discussed various tuning options available  \\n for deep learning networks,  \\n let's put them into practice to tune a neural network.  \\n I would again like to caution that the results would vary  \\n based on the use case being executed,  \\n and consistency of results across multiple trends  \\n would be impacted by the amount of training data.  \\n In this course, we use smaller datasets  \\n for demonstration purposes.  \\n This is an exercise that the students  \\n are encouraged to attempt on their own,  \\n and then come back to the following videos  \\n to look at solutions.  \\n There are multiple ways to solve the problem,  \\n and what is presented here, is one such example.  \\n This is the same exercise that was provided  \\n in the deep planning getting started course,  \\n and we will continue to improve the basic model  \\n we built in that course.  \\n The use case to solve relates to root cause analysis  \\n of problems found in our data center.  \\n We have a data center  \\n that runs a number of software services.  \\n Service failures do happen from time to time,  \\n and the data center team needs to look  \\n to quickly troubleshoot and identify the root cause.  \\n The team wants to build a model that can predict root causes  \\n reported by customers based on telemetric, regenerated,  \\n and errors noticed.  \\n They already have a system monitoring tool  \\n that tracks CPU, memory,  \\n and application latency characteristics of their servers.  \\n In addition, they also track errors reported  \\n by their applications.  \\n Can we use this information to predict root causes  \\n of these issues?  \\n This is the same problem we discussed in the Deep Learning,  \\n Getting Started Course.  \\n The problem statement is as follows,  \\n using data about CPU load, memory load, network delays,  \\n and four types of errors observed,  \\n build a deep learning model  \\n to predict the root cause of the error,  \\n then optimize the model performance using various techniques  \\n described in the course.  \\n A dataset is available that has one record  \\n for each of the incident,  \\n indicating if any of the load issues or errors were noticed  \\n when the problems happen.  \\n This is the CSV file with the data available,  \\n the file called root cause analysis.CSV  \\n available in the exercises folder.  \\n Each record in the file has a unique identifier called ID  \\n that represents the Incident.  \\n There are seven feature variables, namely,  \\n CPU load, memory load, delay, Error_1000, Error 1001,  \\n Error_1002 and Error_1003.  \\n Each of them is a bullion value of one or zero.  \\n The target variable is root cause.  \\n It has three possible values, memory leak, network delay,  \\n and database issue.  \\n We need to build a model to predict the root cause  \\n based on the other values provider.  \\n For the optimization,  \\n the following hyper-parameters need to be optimized.  \\n First, determine the ideal number of layers  \\n needed for the model,  \\n then determine the ideal number of nodes for each layer,  \\n using the number of layers determined before.  \\n Next, tune the backpropagation process.  \\n First select the best optimizer for the problem,  \\n then, using the optimizer selected,  \\n find the best learning rate for the problem.  \\n Please use batch normalization for this purpose,  \\n then reduce overfitting,  \\n by identifying the best regularization algorithm  \\n for the problem.  \\n Identify the best dropout rate  \\n while using the regularization that you have chosen.  \\n Finally assemble all the hyper-parameters selections  \\n based on the individual experiments,  \\n and create a consolidated model with all of them.  \\n Compare its performance against the default settings  \\n to see if overall improvement is obtained.  \\n While the exercise requires only a few experiments,  \\n feel free to experiment with more parameters,  \\n and combinations of them and see how the model performs.  \\n Best of luck for the exercise.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3054009\",\"duration\":51,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Acquire and process data\",\"fileName\":\"3003617_en_US_05_02_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to prepare input data required for the exercise use case and create a reusable method that can be used for multiple experiments in the exercise.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2328589,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] The code for this exercise  \\n is available in the notebook code_05_XX  \\n Incident Root Cause Analysis.  \\n We will start with acquiring and processing the data  \\n for root cause analysis in section 5.2.  \\n For this purpose,  \\n we have created a method called get_rca_data.  \\n This will load up the root cause analysis CSV file.  \\n It will then use the label encoder  \\n to encode the target variable.  \\n We then convert the data set to a numpy array  \\n and separate the feature and target variables  \\n into separate arrays.  \\n The arrays are then returned to the main function.  \\n For building the model and plotting the graphs,  \\n we will continue to use the common experiment functions.  \\n So we will import this notebook at the beginning.  \\n For each of these experiments,  \\n we will follow the same template  \\n that we discussed earlier in the course.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3050007\",\"duration\":62,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Tuning the network\",\"fileName\":\"3003617_en_US_05_03_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to tune the network architecture iteratively to improve outcomes and review results and their implications.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2597217,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - We begin our optimization exercise,  \\n by tuning the number of layers,  \\n in the network.  \\n This is available in section 5.3 of the notebook.  \\n We will start with 32 nodes in a given layer,  \\n which we will anyway tune later in this video.  \\n Then we build a model,  \\n with layer counts one to five.  \\n Then we plot the accuracy values and compare.  \\n Let's review the results from the results.  \\n From the result seen,  \\n two layers seem to provide the highest accuracy level,  \\n at lower HIPO counts,  \\n and we will choose that value for the model.  \\n Next, we move on to nodes in a layer.  \\n Here, we will try nodes counts  \\n from eight to 32,  \\n in increments of eight.  \\n We will use two hidden layers,  \\n which is the value we selected earlier.  \\n We'll then build the model,  \\n and compare its performance.  \\n A node count of 32,  \\n seems to achieve,  \\n higher levels of accuracy,  \\n earlier in the training process.  \\n So we will choose 32.  \\n We will go with a layer count of two,  \\n and 32 nodes in each layer.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3053012\",\"duration\":50,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Tuning backpropagation\",\"fileName\":\"3003617_en_US_05_04_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to tune the backpropagation process by trying different optimizers, reviewing results, and choosing the best option.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2070710,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Kumaran] We will tune the optimizers  \\n and learning rate for the root cause analysis model  \\n in this video.  \\n Let's start with optimizers.  \\n We will try with all the four popular optimizers,  \\n namely SGD, RMSprop, Adam, and AdaGrad.  \\n Let's run the experiment and review the results.  \\n Other than AdaGrad,  \\n all other optimizers seem to perform equally.  \\n We will go with RMSprop.  \\n It could have been any of the other two, too.  \\n Next, we go to learning rates.  \\n We will experiment with five values, as shown here.  \\n Let's run the experiment and compare the results.  \\n The smaller three values seem to provide  \\n equal and best results.  \\n So we will choose RMSprop for optimizer  \\n and 0.001 for learning rate for this exercise.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3049166\",\"duration\":50,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Avoiding overfitting\",\"fileName\":\"3003617_en_US_05_05_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn techniques to avoid overfitting in the model and how to choose the best options for the specific use case.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2027873,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Let's jump to choosing  \\n regularizers and dropouts  \\n in this video.  \\n We will experiment with four values  \\n for the regularizer namely none,  \\n L1,  \\n L2 and L1 _ L2.  \\n Let's run the experiment and review the results.  \\n Both none and L2  \\n seems to provide equivalent performance  \\n and if we run the experiment multiple times,  \\n we will see that they switch lead positions.  \\n We will go with L2 in this case.  \\n Next we move to dropouts.  \\n We will experiment with four values,  \\n namely 0%, 10%, 20% and 50%.  \\n Running these experiments,  \\n we see a dropout of 20%  \\n provide slightly better results.  \\n So we will choose L2 for regularization  \\n with a dropout rate of 0.2.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3051012\",\"duration\":81,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Building the final model\",\"fileName\":\"3003617_en_US_05_06_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to consolidate all the results of tuning, create a final model, and compare the tuned model's performance with the baseline model.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2946744,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Now that we have experimented  \\n with individual hyperparameters  \\n and decided on suitable values for each of them,  \\n let's put them all together into a single model and compare.  \\n Here, we first create the base minimal model  \\n with all the default values.  \\n We create and run this model and measure its accuracy.  \\n Then, we create a model  \\n with all the optimizations we have done  \\n and then measure its accuracy too.  \\n We will compare them in a graph.  \\n Looking at the graph,  \\n we see that the optimized model performs better.  \\n It was able to achieve higher levels of accuracy  \\n earlier in the epoch iterations.  \\n One warning I want to provide here though,  \\n this is a grossly simplified example  \\n with a small amount of training data.  \\n Repeating the experiment may not provide the same results.  \\n Also, while a hyper parameter value  \\n may perform well in an isolated experiments,  \\n it may perform badly  \\n if combined with certain values of other hyperparameters.  \\n So, this is a trial and error process in the real world,  \\n and it may take days or even weeks  \\n to find the right combination of these parameters.  \\n The goal of this course is to discuss the levers,  \\n process and template for running such experiments  \\n that you can take and use in your use cases.  \\n \\n\\n\"}],\"name\":\"5. Model Tuning Exercise\",\"size\":19979211,\"urn\":\"urn:li:learningContentChapter:3052009\"},{\"duration\":40,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3054010\",\"duration\":40,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Continuing your deep learning journey\",\"fileName\":\"3003617_en_US_06_01_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, explore the next steps to take after completing this course.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1476279,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Kumaran] Now that you have learned about the concepts  \\n and processes for optimizing deep learning models,  \\n you can take your learning even further.  \\n Explore additional topics in deep learning,  \\n including convolutional neural networks  \\n and recurrent neural networks.  \\n Analyze a deep learning problem in your work area  \\n and build a deep learning model to solve it.  \\n Optimize the deep learning problem  \\n with learnings from this course.  \\n Learn about scaling  \\n and serving machine learning models in production.  \\n Data always intrigues me.  \\n I bet it intrigues you too,  \\n so let's keep exploring it  \\n and find better ways of extracting knowledge out of it.  \\n \\n\\n\"}],\"name\":\"Conclusion\",\"size\":1476279,\"urn\":\"urn:li:learningContentChapter:3056017\"}],\"size\":118861454,\"duration\":3262,\"zeroBased\":false},{\"course_title\":\"Full-Stack Deep Learning with Python\",\"course_admin_id\":3095447,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":3095447,\"Project ID\":null,\"Course Name\":\"Full-Stack Deep Learning with Python\",\"Course Name EN\":\"Full-Stack Deep Learning with Python\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"If you seek a more in-depth understanding of deep learning and Python, this hands-on course can help you. In this course, certified Google cloud architect and data engineer Janani Ravi guides you through the intricacies of full-stack deep learning with Python. After a review of full stack deep learning, MLOps, and MLflow, dive into setting up your environment on Google Colab and running MLflow. Learn how to load and explore a dataset, as well as how to log metrics, parameters, and artifacts. Explore model training, evaluation, and hyperparameter tuning. Plus, go over model deployment and predictions.\",\"Course Short Description\":\"Increase your knowledge and get a hands-on understanding of full-stack deep learning with Python.\",\"Content Type\":\"SKILLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":20161004,\"Instructor Name\":\"Janani  Ravi\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"Certified Google Cloud Architect and Data Engineer\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2024-02-06T00:00:00\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"Yes\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/full-stack-deep-learning-with-python\",\"Series\":\"Advanced\",\"Limited Series\":null,\"Manager Level\":\"Individual Contributor\",\"LI Level\":\"Advanced\",\"LI Level EN\":\"Advanced\",\"Sensitivity\":null,\"Internal Library\":\"Technology\",\"Internal Subject\":\"Artificial Intelligence for Technology\",\"Primary Software\":\"Python\",\"Media Type\":\"Video\",\"Has CEU\":\"No\",\"Has Exercise Files\":\"Yes\",\"Visible Duration\":7081.0,\"Visible Video Count\":25.0,\"Contract Type\":\"INSTRUCTOR_PRODUCTION\"},\"sections\":[{\"duration\":443,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3854102\",\"duration\":405,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Full-stack deep learning, MLOps, and MLflow\",\"fileName\":\"3095447_en_US_00_01_VT\",\"demo\":true,\"videoCreationMetadata\":{\"rawDurationSeconds\":405,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"In this video, discover the steps involved in full-stack deep learning and how MLOps and an integral part of this workflow.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9849076,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Hi, and welcome to this course  \\n on full-stack deep learning.  \\n In this movie,  \\n the role of MLOps in full-stack deep learning,  \\n and how we can implement MLOps using  \\n the MLflow framework.  \\n But first, what is full-stack deep learning?  \\n Full-stack deep learning refers  \\n to the comprehensive understanding,  \\n and expertise in all components  \\n and stages of building and deploying deep learning systems.  \\n These components include everything  \\n in the deep learning lifecycle,  \\n data collection and pre-processing, model development,  \\n training, hyperparameter tuning,  \\n deployment, and monitoring.  \\n A full-stack deep learning practitioner  \\n is proficient in both the technical,  \\n and practical aspects of each of these stages.  \\n Everything that's involved in getting deep learning systems  \\n from prototype to production.  \\n As you might imagine,  \\n full-stack deep learning is a very vast topic  \\n and really not something that you would cover  \\n in a single course.  \\n Full-stack deep learning is something  \\n that you would typically cover over the course of a semester  \\n at a university.  \\n Here are the steps involved in full-stack deep learning.  \\n The first step is planning and project setup.  \\n This is where you figure out what model you want to build.  \\n Data collection and labeling,  \\n getting the data to train your model.  \\n Then we have model training and debugging.  \\n And then finally, deploying, testing,  \\n and maintenance of models.  \\n Let's quickly discuss what's involved  \\n in each of these phases.  \\n Project planning and setup is the initial phase  \\n where we define the project's goals, allocate resources,  \\n and choose the necessary tools  \\n and frameworks that we are going to use in every step.  \\n This is where you'll establish the project environment,  \\n set up version control,  \\n and ensure that you have the infrastructure in place  \\n for all of the steps coming up next.  \\n Once you've figured out what kind of problem  \\n you're going to solve with your deep learning model,  \\n you move on to data collection and labeling.  \\n This is where you'll gather  \\n and pre-process the data required for training your model.  \\n You'll clean and format the data, annotate it if needed,  \\n label it, and get things ready for model development.  \\n Maybe you'll even split your data into training, validation,  \\n and test sets.  \\n You'll then pick the right kind of model for your data,  \\n whether it's regression, classification,  \\n or some other kind of model.  \\n You'll design the architecture of your neural network  \\n and its layers train the model on the data,  \\n monitor the performance of the model,  \\n maybe perform hyperparameter tuning  \\n to get just the right structure for your model,  \\n fine-tune the model,  \\n adjust hyper parameters  \\n and essentially get the model ready for deployment.  \\n Once your model is deployed, well,  \\n that's really just the beginning.  \\n This is where you're constantly evaluating your model  \\n in production, monitoring it and maintaining it,  \\n and possibly retraining it on new data.  \\n Machine learning models require constant updates  \\n so that they continue to perform well in the real world.  \\n Full-stack deep learning is not just about taking models  \\n from planning and project setup through to deployment.  \\n It's an iterative process.  \\n You may need to constantly go back to previous stages  \\n in this process in order to refine and improve your model.  \\n As you can see, full-stack deep learning involves  \\n the entire lifecycle of a deep learning model.  \\n It's a very vast topic,  \\n and it's hard to cover everything in a single course.  \\n A really integral part of full-stack deep learning is MLOps,  \\n and that's the part that we are  \\n going to focus on in this course.  \\n MLOps, short for machine learning operations,  \\n is a set of practices and tools that aims to streamline  \\n and automate the end-to-end machine learning life cycle.  \\n It bridges the gap between the development  \\n of machine learning models  \\n and their deployment into production environments.  \\n The term MLOps comes from the term DevOps  \\n because MLOps borrows several concepts  \\n from development operations  \\n and applies them specifically  \\n to the machine learning workflow.  \\n Here are some important components and concepts in MLOps.  \\n The first is version control.  \\n Just like in software development,  \\n MLOps emphasizes the importance of version control  \\n for machine learning code, data, and even models.  \\n MLOps incorporates continuous integration  \\n to automatically build, test,  \\n and validate machine learning models  \\n and code changes whenever new code is committed,  \\n or new data is available.  \\n MLOps also incorporates continuous delivery,  \\n or continuous deployment,  \\n automating the deployment of machine learning models  \\n into production or staging environments  \\n without manual intervention.  \\n MLOps includes techniques  \\n for packaging machine learning models  \\n into containers or other deployment-ready formats,  \\n making it easier to deploy  \\n and manage models consistently across environments.  \\n Ongoing monitoring and logging of deployed models are also  \\n very important for detecting performance issues, data drift,  \\n and model degradation.  \\n Another key concept in MLOps is model versioning.  \\n Keeping track of different versions of ML models,  \\n along with their associated data and configurations,  \\n is important for reproducibility and auditing.  \\n There are several tools that come together to enable  \\n the MLOps workflow,  \\n and an important tool amongst these is MLflow.  \\n MLflow is an open-source platform  \\n for managing the machine learning lifecycle,  \\n designed to simplify and streamline the end-to-end process  \\n of developing, training,  \\n and deploying machine learning models.  \\n MLflow was developed by Databricks  \\n and is now part of the Linux Foundation.  \\n MLflow covers two important steps  \\n in the full-stack deep learning workflow,  \\n model training and hyperparameter tuning,  \\n and model deployment and serving.  \\n MLflow helps you with model tracking.  \\n You can log and track experiments and model runs.  \\n You can record parameters, metrics,  \\n and artifacts associated  \\n with your different model executions.  \\n MLflow enables you to package your machine learning code  \\n into projects, which is just a directory containing code,  \\n data, and specification files, defining dependencies  \\n and entry points,  \\n making it easier to organize and manage your ML code.  \\n MLflow also allows you to package  \\n and share machine learning models in a standardized format.  \\n It offers a centralized model registry,  \\n making model versioning and management easy.  \\n And finally, it contains everything  \\n that you need for deploying  \\n your model locally or on the cloud.  \\n In this course,  \\n we'll focus on understanding  \\n and we'll get hands-on with MLflow for tracking experiments  \\n runs packaging models,  \\n and deploying models on our local machine.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3852088\",\"duration\":38,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Prerequisites\",\"fileName\":\"3095447_en_US_00_02_VT\",\"demo\":true,\"videoCreationMetadata\":{\"rawDurationSeconds\":38,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"In this video, discover the prerequisites that you need for this course.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":884753,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Before we get into the course content,  \\n let's take a quick look at the pre-reqs that you need  \\n to have for the hands-on demos in this course.  \\n This course is not one for beginners.  \\n I expect that you fully understand the fundamentals  \\n of machine learning.  \\n I also expect that you're comfortable programming in Python  \\n and using Python libraries.  \\n And finally, I expect that you have some experience  \\n with building and training neural network models in PyTorch.  \\n The hands-on demos in this course will use  \\n cloud-hosted notebooks on Google Colab  \\n and will be training a deep learning model  \\n using PyTorch Lightning.  \\n \\n\\n\"}],\"name\":\"Introduction\",\"size\":10733829,\"urn\":\"urn:li:learningContentChapter:3859100\"},{\"duration\":1538,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3855187\",\"duration\":365,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Introducing full-stack deep learning\",\"fileName\":\"3095447_en_US_01_01_VT\",\"demo\":true,\"videoCreationMetadata\":{\"rawDurationSeconds\":365,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"In this video, gain a big-picture understanding of the full-stack deep learning workflow.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7982571,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In the earlier movie,  \\n we've already discussed a little bit about  \\n what Full Stack Deep Learning is all about.  \\n In this movie, I'll just go a little bit deeper.  \\n Full Stack Deep Learning covers the entire lifecycle  \\n of a deep learning model,  \\n right from its conceptualization,  \\n its prototyping, its development,  \\n all the way through to deployment and maintenance.  \\n The steps involved here are iterative in nature,  \\n which means you might come to a step  \\n such as model training and debugging,  \\n realize that your project planning  \\n and setup maybe wasn't correct,  \\n you need to change the technologies that you're using.  \\n You'd go back to a previous step  \\n and iterate and improve upon the model.  \\n The very first step is, of course,  \\n figuring out what you're going to build,  \\n that is in the project planning and setup phase.  \\n This is, of course, an entire complex process of its own,  \\n and I've tried to break this down into several substeps.  \\n You'll first define the goals of the project.  \\n What is it that you are trying to achieve?  \\n You'll then use metrics that you can use to evaluate  \\n whether the project was a success or failure.  \\n Let's say you're building a recommendation systems  \\n in order to upsell some of the products  \\n on your e-commerce site.  \\n Well, what is the uptick that you expect  \\n from customers because of the system?  \\n You need to choose your metrics wisely  \\n so that you know whether the model that you're building  \\n is actually worth it.  \\n You'll need to evaluate your baselines.  \\n What is the current uptake in customer sales  \\n because of the existing recommendation system,  \\n or do you not have one at all?  \\n You'll need to figure out the code base,  \\n and figure out what technologies you're going to use  \\n across the entire model development lifecycle.  \\n What deep learning framework you're going to be using,  \\n what programming language,  \\n what cloud platform or environment  \\n will you use to train your model?  \\n Where are you going to deploy and serve the model?  \\n All of that thought process, comes here.  \\n Now, a very important part of project planning and setup  \\n is to determine the impact of your project.  \\n A deep learning project may not be worth taking on  \\n unless it's impactful.  \\n Is the investment in this project going to be worth it?  \\n Is the predictions made by our model  \\n significantly going to improve business performance?  \\n Can you automate the entire complicated software pipeline  \\n in order to improve the product for users?  \\n These are some of the details  \\n you should consider for impact.  \\n The next thing you need to assess  \\n is the feasibility of your project.  \\n Deep learning projects require a lot of investment  \\n in terms of infrastructure, resources, data,  \\n and so much more.  \\n You need to ensure that all of the effort  \\n that you're putting in will result  \\n in a feasible maintainable model.  \\n Machine learning costs are often non-linear in nature,  \\n which means if you need a very high level  \\n of accuracy in your predictions,  \\n you might find that the investment is very, very high.  \\n The project costs scales non-linearly  \\n for greater accuracy requirements in predictions.  \\n These are the trade offs you need to think of  \\n in the project planning and setup phase.  \\n Also, machine learning models  \\n are probabilistic and not deterministic,  \\n and you should think to see  \\n whether probabilistic predictions are okay  \\n for whatever product it is that you're trying to build.  \\n Once you've figured out the basics  \\n of your deep learning project,  \\n that is project planning and setup is complete,  \\n you'll move on to data collection and labeling.  \\n This is where you get access to the data  \\n that you need to train your model.  \\n This is where you'll figure out  \\n the strategy for collecting the various data,  \\n where are your data located?  \\n Is the data already available in the organization,  \\n or do you need to look to external sources?  \\n You need to clearly state  \\n the data requirements of your project,  \\n identify data sources,  \\n ensure data quality in terms of accuracy and relevance.  \\n Make sure that your data is private and protected,  \\n and then set up the ingestion pipeline for your data.  \\n Depending on the kind of model that you choose to build,  \\n you may need to label your data.  \\n Data labeling is where you specify categories  \\n or classes for your prediction tasks.  \\n Now, data labeling is often an onerous and manual process.  \\n If you're doing manual labeling,  \\n you need to think about what the annotation guidelines are  \\n and you need to have processes in place  \\n for quality control of the labels,  \\n or there are several data labeling tools available  \\n that you can use to automate the labeling process.  \\n Once you have label data,  \\n you're ready to move on to model training and debugging.  \\n Model training and debugging is an iterative process,  \\n and this is where you'd follow the steps  \\n of the machine learning workflow.  \\n You'll start off with a simple model  \\n that you implement and debug.  \\n You then evaluate the model to see how it performs  \\n in a real world scenario.  \\n You may tune the models hyper parameters  \\n to improve its performance on your data.  \\n You may rearchitect the model, use different kinds of data,  \\n and you may tweak the model in multiple ways  \\n before you get a model that you're satisfied with.  \\n It's in the model training and debugging phase  \\n where you'll set up your ML Ops workflows.  \\n And finally, when you're happy with the model  \\n that you'll have, you'll deploy it to production.  \\n You'll test it and maintain it in production,  \\n and this maintenance might require constant retraining  \\n of your model on new data as it becomes available.  \\n Again, there are several substeps in this particular step  \\n of the Full Stack Deep Learning pipeline.  \\n You may first set up a small pilot in production  \\n to see how your model performs.  \\n Maybe you'll roll out your recommendations engine  \\n to only a subset of users of your e-commerce site.  \\n You'll then ask to see  \\n whether the new recommendation systems  \\n is an improvement over the old one.  \\n Are more customers buying products  \\n that they see recommended?  \\n If yes, you might go for full deployment  \\n where you'll launch the system for your entire user base,  \\n and then you'll constantly be monitoring  \\n and tracking the system to see, that it performs  \\n the way that you expect over the course of its lifetime.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3853103\",\"duration\":268,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Introducing MLOps\",\"fileName\":\"3095447_en_US_01_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":268,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"In this video, learn how MLOps is crucial to helping automate the ML workflow.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6654740,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] An important part  \\n is MLOps or machine learning operations.  \\n This is a set of practices and tools  \\n that combines machine learning systems  \\n with DevOps practices to automate, streamline,  \\n and manage the end-to-end machine learning lifecycle.  \\n You don't really use MLOps in the first two stages  \\n of full stack development, in project planning and setup  \\n and in data collection and labeling.  \\n MLOps really comes into play in the last two steps  \\n where you train and debug your model,  \\n tune your model using hyper-parameter tuning,  \\n and then deploy, test, and maintain your model.  \\n MLOps serves to automate the machine learning workflow,  \\n as expressed here in this very simple diagram.  \\n You start with a model, you implement and debug that model,  \\n evaluate that model, tune hyper-parameters,  \\n improve the model or the data that you use,  \\n and when the model meets requirements,  \\n you deploy to production.  \\n This entire workflow can be automated using MLOps tools  \\n and practices.  \\n MLOps is simply an extension of DevOps for data and models.  \\n DevOps is a set of practices to bridge the gap  \\n between development and operations.  \\n Development involves creating software  \\n and operations involved managing and deploying the software  \\n in production environments.  \\n DevOps practices have been shown  \\n to promote collaboration automation  \\n and a cultural shift to enable faster  \\n and more reliable software delivery.  \\n Now, MLOps is simply DevOps applied to building  \\n and training machine learning models.  \\n MLOps is just a set of practices and tools focused  \\n on automating and streamlining  \\n the machine learning lifecycle, extending DevOps practices  \\n to building and deploying machine learning models.  \\n Building and training machine learning models  \\n thus involve software, but there is a lot more  \\n to machine learning than just plain software development.  \\n MLOps is geared to address the unique challenge  \\n where data and models are equally important artifacts.  \\n So MLOps has to deal with a data pipeline  \\n as well as a code pipeline.  \\n The building and training machine learning models involve  \\n the use of software.  \\n Software development is fundamentally different  \\n from building and training ML models.  \\n You can think of a machine learning model  \\n as having two separate, very different inputs,  \\n data and code, and the characteristics of data  \\n and code are code very, very different.  \\n The code or the software that you use  \\n to train a machine learning model comes  \\n from a controlled environment, you have complete control  \\n over the version of the code that you use  \\n and the exact nuances of the software.  \\n In addition to code that is predictable,  \\n there is another factor involved in an ML model,  \\n and this is data, and data is often ever-changing  \\n and unpredictable.  \\n Data comes from an uncontrolled environment.  \\n When you build a machine learning pipeline, you have  \\n to handle two very disparate variables, data and code.  \\n The lifecycle and characteristics of both  \\n of these inputs are very, very different.  \\n MLOps thus seeks to productionize systems,  \\n which have inputs that have different evolutions  \\n and lifecycles.  \\n When you set up a continuous integration,  \\n continuous deployment pipeline for a machine learning model,  \\n this pipeline should include both data pipelines  \\n as well as code pipelines.  \\n The model will need to be updated  \\n if the data that is used to train it changes  \\n or if the code that is used to train it changes.  \\n Training and deploying a machine learning model  \\n is not a one-way process, machine learning  \\n is intrinsically iterative in nature.  \\n As new data comes in, the model will need to be retrained  \\n on that data and this, of course, means redeployment.  \\n If the machine learning algorithm changes,  \\n that is the code changes, the model will need  \\n to be retrained using the new code.  \\n If you find that your model isn't performing well,  \\n data relabeling may be required  \\n or you may need to choose a different kind of model.  \\n MLOps is extremely important  \\n in the machine learning workflow because deploying models  \\n to production is just the beginning.  \\n Models have to be constantly monitored  \\n and retrained on new data, and this is only scalable  \\n if the entire process is automated using MLOps.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3855188\",\"duration\":261,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Introducing MLflow\",\"fileName\":\"3095447_en_US_01_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":260,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"In this video, discover how MLflow helps simplify the machine learning lifecycle.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6378816,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Now if you were to set up an MLOps workflow  \\n for your deep learning system,  \\n there are many different tools  \\n and technologies that you could use.  \\n In this course, however, we'll focus on one, MLflow.  \\n MLflow is an open source platform  \\n that allows you to manage  \\n the entire machine learning lifecycle.  \\n MLflow is explicitly designed to simplify  \\n and streamline the end-to-end process of developing,  \\n training, tuning, and deploying machine learning models.  \\n MLflow is designed to be language-agnostic,  \\n meaning you can use it with different programming languages  \\n and machine learning frameworks.  \\n It supports popular languages such as Python and R,  \\n as well as machine learning frameworks,  \\n such as TensorFlow, PyTorch, and scikit-learn.  \\n Let's discuss the components that make up MLflow  \\n before we get hands on.  \\n MLflow has features that enable tracking  \\n of machine learning experiments and runs.  \\n MLflow allows you to deal  \\n with model artifacts in a standardized package and format.  \\n MLflow allows you to set up projects  \\n where you can organize your machine learning workflows,  \\n code, and structure.  \\n MLflow offers a model registry  \\n where you can register and manage the model versions.  \\n And finally, MLflow can also be used  \\n for model deployment and serving.  \\n Let's first talk about the features that MLflow offers  \\n for model tracking.  \\n MLflow uses experiments and runs to organize  \\n and track ML experiments and executions.  \\n Each time you train an MLflow model,  \\n that is a run within an experiment.  \\n The experiment is just a logical container used  \\n for organizing a set of runs.  \\n Think of the experiment as a high level grouping mechanism  \\n for model executions.  \\n Each experiment has a unique name  \\n and can contain multiple runs  \\n corresponding to multiple executions of the model.  \\n A run is a single execution of a machine learning workflow.  \\n A workflow might involve training a model  \\n with specific hyperparameters and data.  \\n Every run is associated with an experiment,  \\n which helps you categorize  \\n and organize your runs.  \\n Within a run,  \\n you can log various details,  \\n including hyperparameters, metrics, and model artifacts.  \\n All model artifacts are packaged in a standard format  \\n that can be used by deployment tools.  \\n Every model in MLflow is a directory  \\n that contains several files.  \\n At the root of the model directory  \\n is a special file called MLmodel,  \\n and this is what defines the various flavors  \\n in which the model is available.  \\n This tells you whether you can access a model  \\n as a PyTorch artifact, a Python function,  \\n or a TensorFlow artifact.  \\n In addition to the MLmodel file,  \\n a model contains several environment files  \\n that define the packages  \\n and versions the model needs to run.  \\n We'll be working with MLflow Tracking and MLflow Models.  \\n We won't be working with projects,  \\n but let me tell you what they are.  \\n MLflow Projects are a core feature  \\n of the MLflow platform.  \\n They provide a standardized  \\n and organized way to package, share,  \\n and execute machine learning code and workflows.  \\n MLflow Projects are very useful for model reproducibility  \\n and collaboration in ML projects.  \\n Once you have a model that you're satisfied with  \\n and which you may want to choose  \\n to deploy in a certain environment,  \\n you can use the MLflow Model Registry  \\n to register your model.  \\n The Model Registry is a centralized repository  \\n and management system for models,  \\n and it facilitates organization, versioning,  \\n tracking, and collaboration on ML models.  \\n This is where you'll deploy multiple versions of a model  \\n and all of the versions are accessible  \\n within the Model Registry.  \\n You can also move your model  \\n between different environments,  \\n such as staging, production, and archive.  \\n The Model Registry makes it very easy  \\n to manage models in a systematic and controlled manner.  \\n And finally, MLflow can also be used  \\n for model serving and deployment.  \\n MLflow, in fact, supports deploying to cloud platforms,  \\n such as Azure and GCP.  \\n MLflow has integrations with several cloud platforms,  \\n but you can also deploy  \\n and serve your models locally.  \\n With MLflow model serving, once you deploy your model,  \\n inferencing will be available via REST endpoints  \\n that the serve model exposes.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3859099\",\"duration\":322,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Setting up the environment on Google Colab\",\"fileName\":\"3095447_en_US_01_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":322,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"In this video, learn how to set up the Google Colab environment to run code.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12086840,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this demo, we'll see how we  \\n can use MLflow to log our model parameters  \\n and metrics while we train a dense neural network  \\n to perform image classification.  \\n Now, if you're familiar with neural networks, you know  \\n that typically you would not perform image classification  \\n using dense neural networks.  \\n You use convolutional neural networks.  \\n However, here we'll start off with a dense neural network,  \\n so you know how we can use MLflow,  \\n and then we'll move on to a convolutional neural network  \\n in the next demo.  \\n Now we'll be performing our model training  \\n and even deploying MLflow on Colab.  \\n So head over to colab.research.google.com.  \\n Colab is a Google project that gives you free access  \\n to a cloud hosted Jupyter Notebook.  \\n The Colab runtime comes pre-installed  \\n with many useful Python packages that we'll use  \\n for model building and training.  \\n And most importantly, Colab allows you  \\n to access GPUs entirely free of charge, at least  \\n for a limited duration.  \\n And that's the feature that we are going to be using.  \\n Now, sign into Colab with your Google account,  \\n and if you've never used Colab  \\n before, you need to sign up for Colab.  \\n We're going to be using Colab  \\n because we need access to GPUs  \\n to train our image classification model,  \\n whether it's using dense neural networks  \\n or convolutional neural networks.  \\n Click on new notebook here  \\n and let's start coding on a brand new notebook.  \\n In order to have the code in this notebook have access  \\n to a GPU, you'll need to head over to Runtime  \\n and go to change a runtime type.  \\n This will bring up a dialogue which will show you  \\n what options you have for your runtime.  \\n Notice there is CPU  \\n and there is a T4 GPU that is available.  \\n You also have access to TPUs  \\n or tensor flow processing units.  \\n Select the T4 GPU as an option.  \\n You'll be writing code in PyTorch to run on a GPU.  \\n Go ahead and hit Save. Our runtime now uses a GPU.  \\n Next, let's give this notebook a meaningful name.  \\n Click on the title that you see here,  \\n and let's change of the notebook  \\n to EMNISTClassification using DNNs or dense neural networks.  \\n Now this EMNIST data set that we are going to be working  \\n with is a short form for extended MNIST, an extension  \\n of the well-known MNIST dataset.  \\n The MNIST dataset, you're likely aware, is a dataset  \\n of hundred digits 0 through 9 comprising of 28  \\n by 28 gray scale images.  \\n The extended MNIST dataset  \\n includes handwritten characters from the English alphabet  \\n and is designed to be a more comprehensive dataset  \\n for character recognition tasks.  \\n Here in the Google Drive associated  \\n with my same Google account, I have a folder  \\n called EMNIST_data under My Drive.  \\n And here I have two CSV files, emnist-letters-test  \\n and emnist-letters-train containing the test  \\n and training data for my model.  \\n Back to our notebook, let's install the libraries  \\n that we need to write our code for our model.  \\n We'll install torch matplotlib numpy and pandas.  \\n Torch because we're going to be building a neural network  \\n using PyTorch Lightning.  \\n Go ahead and run install to install these libraries.  \\n Many of these will already be available  \\n within your Colab environment,  \\n so there's nothing to update here.  \\n Now, MLflow tracking  \\n and logging does not work with plain Vanilla PyTorch.  \\n You need to use PyTorch Lightning,  \\n which is an open source lightweight PyTorch wrapper  \\n that simplifies the training  \\n and research process for deep learning models.  \\n So pip install pytorch_lightning as well.  \\n This is not available in the Colab environment, so you need  \\n to explicitly install this.  \\n I'm going to install the latest version  \\n of MLflow available at the time of this recording,  \\n which is MLflow 2.91.  \\n If there is a newer version of MLflow available,  \\n you might want to explicitly install MLflow 2.91 to ensure  \\n that all of your demos work.  \\n And this is simple to do with pip,  \\n simply run pip install mlflow==2.9.1.  \\n We're going to be running MLflow in the Colab environment,  \\n which means that the MLflow UI  \\n and server will be hosted on the runtime of Colab.  \\n Now we do not have direct access to Colab's runtime.  \\n Our Colab notebook is hosted on some virtual machine  \\n in Google's Colab environment.  \\n Now, whatever virtual machine hosts our Colab notebook  \\n will be running our MLflow development server  \\n on that virtual machine,  \\n but we do not have direct access to the ports  \\n and other details of that pm.  \\n So if you run MLflow within Colab,  \\n how do we access MLflow?  \\n Well, we're going to be using Ngrok.  \\n Ngrok is a cross-platform application  \\n that allows developers to expose a local development server  \\n to the internet in practically no time at all.  \\n You have to do very little work to actually expose a server  \\n that's running locally to the internet complete with a URL.  \\n So whatever MLflow development server will be running  \\n in the Colab runtime, we exposed to the internet  \\n using Ngrok.  \\n And we are installing PyNgrok, the package that allows us  \\n to interface with Ngrok using Python code.  \\n We talk about Ngrok in more detail in the next movie.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3852089\",\"duration\":322,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Running MLflow and using ngrok to access the MLflow UI\",\"fileName\":\"3095447_en_US_01_05_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":322,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"In this video, discover how to use ngrok to expose local development servers to the internet.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10126449,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Now, in the earlier movie I'd mentioned  \\n that we are going to be using ngrok  \\n to expose our locally running MLflow to the internet  \\n so that we can view the MLflow UI  \\n and view the tracking parameters and metrics  \\n for our model training process.  \\n Now, we wouldn't actually need ngrok,  \\n had we been running this  \\n DNN training for image classification on our local machine.  \\n We'd simply install and run MLflow locally.  \\n However, because we're using colab for training  \\n and we are going to be integrating  \\n with MLflow running on colab,  \\n we need to expose MLflow running on the colab  \\n runtime to the internet.  \\n And that's why we are using ngrok.  \\n Now in order to use ngrok,  \\n we need an authentication key from ngrok.com  \\n and that's where I'm headed.  \\n You can see here that  \\n is a lot more than exposing your locally running server  \\n to the internet.  \\n But that's the use case  \\n that we are going to be using it for.  \\n Let's sign up for an ngrok account here.  \\n I'll use the same email ID I did for colab.  \\n I'll specify a new password.  \\n I'll indicate that I'm not a robot  \\n and I'll accept the terms of service of ngrok.  \\n At this point, if you want to verify your account,  \\n you can head over to Gmail.  \\n You should have received an email  \\n that'll allow you to verify your account.  \\n But in a few moments,  \\n you'll be taken to the main page for ngrok.  \\n Now here you'll find instructions  \\n for downloading and installing the ngrok stk  \\n on your local machine,  \\n whether it's macOS, windows, or a Linux machine.  \\n Since I'm running on a macOS machine,  \\n I get the instructions here for macOS.  \\n But we don't really need all this.  \\n All we need is an Authtoken.  \\n Click on Your Authtoken  \\n off to the left hand side of your screen  \\n and this will display to you the Authtoken  \\n for your ngrok account.  \\n And this is the Authtoken  \\n that we'll use to authenticate our ngrok agent  \\n that we used to run ngrok.  \\n And the ngrok agent that we'll be using is by ngrok.  \\n That is the Python agent.  \\n Copy the authentication token over  \\n and we'll use this in our code right now.  \\n Here is the Python code  \\n that I execute here in my colab notebook  \\n to run an MLflow server  \\n on the local host of the colab runtime.  \\n And then expose that endpoint to the internet using ngrok.  \\n The code that you see online  \\n to runs the MLflow tracking user interface  \\n in the background on the colab runtime.  \\n So notice I run the command \\\"mlflow ui --port 5000 &\\\"  \\n to run the tracking UI in the background.  \\n This will get MLflow running  \\n on the colab runtime for this notebook.  \\n Next, we need to create a remote tunnel  \\n to the current environment that we are on  \\n to allow ngrok local port access on our colab runtime.  \\n Ngrok.kill will terminate any open tunnels if they exist.  \\n We then specify our NGROK_AUTH_TOKEN.  \\n This is the Auth token that I've copied over  \\n from my ngrok account that we just created.  \\n I call ngrok.set_auth_token  \\n to set the auth token to my Python client  \\n to authenticate the Python client.  \\n On line 17, I call ngrok.connect  \\n to set up the remote tunnel to port \\\"5000\\\"  \\n on the local environment.  \\n This port on our local machine  \\n will be exposed to the internet via an HTTPS tunnel.  \\n And then we'll print out the public_url  \\n where we'll be able to access the MLflow UI.  \\n Now, if I were to click on this public_url,  \\n you'll see that this brings up  \\n whatever is running on local host 5000 in my colab runtime,  \\n and that is the MLflow UI.  \\n You should see a warning here about accessing this URL.  \\n We trust this URL.  \\n We know that we've exposed this  \\n particular URL to the internet.  \\n Let's visit the site  \\n and here is what the MLflow UI looks like.  \\n The colab runtime is an ephemeral runtime.  \\n So this UI and the MLflow that's running on that UI  \\n will only be accessible  \\n so long as my colab runtime environment is available.  \\n So if you kind of close the notebook  \\n or terminate your runtime,  \\n well, you'll find that MLflow will be killed as well.  \\n So it's ephemeral in nature,  \\n but it works perfectly well for the purposes of our demo.  \\n Of course, in a production environment,  \\n you'll have a permanent setup with your MLflow UI  \\n and your training runs for your ML models.  \\n Now that you've understood how we've used ngrok  \\n to access MLflow running on colab,  \\n let's explore the MLflow UI.  \\n Notice on the left, we have a default experiment  \\n that has already been created.  \\n An experiment is just a container  \\n for all of your different model executions or runs.  \\n We have no runs at this point in time  \\n and that's why the middle pane is empty.  \\n Once you have runs logged,  \\n you can use these configuration options  \\n to sort based on active runs,  \\n to sort based on different columns  \\n that you have displayed in the runs  \\n and essentially configure your view.  \\n We'll primarily work with  \\n experiments and runs in this course.  \\n However, you can also register your models  \\n using the model registry.  \\n And once you do that,  \\n the models will show up here in the models tab.  \\n This is where you'll track  \\n the different versions of your model,  \\n tag them as being in staging, archive  \\n or production environments and so on.  \\n \\n\\n\"}],\"name\":\"1. An Overview of Full-Stack Deep Learning\",\"size\":43229416,\"urn\":\"urn:li:learningContentChapter:3852093\"},{\"duration\":2008,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3852090\",\"duration\":293,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Loading and exploring the EMNIST dataset\",\"fileName\":\"3095447_en_US_02_01_VT\",\"demo\":true,\"videoCreationMetadata\":{\"rawDurationSeconds\":293,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"In this video, learn how to access and load the EMNIST dataset for model training.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9786139,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Now that we have ML flow running on Colab  \\n and we have access to our ML flow environment,  \\n using Ngrok, let's get started coding.  \\n First, I set up the import statements  \\n for all of the Python libraries that we need.  \\n We have the ML flow library,  \\n torch, matplotlib, numpy, pandas to work with data  \\n and to set up our deep learning model.  \\n The data set that we'll be using for classification  \\n is on Google Drive,  \\n so let's mount Google Drive onto our Colab notebook  \\n using drive.mount.  \\n This will bring up a dialogue asking you  \\n to authenticate the user drive  \\n from within your Colab notebook.  \\n Continue to Google Drive and make sure you log in  \\n with the account that you're using for Google Drive,  \\n which should be the same as the account  \\n that you're using for Colab  \\n and give your Colab notebook  \\n access to your Google Drive folder.  \\n Once you've successfully given access,  \\n you'll see that the contents of Drive  \\n will be available at /content/drive.  \\n And if you open up this folder on the left side bar,  \\n you'll see a drive folder here in your local runtime.  \\n Under MyDrive, you'll find that all of your drive folders  \\n will be available to your Colab notebook,  \\n and this will allow us  \\n to access our training data under MyDrive.  \\n Observe there is also an ML runs folder  \\n that has been created here.  \\n This folder did not exist before,  \\n this folder was created when we launched ML Flow  \\n in our Colab runtime.  \\n ML Flow uses this ML Runs folder  \\n to track all of the experiments that we create,  \\n all of the runs or executions of our model,  \\n the model parameters, artifacts,  \\n everything that ML flow tracks  \\n will be locked to this folder by default.  \\n Let's get back to the code and let's access and load in  \\n our training and test data.  \\n I use Pandas for this pd.read_csv  \\n and I point to the folder on the mounted Google Drive  \\n where my training and test data lives.  \\n Both of these files have no headers  \\n and that's why I've set header equal to none.  \\n Read in this data and let's print out  \\n a sample of the training data so you can see  \\n what the data looks like.  \\n Emnist_images are gray scale images,  \\n 28 pixels by 28 pixels,  \\n so total of 784 pixels.  \\n You can see the column header start with zero,  \\n end at 784.  \\n The zero column is the label associated with each image.  \\n Notice that the labels range from one through 26.  \\n Each image represents a single character in the alphabet.  \\n You'll see that the test data  \\n is set up in a similar structure as well.  \\n We have the zeroth column  \\n containing the labels for the test images  \\n and columns one through 784,  \\n those are the actual pixel values of the images.  \\n In order to quickly understand the numbers in the CSV file  \\n representing the images and the labels,  \\n let's run describe on this data frame.  \\n Observe that we have a total of 88,800 records  \\n in the training data.  \\n For column zero, the min value is one,  \\n and the max value is 26.  \\n So you can see that these numbers represent letters  \\n from A through Z.  \\n You can see that the pixel values are just intensities  \\n ranging from zero through 255.  \\n The training data for the Emnist dataset  \\n is randomly shuffled,  \\n but the test dataset is not.  \\n So I call emnist_test_data.sample(frac = 1)  \\n in order to shuffle the test data as well.  \\n Next, I'll set up a Python list  \\n representing the classes or categories in this data  \\n from A through Z.  \\n Now, one thing to note here,  \\n that the labels in this dataset go from one through 26,  \\n but the indexes of the elements in a Python list  \\n go from zero through 25.  \\n Just something to keep in mind  \\n because we need to make an adjustment for this  \\n when we view and work with this data.  \\n Now let's take a look at the data that we are working with  \\n before we start setting up our experiment in ML flow.  \\n On lines two and three,  \\n I access the labels and the training data  \\n and the actual image values.  \\n Remember, the first column in the data frame  \\n comprises of the labels.  \\n The training images are in the flattened form,  \\n and in order to visualize these images,  \\n we need to reshape them  \\n to the original dimensions, 28 by 28,  \\n this is what I do on line six.  \\n On lines nine through 13,  \\n I sample 18 different images at random  \\n from the training set.  \\n And on lines 15 through 24,  \\n I display these images using matplotlib  \\n along with the corresponding labels.  \\n Observe on line 20 that I have a  \\n train_labels[idx] - 1.  \\n This is an adjustment I have to make  \\n before we can access the right label in the classes list.  \\n Let's run this code  \\n and take a look at the data that we are working with.  \\n You can see that all of these images  \\n are of letters in the English alphabet,  \\n both lowercase and uppercase.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3855189\",\"duration\":366,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Logging metrics, parameters, and artifacts in MLflow\",\"fileName\":\"3095447_en_US_02_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":366,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"In this video, discover how you can create MLflow runs for tracking.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10997653,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Now that we have our data set up  \\n for training our model,  \\n let's play around with MLflow and understand how it works.  \\n The first thing we need to do is  \\n create an MLflow experiment,  \\n and you can do this programmatically  \\n by calling mlflow.create_experiment,  \\n and specifying a name for that experiment.  \\n You can do this using the UI as well.  \\n An experiment is made up of runs.  \\n A run is an execution of a model  \\n and a run has all of the metrics  \\n and parameters that are logged when the model is run.  \\n Once you've created an experiment, you can head over  \\n to the MLflow UI  \\n and under experiments you should find our newly  \\n created experiment.  \\n You'll find the test experiment over on the left  \\n and if you were to select it, you'll find  \\n that it's completely empty.  \\n That's because we haven't created any runs  \\n yet within this experiment.  \\n Back in our notebook,  \\n let me open up the left sidebar  \\n and show you the contents of the mlruns folder.  \\n If you expand mlruns, you'll find  \\n that there is a sub folder for each experiment  \\n that we've created in MLflow.  \\n We had the default experiment with ID 0  \\n and our newly created experiment  \\n with an ID starting with 61.  \\n There's also models folder, which contains the models  \\n registered with the model registry.  \\n This is not something we'll be working  \\n with much in this course.  \\n Now that we've created an experiment,  \\n let's access this experiment  \\n and look at the details of this experiment,  \\n mlflow.get_experiments accepts an experiment ID  \\n and returns an experiment object, which you can use  \\n to access the name, the ID, the artifact location, tags,  \\n lifecycle stage, and the creation time  \\n for this experiment.  \\n Notice the artifact location is in the mlruns folder.  \\n This is where the artifacts of our model training,  \\n that is the serialized model and other images  \\n and any other artifacts that we store will be located.  \\n The next thing I'm going to do is create runs  \\n within this experiment.  \\n For that, you need to set the current experiment  \\n within this notebook, mlflow.set_experiment.  \\n That's why the name of the experiment will set that up  \\n as the experiment to use for all of the code that follows.  \\n Now you can create a run within this experiment  \\n by calling mlflow.start_run.  \\n This will be created within the currently active experiment.  \\n Mlflow.end_run will end the run.  \\n Every start run has to be accompanied  \\n by a corresponding end run.  \\n Then all of your model executions  \\n and logging of your model parameters  \\n and metrics should be done within this run.  \\n Execute this and now head back to the MLflow UI  \\n and refresh the page for the test experiment.  \\n You should see a newly created run there.  \\n Notice that MLflow has picked the name  \\n for the run at random.  \\n Let's look at this awesome-slug run.  \\n If you click through, there are no details  \\n because this is just an empty run.  \\n We just started and ended the run right away.  \\n We did not actually log any metrics, artifacts,  \\n or model parameters within the run.  \\n When we actually create a run, let me show you  \\n how it's tracked on a locally running MLflow server.  \\n Open up this folder icon off to the left  \\n and notice under our experiment folder,  \\n there is another sub folder for our run.  \\n The folder starting with 61 is the folder  \\n for our text experiment  \\n and the folder starting with c5 is the folder  \\n for our current run.  \\n And under a run you can see the different folders  \\n tracking the artifacts, metrics, params and tags.  \\n These will be populated when we actually train our model  \\n using an MLflow run.  \\n Let me show you how you can log metrics, parameters,  \\n artifacts and figures within a run.  \\n The first thing I'm going to do is set up a simple text file  \\n that's going to be an artifact that I want logged.  \\n Data info is a string which contains information  \\n about the MNIST dataset,  \\n and I write that out to a data_info.txt file.  \\n This is the code on lines 9 and 10.  \\n Now I have an artifact that can be logged.  \\n What I'm going to do now is start an MLflow run  \\n using the width keyword.  \\n When you're using MLflow  \\n using the width keyword to start a run is a best practice  \\n because this will automatically close  \\n or end the run for you.  \\n So with MLflows, start run, the name  \\n of the run is test_experiment_run,  \\n and this is stored in the current run variable.  \\n And then I explicitly log some metrics,  \\n params, artifacts and tags.  \\n Mlflow.log_metric. I set the accuracy to 0.67.  \\n Even though we are not actually training a model.  \\n I set up some fake params for the model on lines 5  \\n through 7 and log those parmas on line 8.  \\n Notice how I call log_metric to log metrics,  \\n log_params to log parameters.  \\n And mlflow.log_figure can be used to log images.  \\n Figure refers to the mapplotlib figure that we use  \\n to display the images earlier on in this demo.  \\n Log_artifact is used to log artifacts.  \\n That is a data info text file that I just saved now.  \\n And I've also specified a tag for this run in the form  \\n of a key value pair EMNIST classification using DNNs.  \\n Execute this code.  \\n And now that we have a run  \\n where we logged different parameters, metrics, et cetera,  \\n let's head over to our experiments  \\n and take a look at how this is displayed.  \\n Observe under test_experiment, we have two runs.  \\n The first one, awesome-slug is the one  \\n that we created earlier.  \\n The second one is test_experiment_run  \\n where we specified our own run name.  \\n Let's click through to the test_experiment_run  \\n and see how the metrics and params have been logged.  \\n Notice there are sections for different parts.  \\n If you expand parameters, you can see num_nn_layers  \\n are parameters has been logged there.  \\n Under metrics you can see accuracy.  \\n And under tags you can see our tag, EMNIST.  \\n At the bottom here we have artifacts  \\n where we have our test artifact that we logged out.  \\n Also, the image artifact, sample_images.png .  \\n Artifacts can be files, images,  \\n and of course when we train a model,  \\n we'll have our model artifacts here.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3853104\",\"duration\":227,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Set up the dataset and data loader\",\"fileName\":\"3095447_en_US_02_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":227,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"In this video, learn how to create a PyTorch dataset and dataloader to work with training, validation, and test data.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6936420,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Now that we know how ML flow tracks  \\n runs within experiments, we are ready to train  \\n our dense neural network  \\n for image classification.  \\n Once again, A DNN is not the right model for this,  \\n but it'll give us a handle on how ML flow works  \\n and will work well as a preparatory step  \\n before convolutional neural network training.  \\n The first thing I'm going to to do is set up a dataset  \\n to access our emnistS data.  \\n A dataset is just an abstraction that represents your data  \\n and it typically provides access  \\n to individual data samples one at a time.  \\n This emnist dataset class inherits from the dataset base  \\n class in PyTorch.  \\n Within the init method, we initialize the images  \\n and labels as torch tensors.  \\n Observe that the init method takes in the data frame  \\n for our training or test data as an input argument.  \\n The Len Method returns the length of the dataset.  \\n That's just the length of the images get item  \\n allows us to access the data samples one at a time.  \\n It takes in an index as an input argument  \\n and returns the images and labels at that index.  \\n Notice on line 14, we divide all of the pixel values  \\n of the images by 255 so that every pixel value  \\n is represented in the range zero to one.  \\n This will make training of our neural network more robust  \\n and allow our neural network to converge.  \\n Having set up this dataset class,  \\n let's instantiate our training and test data.  \\n We have the trained dataset  \\n and the test dataset, both of the kind emnist dataset.  \\n Make sure you pass in the right data frames in.  \\n We have 88,800 records for training  \\n and 14,800 records to test and evaluate our model.  \\n I'm going to carve out some samples from the training dataset  \\n to use for validating our model as training progresses.  \\n So I import the random split method from torch utils data.  \\n We use 10% of the training records.  \\n For validations I've set  \\n val percentage should be well proportion 2.1.  \\n I compute the length of the validation data  \\n on line four, that is val length.  \\n And then I use the random split to get the training data set  \\n and the validation data set.  \\n And if you look at the length of both of these data sets,  \\n 79,920 records for training.  \\n 8,880 records for validation.  \\n Before we use this data to train our model,  \\n let's instantiate data loaders for the training, test,  \\n and validation data.  \\n A data loader is a utility that wraps around a data set  \\n and provides batching, shuffling,  \\n and parallel loading of data.  \\n I've gone with a batch size of 64.  \\n This is something of course that you can tweak  \\n and I've instantiated three different data loaders.  \\n And then at the bottom I print out the length  \\n of the data loader, which will tell us the number  \\n of batches in each of our data sets.  \\n Notice for the train dataloader I've set shuffle  \\n to true because I want the training data to be shuffled.  \\n Drop last is true, so that last batch, which may not  \\n be the same size  \\n as the other batches will be dropped.  \\n And for all data loaders, I've set number workers equal  \\n to one because we have just one GPU  \\n available in our runtime.  \\n PyTorch data loaders are used  \\n with iterators giving you access to one batch  \\n of data at a time.  \\n Here is one batch of images from the training data,  \\n and here you can see corresponding batch of labels  \\n for the first batch of images.  \\n Let's take a look at the shape of one batch of data  \\n that will be feeding into our dense neural network.  \\n The batch size that we are chosen was 64,  \\n so you can see one batch of images is 64 by 784,  \\n where 784 is the flattened representation of each emnist  \\n image, and of course the length correspond to.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3852091\",\"duration\":296,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Configuring the image classification DNN model\",\"fileName\":\"3095447_en_US_02_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":296,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"In this video, learn how to configure a simple DNN for image classification.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10192550,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Let's set up the MLflow experiment  \\n to track our dense neural network training.  \\n I'm going to call mlflow.create_experiment.  \\n The name of the experiment  \\n is emnist_letters_prediction_using_dnn.  \\n And I'm going to set that experiment  \\n as the active experiment for this notebook.  \\n So any runs we create will be created  \\n within this emnist_letters_prediction_using_dnn experiment.  \\n Next, I'm going to import some Pytorch-related libraries  \\n and classes that we'll need to set up our neural network.  \\n We're going to be using a dense neural network  \\n for image classification.  \\n The size of the input fed into this dense network  \\n will be 28 by 28, that is 784,  \\n and the size of the output will be 26  \\n since each image can be classified  \\n into one of 26 categories.  \\n The output will be a probability score  \\n for each class or category,  \\n and the category with the highest probability  \\n will be the predicted label of the model.  \\n We are now ready to set up our dense neural network  \\n for image classification.  \\n Now, I'm defining this as a class  \\n that inherits from pytorch_lightning.LightningModule.  \\n A LightningModule is designed to encapsulate  \\n the entire machine learning workflow,  \\n including model architecture, the training loop,  \\n validation loop, and any test functionality.  \\n You should have your class representing your model  \\n inherit from LightningModule  \\n and implement several hooks or placeholders  \\n or required methods in your derived class.  \\n The Pytorch Lightning trainer  \\n can work with the Pytorch LightningModule  \\n to train, validate, and test your model.  \\n Now, within the init method here,  \\n I set up the structure of my dense neural network.  \\n Because this is a classification model,  \\n we'll use the cross-entropy loss that measures the distance  \\n between two probability distributions.  \\n We have the initial linear layer  \\n which takes in our input and has 512 neurons,  \\n and we have linear layers two, three, and four.  \\n The output of each layer  \\n feeds as an input into the next layer.  \\n And notice our last linear layer  \\n has the output size equal to the number of classes  \\n or categories that the data can be classified into.  \\n The forward function in this LightningModule  \\n defines a forward pass through the neural network.  \\n Xb is one batch of data fed into the model,  \\n which is then passed through the first three linear layers.  \\n Each of these linear layers have ReLU activation.  \\n The data is then passed through the last linear layer,  \\n linear4, which has no activation.  \\n In order to specify the optimizer to use  \\n for your neural network training,  \\n you override the configure_optimizers function.  \\n And here, you've seen that I've initialized  \\n an Adam optimizer with a learning rate of .0001.  \\n The training_step will be invoked  \\n during the training of your neural network.  \\n Observe that the training_step takes in one batch of data  \\n along with the indexes of the batch.  \\n We access the x, features, and y, labels, of the batch  \\n on line 28.  \\n On line 29, I subtract the y, labels, by one  \\n so that they're indexed starting at zero.  \\n So zero will represent the letter A,  \\n one will represent the letter B, and so on.  \\n The original dataset uses one to represent the label A,  \\n two to represent B.  \\n And we want the categories to start at zero,  \\n that's why I have the y -= 1.  \\n On line 31, we make a forward pass through the model  \\n to get the predictions  \\n with the current model parameters, y_hat.  \\n Invoking self on the input data  \\n will automatically invoke the forward method  \\n in this LightningModule.  \\n On line 32, we compute the current loss of the model.  \\n And on line 33, we get the actual predicted labels  \\n by computing the category or class  \\n with the highest probability score using argmax.  \\n On line 35, we compute the current accuracy of the model.  \\n And on lines 37 and 38, we log the current training loss  \\n and the current training accuracy.  \\n Observe on line 40, we return the loss  \\n from the training_step.  \\n This loss will be used by the PyTorch trainer that we'll use  \\n with this LightningModule  \\n to make a backward pass through the model.  \\n The validation_step is invoked on validation data.  \\n Once again, it takes in a batch of data  \\n and the batch indexes as input,  \\n and the code within the validation  \\n is exactly the same as a code within the training_step.  \\n At the end of the validation_step,  \\n on line 55 we return the current accuracy  \\n on the validation data.  \\n Next, we have the test_step,  \\n which is invoked on the test dataset.  \\n The code on lines 58 through 70 for the test_step  \\n is identical to the code in the validation_step,  \\n including the fact that we return the accuracy.  \\n And then we have the final predict_step,  \\n which is invoked when we use the trained model  \\n for predictions.  \\n That just makes a forward pass on the data  \\n by invoking self on the x input.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3858093\",\"duration\":246,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Training a model within an MLflow run\",\"fileName\":\"3095447_en_US_02_05_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":246,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"In this video, learn how to track model training parameters automatically with MLflow.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10850401,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] With our model configured,  \\n now it's time for us to train the model  \\n and track the metrics, parameters,  \\n and artifacts of this model using ML Flow.  \\n Notice the imports on lines one, two, and three.  \\n These are imports that have to do with logging  \\n all of the details of the model,  \\n including the model signature, the schema,  \\n and tensor specifications for the tensors  \\n that we feed into the model.  \\n I instantiate the model on line five.  \\n That is our emnist_model.  \\n And on line seven, I instantiate the CSVLogger.  \\n The CSVLogger is what we use to log our details  \\n of the training process to our local machine.  \\n The actual training process will be run  \\n using the pytorch lightning trainer,  \\n that I instantiate on line nine.  \\n We'll train for a maximum of 10 epochs.  \\n And notice, I pass in the CSV logger  \\n as an input argument, so that the trainer  \\n can use that logger to log out details during training.  \\n Now, ML Flow can track parameters and metrics  \\n in a very granular and manual fashion,  \\n by calling log metrics log params,  \\n as you saw earlier in our test example.  \\n However, an easier thing to do  \\n when you're working with PyTorch, TensorFlow,  \\n or any of the standard frameworks  \\n is to use ML Flow Auto Log.  \\n On line 11, I enable auto log for pytorch,  \\n mlflow.pytorch.autolog.  \\n I'm going to ask auto log to log  \\n all of the details it usually does,  \\n parameters, metrics, tags, and so on,  \\n except for the actual model artifacts.  \\n I've set log models to false, indicating that I  \\n do not want model artifacts to be logged.  \\n I'm going to be logging them myself,  \\n manually in an explicit fashion.  \\n This is so I can explicitly log the model's signature.  \\n On line 13, I kickstart an ML Flow run,  \\n using mlflow.start_run.  \\n Now all of the training that you'd run  \\n using PyTorch Lightning, within this start run with block,  \\n will be instrumented and tracked automatically by ML Flow.  \\n ML Flow will plug into the training process  \\n of your PyTorch Lightning module  \\n and it will track metrics and parameters,  \\n as model training is going on.  \\n On line 15, we start the model training process  \\n by calling trainer.fit.  \\n The model to be trained is the emnist model.  \\n The training data is in the train_dataloader.  \\n And the validation data is in the val_dataloader.  \\n Once training is complete, we'll evaluate the model  \\n on the test data, I call trainer.test  \\n and pass in the test data loader for evaluation.  \\n Now I want to explicitly specify the schema  \\n of the input data fed into the model  \\n and the output predictions received from the model.  \\n I instantiate those schemas on lines 18 and 19.  \\n The shape of the input data is a tensor.  \\n The mat size can be anything, that's the minus one.  \\n But each image is 784 pixels.  \\n The shape of the output schema is 26 different outputs,  \\n with probability scores for each of the 26 categories.  \\n On line 21, I instantiate a model signature  \\n with the input and output schema.  \\n And I explicitly call log_model on line 23,  \\n to log out the model artifacts,  \\n along with the model signature.  \\n The name of the model is  \\n emnist-letters-classifier-dnn-model.  \\n I've noticed that for PyTorch, auto log  \\n logs out the model artifacts fine,  \\n but it doesn't explicitly specify  \\n the signature of the model,  \\n that is the input schema and the output schema.  \\n Because I want that,  \\n I explicitly logged out the model myself.  \\n Let's kickstart the training process.  \\n Now the training process took about 15  \\n to 20 minutes, to run on the GPU.  \\n There is a lot of data that we have to train with.  \\n Observe the first line, GPU available, true  \\n and used is true, so training ran on the GPU.  \\n And if you scroll down, you'll see  \\n the final results of training.  \\n The test accuracy is almost 85%, which is quite good  \\n considering we have 26 classes or categories  \\n into which the input images can be classified.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3854103\",\"duration\":259,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Exploring parameters and metrics in MLflow\",\"fileName\":\"3095447_en_US_02_06_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":259,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"In this video, learn how to understand and interpret results displayed in the MLflow UI.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8821854,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] With model training complete,  \\n let's head over to the MLflow UI,  \\n and if you hit Refresher,  \\n you'll find that our new experiment  \\n containing our PyTorch model run, is available.  \\n Here we have the  \\n emnist_letters_prediction_using_DNN experiment.  \\n And within this experiment, we have a single run,  \\n that is the training of our PyTorch model  \\n that we just completed.  \\n Now let's take a look at the charts first,  \\n because they're very interesting.  \\n You'll see that MLflow automatically logs the charts,  \\n for all of the metrics that were tracked during training.  \\n Here you can see first a bar chart,  \\n tracking the accuracy on the test data.  \\n That's 0.85.  \\n If you scroll down, you'll find other useful charts.  \\n Let me show you a few.  \\n Here is a chart of the training loss  \\n over the epoch of training.  \\n You can see how the loss falls as we train for longer.  \\n Here is a chart for the validation accuracy,  \\n which grows as we train for longer,  \\n and here is another chart for the validation loss.  \\n All of these charts were automatically logged  \\n when we used MLflow's auto logging feature.  \\n Now let's click through, and take a look at the run.  \\n This is where we'll be able to see all of the metrics  \\n and parameters that were logged.  \\n Let's expand the parameters section,  \\n so you can look at that first.  \\n Observe that all of the parameters of the model,  \\n including neural network layers, number of neurons,  \\n number of model parameters, learning rate of the optimizer,  \\n the optimizer used, everything is tracked here.  \\n Let's take a look at the metrics next.  \\n You can see that we had three data sets:  \\n test, validation, and training.  \\n And we get the loss and accuracy  \\n for each of these datasets.  \\n You can see here that the accuracy on the training data  \\n was 0.8797, that's the train accuracy.  \\n and on the test data, it was 0.853.  \\n That is the best accuracy up top.  \\n Mlflow has also auto logged some tags for our training run.  \\n Notice the tag here says \\\"Mode is testing,\\\"  \\n because we had some test data,  \\n and here at the bottom we have the model artifacts  \\n that we logged explicitly.  \\n There's a lot going on here,  \\n and I'll break this down for you.  \\n The model artifacts are in the form of a folder,  \\n which contains the actual model that has been serialized  \\n and saved out, in the data sub folder,  \\n and it also defines the model's environment,  \\n those are the remaining files,  \\n The MLmodel file, the conda.yaml, the Python_env.yaml,  \\n and the requirements.txt.  \\n Here on the right in the center pane,  \\n you can see the model schema  \\n that we explicitly logged the input schema,  \\n so you know what kind of data to feed in,  \\n and the output schema,  \\n so you know what kind of output to expect.  \\n And over to the right,  \\n how you can load in a trained model, and make predictions.  \\n We'll get to that in a bit.  \\n We'll do that in the next movie.  \\n In the meanwhile,  \\n let's quickly understand this model artifact structure.  \\n In the data sub folder, under the main model folder,  \\n notice we have the model path file,  \\n which contains the actual serialized model.  \\n The model has been serialized using the Pickle format,  \\n that's what the second file indicates.  \\n The MLmodel file is a special file that MLflow uses  \\n to package and serialize machine learning models,  \\n along with their associated metadata.  \\n This MLmodel file is primarily used  \\n when we deploy and serve machine learning models,  \\n using Mlflow.  \\n And we'll do that in the very last demo of this course.  \\n You can see the Python version that was used  \\n to train the model 3.10.12.  \\n You can see the PyTorch version 2.1.0.  \\n You can see the MLflow version 2.9.1.  \\n because we explicitly logged out the model signature,  \\n the MLmodel file also contains the signature  \\n of the input data to be fed into the model,  \\n and the outputs to be received from the model.  \\n The other files here, such as conda.yaml,  \\n is used to define the conda environment  \\n that can be used to train this model.  \\n Similarly, python_env.yaml defines the Python environment  \\n used to train the model:  \\n the build dependencies, and the requirements.txt file,  \\n contains the versions of all of the libraries needed  \\n for this model training.  \\n And model_summary.txt gives you an overview of the model  \\n that was trained, the layers in the model,  \\n and the number of trainable parameters in the model.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3857096\",\"duration\":321,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Making predictions using MLflow artifacts\",\"fileName\":\"3095447_en_US_02_07_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":321,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"In this video, learn how to load model artifacts and make predictions using Python code.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11260287,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Let's visualize some  \\n there is a metrics.csv file under the log directory  \\n of our PyTorch Lightning model trainer.  \\n I'm going to read the contents of this metrics.csv file,  \\n and this is a data frame that gives you all  \\n of the training accuracy, the various steps,  \\n and other details of training.  \\n I'm going to use Seaborn to visualize some of these training  \\n and validation metrics as a line plot.  \\n If you take a look at this line plot,  \\n you see the validation accuracy, validation loss,  \\n and training accuracy and loss per epoch.  \\n Observe the two lines for accuracy,  \\n the straight blue and the dotted green line.  \\n The accuracy improves during training on the training data  \\n and the validation data while the loss falls.  \\n Every MLflow run has a unique run ID,  \\n and you can access this programmatically  \\n by calling mlflow.last_active_run().info.run_id,  \\n this is the run ID of the run that we just executed.  \\n Using this run ID, we should be able  \\n to access the model artifacts associated with this run  \\n and then load in those artifacts  \\n to use the train model for prediction.  \\n First, let me set up a batch of the test data  \\n that will pass through the model for predictions.  \\n Test images and test labels contain the data and labels  \\n of one batch in the test data, remember,  \\n this is data the model has not seen during training.  \\n Now let's access the model artifacts  \\n and load the model into our notebook,  \\n the log model is available here at this URL,  \\n runs:/ the run ID and the name of the directory  \\n that we use to save out the model.  \\n Using this URL, you can load the model in as a pyfunc model  \\n using mlflow.pyfunc.load_model.  \\n Once we have the loaded model on line six,  \\n I call model.predict on the batch of test data  \\n that we just accessed and then I print out  \\n the first five predictions.  \\n You can see the predictions  \\n are all in the form of logit scores.  \\n These are the raw unnormalized scores produced by a model.  \\n These can be transformed into probabilities,  \\n but that's not really needed, we can use the logits  \\n to get the predictions from the model as well.  \\n Let's consider the image at index six in our first batch.  \\n The test label at index position six is equal to eight.  \\n Now let's look up the class or category  \\n that's associated with this label eight.  \\n Remember, we have to subtract one since our classes start  \\n at index position zero and the labels start  \\n at index position one, and you can see that this corresponds  \\n to the letter h.  \\n Let's see the predictions from the model  \\n for this index position six to see  \\n whether it matches the actual label in the dataset.  \\n The predictions are in the form of logit scores,  \\n so we have to use argmax to get the actual prediction.  \\n And you can see that the actual prediction is indeed h.  \\n I'll set up a little helper function here to display  \\n the images that we have in our batch of test data,  \\n so we pass in the index position  \\n and view the image at that particular index position.  \\n This show utility method also allows us  \\n to pass in a title for each image.  \\n Now, with this utility method, what I'm going to do  \\n is iterate over all of the images in our test batch,  \\n all 64 of them.  \\n For every image, we'll access the actual label from the data  \\n and also get the prediction from our classification model.  \\n And in the title of each image, we'll print out  \\n the actual label and the model prediction, both of them.  \\n And for each of these 64 images, you'll be able  \\n to see the title to see whether the prediction matches  \\n the actual label associated with the image.  \\n Here is one that does not match  \\n and here is another that actually matches.  \\n Next, we'll get the model to make predictions  \\n on the entire test data, you can see on line seven,  \\n I iterate over the inputs and labels  \\n over the entire test data, on line 16,  \\n we'll compute the accuracy score of the model  \\n on the test data, print that out to screen,  \\n and on lines 20 through 23, I'll plot out a confusion matrix  \\n to see how our model performed on the test data.  \\n Now, this is going to be a rather large confusion matrix  \\n because we have 26 classes or categories.  \\n Notice the accuracy on the test data, 0.853.  \\n You already expected that.  \\n That's the same number we have logged in MLflow.  \\n All of the numbers on the main diagonal from the top left  \\n to the bottom right are predictions  \\n that our model got right, so you can see  \\n that a model got a large number right.  \\n Let's look at an example of a prediction a model got wrong.  \\n Notice in the first row, we have the number 265.  \\n Along the row, we have the letter i,  \\n and along the column for 265, we have the letter l.  \\n This tells us that the model tends to get confused  \\n between the letters i and l, which is understandable.  \\n At this point, you've successfully used MLflow  \\n to track the parameters and metrics  \\n for the training of your dense neural network.  \\n In the next demo, we'll see how we can train  \\n a convolutional neural network for image classification  \\n and use MLflow for tracking.  \\n \\n\\n\"}],\"name\":\"2. Model Training and Evaluation Using MLflow\",\"size\":68845304,\"urn\":\"urn:li:learningContentChapter:3855191\"},{\"duration\":2160,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3856119\",\"duration\":242,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Preparing data for image classification using CNN\",\"fileName\":\"3095447_en_US_03_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":242,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"In this video, learn how to prepare data for image classification using CNNs.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8923631,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Here I am on a brand new colab notebook,  \\n EMNIST classification using convolutional neural networks.  \\n Now, a new notebook implies a new colab runtime,  \\n which means we need to restart mlflow  \\n on this local machine.  \\n You can see from the message at the bottom  \\n that I've set up this runtime to run on a GPU.  \\n That's what we'll use to train our image classification  \\n convolutional neural network on the EMNIST data.  \\n Now, we need to install the libraries once again  \\n because we are on a new runtime.  \\n Torch, matplotlib, numpy, and pandas, we need all of these.  \\n We also need pytorch lightning  \\n because we'll be setting up our model  \\n using pytorch lightning, and we also need mlflow.  \\n Once again, this will get us mlflow 2.9.1,  \\n the latest version at the time of this recording.  \\n In order to ensure there are no breaking changes  \\n that mess up your demo, you might want  \\n to specifically install mlflow 2.9.1 yourself.  \\n And we also need pyngrok so that we can set up a tunnel  \\n from the colab machine to the external internet using ngrok.  \\n Because we're on a new notebook  \\n that sets up a new colab runtime,  \\n which means when I run the mlflow development server,  \\n this will be an entirely new instance.  \\n So all of our old experiments and runs  \\n will no longer be available.  \\n This is the same code that we've seen earlier  \\n to run mlflow on Port 5000 and then set up a tunnel  \\n to expose the local development server to the internet.  \\n Here is the mlflow tracking URL on ngrok.  \\n And if you click on this, you should be able  \\n to see the mlflow UI.  \\n Let's click through the warning message  \\n and here is the familiar mlflow user interface.  \\n Once again, we are set up with the default experiment  \\n and there are no additional experiments or runs.  \\n No matter, we are going to be creating one very soon.  \\n Back in our notebook, the initial part of the code  \\n where we import all of the libraries  \\n that we are going to use and where we access  \\n and set up our training data is going to be the same.  \\n I mount drive to the runtime of my current notebook  \\n because Google Drive is where we've stored  \\n the EMNIST training and test data.  \\n As soon as you allow your colab notebook access  \\n to Google Drive, the drive contents will be mounted  \\n at this path, /content/drive.  \\n Let's read in the training  \\n and test data using pd.readcsv.  \\n The data is under Mydrive emnist_data  \\n and then we have the two CSV files.  \\n Header is equal to none  \\n because neither of these files have headers.  \\n Now that we have the data, let's set up  \\n the dataset class EMNIST dataset.  \\n The structure of this is exactly the same  \\n as in the previous demo.  \\n For both the training and test data,  \\n we convert the images and labels to tensors,  \\n this is on lines 4 and 5.  \\n And on 14, when we access a single image,  \\n we divide image pixel values by 255.  \\n This expresses all pixel intensities  \\n in the range zero through one.  \\n We'll shuffle the test data as we did before,  \\n using the sample function frac equal to one,  \\n preserves the entire test data set,  \\n but now it'll be shuffled.  \\n Next, let's instantiate the data set  \\n for both the training data as well as the test data.  \\n Once again, I'm going to use random split  \\n to split the training dataset so that a fraction  \\n of this data, 10%, is kept aside for validation  \\n during the training process.  \\n Again, this is code you've seen before.  \\n Next, we'll instantiate our data loaders.  \\n We use the same batch size of 64 as before,  \\n and have set up three data loaders:  \\n train, validation, and test.  \\n num workers is always equal to one  \\n because we have just one GPU.  \\n The train data set has shuffle equal to true  \\n so that the data set is shuffled while training our model  \\n and drop last is equal to true  \\n so that all batches have 64 records.  \\n So if you have a batch with fewer than 64 records,  \\n that batch will be dropped.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3858094\",\"duration\":379,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Configuring and training the model using MLflow runs\",\"fileName\":\"3095447_en_US_03_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":379,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"In this video, learn how to track model runs using MLflow auto logging.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":14730985,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] We can now  \\n for image classification.  \\n Once again, I import some PyTorch libraries  \\n and classes that we'll need to set up our network.  \\n And next we'll create a new experiment within which we'll  \\n have a training run for our cnn.  \\n I call mlflow.create.experiment.  \\n The name of the experiment  \\n is emnist_letters_prediction_using_cnn,  \\n and I also set this as the active experiment  \\n so that any run that we create will be  \\n within this experiment.  \\n Next, we set up a class  \\n that inherits from a lightning module  \\n where we'll define our convolutional neural network, as well  \\n as the training and validation steps for our model.  \\n As before, for our classification model,  \\n we'll use the cross entropy loss function.  \\n Next, we define our convolutional neural network  \\n with multiple blocks of convolutional  \\n and polling layers.  \\n On line 8, we have our first convolutional layer.  \\n It takes in a single channel image as an input notice.  \\n The first input value is 1,  \\n and then it produces 32 feature maps at the output.  \\n It's followed by a ReLU activation layer,  \\n and we have the second convolutional layer on line 10,  \\n followed by a ReLU activation layer again.  \\n And then on line 12 we have a pooling layer  \\n to subsample the feature maps generated  \\n by the convolutional layers.  \\n Then on lines 14 through 18, we have another block  \\n with two convolutional layers with ReLU activation  \\n and a max pool layer again.  \\n On lines 12 and 18,  \\n notice I've specified in the comments the shape  \\n of the output feature maps from each of the max pool layers.  \\n This is something that you can compute by knowing the size  \\n of the input, knowing the kernel that you're using,  \\n the stride that you're using for the kernel,  \\n and of course the padding  \\n that you're using on the input image.  \\n The convolutional and pooling layer blocks are followed  \\n by a linear layer on line 21.  \\n We flatten the feature maps generated  \\n by the convolutional and pooling blocks  \\n and pass the flattened image through the linear layer,  \\n followed by ReLU activation.  \\n Observe the input dimensions  \\n of the linear layer on line 21 matches the size  \\n of the output feature maps  \\n from the max pooling layer on line 18.  \\n We have two linear layers  \\n with ReLU activation on line 21, 22, 24, and 25.  \\n And then we have our last linear layer on line 27.  \\n The output dimension for the last linear layer is 26 equal  \\n to the number of classes or categories  \\n into which the images can be classified.  \\n We've overridden the forward function,  \\n which defines a forward pass through the network.  \\n The input batch of images xb will be flattened  \\n and it needs to be reshaped into a form  \\n that can be fed into a convolutional neural network.  \\n The reshape function on line 31 converts the images  \\n to a form that is acceptable to PyTorch.  \\n That is the batch size is the first dimension.  \\n Then the number of channels  \\n and then the heightened width of each image.  \\n In configure optimizers, we specify the Adam optimizer  \\n with a learning rate of 0.0001.  \\n The code for the training step line 36  \\n through 49 is identical to the code  \\n that we had in the previous model.  \\n We make a forward pass through the model,  \\n get the predictions, compute the accuracy and the loss,  \\n and we return the loss on line 49.  \\n The code for the validation step is the same  \\n as the training step, again, same  \\n as in the previous dense neural network that we built.  \\n So the code on line 51 to 64 needs no explanation.  \\n Again, note that on line 64,  \\n the validation step returns the accuracy  \\n of the model on the validation data.  \\n Here is the method for the test step.  \\n This works on the test data,  \\n and on line 79, you can see  \\n that this returns the accuracy on the test data.  \\n And finally, we have the predict step.  \\n All this involves is a forward pass through the model  \\n to get predictions.  \\n Once again, we use the PyTorch Lightning Trainer  \\n to train the model,  \\n and we use MLflow runs to track the models,  \\n parameters and metrics during the training process.  \\n We instantiate our convolutional neural network  \\n on line 5, we use the CSV logger instantiated on line 7  \\n for the trainer to track out the model metrics  \\n during the training run.  \\n We'll instantiate the trainer on line 9.  \\n Again, we train for 10 epoch.  \\n You can train for longer if you want to,  \\n and we pass in the CSV logger so that the trainer  \\n can log out metrics.  \\n Once again on line 11, I turn on MLflow PyTorch autolog,  \\n so all metrics, parameters, tags,  \\n et cetera are logged out automatically except  \\n for the model artifacts.  \\n Notice I've set log models to false.  \\n I start the MLflow run on line 13.  \\n This run will automatically be ended once we are out  \\n of the width block.  \\n We start the training process on line 15  \\n by calling trainer.fit.  \\n We evaluate the trained model on the test data on line 16.  \\n Observe the input schema is now different  \\n because we're expecting input in the form of images  \\n and not flattened images,  \\n so the input is expected in the form of batch, number  \\n of channels, height and width  \\n of the image, minus 1, 1, 28 28.  \\n The output schema, again, has a dimension of 26  \\n because there are 26 classes  \\n or categories into which we can classify images.  \\n We instantiate a model signature object on line 20,  \\n and I explicitly call MLflow PyTorch log model.  \\n This will log out the model artifacts in the folder,  \\n emnist-letters-classifier-cnn-model, along  \\n with the model signature in the ML model file.  \\n I'm going to kickstart the training process,  \\n and for about 10 epochs of training, it took maybe 20  \\n to 25 minutes for this convolutional neural network.  \\n You can see on the first line here,  \\n GPU available: True, used: True.  \\n The PyTorch Lightning Trainer realized  \\n that a GPU was available  \\n and used that for training.  \\n Now this convolutional neural network does  \\n so much better on our data than the dense neural network.  \\n Notice the accuracy on the data is 0.907.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3858095\",\"duration\":412,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Visualizing charts, metrics, and parameters on MLflow\",\"fileName\":\"3095447_en_US_03_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":412,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"In this video, learn how to view and interpret charts generated by MLflow.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":14796997,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Now that we've  \\n and tracked its metrics  \\n and parameters using MLflow runs, let's head over  \\n to the MLflow UI  \\n and here you can see the experiment that we've just created  \\n and used the emnist_letters_prediction_using_cnn.  \\n You can see this exactly one run here  \\n within this experiment, mysterious-fly-874.  \\n That is our current training run.  \\n Let's take a look at the chart first so that we can see how  \\n training accuracy and validation accuracy changed over time.  \\n The very first chart that we get,  \\n let me expand the view first is of the test accuracy.  \\n This is a single value  \\n and you can see that it's rather high, 0.91.  \\n If you scroll down, you'll see  \\n how the training loss changed over time.  \\n You can see the loss was high  \\n and it gradually fell over the 10 epochs of training.  \\n Maybe we could have trained further to get a better model.  \\n You can see the validation accuracy here.  \\n It arose up to about 0.91.  \\n Here is the validation loss also fallen over the 10 epochs  \\n of training, and here below is the training accuracy,  \\n which went up to about 0.95.  \\n These charts are automatically generated when we use auto  \\n log with MLflow while training in PyTorch.  \\n Let's click through to the run  \\n and view the details of the run here.  \\n Here we can see the parameters, metrics, tags,  \\n and artifacts that are logged.  \\n Let's expand the parameters here first.  \\n You can see epochs of training.  \\n Then the optimizer name is Adam  \\n and a bunch of other details.  \\n What I'm interested in is the model metrics, so I'm going  \\n to expand the metrics section.  \\n Notice the test accuracy 0.907.  \\n We've seen that training accuracy went up to 0.948,  \\n and validation accuracy was at 0.9181, so all in all,  \\n a pretty decent model.  \\n Once again, since we explicitly logged the model,  \\n your other model artifacts, all  \\n of the artifacts are placed in this folder structure  \\n inside the top level folder that we had specified  \\n by name emnist-letters-classifier-cnn-model.  \\n In a production environment, MLflow would be part  \\n of a shared workspace  \\n and you'd be able to share this run with your team members.  \\n They'd be able to look at the model schema, know the schema  \\n of the input that needs to be fed into this model  \\n and the format of the output  \\n that will be received from this model.  \\n Once again, we have the MLmodel file,  \\n which defines the environment used to train your model  \\n and what flavors of the model are available.  \\n These are the flavors that you can use  \\n to load in the train model and use it for predictions.  \\n Once again, all of this is typically used  \\n by deployment tools.  \\n Here below you can see the signature  \\n of the model specifying the input and output schema.  \\n We're familiar with the other files here,  \\n nothing really interesting there.  \\n Let's head straight over to model summary.  \\n What I found interesting here was observe that every detail  \\n of our model is logged out, all of the layers  \\n in our convolutional neural network  \\n and the trainable params.  \\n Let's head back to the notebook.  \\n Let's visualize the training and validation loss  \\n and accuracy using the metrics that was logged out  \\n by the PyTorch Lightning Trainer.  \\n Here's the metrics file  \\n that I read in from the log directory.  \\n I'll now use some simple seaborn auto visualize the metrics  \\n for our training and validation data.  \\n The data available in metrics do CSV allows us  \\n to visualize these metrics right within our notebook.  \\n We've already seen these charts in MLflow.  \\n Those were auto logged.  \\n Let's get the run ID of the last active run so  \\n that we can then access the model artifact  \\n and load it into our notebook and use it for predictions.  \\n Here is the ID of the last active run.  \\n As we did before, I'm going to get one batch  \\n of data from our test dataset.  \\n I have the images and labels.  \\n We have 64 images and labels in this batch.  \\n Next, I'm going to load the serialized model  \\n into my notebook.  \\n I use the run ID to get a path  \\n to the model artifacts on our local machine.  \\n That is the URL runs /run_id  \\n and then the folder for the model.  \\n Pyfunc here stands  \\n for python function, which is a flexible  \\n and general way to package  \\n and deploy machine learning models as Python functions.  \\n When we use mlflow.pyfunc.load_model,  \\n we are essentially loading our model as a Python function  \\n that we can then invoke.  \\n We call loaded_model.predict pass in the test data  \\n to get the predictions on the test data.  \\n The predictions are in the form of raw logics scores.  \\n This gives us predictions for a single batch of test images,  \\n so if you look at the shape of the predictions,  \\n you should see that we have 64 different predictions.  \\n Now, the prediction  \\n for the image at index 2 in our test data  \\n is the label 4.  \\n Now let's look at what class this label 4 corresponds to.  \\n So I'll set up the classes list here  \\n and I'll look up the classes list by using the label  \\n for index 2.  \\n I have to subtract 1  \\n because remember, our classes list is indexed starting  \\n at 0, whereas the labels in our dataset are indexed  \\n starting at 1.  \\n The image at index 2 corresponds to the letter D.  \\n Let's see what the prediction from our model says.  \\n Let's look at predictions at index 2.  \\n This will give us the raw logics scores, so we need  \\n to use argmax to compute what prediction this actually was,  \\n and you can see that the model also predicted the letter D.  \\n I'm going to set up a utility function show as  \\n before, which will look up an image  \\n by index in the test images  \\n and display a title for that image.  \\n We'll then iterate over all 64 images in one batch  \\n of the test dataset  \\n and see what the predictions from the model were.  \\n The title will display both the predicted  \\n and the actual values from the dataset,  \\n and here are the results.  \\n You can see that in most cases,  \\n the model predictions were spot on.  \\n You'll find very few errors.  \\n That's because our model here has an accuracy  \\n of 91% on the test data.  \\n I use the same code as in the previous demo  \\n to get predictions for the entire test data  \\n and view the results in the form of a confusion matrix.  \\n Notice the accuracy on the test data, 0.907,  \\n that's what we saw logged in MLflow.  \\n The main dial from the top left to the bottom right,  \\n those are the correct predictions of the model,  \\n but our model does get confused with a few letters.  \\n The 246 corresponding to row I  \\n and column L tells us that the model still tends  \\n to mix up I and L.  \\n The 181 on row Q and column G tells us  \\n that Q and G are also confusing for the model.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3853105\",\"duration\":335,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Setting up the objective function for hyperparameter tuning\",\"fileName\":\"3095447_en_US_03_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":335,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"In this video, learn how to implement an objective function for hyperparameter training with Hyperopt.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11990693,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] An important part of model development  \\n in the full stack development workflow is  \\n hyper parameter tuning,  \\n and in this demo we'll see how  \\n to use the hyperop Python library for hyper parameter tuning  \\n and optimization of our convolutional neural network.  \\n Notice I'm on the same notebook  \\n as before EMNIST classification using CNN.  \\n This is the same GPU runtime as  \\n before with ML flow running on Port 5,000.  \\n Hyperopt is an open source python library  \\n for hyper parameter optimization.  \\n The process of finding the best set of hyper parameters  \\n for your machine learning model.  \\n Hyperop is designed to automate  \\n and streamline the search for optimal hyper parameters,  \\n making it easier to fine tune models  \\n and improve their performance.  \\n Now, the reason we select hyperop  \\n for hyper parameter tuning is  \\n because it has great integration with ML flow.  \\n You can combine hyperop  \\n and ML flow to perform hyper parameter tuning  \\n within the context of ML flow experiments and runs.  \\n Now, the first thing I'm going to do is import a bunch  \\n of libraries from the HYPEROP framework, fmin, tpe, hp,  \\n and trials.  \\n I'll explain each of these libraries as we use them.  \\n What I've done here is set up the search space  \\n for hyper parameter optimization.  \\n I've defined the third space  \\n for the learning rate LR in the long space.  \\n HP log uniform is used  \\n to specify a continuous distribution over positive values  \\n in the logarithmic space.  \\n Other number of neurons in the two linear layers at the end  \\n of the convolutional blocks, L one and L two.  \\n We'll try values of 32, 64, and 128 for the first layer  \\n and 64, 128, and 256 for the second layer.  \\n Next, I'll set up our lightning module.  \\n The EM model, the code for the neural network,  \\n and this class is exactly the same  \\n On line two, observe that the init method takes an hparams,  \\n that is the hyper parameters used to configure the model.  \\n Now on line five, self-taught save hyper parameters hparams  \\n will save the hyper parameters past so  \\n that it can be referenced elsewhere in this class.  \\n If you scroll down below  \\n in our convolutional neural network architecture on line 23,  \\n we set up the number  \\n of neurons in the first linear layer  \\n using self hparams L one.  \\n On line 25, we configure the second linear layer  \\n using hparams L two,  \\n and on line 34,  \\n when we instantiate the atom optimizer,  \\n we specify its learning read using our hyper parameter  \\n self-taught hparam lr.  \\n There is absolutely no other change to the code  \\n of this model.  \\n For hyper parameter tuning with hyperop,  \\n you need to define an objective function  \\n and that's what I'm going to do next.  \\n This train emnist function,  \\n which takes in the hyper parameters  \\n for this particular iteration  \\n of training is the objective function.  \\n The objective function  \\n usually contains the model training code  \\n that you want to perform for different runs of training,  \\n and this function represents the performance metric  \\n or evaluation criteria that you want to minimize  \\n during the hyper parameter optimization process.  \\n The objective function is at the core  \\n of hyper parameter tuning with hyperop,  \\n and it aims to find the set of hyper parameters that leads  \\n to the best value of this function.  \\n You'll find that our entire model training code is  \\n encapsulated within this objective function.  \\n This objective function will be repeatedly called  \\n during the hyper parameter optimization process  \\n with a different set of hyper parameters  \\n to build up the model.  \\n Notice the input argument  \\n to this objective function is the params dictionary  \\n containing the set of hyper parameters  \\n to use for this model.  \\n For each model that's trained, we start an ML flow run.  \\n This is on line six.  \\n Observe the fact that we pass in nested equal to true.  \\n Every run part  \\n of this hyper parametal tuning process will be nested  \\n within a parent run.  \\n All of the different trial runs  \\n of the process will be child runs of the parent run.  \\n Now within ML flow start run,  \\n we instantiate the emnist model  \\n and pass in the parameters for this particular model.  \\n On line 10, we instantiate the PyTorch lightning trainer  \\n and on line 12 we start the training process  \\n by passing in the training and validation data.  \\n We are not using ML flow auto logging here, so on lines 14  \\n through 17, we compute the metrics for the training process  \\n of this model on the training and validation data  \\n and on lines 21 through 24,  \\n we log those metrics out explicitly.  \\n On line 19, we explicitly log out the hyper parameters  \\n to construct this model.  \\n We have the metrics and parameters logged.  \\n Then as usual, we compute the input schema  \\n and the output schema for the model,  \\n set up the model signature, and log the model on line 31.  \\n This will be done for every model that's built  \\n and trained as a part  \\n of the hyper parameter optimization process.  \\n Notice what we return here on line 33, that is the core  \\n of this objective function.  \\n Now the objective function returns the metric  \\n that will be minimized  \\n during the hyper parameter optimization process,  \\n and I return the negative value of the validation accuracy.  \\n Minimizing the negative  \\n of the validation accuracy is equivalent  \\n to maximizing the validation accuracy.  \\n So the best model will be the one with the highest accuracy  \\n on the validation data.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3855190\",\"duration\":381,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Hyperparameter optimization with Hyperopt and MLflow\",\"fileName\":\"3095447_en_US_03_05_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":381,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"In this video, learn how to perform hyperparameter optimization with Hyperopt and MLflow.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12938387,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Now that we've set up the objective function,  \\n which returns the metrics that has to be minimized  \\n during the process of hyper parameter optimization,  \\n we can start the hyper parameter tuning process.  \\n Notice that we perform hyper parameter tuning  \\n within an outer ML Flow run.  \\n I call with mlflow.start_run.  \\n All of the runs used to track the individual  \\n model trainings metrics and parameters  \\n will be nested within this outer run.  \\n Now the way you perform hyper parameter tuning  \\n using hyperop is by using this fmin function.  \\n The fmin function is responsible for executing  \\n the actual hyper parameter optimization process  \\n and searching for the best set of hyper parameters  \\n that minimize our objective function.  \\n The function that fmin will run over and over again  \\n to train the different models, which are part  \\n of this optimization process, is the function  \\n that we pass in as an input argument on line three,  \\n the train_emnist function.  \\n That is the objective function that we just defined.  \\n Fmin also needs the third space for the hyper parameters,  \\n which I specify on line four,  \\n and the maximum number of evaluations  \\n or model trainings that we run, I specify on line six.  \\n That is max evals equal to 10.  \\n The fmin function also allows you to specify  \\n the algorithm to use for finding the model  \\n with the best set of hyper parameters.  \\n On line five, you can see that I've asked fmin  \\n to use the tpe.suggest algorithm.  \\n The tpe here stands for tree of parzan estimators,  \\n which is an optimization algorithm  \\n used for Bayesian hyper parameter optimization.  \\n Bayesian optimization is a technique  \\n that uses a probabilistic model  \\n to approximate the objective function  \\n and then make informed decisions, about where  \\n to sample the next set of hyper parameters.  \\n This is a popular choice over other optimization algorithms  \\n because it can find the optimal set of hyper parameters,  \\n while minimizing the number of evaluations required.  \\n And the model with the best results  \\n will be stored in the best result variable.  \\n Let's kick start our hyper parameter optimization process  \\n by hitting shift enter and executing the fmin function.  \\n Now, remember that there'll be 10 different trials.  \\n That is 10 different models will be trained,  \\n so this is going to take a while.  \\n Now, while the training is in progress,  \\n and the entire training is going to take  \\n about 60 minutes to run through,  \\n let's head over to ML Flow.  \\n And notice we have a new run  \\n within our emnist_letters experiment,  \\n the hilarious-shad-653.  \\n Observe the little plus next to that top level run.  \\n This indicates that this is a parent run  \\n and nested within it, there are several child runs.  \\n Exactly one at this point in time,  \\n but this is going to increase.  \\n All of the runs nested within the parent run  \\n are child runs, each representing  \\n a separate model that has been trained.  \\n Let's click through to the first run here  \\n and here you'll be able to view the parameters  \\n and metrics of this first model that's being trained.  \\n The model training for the first model seems to be complete.  \\n If you look at the metrics, you can see  \\n that the validation accuracy is .8989.  \\n Let's go back to our experiment page here  \\n where all of the runs are listed.  \\n Now the second model is currently being trained  \\n and you can click on this little refresh icon  \\n to get additional details.  \\n When a run is complete, that should show up.  \\n Let me click on the experiment once again,  \\n and notice that we have two child runs under the parent run.  \\n You can click through and view the details  \\n of this particular run if you want to.  \\n But what I'm going to show you instead  \\n is an interesting way you can configure  \\n this particular page, to make it more useful.  \\n If you click on the Columns option here,  \\n you'll see additional columns  \\n that you can view on this Experiment page.  \\n Observe that it's possible to view  \\n the metrics of the various models  \\n right here on this page, so I'm going  \\n to select a few metrics that I want to see.  \\n The test accuracy, then maybe the training accuracy,  \\n and the validation accuracy.  \\n If there are other columns that you want to view,  \\n you should go ahead and select those here.  \\n These are the three that I'm interested in,  \\n so I'm going to just stick with that.  \\n And these should be now visible as columns  \\n here in this experiment view.  \\n I'm not showing them to you yet,  \\n because they are not as interesting.  \\n I'll show them to you in just a bit.  \\n Meanwhile, I'm waiting for more child runs to complete.  \\n Remember, we'll be running a total of 10 trials,  \\n so we still have a ways to go.  \\n What I'm going to do now  \\n is show you how you can compare runs.  \\n I'm going to hide all of the runs  \\n that I'm not interested in, by clicking  \\n on the little eye icon next to the run.  \\n So I'm going to click on this eye icon,  \\n that'll hide this particular run.  \\n And the only runs I have selected are the last two runs,  \\n that is the last two model executions.  \\n You can see the popup that says  \\n switch to the chart view to compare runs.  \\n Click on \\\"Got It,\\\" and that will take you  \\n immediately to the chart view.  \\n And this will show you the two runs that we have selected.  \\n It will compare all of the metrics for those two runs.  \\n Let's take a look at the charts here.  \\n Here is the training loss for the two runs.  \\n The colors in the chart correspond  \\n to the colors for each of the runs,  \\n specified in the little table off to the left.  \\n The yellow color is for unequaled-cub-63,  \\n and the red color is for aged-hawk-722.  \\n You can see that the second run, the one  \\n denoted in yellow, is still in progress.  \\n Only three epochs are done of training,  \\n and that's why you don't see a complete line.  \\n Let's scroll down a little bit further.  \\n Here you can see how the validation accuracy  \\n of the two runs compare.  \\n And again, the second run isn't complete yet.  \\n And scrolling down further, here we have  \\n the train accuracy for the two runs.  \\n You can see that the run in red  \\n is a better model overall than the run  \\n in yellow, at least so far.  \\n I'll now go back to the main able view here.  \\n There is nothing much we can do  \\n except wait for this hyper parameter  \\n optimization process to complete.  \\n All 10 evaluations need to go through.  \\n So I've been waiting patiently, but at some time,  \\n model training will indeed complete.  \\n And you can see here in the notebook  \\n that we've reached end of the optimization process.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3856120\",\"duration\":219,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Identifying the best model\",\"fileName\":\"3095447_en_US_03_06_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":219,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"In this video, learn how to identify the best model parameters found using hyperparameter optimization.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7632266,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Now that the hyper parameter  \\n optimization process is complete, the variable best result  \\n should hold the hyper parameters for the model  \\n with the best accuracy score on the validation data.  \\n So let's take a look at best result here.  \\n And this was the result where we chose the first option  \\n for l1 the second option for l2,  \\n and the learning rate was around 0.000285.  \\n Now, in order to know what the model parameters were  \\n for this best possible model, you can print out the results  \\n of the hyper opt of space eval function,  \\n pass in the search space, pass in the best result,  \\n and you'll get the hyper parameters for the best model.  \\n l1 has a value of 64, l2, a value of 256,  \\n and lr is 0.0002855.  \\n Now, let's go back to our ml flow experiment.  \\n Now, if you remember, we had added to this page,  \\n three different columns: the training accuracy,  \\n validation accuracy, and the test accuracy.  \\n If you scroll over to the right here, you'll see  \\n that these three columns are available here in this view,  \\n there is no test accuracy metric, but we do have the train  \\n and validation accuracy metrics.  \\n And you can actually sort your runs  \\n based on the validation accuracy.  \\n Let's do exactly that.  \\n I'm sorting by the descending order of validation accuracy  \\n and you can see that the run  \\n that had the best model was aged hawk 722.  \\n This is the run that produced the model  \\n with the best parameters that we saw in our notebook.  \\n Let's click through to this run  \\n and take a look at the parameters of the model  \\n that was trained in this run.  \\n If you expand the parameters, notice l1 is 64, l2 is 256,  \\n and lr is 0.0002855.  \\n You'll be able to view all of the metrics  \\n for this model on the training and validation data.  \\n If you expand the metrics here,  \\n you can see the training accuracy was very high, 0.968,  \\n the validation accuracy was 9324.  \\n For every model that we trained,  \\n we also log the model artifacts, and they're available here  \\n in the artifacts section at the bottom.  \\n You can select the individual details here  \\n in the model artifacts and view them.  \\n Now, I want to load and use this model artifact  \\n for predictions on the test data.  \\n So I'm going to copy over the URL for the logged model  \\n and use that within my notebook.  \\n The logged model references the best model  \\n that was found using hyper parameter tuning  \\n based on the validation accuracy, remember that.  \\n I'll now use this model  \\n for predictions on one batch of the test data.  \\n On line 5, I use mlflow.pyfunc.load model  \\n to load the model in as a Python function  \\n from the artifacts directory.  \\n And on line 9, we make predictions on test images,  \\n that is one batch of the test data.  \\n And we'll print out the first five predictions,  \\n and these are in the form of raw logic scores.  \\n Now, with this loaded model,  \\n let's make predictions on the entire test dataset.  \\n We run a for loop over the entire test data on line 7.  \\n On line 8, we call loaded model.predict  \\n on the current patch of the test data.  \\n We get the predictions on line 10, we add the predictions  \\n to the y pred list on line 11,  \\n and we add the true values to the y true list on line 14.  \\n On line 16, we compute the accuracy  \\n of the model on the test data, and you can see  \\n that this is also fairly high, 0.9256 or 92.56%.  \\n So hyper parameter tuning with ml flow allowed us  \\n to identify the best model.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3857097\",\"duration\":192,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Registering a model with the MLflow registry\",\"fileName\":\"3095447_en_US_03_07_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":192,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"In this video, learn how to register your model with the MLflow model registry and manage the model's environment.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5551710,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Here I am back in the ML Flow page  \\n for the run that produced the best model on our data.  \\n Now, I did tell you early on that we won't be  \\n working at all with the model registry,  \\n but I'll show you one little thing here.  \\n I'll show you how you can register a model  \\n with the ML flow model registry,  \\n and this will help you keep track  \\n of the different versions of your model  \\n that you create over time.  \\n Now, here on this run page,  \\n notice you have a button for register model.  \\n Just click on that button.  \\n This will bring up a dialogue, select create new model,  \\n and specify a name for your model.  \\n I've called this emnist_cnn_classification.  \\n Click on register,  \\n and your model is now registered  \\n with the ML Flow Centralized Model Registry.  \\n And a version is associated with this model.  \\n If you head over to the Models tab,  \\n you should see our newly registered model in there.  \\n You can see that this is version one of the model.  \\n As you create new versions of the model,  \\n you can use that to replace this older version.  \\n And the centralized model registry will keep track  \\n of your different model versions.  \\n Let's click through and take a look.  \\n You can see we have just one version  \\n of the model, version one.  \\n If you had multiple versions, they'd be listed here.  \\n I'll click through to version one,  \\n and here you'll be able to see  \\n the details of the registered model.  \\n Notice that the input and output schema  \\n are both available here for you to view.  \\n You can see the source run  \\n that created this model, aged-hawk-722.  \\n And you can see that the current stage  \\n of the model is set to none by default.  \\n Now let's say you've tested this model  \\n thoroughly in the development environment  \\n and you're ready to transition this model.  \\n You can choose to transition  \\n to the staging or production environments.  \\n The next step would likely be the staging environment.  \\n So I'm going to go ahead and transition this model  \\n to the staging environment.  \\n Because this is our locally running ML flow server,  \\n this transition does not require any approval.  \\n If you're working in a production environment  \\n as a part of a shared workspace,  \\n these transitions usually require approval  \\n from someone higher up in your team.  \\n Observe that the model is currently  \\n in the staging environment, and if you head back  \\n to the model, you can see that version one  \\n is in staging, and you can have  \\n multiple versions in different environments,  \\n staging, production, and even archive.  \\n At some point, you've likely tested this model  \\n in the staging environment and you are satisfied with it.  \\n That's when you'd transition the model  \\n to the production environment.  \\n And, this is where you indicate that this model  \\n is ready to be deployed to production.  \\n If you work with ML Flow integrated as a part  \\n of a cloud platform such as Databricks,  \\n well, you can manage all of these transitions  \\n within a Databricks workspace, and you can also  \\n deploy your model once you've registered it  \\n to be part of the model registry.  \\n Because you're working with a locally running  \\n ML flow in a CoLab environment,  \\n we can't really deploy our model here.  \\n In the next demo, we'll work with model deployment  \\n and we'll use a slight workaround,  \\n in order to see how exactly ML Flow  \\n serving and deployment work.  \\n \\n\\n\"}],\"name\":\"3. Model Training and Hyperparameter Tuning\",\"size\":76564669,\"urn\":\"urn:li:learningContentChapter:3855192\"},{\"duration\":828,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3852092\",\"duration\":296,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Setting up MLflow on the local machine\",\"fileName\":\"3095447_en_US_04_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":296,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"In this video, learn how to install and set up MLflow on your local machine.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7998830,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] While working on Colab,  \\n we don't have access to the underlying virtual machine  \\n that hosts our cloud notebook,  \\n which is why we had to use Ngrok  \\n to access MLflow running on Colab.  \\n Now, if you want to be able to serve  \\n and deploy our models using MLflow,  \\n well Colab is just not going to work.  \\n So I'm going to use a little work around  \\n and set up MLflow on my local machine  \\n and we'll serve the model  \\n that we trained on Colab on our local machine.  \\n This will involve downloading the artifacts  \\n trained on Colab, setting up the same directory structure  \\n on our local machine, and then using MLflow to deploy  \\n and serve the model artifacts.  \\n First thing here on my local machine,  \\n let's make sure I have Python installed.  \\n Python --version tells me I have Python 3.10.9,  \\n the same version of Python that we use  \\n to train our model.  \\n We'll be using a locally running Jupyter Notebook,  \\n so I'm going to check whether I have Jupyter installed.  \\n Jupyter --version tells me that I have a new version  \\n of Jupyter available that I can use.  \\n I'm going to create a folder called full_stack_deep_learning  \\n that will serve as my working directory.  \\n I create this folder and I'm going to CD into this folder.  \\n We'll need to install MLflow on our local machine,  \\n and for that I'm going  \\n to set up a Python virtual environment.  \\n It's always a good practice  \\n to run MLflow within an isolated virtual environment.  \\n I've created an environment called fsdl_venv,  \\n and if you run an ls -l here in the current folder,  \\n you should see there is a folder  \\n that corresponds to this virtual.  \\n Since I'm working on a Mac machine,  \\n I use this source command in order  \\n to activate this virtual environment source fsdl_venv  \\n /bin/activate.  \\n If you're on a Windows machine, this is the command  \\n that you'd use to activate the virtual environment.  \\n You'd run the activate.bat batch script  \\n within the bin folder.  \\n Notice that our prompt has changed indicating  \\n that we are now within the fsdl_venv virtual environment.  \\n Next, I'm going to install IPyKernel.  \\n IPyKernel is a Python package  \\n that provides the communication  \\n between the Jupyter Notebook interface  \\n and the Python kernel.  \\n And this is the Python package that will allow us  \\n to run our Jupyter notebook  \\n using this virtual environment that we've created.  \\n Once IPyKernel is installed, run jupyter kernelspec list  \\n to see what kernels are currently available  \\n to your Jupyter Notebook.  \\n You can see there's exactly one Python 3 kernel  \\n that's available.  \\n Let's install the kernel associated  \\n with our virtual environment, python -m ipykernel install.  \\n The name of the kernel to install is fsdl_venv.  \\n That is our virtual environment,  \\n and I'm installing this for the current user.  \\n So this kernel specification has now been installed  \\n for Jupyter Notebook.  \\n If you're on Jupyter Kernel spec list, you can see  \\n that we have a new kernel available, fsdl_venv kernel.  \\n We'll be using the Python package manager pip  \\n to install packages.  \\n So let's upgrade pip so that we  \\n have the latest version, 22.3.1,  \\n at the time of my recording.  \\n I'll now install the different Python packages  \\n that we need within this virtual environment,  \\n torch, matplotlib, numpy, pandas, and mlflow.  \\n We install all of these.  \\n Once the installation has run through,  \\n let's confirm that MLflow is indeed available  \\n on our local machine, run mlflow --version.  \\n And this should give you a version number.  \\n You can see that we are using MLflow version 2.9.1.  \\n If you are building and training your models locally  \\n using MLflow, the way you bring  \\n up the MLflow development environment  \\n is by running MLflow UI in your terminal.  \\n I'll show you that we'll see the same MLflow page  \\n as before when we worked on Colab.  \\n So let's head over to 127.0.0.1:5000.  \\n And here is our familiar MLflow user interface experiments  \\n and models.  \\n We won't really be using the MLflow development server  \\n on our local machine except to deploy  \\n and serve our MLflow model.  \\n So let's go ahead and heal the MLflow UI.  \\n Within this virtual environment,  \\n I'll now bring up the Jupyter Notebook server  \\n on my local machine, and this is what we'll use  \\n to send request to our deployed model  \\n to get predictions.  \\n Let's open up the Jupyter Notebook server here.  \\n I've created a new notebook called ModelDeployment  \\n on our locally running Jupyter Notebook server.  \\n And you can see on the top right that the Python kernel  \\n that this notebook is using  \\n is our virtual environment, fsdl_venv.  \\n I'm just going to toggle the header here under view so  \\n that we have more room on our notebook for our code.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3854104\",\"duration\":139,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Workaround to get model artifacts on the local machine\",\"fileName\":\"3095447_en_US_04_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":139,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"In this video, discover how to download MLflow artifacts.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4107144,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Now early on in this course  \\n I had mentioned that because we needed to use a GPU,  \\n we couldn't train this convolutional neural network on our  \\n local machine and instead had to use Colab.  \\n We then set up ML flow on the Colab runtime  \\n and then used ML Flow to track our models, metrics,  \\n parameters, and artifacts.  \\n Now, here are our models,  \\n artifacts available on the Colab runtime,  \\n but they're not present on my local machine.  \\n I want to show you how we can deploy  \\n and serve this model using ML flow  \\n and we'll do that on our local machine.  \\n So what I need to do is download all of the artifacts  \\n that ML Flow has saved into this emnist letters classifier,  \\n CNN model, sub folder to the local machine.  \\n I've selected the model.path file under data,  \\n and I'm going to click on this download button,  \\n and this will download this into my downloads folder.  \\n And I'm going do this for every file under artifacts here.  \\n I'm going to download this text file as well,  \\n and I'm going to download all of the other files one by one.  \\n So this is not something that you'd have  \\n to do if you are essentially serving the model exactly  \\n where you train the model.  \\n It just so happened that we train the model on CoLab  \\n and we are going to be deploying  \\n and serving the model on our local machine.  \\n So I need all of these artifacts here on my local machine.  \\n On my local machine, I use all of the downloaded files  \\n and set up the structure  \\n of a folder called Best underscore Model.  \\n This has the same structure as the ML flow artifacts folder,  \\n and I've placed this best model sub folder under the ML runs  \\n directory that ML Flow created when we  \\n ran the ML flow server.  \\n So under best model, I have a conda YML file  \\n for the conda environment, an ML model file, a Python  \\n underscore ENV YML file, and a requirements.text file.  \\n And in the data sub folder, I have the model artifact,  \\n the model.path file, and the module info text file.  \\n So this best model folder exactly mimics the model artifacts  \\n folder that ML flow creates.  \\n Again, we've had to do this as kind of a hack  \\n or a workaround because we are going to be deploying  \\n and serving our model locally while the model was trained  \\n and tracked in ML flow in a CoLab environment.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3854105\",\"duration\":393,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Deploying and serving the model locally\",\"fileName\":\"3095447_en_US_04_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":393,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"In this video, discover how to use MLflow serving to deploy your model on your local machine.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12574703,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Before we deploy  \\n and serve the model using MLflow,  \\n let's load the model in from the best model folder  \\n as a Python function  \\n and use it for predictions right here  \\n in this Jupyter Notebook.  \\n I'm going to install PyTorch Lightning  \\n because I'm going to set up a data set  \\n and a data loader for the test data.  \\n Let's quickly import the libraries  \\n that we need to work with PyTorch Torch, NumPy, matplotlib,  \\n pandas, and so on, and also the dataset and the data loader.  \\n I have the CSV file  \\n of the test data in my local machine  \\n in the current working directory,  \\n so I'm going to use Pandas to read in this data.  \\n Once we have the test data, I'm going to shuffle it  \\n by using the sample function in Pandas.  \\n We now have the test data in the form of a data frame.  \\n I create a dataset to represent this test data.  \\n This is the same emnist dataset  \\n that we've seen in earlier demos.  \\n I'm just setting this up in this notebook.  \\n Next, I instantiate the test data set  \\n by passing in the test data frame  \\n and I also instantiate a test data loader  \\n with a batch size of 64.  \\n This is the batch size we've been  \\n consistently using with this data.  \\n Next, let's set up an iterator over this test data loader  \\n to get the first batch of test images.  \\n The shape of the test images is 64 by 784.  \\n This is one batch. We have the images as well as the labels.  \\n Let's now access the trained model to use for predictions.  \\n We'll reference the artifacts  \\n that we downloaded from Colab.  \\n The best model sub folder  \\n that we set up is in the ML runs directory.  \\n That is in the current working directory of this notebook,  \\n so the log model is at mlruns/best_model.  \\n We load the model using mlflow.pyfunc.load_model,  \\n and then called loaded_model.predict on the test images.  \\n This will give us 64 predictions on the first batch  \\n of the test data.  \\n It's likely that you'll encounter some warnings  \\n when you do this.  \\n That's because all of the packages  \\n and versions for the various Python libraries  \\n that we've used on Colab may not exactly match the packages  \\n and versions that we have in our local environment.  \\n This is because we are using a workaround to deploy a model  \\n that we trained on Colab on our local machine.  \\n This is not a trick you're likely  \\n to be using in a production environment.  \\n Well, now that we have the predictions from our model,  \\n let's take a look at one of the test images,  \\n the one at Index 5,  \\n and this seems to be an image of an I or maybe an L.  \\n Let's take a look at the test label associated with 5,  \\n and you can see that it's 12 indicating  \\n that this is likely an L.  \\n We need a list of the classes  \\n or categories into which the images  \\n are classified, A through Z.  \\n Let's see the actual label associated  \\n with the test image 5, and you can see  \\n that it corresponds to an L.  \\n This is the actual label from the test data.  \\n Now let's get the prediction from our model,  \\n but rather than use the model loaded into this notebook  \\n to get the prediction, let's deploy this model  \\n using MLflow to a local endpoint.  \\n And deploying a model with MLflow is very straightforward.  \\n Simply call mlflow models serve, specify the path  \\n to the model artifacts folder.  \\n That is mlruns/best_model.  \\n This is a locally running MLflow, so env-manager is local  \\n and the host at which the model endpoint  \\n will be available is 127.0.0.1:1234.  \\n Executing this command will deploy  \\n and serve your package model locally available  \\n at the endpoint that we have specified.  \\n Now, back to our notebook.  \\n Let me show you how we can hit this locally running endpoint  \\n with some image data.  \\n I'm going to take the test image at index 5.  \\n I need the data in a particular format so I can use  \\n that data to hit the model endpoint.  \\n I reshape the image to be of a form that the model accepts.  \\n Bat size is the first dimension, the number of channels,  \\n and then height and width.  \\n And I convert the image data to a list  \\n and I set up a JSON structure  \\n where this list is the value corresponding  \\n to the key instances.  \\n This is the structure that we need to use  \\n to send this image data to our prediction endpoint.  \\n I'm just going to copy this entire structure over so  \\n that I can use it to make the curl request  \\n to the prediction endpoint in the next code cell.  \\n Go ahead and copy this, and here is my curl request.  \\n I use the curl utility to make a get request  \\n to the URL http://127.0.0.1:1234/invocations.  \\n This is the rest endpoint of the locally deployed model.  \\n I have a request body in this HTTP request that I make  \\n and the request body specified using -d is the JSON data  \\n representing a single test image  \\n that I copied over from the previous code cells output.  \\n Let's go ahead and hit shift enter,  \\n and you can see the predictions  \\n from our locally running endpoint.  \\n These other raw logics scores.  \\n The responses in the form of a JSON string will need  \\n to extract the actual predictions from this response.  \\n Going to copy this JSON string over  \\n and use json.loads to get it in the JSON format.  \\n We'll then look up the value for the predictions key  \\n and we'll index into it at index 0.  \\n That'll give us the array of the actual predictions.  \\n You can see the predictions variable here  \\n contains the predictions in the list format.  \\n Let's now get the predicted label  \\n from the raw logics scores.  \\n I use np.argmax and index into the classes list,  \\n and you can see here that the model has predicted L.  \\n The predicted label is equal to the actual label.  \\n Now here's some practice that you can do on your own.  \\n Simply pick a different test image converted  \\n to the JSON format that are locally  \\n hosted prediction endpoint expects,  \\n and then use the curl command  \\n to get predictions for the test image.  \\n Pass the predictions response  \\n and see what the predicted label is.  \\n All of the code is available for you to use  \\n right in this notebook.  \\n \\n\\n\"}],\"name\":\"4. Model Deployment and Predictions\",\"size\":24680677,\"urn\":\"urn:li:learningContentChapter:3857098\"},{\"duration\":104,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3853106\",\"duration\":104,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Summary and next steps\",\"fileName\":\"3095447_en_US_05_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":104,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2513834,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] This demo brings us  \\n to the very end of this course.  \\n Let's quickly review what we've covered so far.  \\n We started off with an overview of full-stack deep learning,  \\n and we saw that this covers the complete lifecycle  \\n of a deep learning model,  \\n from prototyping to production.  \\n we understood the role of MLOps in full-stack deep learning,  \\n and we were introduced to the MLflow tool that streamlines  \\n and automates the machine learning lifecycle.  \\n We then got hands-on with MLflow  \\n and saw how we could track logs  \\n and metrics using MLflow experiments and runs.  \\n We trained two different image classification models  \\n against neural network  \\n and a convolutional neural network,  \\n and we trained them to classify images  \\n from the EMNIST dataset.  \\n We performed hyperparameter tuning  \\n on our convolutional neural network  \\n using the Hyperopt Python library,  \\n which integrates very well with MLflow.  \\n And finally, we used MLflow serving  \\n to deploy our model on the local machine.  \\n Here, at the end of this course,  \\n if you're still interested in learning more  \\n about deep learning systems,  \\n here are some other courses on LinkedIn Learning  \\n that you might find interesting,  \\n AI Text Summarization Using Hugging Face,  \\n Self-Supervised Machine Learning,  \\n and GANs and Diffusion Models in Machine Learning.  \\n The AI Text Summarization course will show you  \\n how you can use Hugging Face transformers  \\n for abstractive text summarization.  \\n Self-Supervised Machine Learning will show you  \\n how you can leverage unlabeled data to build models.  \\n And the third course on GANs  \\n and Diffusion models will introduce you  \\n to early generative AI models.  \\n It's time for me to say goodbye.  \\n That's it from me here today.  \\n Thank you for listening.  \\n \\n\\n\"}],\"name\":\"Conclusion\",\"size\":2513834,\"urn\":\"urn:li:learningContentChapter:3857099\"}],\"size\":226567729,\"duration\":7081,\"zeroBased\":false},{\"course_title\":\"AI Workshop: Build a Neural Network with PyTorch Lightning\",\"course_admin_id\":3096406,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":3096406,\"Project ID\":null,\"Course Name\":\"AI Workshop: Build a Neural Network with PyTorch Lightning\",\"Course Name EN\":\"AI Workshop: Build a Neural Network with PyTorch Lightning\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"&lt;p&gt;If you\u00e2\u20ac\u2122re looking for hands-on AI practice, this workshop-style coding course was designed for you. Join instructor Janani Ravi as she shows you how to build a neural network with PyTorch Lightning, the open-source library from Python that provides an interface for the popular deep learning framework PyTorch. Explore the core components of building a neural network with PyTorch, including setting up the virtual environment, loading and exploring data, preprocessing data for training, creating and training a simple neural network, setting up the Dataset and DataLoader, visualizing losses, and much more. Along the way, Janani covers the basics of using modules in PyTorch Lightning to build, train, and evaluate both regression and classification models.&lt;/p&gt;&lt;p&gt;This course was created by Loonycorn. We are pleased to host this content in our library.&lt;/p&gt;\",\"Course Short Description\":\"Learn how to build a neural network with PyTorch Lightning in this interactive, workshop-style coding course.\",\"Content Type\":\"TOOLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":20161004,\"Instructor Name\":\"Janani  Ravi\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"Certified Google Cloud Architect and Data Engineer\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2023-12-08T00:00:00\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"Yes\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/ai-workshop-build-a-neural-network-with-pytorch-lightning\",\"Series\":\"One-Off\",\"Limited Series\":null,\"Manager Level\":\"Individual Contributor\",\"LI Level\":\"Intermediate\",\"LI Level EN\":\"Intermediate\",\"Sensitivity\":null,\"Internal Library\":\"Technology\",\"Internal Subject\":\"Artificial Intelligence for Technology\",\"Primary Software\":\"PyTorch\",\"Media Type\":\"Video\",\"Has CEU\":\"No\",\"Has Exercise Files\":\"Yes\",\"Visible Duration\":5449.0,\"Visible Video Count\":19.0,\"Contract Type\":\"INSTRUCTOR_PRODUCTION\"},\"sections\":[{\"duration\":719,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4552015\",\"duration\":339,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"AI workshop: Build a neural network with PyTorch Lightning\",\"fileName\":\"3096406_en_US_00_01_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":339,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"After watching this video, you will be familiar with the features of PyTorch and PyTorch Lightning.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8486016,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Hi, and welcome to this course.\\nAI workshop: Build a neural network with PyTorch Lightning.\\nSince this course is an AI workshop, for most of this course\\nwe'll be performing hands-on coding.\\nWe'll build a neural network with PyTorch and we'll see how\\nwe can write cleaner, more modular reusable code\\nwith PyTorch Lightning.\\nNow, before we get to the demos, just a little bit of an overview\\nof PyTorch and PyTorch lightning.\\nFirst, what exactly is PyTorch?\\nHere is a definition from the PyTorch documentation.\\n\\nIt's an optimized tensor library for deep learning using\\nGPUs and CPUs.\\nThe tensors here refer to multi-dimensional arrays that can\\nbe trained in a distributed manner.\\nAnother way to look at PyTorch,\\nalso from the documentation.\\nIt's an open-source machine learning framework based on the\\nPython programming language.\\nIt has simple and intuitive APIs which accelerate the path from\\nresearch prototyping to production deployment.\\nThe PyTorch framework is primarily used to build deep learning\\nneural network models, and its APIs are so simple that\\nwith just basic knowledge of Python,\\nyou should be able to work in PyTorch right away.\\n\\nNow, hopefully, you've worked with neural networks before,\\nand this is not your first neural network course.\\nNeural network models, you know, are just directed acyclic graphs.\\nPyTorch uses something known as dynamic computation graphs.\\nThis means you can build the graph for the model and execute\\nit right away.\\nThis makes it easier and more flexible to build complex\\nneural networks.\\nNow, PyTorch is deeply integrated with NumPy.\\nYou can set up your data in the form of NumPy arrays and convert\\nthose to PyTorch tensors and vice-versa very easily.\\n\\nPyTorch has native support for training on GPUs.\\nYou can have your model parameters and data all moved to the GPU\\navailable on the machine that you're running\\ntraining and the entire training process will run there.\\nPyTorch also uses a powerful library called Autograd for\\nautomatic differentiation.\\nAutomatic differentiation is an important part of training\\na neural network model.\\nThis involves computing partial derivatives of the loss function\\nwith respect to every model parameters,\\nand then using that information to tweak model parameters to minimize\\nthe loss of a network.\\n\\nThe PyTorch library contains everything that you need to\\nbuild neural networks.\\nYou have classes for the layers of a neural network,\\ndifferent kinds of layers, optimizers that you use to\\ntrain neural networks,\\nloss functions for different kinds of models,\\nserializers to serialize the model out to disk.\\nThe PyTorch framework is flexible and easy to use.\\nWhen you use PyTorch directly to build and train neural networks,\\nyou get access to a low-level API for model training.\\n\\nAnd this is great when you really want to configure and customize\\nyour model and want very granular control over the training process.\\nBut if you want to be abstracted away from the details\\nof model training,\\nusing the PyTorch framework directly is not a great choice.\\nPyTorch has many repetitive tasks and a lot of boilerplate code,\\nso it's often very tedious to write code in PyTorch\\nto train your model.\\nIf you want to avoid working with all of these nitty-gritty details\\nand want your model code to be cleaner and more modular,\\nwell, you use PyTorch Lightning.\\n\\nPyTorch Lightning is an open-source\\nlightweight wrapper or framework built on top of PyTorch that\\nsimplifies the training and research process for deep\\nlearning models.\\nSo this is something important.\\nPyTorch Lightning is just a wrapper,\\nso you can't do anything in Lightning that you can't\\ndo with PyTorch.\\nThe fact is, it's just much easier to work with\\nPyTorch Lightning. PyTorch Lightning abstracts away all of\\nthe nitty-gritty details and really reduces the boilerplate\\ncode that you have to write for training models.\\n\\nWhatever you need to do to build and train neural networks,\\nPyTorch Lightning will give you a high-level interface for this.\\nYou can define data sets, define models,\\nset up training loops, and log your experiments all using\\nthis high-level interface.\\nWhat are some of the advantages of using PyTorch Lightning?\\nWell, your code is much cleaner because most of the repetitive\\ncode and training loops that you have to use in PyTorch\\nis abstracted away.\\nYour code is also more modular with Lightning.\\n\\nIt encourages a modular design by separating the different parts of\\nthe training process into well-defined components\\nsuch as the model DataLoaders and training logic. Cleaner\\nmodular code results in better reproducibility of your\\nmodel and data.\\nLightning provides built-in support for experiment logging\\nand tracking, as well.\\nLightning support for distributed training is more straightforward\\nbecause you do not need to\\nmove your model parameters and data to specific devices to\\nactually train on that device.\\n\\nLightning offers a callback system,\\nallowing you to add custom functionality at various points\\nduring the training process without modifying the\\ncore training loop.\\nInstead of writing complex for loops to train your model,\\nthe trainer class in Lightning abstracts away many training\\nloop details.\\nIf you feel that PyTorch Lightning does not offer you the flexibility\\nthat you need for model training, well, you can use Lightning along\\nwith the PyTorch API. So they are interoperable,\\ngiving you experiment flexibility.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4554027\",\"duration\":51,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Prerequisites\",\"fileName\":\"3096406_en_US_00_02_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":51,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"After watching this video, you will be familiar with the prerequisites to working with PyTorch.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1217837,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Before you get hands-on and that will be very soon,\\nlet's quickly look at some of the prereqs\\nyou need to have to make the most of your learning.\\nThe first thing here is you need to have a basic understanding\\nof machine learning.\\nThis is not a beginner machine learning course.\\nInstead, it's an AI workshop, which means we'll get hands-on\\nwith demos right away.\\nA basic understanding of machine learning,\\nregression, and classification models will really help you.\\nAlso, you need to have a basic understanding of how neural\\nnetworks work.\\n\\nneural networks function, but that's more of revision\\nrather than explaining all of the nitty gritty of neural\\nnetwork training.\\nSo basic understanding of neural networks would really help.\\nAnd finally, because we are going to be coding a lot using Python,\\nyou should be comfortable programming in Python.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4551029\",\"duration\":329,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Quick overview of neural networks\",\"fileName\":\"3096406_en_US_00_03_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":329,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"After watching this video, you will be familiar with how neural networks work.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8928669,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Let's do a quick revision of how neural networks work before\\nwe get down to the demos.\\nRemember, this is not a comprehensive overview or a look\\nat neural network training, but a quick overview to give you\\nthe main points to remember as you dive into the code.\\nNeural network models are made up of layers and how these layers are\\narranged and connected make up the architecture of the model.\\nYou can think of every layer in a neural network as being connected\\nto other layers in the neural network.\\n\\nThe way neural networks function is that every layer in the neural\\nnetwork is responsible for extracting a different detail\\nfrom the underlying data,\\nand all of the layers put together make predictions.\\nNow, the first layer here in our neural network,\\nthat's the input layer.\\nThis is where we feed in the input data,\\nwhether during the training process or for predictions.\\nThe final predictions of the neural network are available\\nfrom the last layer,\\nthat is the output layer. Between the input and output layers,\\nyou have one or more hidden layers and these hidden layers\\ntransform the data.\\n\\nThese transformations are applied as the data flow through the\\nlayers of the model.\\nThe operation of each hidden layer is to extract a different bit of\\ninformation from the data that passes through. In a\\nneural network,\\nevery layer is made up of active learning units called neurons.\\nThey are called active learning units because it's these neurons\\nthat are identifying patterns and making generalizations from the\\ndata that passes through the network.\\n\\nNeurons are fed inputs and they produce outputs.\\nAnd these inputs and outputs are essentially interconnections\\nin the model.\\nThe output of every neuron may be connected to one or more neurons\\nin the layer after it. And how these connections\\nare set up,\\nwell, that's a part of the neural network architecture.\\nNow, we've said that neurons are active learning units,\\nbut what exactly is a neuron?\\nEach neuron is nothing but a mathematical function.\\nEach neuron applies this function that you see here at the\\nbottom to its inputs.\\n\\nIt computes the weighted X values, X values are the input,\\nadds a bias, and applies an activation function on Wx + b\\nto compute the final output Y.\\nThe first of these mathematical functions that the neural network\\napplies is responsible for learning linear relationships\\nthat exist in the data.\\nA neuron receives a vector of inputs.\\nYou can think of these as X1 through Xn,\\nand it basically applies a weight value to each element\\nof the vector.\\n\\nThese weights are associated with the connections that flow into the\\nneuron. Wx + b is the first mathematical operation\\nof the neuron, and this operation is responsible\\nfor learning linear relationships that exist in data.\\nThe second mathematical function that a neuron applies to its\\ninputs is the activation function.\\nThe activation function is responsible for learning\\nnon-linear relationships that exist in data.\\nPopular activation functions include the rectified\\nlinear unit or ReLU,\\nthere is, the sigmoid activation function,\\nand many others.\\n\\nThe choice of activation function is a part of the neural network\\ndesign.\\nThe weights and biases of all of the neurons in your neural network\\nmake up the trainable parameters of the model.\\nThese weights and biases are what are found during the training\\nprocess. You can think of\\nthe objective of the training process of a neural network is to\\nfind the weights and biases for all of the interconnections that\\nminimizes the loss of the model.\\nThe loss here is essentially a measure of how far the predictions\\nof the model are from the actual values\\nin the training data. We know that model parameters are\\nfound during the training process of the neural network.\\n\\nBut how does training work?\\nHere is a very high level explanation.\\nDuring the training process, we feed training data in batches\\nthrough the network and get predictions using the current\\nparameters of the model.\\nThese predictions, at least to start off with,\\nwill not be very good ones.\\nWe'll measure how good the predictions of the model are\\nby computing the loss.\\nThe loss represents how far is the prediction of the model from the\\nactual labels in the training data.\\n\\nOnce we have the loss function, we'll compute gradients, where\\ngradients are just the partial derivatives of the loss with\\nrespect to each parameter\\nin model training. These gradients give us a sense of\\nhow to tweak the model parameters to minimize the loss of the model.\\nWe then make a backward pass through the model to update\\nparameters to minimize the loss.\\nAnd this forward pass to get predictions and then backward pass\\nto update the model parameters continues through the entire\\ntraining process until the model parameters converge.\\n\\nThe entire objective of the training process is to minimize\\nthe loss of the network, and thus improve the predictions\\nof the model.\\nThis minimization of the loss of the network is done using an\\noptimization algorithm called gradient descent.\\n\"}],\"name\":\"Introduction\",\"size\":18632522,\"urn\":\"urn:li:learningContentChapter:4550022\"},{\"duration\":2462,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4554028\",\"duration\":264,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Setting up the virtual environment\",\"fileName\":\"3096406_en_US_01_01_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":264,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"After watching this video, you will be able to set up a virtual environment.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6648730,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"In this course, we'll first build a simple neural\\nnetwork model for regression using PyTorch.\\nAnd you'll see that there are a lot of granular details that you\\nneed to know about model building in order to work with\\nPyTorch directly.\\nThere will be a lot of boilerplate code.\\nThen we'll basically build the same neural network using\\nPyTorch Lightning.\\nWith PyTorch Lightning, we'll eliminate a lot of the boilerplate\\ncode and create reusable components.\\nYou'll see how much cleaner the code is with PyTorch Lightning.\\n\\nBefore we do any of that, let's set up a virtual environment\\nwithin which we'll install PyTorch and build and train our\\nneural network models.\\nHere I am on my local machine and I have Python installed.\\nMake sure you have a recent version of Python.\\nYou can see that I'm working with Python 3.10.9.\\nI'll now create a Python virtual environment.\\nA virtual environment is just an isolated environment for\\nPython projects, ensuring that each project can\\nhave its own dependencies regardless of what dependencies\\nother projects may have.\\n\\nThis command creates a virtual environment called\\npytorch_venv using the venv module.\\nWhen you create a virtual environment,\\nthis sets up a directory under your current working directory\\nwith the name of your virtual environment.\\nYou can see the pytorch_venv directory here.\\nThis is where all of the packages that we install in the virtual\\nenvironment will be set up and stored.\\nNow, to activate the virtual environment,\\nyou'll run the source command pytorch_venv/bin/activate.\\n\\nThis will activate the virtual environment.\\nNotice that my prompt has changed.\\nThe name of the virtual environment is now part\\nof the prompt.\\nThe same version of Python that I had installed on my local machine\\nshould now be available here\\nin my virtual environment. It's possible to create virtual\\nenvironments using different versions of Python,\\nbut I'm happy with the Python version that I have.\\nIn order to be able to work within this virtual environment\\non a Jupyter Notebook, let's install the ipykernel\\nmodule in Python.\\n\\nUse pip install to install the latest version of ipykernel.\\nThis is the Python package that provides the kernel for Jupyter\\nNotebook and Jupyter Lab.\\nThe kernel is just the computational engine that executes\\nthe code on the notebook.\\nNow, once we have this installed, run jupyter kernelspec list to\\nsee what Python kernels you have available.\\nYou can see I have just the one Python 3.\\nI'll now install the kernel associated with my virtual\\nenvironment using this command here, python -m ipykernel\\ninstall the kernel with name pytorch_venv.\\n\\nRemember, pytorch_venv is a folder in our current working directory,\\nand it is that folder that will be used to set up the kernel.\\nThus, we have a kernel with our virtual environment available when\\nwe use Jupyter Notebooks.\\nRun jupyter kernelspec list once again,\\nand you can see the pytorch_venv kernel.\\nThat's the kernel that we'll use to run our code.\\nWe are within our virtual environment.\\nWe've installed the pytorch_venv kernel.\\nLet's bring up the Jupyter Notebook server so that we can\\nwork within Jupyter Notebook to build and train models using\\nPyTorch and PyTorch Lightning.\\n\\nHere, let's open up a new notebook,\\nclick on \\\"New\\\" and make sure that you choose pytorch_venv\\nas the kernel that you want to run your code on.\\nIf you choose this kernel, we'll be running within our\\nvirtual environment. On the top right,\\nnotice the kernel.\\nIt's pytorch_venv.\\nIf you happen to be in some other kernel and you need to switch,\\nsimply select the kernel dropdown menu here on this page,\\nand there you'll find an option to switch your kernel.\\n\\nMeanwhile, let's rename this notebook and give it\\na meaningful name.\\nLet's call this TrainingRegressionModelUsingPyTorch\\nbecause first, we'll work with PyTorch,\\nwhich is much more low-level and involves much more boilerplate in\\norder to understand the different components that you'll use to\\nbuild a neural network model\\nand then we'll switch to PyTorch Lightning. In order to have more\\nscreen space for code, I'm going to toggle the header and\\ntoggle the toolbar here in this notebook.\\n\\nSo we are only left with the code cells.\\nWe don't have all this extra stuff here on top.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4552016\",\"duration\":320,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Loading and exploring regression data\",\"fileName\":\"3096406_en_US_01_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":320,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"After watching this video, you will be able to load data for regression.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9886927,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"The first thing I'm going to do here is put in some code to ignore\\ncertain warnings in this notebook.\\nNow, generally, it's not a good practice to ignore\\nwarnings in your Python code, but at the time of this recording,\\nthe Seaborn Library throw some internal warnings\\nwhich we can't really eliminate.\\nThere is an issue being tracked for Seaborn right now.\\nThe next release should fix it, but since I did not want the demo\\nscreen to be cluttered with warnings,\\nI added these ignore statements at the very top of my code.\\n\\nThis is the issue that I refer to.\\nBy the time you are watching this course,\\nit's likely that it's fixed and you can just get rid\\nof these warnings.\\nWe'll be using the scikit-learn module in Python in order\\nto preprocess our data.\\nSo go ahead and pip install scikit-learn.\\nWe'll use functions such as train, test,\\nsplit, etc. to get training and test data to train our model.\\nSo scikit-learn is a package that you'll need.\\nAnd I install this in the virtual environment.\\nNext, of course, we are going to be using PyTorch to train our model.\\n\\nSo you'll need to pip install the PyTorch framework, as well.\\nYou can see the PyTorch framework version that I'm working\\non is 2.0.1.\\nAnother PyTorch-related module that you need is Torch metrics.\\nThis is the library that contains metrics to evaluate our model's\\nmean square error for regression,\\nno accuracy, precision, and recall for classification.\\nSo make sure you pip install and have this module ready within\\nyour virtual environment.\\nNow within this virtual environment,\\nI need to set up other commonly used libraries for data processing\\nand analysis\\nsuch as pandas.\\n\\nSo make sure you pip install pandas and have that available.\\nAnother library that we need is the Seaborn Library.\\nThis is what we'll use for visualization.\\nSeaborn depends on matplotlib, so the matplotlib library should\\nalso be installed.\\nNow that we have the libraries that we need,\\nlet's confirm the PyTorch version that we are using.\\nI'm running PyTorch version 2.0.1, so make sure you have a recent\\nversion of PyTorch greater than or equal to two\\nin order to be able to run these demos.\\n\\nI'll now set up a bunch of import statements for all of the\\nlibraries and classes that we need\\nfor this demo. I'll use NumPy, pandas,\\nSeaborn,\\nmatplotlib,\\nTorch, scikit-learn.\\nWe won't go through these import statements right now,\\nwe'll discuss each class or function as we use it.\\nThe dataset that we'll be using to train our regression model is\\nan insurance charges dataset and is present here within this\\ndatasets directory.\\nUnder my current working directory, you can see this insurance.csv\\nfile.\\n\\nThis is the file that I'm going to read into my notebook\\nusing pandas.\\nThe dataset is fairly simple.\\nThe records contain details of insurance,\\ncustomers, age, gender, bmi, number of children,\\nwhether they smoke or not, and the region in which they live.\\nThese are all the features of the data.\\nWe'll try to use this information to predict how much they've been\\ncharged for insurance.\\nThe label column is charges.\\nLike I said, this is a fairly simple and small dataset,\\nperfect for training a simple regression model using PyTorch.\\n\\nThe shape of the data shows us that there are a total\\nof 1338 records.\\nLet's make sure every column in this data is of the right type.\\nFor that, I run the info method on a pandas data frame and you can see\\nthat the types are correct. Age, bmi, number of children,\\nand charges are numeric columns,\\nthe remaining are string columns or categorical columns.\\nLet's just use a few visualization techniques to understand the data\\nthat we are working with.\\nLet's take a look at a histogram of the charges information.\\n\\nYou can see that for a vast majority of customers,\\nthe insurance charges tend to be under $15,000.\\nYou can see that on the x-axis.\\nHowever, there are a few customers for whom insurance charges tend to\\nbe very high in the order of $40,000 to $50,000.\\nIn this dataset, all of the feature variables are\\nrelevant to predict the insurance charges for customers,\\nbut one of the most significant features is this smoker feature.\\n\\nWhether you're a smoker or not, heavily influences your\\ninsurance charges.\\nYou can see that for non-smokers, the insurance charges tend to be\\nmuch lower than for smokers.\\nThis boxplot makes that very clear.\\nAlso, how old the customer is influences insurance charges.\\nYou can see a scatterplot of insurance charges versus age,\\nand there is a linear relationship.\\nYou can see that insurance charges tend to increase with age.\\nBut for each age, they seem to be different bands of charges.\\n\\nNow that we've understood the data that we're working with,\\nlet's quickly split the data into training and test data using\\ntrain_test_split. X features include all columns except\\ncharges,\\nthe Y values that we're trying to predict are the insurance charges.\\ntrain_test_split will split the features and labels so that we\\nhave 80% of the data to train our neural network model\\nand 20% of the data to validate the model. Thousand and seventy records\\nfor training and 268 records for validation.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4552017\",\"duration\":383,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Preprocessing data for training\",\"fileName\":\"3096406_en_US_01_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":383,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"After watching this video, you will be able to preprocess data for model training.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10646982,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Now that we have training and validation data,\\nthe next step is to preprocess the data so that we can feed that into\\na machine learning model.\\nNow, neural network models and all machine learning models only\\nunderstand numeric values.\\nYou can't feed in strings to those models,\\nwhich means you need to numerically encode all of your\\ncategorical variables, which may be represented\\nas strings.\\nNow, there are different ways to numerically encode this data.\\nWe'll use one-hot encoding.\\n\\nThere are three categorical columns in our data; sex,\\nsmoker, and region.\\nAll of these are nominal categorical values.\\nThat means that there is no inherent ordering across\\ncategories for any of these columns.\\nAnd so one-hot encoding is perfect\\nin such a situation. We instantiate the one-hot encoder\\ncategorical transformer, handle unknown is ignored.\\nThat is, if we encounter unknown values,\\nthis transformer will simply ignore them.\\nDrop is equal to\\ncategories in the feature.\\n\\nLet's say the smoker column can have two possible values,\\nyes or no.\\nIn the final output, you'll have just one column, either\\nsmoker yes or smoker no\\nwith zero/one values indicating whether the customer\\nis a smoker or not.\\nSparse output set to false means that the resulting one-hot encoded\\nvalues will not be in the sparse representation.\\nIt will be a complete representation.\\nLet's instantiate a column transformer next to perform\\nthe preprocessing,\\nand this column transformer uses the one-hot encoder for\\ncategorical values.\\n\\nFor the remaining numeric columns, we'll just pass through,\\nmeaning the numeric columns won't be affected,\\nonly the categorical columns will be affected.\\nOnce we've instantiated the transformer,\\nlet's pre-process our data.\\nI call preprocessor.fit_transform on the training data, and\\nusing the computed values on the training data,\\nwe simply call transform on the validation data.\\nThis ensures that the properties computed on the training data are\\nwhat we use to transform the validation data,\\nand we are left with eight features in our data after\\none-hot encoding.\\n\\nLet's take a look at the training data and you'll find that\\nit's just a NumPy array.\\nWe don't have the corresponding columns.\\nIf you want to understand this data,\\nlet's convert it to a temporary data frame and see how the data\\nhas been transformed.\\nSo we have one column for gender,\\nmale,\\none column for smoker,\\nyes/no;\\nand then columns for northwest, southeast, and southwest.\\nNotice that the categorical feature southeast, that column\\nhas been dropped.\\nA value of all zeros for northwest,\\nsoutheast, and southwest essentially indicates that\\nthe region is southeast.\\n\\nThe numeric columns; age, bmi, and children,\\nthey have been passed through unaffected.\\nThe Y values are still in the data frame format.\\nLet's convert those to the NumPy format, as well.\\nAnd from NumPy arrays,\\nlater on, we'll convert these to Torch tensors.\\nWe haven't yet completed the preprocessing of our data.\\nWe've converted all of the columns to numeric values.\\nAnd I'm now going to standard scale these numeric values.\\nStandard scaling involves converting all numeric\\nvalues to z scores,\\nthat is, expressing every feature in terms of number of standard\\ndeviations from the mean.\\n\\nWhen you feed in numeric values to neural networks,\\nneural networks perform much better with smaller\\nnumeric values,\\nand also when the individual features do not have wildly\\ndifferent ranges.\\nAnd standard scaling is one way to preserve the information\\nin individual features, but also have them all centered\\naround zero and expressed using small numeric values.\\nSo I call fit_transform on the training data, and the mean and\\nstandard deviation computed on the training data will be used to\\ntransform the validation data.\\n\\nNotice I call just transform on X_val.\\nAnd now if you look at the training data, you can see that the\\nnumbers are very small, usually between -3\\nand +3.\\nStandard scaling or standardization computes the\\nmean for each feature,\\nsubtracts the mean from every value,\\nand then divides by the standard deviation so that the values are\\nexpressed in terms of z scores or number of standard deviations\\naway from the mean.\\nNow, the Y values that we need to train our model are currently in\\nthe form of a single-dimensional array or a vector.\\n\\nIn order to feed them into a neural network,\\nthey need to be in the form of a multi-dimensional array.\\nSo instead of a vector of length size,\\nwe'll have a multi-dimensional array of dimensions\\nsize comma one.\\nAnd that's what this reshape operation accomplishes.\\nIt's the same Y values, the charges,\\nin the form of a multi-dimensional array.\\nAs I mentioned before,\\nneural networks work better when you're dealing with small\\nnumeric values.\\nNow, our insurance charges vary from zero to about $50,000, $60,000.\\n\\nThese are not small numeric values.\\nAnd in order to make our neural network training more robust,\\nmore likely to converge, I'm going to use the min_max_scaler\\nto scale all insurance charges to be expressed\\nin the range zero to one.\\nThat's what the min_max_scaler does by default.\\nNow, all insurance charges are expressed as values\\nbetween zero and one.\\nWe now have our input features and labels that we'll use to train\\nour neural network.\\n\\nHowever, they are in the NumPy format.\\nI'm now going to convert them to Torch tensors.\\ntorch.from_numpy will convert NumPy arrays to Torch tensors.\\nNow, Torch tensors are the primary data structures used in PyTorch\\nfor building neural networks and other ML models.\\nTorch tensors are multi-dimensional arrays like NumPy,\\nbut they support distributed training using GPUs.\\nThey are used in neural network training because they support\\nautomatic differentiation for gradient computation\\nand essential part of the training process of a neural network.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4550020\",\"duration\":343,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Creating a simple neural network\",\"fileName\":\"3096406_en_US_01_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":343,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"After watching this video, you will be able to create a simple neural network in PyTorch.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8858003,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"At this point, our training data is processed and ready to be used\\nto train a neural network model.\\nSo the first thing we'll do is set up a very simple neural network.\\nIn fact, the simplest possible neural network,\\none with just one neuron and no activation function.\\nSo all this neural network will be able to learn is linear\\nrelationships in the data.\\nSince the dataset that we're using is a simple\\nstraightforward one, you'll find that this very simple\\nneural network also does fairly well and can be used to build a\\nfairly decent regression model.\\n\\nLet's see how we set up this very simple neural network.\\nHere I've defined a class called SimpleNeuralNet that inherits\\nfrom the PyTorch nn.Module class.\\nnn.Module is a base class for all neural networks that\\nyou'll build using PyTorch.\\nIt gives you a wide range of functionality that makes the\\ndevelopment and management of neural networks easier\\nand more sustainable.\\nWithin the init method of the nn.Module class,\\nyou'll specify the layers of the neural network.\\n\\nHere are init method, takes in one input argument,\\nthe number of features in the training data,\\nand within that we have just one layer,\\nand that layer has just one neuron.\\nWe instantiate that layer using the nn.Linear object.\\nNotice this linear layer takes in num features as input,\\nthat is all of the features in our training data, and has\\njust one neuron.\\nYou override the forward function in the base nn.Module class to\\nspecify the forward pass-through the neural network.\\n\\nNotice the forward function here takes in the record as\\nan input argument,\\nthat is, a training data and essentially invokes the linear\\nlayer on the training data.\\nSo you're passing the input data through that linear layer.\\nAnd this transformed output x is what we return.\\nThe nn.Module class gives you other bits of functionality\\nthat will be useful, such as moving all of the\\nparameters of the neural network to a CPU or GPU device\\nso that it can be trained on that device.\\n\\nNow that we have our very first simple neural network,\\nlet's explore and understand it.\\nLet's instantiate the neural network.\\nThe number of features that we have are eight.\\nRemember that's the number of columns in the X train data.\\nPrinting out the neural network will give us a string\\nrepresentation of the layers in the net.\\nWe have just one linear layer with a single neuron and no\\nactivation function.\\nBefore a neural network is trained,\\nthese weights and biases are initialized to random values.\\n\\nYou can actually access the weights and biases of each layer\\nby running a for loop through the layers in your model.\\nHere, for every linear layer in the model,\\nwe have just one.\\nI print out the weights and biases,\\nand you can see that there are eight weights corresponding to the\\neight features that are going to be fed into the single neuron\\nin our linear layer\\nand one bias value.\\nThese weights and biases are the model parameters that will be\\nfound during the training process of the model.\\n\\nThese weights and biases will converge to some values,\\nallowing the model to make predictions.\\nYou can actually count the number of parameters that this model\\nis going to train.\\nHere is a count parameters function that will\\nhelp us do that.\\nYou can iterate over all of the model parameters by accessing the\\nparameters function on the model, and if the parameter\\nrequires gradients, that is, gradients\\nwill be computed,\\nyou know that it's a trainable parameter.\\nAnd by running this, you see that we have a total of\\nnine trainable parameters for this very simple neural network,\\neight weights and one bias.\\n\\nTraining a neural network involves using a loss function.\\nThis loss determines how good the neural network is at\\nany point in time.\\nYou can think of the loss as representing how far away the\\npredictions of the neural network are from the actual target values.\\nSince this is a regression model, the loss function that we'll use\\nis going to be the mean squared error loss available\\nin F.mse_loss.\\nLet's compute the loss on predictions made by our\\nuntrained model.\\n\\nNotice that we pass train inputs through the model and then compare\\nthose predictions with the train targets.\\nAnd then we compute the loss function.\\nAnd the loss here is 0.5406.\\nThe loss is not really meaningful unless we see how the loss falls\\nas we train the model.\\nBut this is just to show you how the loss function is computed.\\nLet's get and view the predictions from our model\\nat this point in time.\\nRemember we haven't trained the model at all.\\nThe model parameters all have random values.\\n\\nSo these predictions are actually just random predictions.\\nWhat we are seeing here is some of the steps that\\nwe'll be performing during the model training process.\\nOnce the model has been trained and we get the final predictions\\nfrom the model, we'll evaluate the model using the\\nr-square score and by computing the mean squared error.\\nThe R2Score and the MeanSquaredError\\nclasses are available as a part of Torch metrics regression.\\nWe instantiate those objects, MSE and r2score,\\nand we compute these values on Lines 8 and 9 by passing in\\nthe predictions from the model and the actual target values.\\n\\nAgain, remember the model has not been trained.\\nSo both the mean squared error, that's just the loss,\\nand the r squared will essentially have random values.\\nThe r squared is actually negative.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4551030\",\"duration\":146,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Setting up the dataset and DataLoader\",\"fileName\":\"3096406_en_US_01_05_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":146,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"After watching this video, you will be able to create a PyTorch dataset and dataloader.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3933470,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"In order to feed our training data into our PyTorch neural\\nnetwork in batches, we are going to be using a tensor\\ndataset and a tensor DataLoader. In PyTorch,\\nthe dataset and DataLoader are foundational classes provided by\\nthe torch.utils.data module.\\nThese facilitate the loading, processing, and batching of data.\\nDataset is an abstract base class in PyTorch and we'll be using the\\nderived tensor dataset class.\\n\\nYou can think of a dataset as representing a collection\\nof data items.\\nAnd this tensor dataset that we've instantiated here holds\\nour training data.\\nWe instantiate a tensor dataset using the train inputs\\nand train targets,\\nand here are the first five records in the tensor dataset.\\nJust a heads up that here we've used one of the built-in dataset\\nclasses, the tensor dataset,\\nbut it's also possible for you to create your own custom dataset by\\nderiving from the dataset base class.\\n\\nOnce we've set up a dataset, when we actually access the\\ntraining data to train our model, we'll want to load the\\ndata in batches.\\nWe may want to shuffle the data or use multiple workers to\\nspeed up data loading.\\nAll of that is done via the DataLoader.\\nI've instantiated a DataLoader here and specified a batch size of\\n8. For the training data,\\nI've also set shuffle equal to true.\\nSo when we feed the data into our model for training,\\nit will be shuffled.\\nIt will not come in any predictable pattern.\\n\\nThe DataLoader is an iterable that allows us to iterate over the\\ndata in batches. On Line 5\\nyou can see I create an iterator and call next on it,\\nand this will allow us to see the first batch of training data.\\nNotice that we have eight records here because we specified\\nbatch Size 8.\\nWe've now created a dataset and DataLoader for our training data.\\nLet's do the same for validation data.\\nFirst, we convert X and Y value to the tensor format.\\nAnd once that's done, we'll instantiate a tensor dataset\\nfor our validation data.\\n\\nAnd then we'll instantiate a DataLoader using this tensor dataset.\\nNotice that when we instantiate a DataLoader for the\\nvalidation data,\\nI haven't specified shuffle equal to true.\\nValidation data is only used to evaluate the model and does\\nnot need shuffling.\\nHere is the first batch of records from the validation data.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4552018\",\"duration\":465,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Training a neural network using PyTorch\",\"fileName\":\"3096406_en_US_01_06_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":465,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"After watching this video, you will be able to train a neural network in PyTorch.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":14452465,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"We are now ready to start training our neural network.\\nI'm going to set up a dictionary called loss_stats\\nwhich will hold the values of the training loss and validation\\nloss for each epoch.\\nWe'll run 100 epochs of training and epoch,\\nas you likely already know, is one pass through the\\nentire training data.\\nThe next thing we need to do is figure out on what device\\nwe'll run this training.\\nNow, because I'm running on my local machine,\\nI do not have access to a GPU, but it's possible that you are\\nrunning this on Google Colab or a machine where a GPU is available.\\n\\nWhat we are doing here is a check to see whether a GPU is available.\\nIf it is, we'll use the GPU.\\nOtherwise, we'll use the CPU.\\nSo if torch.cuda.is_available\\nreturns true, that is, we have a GPU, then the device will be CUDA.\\nIf torch.backends.mps.is_available is true,\\nthis means that the new metal performance shaders backend for\\nGPU training and acceleration is available on your machine,\\nso the device will be mps.\\n\\nThis is likely to be available if you're working on a\\nnew Mac device, or if neither of these\\noptions is true, we'll just go with CPU training\\nand device will be CPU.\\nYou can see here that we're using the CPU device because I do\\nnot have a GPU available.\\nWe'll now instantiate and train our neural network using PyTorch.\\nRemember PyTorch is a lower-level API\\nand it does not abstract us away from the details of neural\\nnetwork training.\\nAnd there will be a lot of boilerplate code involved.\\n\\nI instantiate the simple neural network num features\\nis equal to eight, and I call to device in order to\\nmove the model parameters of the neural network to whatever device\\nwe are using for training either CPU or GPU.\\nMoving to the device that you're using for training is a part\\nof PyTorch's boilerplate.\\nFor all of your training data and your model,\\nyou have to move them to the right device so that the training occurs\\non the right device.\\nThe objective of training a neural network is to update your model\\nparameters for every iteration of training,\\nso as to minimize the loss function.\\n\\nIn PyTorch, it's the optimizer that actually updates the model\\nparameters using gradient values.\\nSo I've instantiated an optimizer for that purpose.\\nThe optimizer I've used here is the SGD or the stochastic gradient\\ndescent optimizer.\\nThere are several different optimizers available as a part\\nof the PyTorch framework.\\nSGD is a commonly used straightforward optimizer.\\nThe optimizer takes in the model parameters that need\\nto be updated,\\nas well as the learning rate, which are set to 10^-2.\\n\\nThe learning rate determines the step size for how the model\\nparameters converge to their optimal values.\\nToo larger step size, your model may not converge,\\ntoo smaller learning rate, and your model may take\\ntoo long to converge.\\nThis 0.01 works well for this particular model,\\nand that's why I've selected it.\\nNext, let's set up the training loop for our model.\\nAnd here is where you'll really see the boilerplate code.\\nAnd you'll find that when we use PyTorch Lightning in\\nthe next demo,\\nmost of this code will be eliminated.\\n\\nFirst, I have a for loop to iterate over the number of epochs\\nof training that we'll run.\\nI initialize the training epoch loss to zero,\\nwe'll reset this for every epoch, and then we make sure that the\\nmodel is in training mode by calling model.train.\\nIn the training mode, gradients will be computed so that\\nmodel parameters can be updated using those gradients.\\nGradients are just partial derivatives of the loss function\\nwith respect to individual model parameters,\\nand these partial derivatives are used to determine how model\\nparameters should be tweaked to minimize the loss function.\\n\\nThis is all you need to understand conceptually about gradients.\\nFor every epoch, we run another for loop,\\niterating over each batch of the training data.\\nThis is on Line 7.\\nNow, for each batch of training, we zero out the optimizers\\ngradients so that gradients that were computed previously do not\\naffect this particular batch.\\nOn Lines 12 and 13, we move our training data to the\\ndevice that we are using for training,\\nwhether it's a GPU or a CPU.\\nNotice the boilerplate to device code here.\\n\\nNext, we make a forward pass through the model,\\nthis is on Line 16, for the first batch of training data\\nand get predictions.\\nThis forward pass uses the current value of the model parameters.\\nWe then compute the loss of the model at this stage by invoking\\nthe loss function, which takes in the prediction\\nand the Y values,\\nand then we perform a gradient descent.\\nWe make a backward pass-through the model by calling\\ntrain_loss.backward.\\nThis is where gradients are computed,\\nare partial derivatives, and optimizer.step\\nwill then use those gradients to tweak our model\\nparameter values.\\n\\nAnd then on Line 25, we add the current training loss\\nfor this batch to the training loss of the epoch as a whole.\\nAll of the steps you see from Line 9 through Line 25 is repeated\\nfor every batch of data in each epoch.\\nModel parameters will be updated for every batch in each epoch,\\nand the loss function will be minimized to improve the model.\\nAfter each epoch of training, we'll run the validation data\\nthrough the model and evaluate the model's performance.\\n\\nYou can see the with torch.no_grad with block on Line 28,\\nthat's within the outer for loop for the epoch,\\nbut outside of the for loop for the individual batches\\nof training.\\nThe torch.no_grad method turns off gradient computation\\nfor the model,\\nso gradients will not be computed when we pass through the\\nvalidation data.\\nI initialize the validation epoch loss to zero on Line\\n30, and on Line 32,\\nwe switch the model over to the evaluation state by calling\\nmodel.eval.\\n\\nThis is the state for evaluating the model.\\nThen once again I have a nested for loop where we iterate over the\\nbatches of validation data.\\nOn Lines 36 and 37, we move the validation data to the\\ndevice that we are using for training, CPU or GPU.\\nWe get the predictions on the validation data on Line 39,\\ncompute the loss on Line 41, and we add the loss of this batch\\nto the validation epoch loss.\\nOn Lines 45 and 46, we compute the training loss and\\nvalidation loss for the entire epoch,\\nand then append that information to our loss stats dictionary.\\n\\nThis is on Lines 48 and 49. On Line 51,\\nfor each epoch, we print out the training loss\\nand the validation loss.\\nAnd that's it.\\nThis is the training process.\\nIt's simple, but there is really a lot of boilerplate code involved.\\nLet's look at the output of training. Because this is a very\\nsimple neural network, training runs through very quickly.\\nYou can see that after the first epoch of training,\\ntraining loss was at 0.07 and validation at 0.01,\\nbut then training loss falls to 0.011,\\nvalidation loss falls to 0.008. Training loss further falls to\\n0.010 and stays there for the remaining epochs.\\n\\nThat is the lowest value of loss for this particular neural network\\nthat our model was able to achieve.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4553030\",\"duration\":167,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Visualizing losses and evaluating models\",\"fileName\":\"3096406_en_US_01_07_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":167,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"After watching this video, you will be able to evaluate a regression model using PyTorch metric libraries.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4413310,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Now that we have a trained model, let's visualize how the training\\nloss and validation loss change over epochs of training.\\nAnd for that, I'm going to set up a data frame with the training\\nloss and validation loss along with the epochs.\\nThis information is available in the loss statistics that we've\\nmanually populated in the training process.\\nAnd we now have this in the form of a data frame.\\nWe have the epochs,\\nthen whether it's training or validation loss and the\\ncorresponding value. The head shows us all of\\nthe training losses,\\nand the tail of this data frame contains all of the\\nvalidation losses.\\n\\nNow with this information in the data frame format,\\nvisualizing this using a Seaborn lineplot is very straightforward.\\nWe'll have epochs on the x-axis and training and validation\\nlosses on the y-axis.\\nAnd here is what the line chart looks like.\\nThe training loss and the validation loss falls drastically\\nin the first two or three epochs, but remains constant after that.\\nTwo to three epochs of training was sufficient for this model.\\nThe model does not improve beyond that.\\n\\nLet's now compute the R-square score of the model on\\nthe validation data.\\nIdeally, we should have a separate test dataset for this purpose,\\nbut because the dataset was fairly small,\\nlet's just do it with the validation data.\\nWe turn off gradients with torch.no_grad,\\nswitch the model to eval mode, model.eval, and we iterate over\\nevery batch in the validation data.\\nMove the features to the device.\\nThis is on Line 9.\\nGet the predictions from the model. y_pred will hold the predictions\\nfrom the model, y_true will hold the labels from the actual data.\\n\\nLet's quickly look at the format of the actual data that is in\\ny_true.\\nWhat we have here is a list of tensors where each tensor contains\\na prediction for one batch of data.\\nYou can check this out on your own.\\nThe prediction data will also be in the same format.\\nI'll now perform a torch.stack operation that will give us the\\nactual values in the form of a single tensor,\\nrather than a list of tensors.\\n\\nThis is what torch.stack outputs.\\nI now have a single tensor with all actual values.\\nI'll use torch.stack on the predicted values\\nso that we now have a single tensor with all predicted\\nvalues, as well.\\nNow that the data is in this form, let's compute the mean squared\\nerror and R-square score for this model on the validation data.\\nI instantiate mean squared error and R-square score and move those\\nto the device as well and compute the two values.\\nYou can see that the R-square of this model is 0.797,\\nwhich is a fairly good score.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4552019\",\"duration\":374,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Building and training a more complex neural network\",\"fileName\":\"3096406_en_US_01_08_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":374,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"After watching this video, you will be able to build a complex neural network in PyTorch.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":15258281,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"What I've done here is scroll back up in our Jupyter Notebook to\\nwhere we had defined our simple neural network.\\nRemember we mentioned that this neural network contains just a\\nsingle linear neuron with no activation function.\\nWhen you use a neural network with a single neuron,\\nessentially what you're doing is performing linear regression that\\nyou would with a traditional machine learning library\\nsuch as scikit-learn.\\nI'm now going to replace this neural network to have a more\\ncomplex one with several layers and interconnections.\\n\\nI've still called it SimpleNeuralNet.\\nWe still inherit from the nn.Module base class,\\nbut you can see that overall the neural network has\\nmany more layers.\\nThe layers are defined in the init method.\\nWe take in the number of features as an input argument,\\nand Layer 1 comprises of 16 neurons.\\nNotice I instantiate nn.Linear num features,\\nthat is, the input and the number of neurons is 16.\\nLayer 1 is the first layer in our neural network.\\n\\nThe output of this linear layer will be fed to the second\\nlinear layer.\\nThis is Layer 2 instantiated once again using nn.Linear.\\nThe dimensionality of the inputs to the second layer is 16,\\nand this needs to match the number of neurons in the previous layer.\\nSo Layer 1 has 16 neurons and this matches the number of input\\nfeatures fed into Layer 2.\\nRemember this is because the output of Layer 1 is\\nfed into Layer 2.\\n\\nThe number of neurons in Layer 2 is 32.\\nAnd then we have Layer 3, the third linear layer in\\nour neural network.\\nThe input features to the third linear layer is 32,\\nand this should match the number of neurons in the previous\\nlayer which is 32.\\nLayer 3 has just 16 neurons.\\nAnd then finally, we have the last linear layer, that is the\\noutput layer, layer out.\\nIt accepts 16 input features as input and produces\\njust one output.\\n\\nThe 16 features as input corresponds to the 16 neurons\\nin the previous layer.\\nEach of the three layers;\\nLayer 1,\\nLayer 2, Layer 3 have an activation function,\\nand the activation function that I've chosen here is\\nReLU activation.\\nActivation functions are what allow us to learn nonlinear\\nrelationships that might exist in the data.\\nNow, the forward function defines the forward pass-through\\nthe neural network.\\nWe receive the inputs as an input argument\\nto this forward function, we apply Layer 1 and then the ReLU\\nactivation function.\\n\\nThen the outputs are then passed through to Layer 2,\\nand then ReLU activation again.\\nAnd the outputs are passed through to Layer 3,\\nand we have the ReLU activation\\nyet again. The transformed data after passing through three layers\\nis finally passed through the output layer.\\nAnd the output layer's prediction is what we return from\\nthe forward pass.\\nThe predict method is invoked when you use this model to\\nget predictions.\\nAnd the predict method makes the same forward pass-through\\nthe neural network.\\n\\nNow, let's quickly execute all of the remaining steps here in\\nthis Jupyter Notebook.\\nHere is a representation of the model, three linear layers and\\noutput layer and ReLU activation.\\nNow this model will have many more parameters\\nsince we have a large number of layers and many interconnections\\nbetween layers.\\nThe weights and biases of each layer have been initialized\\nto random values.\\nLet's count the number of parameters in this model,\\nand you can see that this model has 1233 parameters.\\n\\nYou are familiar with the remaining steps here.\\nI'll just quickly execute them and let's go directly to where we set\\nup the dataset and DataLoader and train our model.\\nHere is where we instantiate the dataset.\\nYou've already seen how that works before.\\nAnd once we have the dataset, we set up the DataLoader.\\nThis is for the training data.\\nWe do the exact same thing for the validation data, as well.\\nSet up the dataset and the DataLoader.\\nAgain, we initialize the loss_stats dictionary and we'll\\ntrain for 100 epochs.\\n\\nWe then see what device is available and that is stored\\nin the device variable.\\nNow that we've set all this up, instantiate the simple neural\\nnetwork and move the model parameters to the device that\\nwe're using for training.\\nOnce again, initialize the optimizer,\\nwhich will update the model parameters during the\\ntraining process.\\nNext, we actually train the model.\\nWe train for 100 epochs, and after each epoch, we pass the\\nvalidation dataset through the model and compute the\\nvalidation loss.\\n\\nI'm going to kickstart the training process and let's see how\\nthis more complex neural network performs.\\nYou can see that initially our training loss was 0.041,\\nthe validation loss is the same.\\nAnd as we run through epochs of training,\\nnotice how both the training loss and the validation loss drops.\\nUntil at the very end, after about 99 epochs,\\nour training loss is 0.007 and validation loss 0.005.\\nLet's set up the data frame with the training loss and\\nthe validation loss so that we can plot and\\nvisualize the values.\\n\\nExecute this visualization code and you'll be able to see how the\\ntraining loss and validation loss fall over epochs of training.\\nBoth losses fall until about 45 epochs of training,\\nafter which they remain fairly steady.\\nI'll hit \\\"Shift-Enter\\\" to get the predictions from the model and the\\nactual values from the data.\\nI'll use torch.stack to get the predictions and the actual\\nvalues in a single tensor.\\nAnd let's compute the R-square and the mean squared error.\\n\\nNotice the R-square score has gone up.\\nIt's now 0.881.\\nSo a more complex neural network that included an activation\\nfunction improve the performance of our model.\\n\"}],\"name\":\"1. Building a Neural Network with PyTorch\",\"size\":74098168,\"urn\":\"urn:li:learningContentChapter:4554030\"},{\"duration\":1121,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4549017\",\"duration\":412,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Encapsulating data using a LightningDataModule\",\"fileName\":\"3096406_en_US_02_01_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":412,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"After watching this video, you will be able to encapsulate data with a LightningDataModule.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":13924647,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"At this point, we've successfully built and trained a neural network\\nto perform regression, but we used PyTorch and\\nnot PyTorch Lightning.\\nIt was important that you see how the model is built using\\nPyTorch first,\\nso that you can see how much cleaner our code is\\nwhen we use PyTorch Lightning. We'll eliminate most of the\\nboilerplate code that you saw for training loops and feeding\\ndata in batches, iterating through number\\nof epochs,\\nAll of that code will just disappear,\\nand we'll build our model in a very clean manner with\\nPyTorch Lightning.\\n\\nPyTorch Lightning is a lightweight PyTorch wrapper that helps\\nresearchers and developers organize their PyTorch code and\\nstreamline the training process.\\nPyTorch Lightning eliminates boilerplate code,\\nsimplifies the training loop, and provides a more structured\\napproach to PyTorch programming without compromising flexibility.\\nPip install lightning to get PyTorch Lightning installed\\non your local machine. You need the lightning module\\nin addition to the PyTorch framework that we've\\nalready installed.\\n\\nLet's go ahead and set up the import statements for the various\\nlibraries that we'll be using.\\nThe imports here are the same as in the previous demo,\\nbut I have a few additional imports for PyTorch Lightning.\\nThe one on Line 9,\\nyou can see import lightning.pytorch as pl.\\nIn addition to abstracting away the training process of\\na neural network,\\nthe training loop, and other code associated with it,\\nPyTorch Lightning also makes available the lightning\\ndata module.\\n\\npl.LightningDataModule allows us to abstract and organize the\\ndata-related aspects of our deep learning model.\\nIt's a way to decouple the data processing steps,\\nthe loading, preprocessing, and splitting of data from\\nthe model training logic.\\nWhen we structure all of our data processing tasks to be\\nencapsulated within a lightning data module class,\\nwe are centralizing all data-related operations in one place\\nand encapsulating all of our code to make it more modular\\nand reusable.\\n\\nHere, I've specified the skeleton of the insurance data module class\\nthat inherits from pl.LightningDataModule.\\nAnd you can see that there are several functions of the base\\nclass that I'm about to override.\\nThe functions have all been named in very meaningful way.\\nSo you know exactly what goes in each of these functions.\\nLet's start by adding in the code for the init method here in this\\ninsurance data module.\\nThis is where we'll initialize various parameters we may want\\nto use with the data.\\n\\nThe only one we have is the batch size. In the prepare_data function\\nis where you access the data wherever it's stored,\\nmaybe you'll need to download the data,\\nand you can also perform a little bit of preprocessing if needed.\\nThe only thing I do here is to read in the insurance.csv file\\ninto a pandas data frame\\ninsurance data.\\nThis method is not invoked in a distributed manner and usually\\ncalled on a single GPU.\\nNext, we have setup.\\nThis is where you will split the dataset and apply whatever\\ntransformations and pre-processing that you need.\\n\\nThis will be called on every GPU separately.\\nAn input argument to the setup function is what stage the model\\nis currently running.\\nThis can be the fit stage, that is, training\\nor it can be the validation or test stages.\\nHere we are keeping things simple, so I'll apply the data\\ntransformations all in the fit stage or the training\\nstage of the model.\\nThe data transformation operations that you see here should all\\nbe very familiar to you because these are the steps we\\ncarried out in the previous demo.\\n\\nOn Lines 9 and 10, we extract the X features\\nand Y values.\\nOn Line 12, I check whether the stage is fit or stage is none.\\nSo in the training phase, we split the data into training\\nand validation.\\nThis is on Lines 13 and 14.\\nThe code on Lines 16 through 28 is where we one-hot encode the\\ncategorical features in our data.\\nOn Lines 30 and 31, we convert the Y values to NumPy\\narrays. On Line 33 through 36,\\nwe standard scale our features. On Lines 38 through 41,\\nwe minmax scale our targets.\\n\\nThat is the Y values. And on Lines 43 through 47, we\\nconvert all our NumPy arrays into tensors.\\nWe'll feed in data to our model in the form of tensors.\\nThe training and validation data are available as member variables\\nof this class;\\ntrain_inputs, train_targets, val_inputs, and val_targets.\\nThe feature and target tensors need to be instantiated\\nas DataLoaders.\\nThe train_dataloader method returns the DataLoader\\nfor the training data.\\n\\nThe steps here are again familiar.\\nWe instantiate a tensor dataset, and using that, we instantiate\\na DataLoader.\\nNotice that I've specified num workers equal to four\\nfor the DataLoader.\\nThis is because I have four cores on my machine,\\nand this will allow me to load data in parallel using\\nthose four cores.\\nThe train_dataloader function returns an instance of the DataLoader\\nfor the training data. In exactly the same way, I've\\noverridden the val_dataloader function.\\n\\nThis is just a DataLoader for the validation data.\\nWe instantiate a tensor dataset and use that to instantiate\\na validation DataLoader.\\nnum_workers, again, set to four, so that four workers running on\\nfour cores can be used to load this data.\\nWhen we actually train our model, this insurance data module will be\\npassed in as an input argument to the trainer object that we'll use.\\nAnd the individual methods of this data module will be invoked at the\\nright point in time to get access to the right bits of data needed\\nfor training and validation.\\n\\nLet's just make sure that the insurance data module\\nworks as expected.\\nI'm going to create an object of the insurance data module.\\nLet's now call prepare data and set up manually so that\\nthe data is available.\\nAnd now I'm going to invoke the train_dataloader,\\nand I'll print out one batch of the training data.\\nAnd you can see that there are eight records in this batch.\\nIn a similar way, let me access the val_dataloader\\nand I'll print out one batch of the validation\\ndata, as well.\\n\\nAnd we have eight records in this batch.\\nObserve how by using a data module to manage all of the data\\npreparation and processing operations,\\nwe've created a modular bit of code that can be reused anywhere.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4551031\",\"duration\":347,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Encapsulating a model using a LightningModule\",\"fileName\":\"3096406_en_US_02_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":347,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"After watching this video, you will be able to encapsulate a model with a LightningModule.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10871150,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"In the previous demo, we built a simple regression\\nmodel using PyTorch.\\nNow in this demo, I'm going to build the same neural\\nnetwork that we used before, but this time I'm going to\\nuse PyTorch Lightning.\\nWhat I've defined here on screen is the skeleton of a class that\\nderives from pl.LightningModule.\\nJust like the lightning data module encapsulates all of the\\ndata-related operations,\\na lightning module is a fundamental class in PyTorch\\nLightning that encapsulates everything related to our\\ndeep learning model.\\n\\nIt extends the functionality of the nn.Module class that we used\\nin PyTorch to build up our neural network.\\nThe lightning module adds additional methods and structures\\nthat streamline the training, validation, testing,\\nand prediction processes of the model.\\nA lightning module organizes your PyTorch code into different\\nsections,\\nand each section is a different method that you override from the\\nlightning module base class.\\nYou can see that I have six different methods here.\\n\\nThese correspond to the six different sections into which\\nlightning module organizes your code.\\nLet's look at and understand each of these step by step,\\nstarting with init. The init method,\\nand in addition, there is also a setup method that I've\\nnot overridden,\\nin the nn.Module init method,\\nI've essentially moved that code in here to the init method\\nof lightning module.\\nThe init method takes in a number of parameters for the model, num\\nfeatures is the number of input features and the learning rate,\\nwhich I've set to 0.01.\\n\\nThis learning rate parameter will be used by the optimizer\\nthat we'll instantiate.\\nNow within the init method,\\nyou can see I've set up the layers of the neural network.\\nThere are three layers,\\nand then the final output layer. And the activation function that\\nwe'll use for the three layers is the ReLU activation.\\nThis network is exactly the same network that we've used\\nin our earlier demo.\\nAn interesting thing to note here is the code on Line 11 where I\\ncall self.save_hyperparameters.\\n\\nsave_hyperparameters is a method in the lightning module\\nbase class.\\nhere in the init method, all of the input arguments to init,\\nhere we have two, num features and learning rate, will be saved as\\nhyperparameters and will be accessible via the\\nself.hparams object.\\nLet me explain what I mean by adding the code here in the\\nconfigure optimizers method.\\nThis is the method where you will instantiate and set up any\\noptimizers and schedulers that you use to train your model.\\n\\nI once again use the stochastic gradient descent optimizer, SGD,\\nI pass in the parameters of the model available in\\nself.parameters,\\nand I pass in the learning rate of the optimizer using\\nself.hparams.learning rate.\\nThe learning rate that we passed in as an input argument to init on\\nLine 3 has been saved in this hparams object that we access\\nhere on Line 13 because we invoked\\nself.save_hyperparameters on line 11. self.save_hyperparameters\\nthus saves all input arguments that you pass into init.\\n\\nThe forward function is where you define the forward pass-through\\nthe neural network, and here we define the same\\nforward pass as we did before\\nin PyTorch. We pass the inputs through the three linear layers.\\nEach layer has the ReLU activation.\\nAnd then finally, we pass through the last output layer and\\nreturn the final value.\\nNow if you remember in PyTorch, we set up a training loop,\\nand within that, we define the training process of a model.\\nThis is what you'll define here\\nin training step.\\n\\nThis training step function will be invoked in a loop.\\nWhat you define here are the operations that need to be\\nperformed on a single batch of training data.\\nYou can see the input arguments a batch of data is passed in.\\nWe access the X features and Y values from this batch.\\nWe make a forward pass through the model by calling self.forward\\non the X features.\\nOn Lines 26 and 27, we instantiate the mean squared\\nerror loss function and compute the loss for this batch\\nof predictions.\\n\\nAnd then we simply call self.log and log the loss out.\\nActually, displaying the loss on screen and logging it out,\\nwell, PyTorch Lightning will take care of that automatically.\\nTo define the validation process of your model,\\nyou'll simply specify validation on one batch of data here in\\nthe validation step method.\\nWell, validation is straightforward.\\nOnce again, we make a forward pass with a batch of data using\\nself.forward,\\nwe compute the mean squared error loss on the validation data\\nusing the loss function, and we log out the\\nvalidation loss.\\n\\nAnd we have a predict step that you can override here.\\nIn order to make predictions on the data,\\nwe access the X variables and Y values from the batch and simply\\nmake a forward pass through the model to get predictions.\\nYou can see here that the entire model training code,\\nwithout the additional boilerplate of moving the model to a device\\nor the training loop, has been encapsulated\\nhere in one class.\\nLet me just instantiate and print out a string representation of our\\nmodel defined in this lightning module class.\\n\\nAnd in the next movie, we'll see how we will actually\\ntrain a model using PyTorch Lightning.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4554029\",\"duration\":362,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Training the model using the PyTorch Lightning Trainer\",\"fileName\":\"3096406_en_US_02_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":362,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"After watching this video, you will be able to train a model with the PyTorch Lightning trainer.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11982679,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"We've defined our model, our training step, and\\nvalidation step\\nnicely encapsulated in a PyTorch Lightning module, and we are now\\nready to train our model.\\nIf you remember in PyTorch, you had to write a lot of code to\\nactually train your model and get validation metrics for your\\nmodel after each epoch.\\nIn addition, in order to ensure that your model trains on a GPU,\\nif a GPU is present, you had to also move the model\\nparameters as well as the X and Y values that you're using to train\\nyour model to the right device for training.\\n\\nNow, keep all of that in mind while we see how easy it is to\\ntrain a model using PyTorch Lightning.\\nYou see those five lines of code here on screen,\\nincluding the import statement,\\nwell, that's all the code you need to run a training loop,\\nrun validation at the end of every epoch,\\nand display all of that nicely to screen.\\nNo nested for loops, no moving the model to\\nthe right device,\\nno loss computation on training and validation data,\\nno optimizer step, no loss.backward.\\n\\nNothing.\\nFirst, let's take a look at the import statement,\\nwhere I import a CSVLogger that will log the details of the\\ntraining process out to screen in a CSV format.\\nNext, I instantiate the insurance data module class,\\nwhich encapsulates all of the data preparation and processing\\noperations for the data that I plan to use to train the model.\\nNext, on Line 5, I instantiate a CSVLogger class\\nto write the logs out to the logs subfolder under my current\\nworking directory.\\n\\nThe actual training process will be taken care of by the\\npl.Trainer class.\\nThis is a central class that manages and automates the\\nentire training process, and abstracts away a lot of the\\nboilerplate code typically associated with training loops,\\ndistributed training, and evaluation.\\nI instantiate the trainer, specify\\nI want to run a maximum of 50 epochs of training,\\npassing the CSVLogger so that logs are generated in my current\\nworking directory.\\nAnd that's it.\\n\\nI call trainer.fit.\\nTrainer.fit takes in an instance of a lightning module,\\nthat is the model that we want to train,\\nand a data module, that is a data set we should use for training.\\nTrainer.fit will invoke the right methods on the model class,\\nas well as the data class to get the right data for training\\nand validation, and it will run the training\\nprocess for 50 epochs.\\nOur training process has begun.\\nObserved that the trainer automatically checks to see\\nwhether a GPU or a TPU is available.\\n\\nIf not, it will just run training on the CPU.\\nThe trainer also shows you the number of trainable parameters\\nin the model.\\nWe had manually computed this earlier\\nin PyTorch. We have about 1.2K or 1200 parameters.\\nAs the training process continues, you'll see for every\\nepoch of training, the trainer prints out the epoch,\\nso you can see Epoch 16 here on screen,\\nthe training loss at this epoch, and the validation loss\\nat this epoch.\\nWe had set show progress bar to true when we logged out our\\ntraining loss and validation loss.\\n\\nAnd that's why you see these progress bars on screen,\\nas well. At Epoch 49\\nare 50th epoch, the training process is complete.\\nThe training loss at this point in time is 0.00598,\\nand the validation loss is 0.00477.\\nNow that we have a trained model, let's see how easy it is to get\\npredictions from the model. I call trainer.predict,\\npass the model in, and specify the validation DataLoader as the\\nDataLoader for the data for which I want predictions.\\n\\nAnd you can see the predictions from the model output\\nhere on screen.\\nThe output format of predictions gives us every batch of\\npredictions in a separate tensor.\\nLet's get all of these in a stacked format by using\\ntorch.cat to concatenate them.\\nThis will give us a single tensor with all the predictions from our\\nmodel for the validation data.\\nIn order to compute metrics for the model,\\nI need the actual values or the labels from the validation\\ndata as well,\\nand I extract this by using a for loop.\\n\\nNow that I have this, let's stack the labels as well\\nso we get a single tensor with all of the labels from our data.\\nNow that we have the predictions as well as the labels,\\nall that's left to do is to compute the mean squared error and\\nthe R-square score for this model.\\nAnd since this is the exact same neural network as the one\\nwe built in PyTorch, the R-square score is\\nalso the same 0.882.\\nIf you remember, we passed in a CSVLogger to the\\npl.Trainer object that we had instantiated to log out the\\nmetrics during the training process.\\n\\nWe can now access these metrics.\\nThey'll be in a metrics.csv file in your log directory.\\nThe log directory is accessible via the trainer instance,\\ntrainer.logger.log_dir/metrics.csv.\\nThis is a data frame that I read in,\\nwhich gives us the training loss, validation loss for every epoch.\\nWe do a little bit of pre-processing with this\\nmetrics data frame.\\nFor instance, I drop the step column and then I go ahead and\\ndisplay the metrics as a line plot.\\n\\nAlong the x-axis, we have the epochs of training.\\nAlong the y-axis, we have the training and validation losses.\\nThe blue line represents the training loss and the orange\\ndotted line is the validation loss.\\nNow, you've trained the same model using PyTorch Lightning,\\nand you can see how much simpler and more intuitive the code was.\\n\"}],\"name\":\"2. Using PyTorch Lightning to Build a Regression Model\",\"size\":36778476,\"urn\":\"urn:li:learningContentChapter:4550023\"},{\"duration\":1069,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4550021\",\"duration\":252,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Loading and exploring classification data\",\"fileName\":\"3096406_en_US_03_01_VT\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":252,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"After watching this video, you will be able to load data for classification.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6823426,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"We've seen how easy it is to build and train a neural network\\nusing PyTorch Lightning.\\nLet's get some more practice with this.\\nAnd this time, we'll build and train a classification model.\\nHere I am on a new Jupyter Notebook.\\nSince we'll be exploring and visualizing a new dataset\\ncomprising of classification data,\\nI'm going to ignore some warnings that will display when I use\\nSeaborn for visualization.\\nBy the time you're watching this course,\\nyou're unlikely to need this bit of code if you're using the\\nlatest version of Seaborn.\\n\\nNext, I set up the import statements for all of the\\nlibraries that I'll use.\\nThis involves data access, data processing libraries.\\nYou can see that I've also imported lightning.pytorch as pl\\non Line 10. Because this is a classification model,\\nwe'll evaluate this model with a different set of metrics.\\nOn Line 13 and 14,\\nyou can see I import accuracy and F1Score.\\nThese are the metrics we'll use to evaluate the model.\\nI have the data that we'll use to train the model in the\\ndatasets folder here.\\n\\nThis is a churn modeling dataset.\\nWe'll have information for a number of customers,\\nand we'll use that information to predict whether the customer\\nchurned or not.\\nLet's read in and take a look at the data before we actually set up\\na lightning data module to encapsulate all our\\ndata operations.\\nI'm going to read in from the Churn_Modelling.csv\\nfile under datasets.\\nHere in this dataset, we have information for bank customers,\\nrow number, customer ID, last name,\\ncredit score, gender, age, tenure, whether the customer has\\na credit card or not.\\n\\nAnd finally, the last column here is exited.\\nThat column contains the labels that we are trying to predict.\\nExited equal to one, meaning the customer churned.\\nZero means the customer did not churn.\\nWhen you take a look at the columns here in this dataset,\\nit's pretty clear that there are certain columns which are not\\nreally relevant in predicting whether the customer\\nchurned or not.\\nFor example, columns such as row number,\\ncustomer ID, or even the surname or last name of a customer.\\n\\nThose are bits of information not really relevant to figuring\\nout churn.\\nNext, let's take a look at the data types for the various columns\\nto make sure they are all of the right type.\\nA quick glance over the column shows me that numeric values\\nare numeric types, either integers or floats,\\nand categorical values are of type objects or strings.\\nThings look good so far.\\nThis dataset contains fields with missing values.\\n\\nWe'll clean up this data by using dropna to drop any records which\\nhave missing values,\\nthat's the code on Line 1,\\nand then this dataset also contains a few duplicate records.\\nAnd we'll eliminate duplicates by calling drop_duplicates\\non a pandas data frame.\\nAnd once both of these are done, the number of records we are left\\nwith for training as well as validation data is about\\n10,000 records.\\nThe classification model that we're trying to train is a binary\\nclassification model.\\n\\nWe are trying to predict whether a bank customer exited the\\nrelationship or not.\\nWe are trying to predict churn.\\nIf you look at the value counts for the exited field,\\nyou can see that this data set is very skewed.\\nEight thousand out of the 10,000 customers did not churn and only 2,000 did.\\nYou can actually view the same information using a nice Seaborn\\ncount plot. Based on the exited values,\\nyou can see that there are many more customers who haven't exited\\nas compared with customers who have exited or churned.\\n\\nOnce again, this is a skewed dataset,\\nand I'll give you a heads-up right now that we won't actually be\\nmitigating the skewness of this data.\\nSo I won't perform any sampling to balance out the customers who have\\nchurned and who've not churned.\\nSo there is a limit to how good our binary classification\\nmodel can be.\\nIf your training data is skewed, it's hard to build a great\\nclassification model.\\nBut since our focus is primarily on learning to use PyTorch\\nLightning to build a neural network model, we'll work with the\\nskewed data.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4549018\",\"duration\":268,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Creating a LightningDataModule\",\"fileName\":\"3096406_en_US_03_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":268,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"After watching this video, you will be able to create a LightningDataModule for data preparation.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10302851,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"If you remember the previous regression demo where we\\nused PyTorch Lightning,\\nthe first thing we set up was a data module class.\\nThis data module encapsulated all of the data preparation,\\nprocessing, and other operations to work with our training\\nand validation data.\\nHere is our BankCustomerChurnDataModule which inherits from\\nthe pl.LightningDataModule base class.\\nNow, in the init method is where we initialize the parameters\\nof the data.\\n\\nto the init method.\\nIn prepare_data is where we load the data from wherever\\nit's available\\nand perform a few preprocessing operations to set up our data.\\nThe prepare_data method when we train our model is run\\non a single GPU.\\nHere I just read the CSV file from the datasets folder,\\nand then I drop all of the records with missing values using dropna\\nand I drop records that are duplicates by invoking\\ndrop_duplicates.\\n\\nThe setup function is where we perform data transformations and\\npreprocessing and data splitting.\\nIt takes in the stage as an input argument.\\nNow, the first thing I do in setup is drop those columns that are\\nnot relevant for prediction.\\nThe X features will not include exited.\\nThat's of course the target.\\nWe have to drop that.\\nBut we'll also not include row number,\\ncustomer ID, and surname because these fields do not have any\\npredictive power to figure out whether a customer churned or not.\\n\\nThe Y value or the target of the classification is the exited\\ncolumn that I assign on Line 18.\\nNow, I'll preprocess the data only if stage is equal to fit\\nor stage is equal to none.\\nThat is only in the training phase.\\nThe training phase will get the training as well as validation\\ndata and preprocess them both. In the training stage on\\nLines 21 and 22,\\nI first use train_test_split from scikit-learn to split the\\ndata, 80% for training, and the remaining 20% to\\nevaluate the model.\\n\\nOn Lines 24 through 37, we one-hot encode the categorical\\nvalues present in the data.\\nThe only categorical features include geography and gender,\\nand we instantiate the one-hot encoder and then use a column\\ntransformer to one-hot encode\\nthese values. On Lines 36 and 37 is where we actually perform the\\none-hot encoding by calling fit_transform on the training data and\\ntransform on the validation data.\\n\\nOn Line 39, we convert the Y values to NumPy arrays,\\nand on Lines 41 through 45, we use the standard scalar to\\nstandardize all numeric values.\\nAnd finally, on Lines 47 through 51,\\nwe take our training as well as validation data and convert them\\nall to PyTorch tensors.\\nAnd then, of course, we have the\\ntrain_dataloader function, which returns the DataLoader\\nfor the training data.\\nWe instantiate a tensor dataset and then we use that to\\ninstantiate a DataLoader.\\n\\nWe load the data using four workers\\nsince I have four cores on my machine.\\nAnd the code in the validation DataLoader is identical,\\nwe instantiate a tensor dataset with the validation data and use\\nthat to instantiate a DataLoader.\\nLet's quickly check that our data module works just fine.\\nI instantiate the bank_customer_churn data module, call\\nprepare_data, and then set up.\\nI'll now access the train_dataloader,\\nand let's take a look at one batch of training data.\\n\\nOnce again, we've used a batch size of eight.\\nAfter all of the pre-processing that we've performed,\\nlet's see the number of features that we have in the input data.\\nWe access one record in the training data,\\nuse the shape property, and get the second dimension,\\nwhich will give us a number of features.\\nIt's equal to 11.\\nRemember, we need this information to set up the layers of our\\nneural network model.\\nNext, let's look at one batch of the validation data to make sure\\nthat the validation DataLoader is also working fine.\\n\\nAnd you can see that indeed it is.\\nAll that's left for us is to set up a lightning module\\nwith our model,\\nand train the model using a lightning trainer object.\\n\"},{\"urn\":\"urn:li:learningContentVideo:2708016\",\"duration\":301,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Creating a LightningModule\",\"fileName\":\"3096406_en_US_03_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":301,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"After watching this video, you will be able to create a model with a LightningModule.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10514992,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"We are now ready to define our PyTorch Lightning module,\\nwhich will hold our model as well as have the steps required for\\ntraining and validating our model.\\nHere is the class that I have defined,\\nLitBinaryClassificationModule.\\nWe are going to be performing binary classification,\\npredicting whether customers churned or not.\\nWe inherit from the lightning module base class.\\nThe init method is where we set up our model.\\nThis is where we define the model architecture and its layers.\\n\\nNow, init takes in two input arguments, the number of features\\nin the input data and the learning rate that\\nI've set to 0.001.\\nI'm using a smaller learning rate here.\\nMy model comprises of three linear layers again,\\nLayer 1, Layer 2, and Layer 3.\\nAnd each of the three linear layers has a ReLU activation.\\nAnd these are initialized separately as Activation 1,\\nActivation 2, and Activation 3.\\nThe final output is also a linear layer.\\n\\nThis is the output layer on Line 12.\\nThe output of this layer will be a probability score,\\nand this is the probability score that we'll use to determine\\nwhether a particular customer churned or not.\\nOnce again, I call self.save_hyperparameters on Line 13.\\nThis will cause num features and learning rate both to be saved as\\nmembers of the hparams object that can then be accessed\\nby the optimizer.\\nThe forward function is where we define what a forward pass-through\\nthe model looks like.\\n\\nYou can see we pass the input through the three layers,\\neach layer has the ReLU activation, and finally, we pass the data\\nthrough the output layer.\\nThis will give us the final predictions that we return.\\nThe training step defines the operations for a forward\\npass through the model\\nfor a single batch of data. The batch is passed in\\nas an input argument,\\nwe access the X features and the Y variables,\\nand then we do a forward pass through the model by invoking\\nself on the input features.\\n\\nA forward pass through the model will output logits for\\nclassification.\\nThe term \\\"logits\\\" refers to the raw unnormalized prediction scores\\noutput by a model for each class or category.\\nSince it's binary classification, we'll have just one logits score.\\nNow, the loss function that we use for our binary classification\\nmodel is the BCE with logits loss.\\nBCE here stands for binary cross-entropy.\\nThe BCE with logits loss converts the raw logit scores\\ninto probabilities.\\n\\nIt squashes the output logits to be probability values\\nin the range zero to one.\\nIt then computes the binary cross-entropy loss,\\nwhich is essentially computing the difference between two probability\\ndistributions.\\nThe probability distributions of the actual value versus\\nthe predicted values.\\nOn Line 30, we compute the BCE with logits loss for\\none batch of data,\\nand we log that out as a training loss along with a progress bar.\\n\\nIn the validation step, we perform predictions on one\\nbatch of validation data, so you can see the code on Lines\\n37 through 42 is the same.\\nWe compute logits and then compute the loss.\\nHowever, here in the validation data, we want the actual\\npredictions from the model.\\nAnd we compute that by converting the raw logits scores to\\nprobability scores using the torch.sigmoid activation.\\nThis will give us probability scores in the range zero to one.\\ntorch.round of this probability score will give us the\\nmodel prediction, zero for not exited, one for exited.\\n\\nNext, on Lines 46 through 49, we compute the accuracy as well as\\nthe F1Score of the classification model.\\nThe accuracy tells us how many predictions the model got right,\\nbut because we have a skewed dataset,\\nthe accuracy is not a great measure of how good this model is.\\nThe F1Score here represents a trade-off between precision\\nand recall,\\nmetrics that are better suited to evaluate models trained\\non skewed data.\\nPrecision is the proportion of positive identifications\\nthe model got right, and recall measures of the\\npositive identifications in the dataset,\\nhow many was the model able to correctly identify.\\n\\nIn the validation step, we log out the validation loss,\\nthe validation accuracy, and the validation F1Score.\\nThe predict step just gives us the predictions from the model.\\nHere we just make a forward pass through the model.\\nIn configure_optimizers, you can see that we've set\\nup an Adam optimizer.\\nThe Adam optimizer is an adaptive learning rate optimization\\nalgorithm,\\nvery popular and widely used in the real world.\\n\"},{\"urn\":\"urn:li:learningContentVideo:2708017\",\"duration\":248,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Training a classification model and evaluating metrics\",\"fileName\":\"3096406_en_US_03_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":248,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"After watching this video, you will be able to evaluate a classification model using PyTorch metric libraries.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8966511,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Now that we've defined our lightning module,\\nlet's instantiate our classification module.\\nWe need to pass in the number of features.\\nHere is what the layers of the model look like.\\nWe know that the training process of this model is very\\nstraightforward using a PyTorch trainer.\\nOnce again, I use a CSVLogger to log out the training metrics\\nin a CSV file.\\nI instantiate the data module on Line 3,\\nthe logger on Line 5, and the trainer,\\nwhich will actually run the training and validation\\nprocess on Line 7.\\n\\nWe'll run for a maximum of 20 epochs of training and start the\\ntraining process by calling trainer.fit.\\nThe trainer will identify that we don't have a GPU here\\non this machine, and it will automatically train\\nthe model using the CPU.\\nNow, the training process took about 6 or 7 minutes to run.\\nHere at the end of one epoch of training,\\nvalidation accuracy is 0.819, so accuracy is high.\\nThe F1 score is just 0.268.\\n\\nI let this run through again for all 20 epochs.\\nAnd at Epoch 19, let's take a look at the various\\ncourse. Validation accuracy is 0.859, it has risen,\\nthe validation F1 score is 0.41, much better than before,\\nbut not great. Now\\nfor some reason, the validation F1 score doesn't display\\ncorrectly here\\nwhen we look at the output of the training of the model.\\nWe'll actually compute the accuracy,\\nprecision, recall, and F1 score for the validation data in just a bit.\\n\\nMeanwhile, let's access the metrics for the training process\\nof this model in the metrics.csv file under the training\\nlogs directory.\\nIn addition to the training and validation loss,\\nwe also logged out the validation accuracy and the validation\\nF1 scores.\\nThose additional metrics are also available here as part\\nof the logs.\\nvisualization, a Seaborn line plot.\\nAnd here you can see four different lines corresponding to\\nthe four metrics that were tracked during the training process.\\n\\nThe orange dotted line on top is the validation accuracy,\\nthe green dotted line is the validation F1 score,\\nand the remaining two lines represent the training and\\nvalidation losses, respectively.\\nNext, I'll call model.predict on the validation data.\\nSo we get predictions from the model and we get them\\nas a stacked tensor.\\nSo we have one tensor with all the predictions.\\nThe predictions here are in the form of raw unnormalized\\nlogits scores.\\n\\nIn order to get these scores in the form of probability values\\nbetween zero and one, you need to apply the\\ntorch.sigmoid function and then torch.round will give us the actual\\npredictions in the form of zero/one values.\\nLet's get the actual values from the validation data.\\nWe'll have to compare the predictions from the model against\\nthese actual values.\\nWe need to call torch.stack on these labels as well\\nin order to get them all in a single tensor.\\nNow that we have the predictions and the actual values,\\nlet's compute some evaluation metrics for the validation data.\\n\\nWe'll compute accuracy, precision, recall,\\nand the F1 score.\\nLet's go ahead and hit \\\"Shift-Enter\\\" and we'll see how the model is.\\nAccuracy is quite good at 0.859.\\nPrecision, which is the proportion of positive identifications\\nof exited customers\\nthat the model got right is quite high, 0.785.\\nThe recall score is on the lower side,\\n0.464.\\nOf the customers identified as exited or churned by the model,\\nhow many were actually right?\\nThis is what recall measures.\\n\\nAnd finally, we have the F1 score, which is the trade-off between\\nprecision and recall,\\nand that's the 0.58.\\nThat's great.\\nAt this point, you've successfully built and trained a classification\\nmodel using PyTorch Lightning.\\n\"}],\"name\":\"3. Using PyTorch Lightning to Build a Classification Model\",\"size\":36607780,\"urn\":\"urn:li:learningContentChapter:4549019\"},{\"duration\":78,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2708018\",\"duration\":78,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Summary and next steps\",\"fileName\":\"3096406_en_US_04_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":78,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1923056,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"And this demo brings us to the very end of this AI workshop on\\nbuilding a neural network with PyTorch Lightning.\\nNow, we started this course off with a quick overview of PyTorch\\nand PyTorch Lightning, and we discussed how PyTorch\\nLightning allows us to write cleaner and more modular code\\nfor model training.\\nWe then got hands-on and we trained a regression model\\nusing the PyTorch APIs.\\nWe identified that there was a lot of boilerplate code here in the\\nmodel building and training process,\\nand we eliminated a lot of this boilerplate repetitive code in the\\nnext demo where we train the same regression model,\\nbut this time we used PyTorch Lightning.\\n\\nAnd then in order to get some more practice with PyTorch Lightning\\nfor model training, we built and trained a\\nclassification model using PyTorch Lightning.\\nWell, this brings us to the very end of this AI workshop.\\nIf you're interested in neural networks and you want\\nto study further, here are some other courses\\non LinkedIn\\nlearning\\ntables and hands-on PyTorch machine learning are both great\\ncourses that might be a good fit for you.\\nWell, that's it from me here today.\\n\\nI hope you had fun in this AI workshop.\\nThank you for listening.\\n\"}],\"name\":\"Conclusion\",\"size\":1923056,\"urn\":\"urn:li:learningContentChapter:4549020\"}],\"size\":168040002,\"duration\":5449,\"zeroBased\":false}]}"