"{\"title\":\"UX Research Professional Certificate by UserTesting\",\"courses\":[{\"course_title\":\"UX Foundations: Research\",\"course_admin_id\":4304078,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":4304078,\"Project ID\":null,\"Course Name\":\"UX Foundations: Research\",\"Course Name EN\":\"UX Foundations: Research\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"UX research helps a business by saving development or process costs, increasing customer happiness and loyalty, and uncovering opportunities to earn more. In this course, Amanda Stockwell shows you practical techniques to improve your UX research to better inform fast-moving projects. Get an overview of different types of research methodologies, usability tests, and conducting interviews. Review card sorts, eye tracking, multivariate testing, and desirability testing. Go over the best uses of expert reviews, surveys, diary studies, participatory design workshops, and personas. Learn how to choose the right research method for your goals, then dive into environmental considerations, such as in-house versus external, agile versus waterfall, and more. Find out how to plan and execute effective research, and then explore the best ways to analyze and present your findings.\",\"Course Short Description\":\"Learn UX research techniques that will help you to better inform fast-moving projects while limiting risks.\",\"Content Type\":\"SKILLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":5287222,\"Instructor Name\":\"Amanda Stockwell\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"President of Stockwell Strategy\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2023-02-24T00:00:00\",\"Course Updated Date\":\"2024-04-29T00:00:00\",\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"Yes\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/ux-foundations-research-19417883,https://www.linkedin.com/learning/ux-foundations-research-19415906,https://www.linkedin.com/learning/ux-foundations-research-revision-2023\",\"Series\":\"Persona\",\"Limited Series\":null,\"Manager Level\":\"General\",\"LI Level\":\"Beginner + Intermediate\",\"LI Level EN\":\"Beginner + Intermediate\",\"Sensitivity\":null,\"Internal Library\":\"Creative\",\"Internal Subject\":\"User Experience\",\"Primary Software\":null,\"Media Type\":\"Video\",\"Has CEU\":\"No\",\"Has Exercise Files\":\"Yes\",\"Visible Duration\":4361.0,\"Visible Video Count\":32.0,\"Contract Type\":\"PERPETUAL\"},\"sections\":[{\"duration\":41,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4403560\",\"duration\":41,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"User experience research\",\"fileName\":\"4304078_en_US_00_01_WL30\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"In this video, get an introduction to UX research.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7470104,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Do you want to get into UX research\\nbut don't know where to start?\\nMaybe you're looking to change jobs\\nor just want to learn\\nhow to better incorporate user feedback\\nin your current role.\\nThen my LinkedIn learning course is for you.\\nHi, I'm Amanda Stockwell.\\nI've spent the last 15 years in UX research.\\nGetting to know the people who use your products\\nand exploring solutions for them is the true power UX.\\nAfter all, you can't call it user experience\\nif you don't talk to any actual users.\\n\\nWith my course,\\nyou'll be able to go\\nfrom not knowing anything about UX research\\nto having all the tools you need to get started.\\nAre you ready to dig in?\\nLet's do this.\\n\"}],\"name\":\"Introduction\",\"size\":7470104,\"urn\":\"urn:li:learningContentChapter:4404628\"},{\"duration\":1639,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4402653\",\"duration\":244,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Why is user experience research important?\",\"fileName\":\"4304078_en_US_01_01_MM30\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"In this video, learn how to elaborate on the key reasons that UX research helps a business: saving development or process costs, increasing customer happiness and loyalty, and uncovering opportunities to earn more. Using this information, you can better inform your design decisions and ensure that your business is meeting and exceeding the expectations of its users.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":17515401,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- User experience, or UX, is all about catering the design\\nof a product or service to fit the needs of its users.\\nUX research is all about\\nthoroughly understanding those users.\\nIt helps you get to know who they are,\\nwhat they need, what their goals are,\\nthe context in which they'll interact with your product,\\nhow will you're serving their needs,\\nand uncover opportunities to create something even better.\\nResearch helps inform design decisions,\\nand ensures that a business is meeting\\nand exceeding the expectations of users.\\n\\nThere are three major ways\\nthat UX research helps a business.\\nIt saves development or process costs.\\nIncreases customer happiness and loyalty.\\nAnd uncovers opportunities to earn more.\\nLet's start with that first point, saving money.\\nTo do that, you need to build the right thing,\\nand build it the right way.\\nThe best way to figure out the right things to build\\nis by understanding the true needs\\nand context of your users.\\nThis can help you make decisions faster\\nthat maximize value for users\\nwhile taking your team's efforts into consideration.\\n\\nHaving a deeper knowledge of their context\\nalso means that you're less likely\\nto learn about a surprise requirement\\nafter much planning and development is already done.\\nMany studies show that code changes become increasingly\\nexpensive the later they are in the development process.\\nSome estimate that changes made after deployment\\nare up to 100 times more expensive\\nthan edits made during the design stage.\\nOngoing research can help you uncover\\nany changing needs of your users\\nso that you can pivot if necessary,\\nagain, reducing the chance\\nfor wasted development time or rework.\\n\\nYou also need to be sure that you're building it right,\\nmeaning that what you implement is easy for your users.\\nIterative research gives you the opportunity\\nto catch potentially confusing designs early on\\nand get user input when deciding\\nbetween alternative solutions.\\nRunning research might also help you identify\\nand address internal solutions\\nthat are costing the company money.\\nLet's say that you work\\nfor a company with a big call center,\\nand every representative uses a system\\nto track their customers and interactions.\\n\\nIf you're able to pinpoint issues and recommend changes\\nthat would save call center representatives\\neven a few moments per transaction,\\nthat can add up to significant savings over time.\\nBeyond saving money, UX research can help ensure\\nthat users have at least their expected positive experience\\nwith a product or service.\\nStudy after study shows that users are willing\\nto leave a website or application\\nif they have trouble finding what they're looking for\\nor run into a usability problem.\\n\\nOngoing research can help you make sure it's easy\\nfor customers to perform key actions,\\nsuch as purchasing or signing up.\\nThis will make it less likely\\nfor customers to go to a competitor\\nand more likely for them to spend even more with you.\\nFinally, UX research can help you uncover opportunities\\nfor improvements or new functions\\nthat users will value and potentially pay for.\\nFor instance, you might notice workarounds\\nyour users have for difficult tasks,\\nor notice that they use another tool\\nto fill a specific need your product doesn't serve.\\n\\nThis sort of information can help you plan future fixes\\nor features to prioritize and new solutions to offer\\nthat you may not have previously considered.\\nYou can also evaluate your competitors\\nto give you another perspective\\non what functions users find valuable\\nor understand weaknesses in your space.\\nSome of the most successful products\\nare not completely new ideas,\\nbut ones that have improved existing solutions.\\nSo remember, UX research saves you money,\\ncreates user satisfaction,\\nand opens up new opportunities for you to improve.\\n\\nNow, think about a product that you use daily,\\nwhat makes it valuable to you?\\nIs there anything that you would change?\\nThat is exactly the sort of information\\nthat a successful UX research effort would uncover.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4403561\",\"duration\":57,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Methodology overview\",\"fileName\":\"4304078_en_US_01_02_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"In this video, learn about the most frequently used UX research methodologies, including usability tests, interviews, card sorts, eye tracking, multivariate tests, desirability studies, expert and heuristic reviews, surveys, personas, and participatory design workshops, so that you can choose the appropriate methodologies for your specific research needs.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4007437,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- There are many methodologies that a UX researcher may use.\\nBefore we talk when and how to conduct research,\\nI'd like to give you a quick rundown\\nof the various research methods.\\nWhile this is by no means an exhaustive list,\\nI'm providing an overview of the most common types\\nof approaches, with brief examples and additional resources.\\nYou might use any combination of these UX research methods\\nto achieve a variety of business goals.\\nI've provided this same list and additional resources\\nin the exercise files if you want to follow along\\nand revisit later.\\n\\nI've also included templates of several documents\\nand deliverable types to help you get started\\nwith screening participants, writing research plans,\\nand reporting on the results of your research.\\nThese templates may be helpful after the course,\\nwhen you're beginning to run your own research sessions,\\nbut they're not required while you watch.\\nThe content is all editable\\nand going to have to be customized for each study,\\nbut should give you a headstart\\nwhen conducting your own research.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3884080\",\"duration\":0,\"visible\":false,\"requiredForCertificateOfCompletion\":null,\"name\":\"FAKE VIDEO FOR ARTICLE\",\"fileName\":\"4304078_en_US_01_03_FAKE_AR\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"updateType\":\"ADDED\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":10,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"NOT_AVAILABLE\",\"cdnStatus\":\"NOT_ATTEMPTED\",\"size\":0,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"NEW\",\"transcript\":null},{\"urn\":\"urn:li:learningContentArticle:137008\",\"duration\":540,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Glossary of methodologies\"},{\"urn\":\"urn:li:learningContentVideo:4404624\",\"duration\":101,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Usability testing\",\"fileName\":\"4304078_en_US_01_03_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"In this video, examine and explore usability tests, one of the most frequently used methods in user experience research, so that you can choose between design alternatives and discover issues that impede the experience.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5504611,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Usability testing is one of the most often used\\napproaches in UX research.\\nIt evaluates how easy it is\\nto use an interface or product.\\nUsability tests can be done on any live site\\nor piece of software, including competitors,\\nor on a prototype of any fidelity.\\nYou may focus on a single product\\nor test multiple versions to help you choose\\nbetween design alternatives.\\nThese tests are particularly effective\\nfor discovering issues that impede the experience.\\n\\nIn a traditional usability test,\\na moderator asks participants to perform tasks,\\nobserves as they go, and asks follow-up questions\\nto understand their thought process.\\nYou may also include things like Likert scale readings\\nto understand perceived ease of use\\nor measure things like how long each task takes.\\nThe tools you can use for this method vary widely\\ndepending on whether or not the participant\\nis remote or in person\\nand whether the test is moderated or unmoderated.\\nIf you're in person, you can sit with someone and observe.\\n\\nYou may want to record the session for posterity\\nand capture their body language, facial expressions,\\nand interactions with whatever you're testing.\\nFor moderated remote sessions,\\nI frequently use the screen sharing\\nand video recording of video conference tools like Zoom.\\nFor unmoderated sessions,\\nor more structured moderated sessions,\\nsome of the most common tools are usertesting.com\\nand UserZoom, which are merging,\\nMaze, Loop11, dscout, UsabilityHub, and Userlytics.\\nEach of these tools have their pros and cons,\\nso you'll have to take your particular circumstance\\ninto consideration.\\n\\nFor more information, you can check out my deep dive course\\non usability testing.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4406595\",\"duration\":104,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Interviewing\",\"fileName\":\"4304078_en_US_01_04_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"In this video, learn how to conduct interviews in the context of user experience so you can examine different types of users, compare the differences in the way those users behave, and gauge the outlook or impressions of specific items. Interviews are especially helpful as an input to creating personas.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5601550,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Interviewing is a widely used technique\\nto gather qualitative information from participants.\\nJust as it sounds, you sit down with a participant\\nand ask them open-ended questions\\nabout their needs, goals, and motivations.\\nWhen possible, do the interview\\nin the user's natural environment,\\nwhich you may also hear called an ethnographic interview.\\nBeing in their normal context\\nusually makes users more comfortable\\nand you can observe conditions\\nthat might impact their experience.\\nThat said, conducting interviews remotely might allow you\\nto reach a broader audience and can save budget.\\n\\nEither way, interviews are a powerful way\\nto learn about your users and their beliefs.\\nInterviews are used to learn\\nabout different types of users,\\ndifferences in the way they think,\\nand to gauge their outlook or impressions on specific items.\\nThey're especially helpful as input into creating personas.\\nHowever, interviews should not be used\\nto dig into behavior or evaluate products.\\nIt can be helpful to use a tool like Calendly\\nto set up times at work for you\\nand allow participants to schedule themselves.\\n\\nIf you're performing remote sessions,\\nit's helpful to have a remote conferencing tool\\nthat has embedded transcripts like Zoom.\\nI like to record sessions when I can\\nand usually use the recording feature\\nwithin the conferencing tool I use.\\nIf you don't have access to that,\\nI recommend using a transcription service like Otter.\\nI also really like the combined service\\nof a tool like Tetra Insights.\\nIt creates transcripts of each session,\\noffers tools to create and manage tags as you review,\\nand allows you to live note take during the session\\nso you can match tags and parse data quickly.\\n\\nFor more information,\\ncheck out my other LinkedIn learning courses devoted\\nto interviewing.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4407455\",\"duration\":57,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Card sorts\",\"fileName\":\"4304078_en_US_01_05_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video explores card sorts, a particular quantitative research method that can enable you to determine categorization and hierarchy when determining information architecture.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2203063,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Card Sorts are used to help determine categorization\\nand hierarchy in determining information architecture.\\nThere are two categories of Card Sorts.\\nOpen and Closed.\\nIn an Open Card Sort,\\nyou ask participants to categorize elements\\nthat you need to organize\\ninto whatever groupings they think make sense\\nand then label them.\\nIn a Closed Card Sort,\\nyou give people existing categories\\nand ask them to place elements within the buckets.\\nOnce you have your navigation structure set,\\nyou can perform what's called a \\\"Tree Test,\\\"\\nwhere you ask people to find particular elements\\nusing your navigational structure.\\n\\nAll of these methods help you define\\nand refine your organizational structure.\\nThere are several great digital card sorting tools\\nout there,\\nbut you can also use sticky notes and Whiteboards\\nor tables if you're in the same room as your participants.\\nMy favorite digital tool is OptimalSort,\\nwhich is options for Open and Closed Card Sorts,\\nas well as Tree Testing.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4400485\",\"duration\":65,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Eye tracking\",\"fileName\":\"4304078_en_US_01_06_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video explores eye tracking, a method that uses equipment to capture and analyze where a person is looking. Eye tracking can enable you to get a true understanding of what actions your users are taking without having to rely on your memory or ability to self-report.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3837539,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Eye tracking can help you learn\\nabout how people are first engaging,\\nwhat draws their attention\\nand how they process information on a pager screen.\\nThis method uses equipment that creates a reflection\\nin a participant's eyes\\nand estimates the position and movement of their eyes.\\nFor detailed eye tracking, you'll need specialized equipment\\nand software that is typically much more expensive\\nthan other UX research tools.\\nThe most well known and well respected is the Toby System.\\nEye tracking gives you a true understanding\\nof what actions users are taking without having to rely\\non their memory or ability to self-report.\\n\\nYou'll learn things like where users looked,\\nhow long they were looking, and their gaze pattern.\\nHowever, you should note\\nthat eye tracking cannot tell you why users are\\nlooking or interacting the way they are.\\nFor instance,\\nif they look at a specific diagram for a long time\\nthat could mean that it's very confusing and\\nthey can't figure it out\\nor it could mean that it's super engaging.\\nTo get the full picture of users' behavior\\nyou should combine eye tracking with other\\nmethods like a follow-up interview.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4404625\",\"duration\":63,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Multivariate testing and A/B testing\",\"fileName\":\"4304078_en_US_01_07_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video explores the differences between multivariate testing and A/B testing.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2694071,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Multivariate testing is a method where you create\\nseveral different versions of something\\nand compare which one does the best job\\nat hitting your goal.\\nMultivariate testing means\\nthat you change more than one variable.\\nA/B testing refers to when you are only changing one thing.\\nFor instance, you may test different button colors\\nand see which gets the most signups on a page.\\nThat would be an A/B test.\\nIf you test a variety of button colors\\nand the placement of the button,\\nthat would be a multivariate test\\nbecause you're changing two elements.\\n\\nRegardless of how many options,\\nthese tests are designed to help you examine\\nthe real-world performance of different options\\nin a live product, site, or service.\\nYou can choose to examine anything concretely measurable,\\nlike the number of clicks, average order size,\\nnumber of signups, et cetera.\\nYou just need to keep in mind\\nthat optimizing one single goal\\nmay disrupt the overall experience goals.\\nSo choose what you measure carefully.\\nThere are many online tools that you can use\\nto automate this type of testing,\\nsuch as Optimizely and Google Optimize.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4400486\",\"duration\":52,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Desirability studies\",\"fileName\":\"4304078_en_US_01_08_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video provides an overview of desirability studies and the specific value to research projects so that you can ensure that your visuals both match brand goals, and evoke the desired emotional response from your end users and customers.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2581938,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Desirability studies allow you to ensure\\nthat your visuals match your brand goals,\\nand evoke the desired emotional response.\\nThere are several variations.\\nBut the most common is that you show participants\\nvariations of visual designs,\\nand ask them to select which words best describe each.\\nThe list of words you give them\\nis based on the words that best describe your brand goals\\nand their opposites.\\nYou can then analyze which of the designs evokes\\nthe most positive associations.\\nIf you moderate the sessions,\\nyou can ask qualitative follow-up questions\\nto dig into why users associate certain visuals\\nwith different words.\\n\\nIf so, the tools you need are simple.\\nThe visual designs, the list of descriptions,\\nand a way to take notes.\\nTo reach a broader audience,\\nyou could automate the collection of responses\\nusing any remote survey tools that allow both screenshots\\nand multiple answer question types.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4400487\",\"duration\":71,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Expert reviews (heuristic reviews)\",\"fileName\":\"4304078_en_US_01_09_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video discusses expert reviews and heuristics analyses, which are detailed assessments of an interface, service, or product conducted by someone trained in current user experience best practices. Learn how to leverage expert reviews and heuristic analyses as a process for ensuring that what you're building follows user expectations and industry best practices.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4128865,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Expert reviews are detailed assessments of an interface,\\nservice or product conducted by someone trained\\nin current user experience best practices.\\nThere are a quick way to see how well\\nan interface might match user expectations.\\nYou might also hear the term heuristic evaluation\\nwhich is the process of directly comparing a product\\nto specific heuristics or predefined guiding principles.\\nTechnically,\\nan expert review might include a heuristic evaluation\\nbut will also include assessments and recommendations based\\non general best practices and industry knowledge.\\n\\nA traditional heuristic review requires several\\nUX professionals to perform reviews and compare notes.\\nThough in practice, there's usually only time\\nfor one person to perform such a detailed assessment.\\nThe only thing you need to get started is access\\nto the interface you want to assess\\nand a set of heuristics or best practices.\\nYour company may have developed internal design guidelines\\nand patterns to follow\\nin which case you can use those as your heuristics.\\nIf not, it may be a good opportunity to\\nstart that conversation to create internal standards\\nor you can use one of the established sets of UX heuristics\\nlike the ones from Jacob Nielsen.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4402654\",\"duration\":53,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Surveys\",\"fileName\":\"4304078_en_US_01_10_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video provides an overview of using surveys in UX research so you can use them to gather facts or opinions or ask a variety of quantitative and qualitative questions to inform your research goals.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2075916,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Surveys used in the UX research world\\nare no different than other surveys.\\nYou craft a list of questions designed\\nto gather certain facts or opinions\\nfrom a targeted list of people.\\nMany user experience professionals integrate various types\\nof questions into surveys, such as text questions\\nabout demographics or first click or desirability tests.\\nYou can quickly get data that is either quantitative\\nor qualitative using surveys.\\nWe'll talk more about the types of data, but you should know\\nthat surveys are best for gathering information\\nlike a user's intent, but not exploring behavior or context.\\n\\nThere are numerous digital survey tools\\nthat vary in complexity from free Google Forms\\nto more sophisticated tools like SurveyMonkey,\\nTypeform, or Qualtrics.\\nSome other combined tools like UsabilityHub\\nand UserTesting.com also allow you\\nto incorporate some survey questions into other studies.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4407456\",\"duration\":72,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Diary studies\",\"fileName\":\"4304078_en_US_01_11_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video gives an overview of diary studies, which involve asking participants to record their behaviors or thoughts on a given topic at specific points over time. Learn how to leverage diary studies as a means to collect specific, detailed information on how individual users both access and respond to what's being built or designed.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3610978,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Diary studies are a kind of longitudinal study\\nwhich means that you look at the same variable over time.\\nIn particular, diary studies involve asking participants\\nto record their behaviors, activities, or thoughts\\non a given topic over time.\\nExamples include asking people to record the time\\nwhen they use a specific app\\nor give feedback on their experience\\nwith a product each day.\\nYou can conduct a structured diary study\\nwhich is when you provide the same set of tasks or questions\\nat regular times, or you can just give them guidelines\\nabout how often they should be providing updates.\\n\\nDiary studies can be used for anything\\nfrom understanding the context\\nof how something is being used in real life\\nto watching to see how habitual behaviors change over time.\\nBecause there are a variety of ways you can collect data,\\nyou may need tools as simple as email\\nor a survey tool in a spreadsheet.\\nYou can also set up a more formal digital tool\\nlike dscout or Indeemo, which can offer reminders to record\\nand features to consolidate different types of data.\\nThe most important thing when deciding how\\nto collect information is to consider\\nthe user base you're investigating.\\n\\nMake it as easy as possible\\nso they can realistically do it in the time period.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4402655\",\"duration\":80,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Participatory design workshops\",\"fileName\":\"4304078_en_US_01_12_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video provides an overview of participatory design workshops. Learn how to host sessions including users, designers, developers, and business decision makers that will help both satisfy research goals, and help ideate solutions for tough user experience problems.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4262327,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Participatory design workshops\\nare collaboration sessions\\nbetween users, designers, developers\\nand other business decision makers.\\nYou might use a variety of different specific exercises\\nbut the goal is to have users actively involved\\nin brainstorming\\nand providing immediate feedback on various ideas.\\nGenerally, each party participates in co-creating a variety\\nof solutions for a predefined problem\\nand ongoing conversations about user needs and issues,\\nbusiness considerations and technical limitations.\\n\\nThe group works together\\nto both ideate and refine solutions throughout the session.\\nTypically, the only tools you'll need are a way to share\\nand record ideas.\\nIf in person,\\nthat's usually just writing utensils, paper, sticky notes\\nor a whiteboard, and a place for the whole team to gather.\\nParticipatory design sessions can also be done remotely\\nbut it takes a little bit more planning\\nand you need to carefully consider how to make it easiest\\nfor each person to participate.\\nMany use tools like Mural\\nor Miro to predefine exercise spaces\\nbut you can also use things like shared Google Docs.\\n\\nYou could even have remote participants sketch\\non paper and upload their images to a shared space.\\nJust be sure to consider who is participating\\nand how to ensure\\nthat everyone is equally comfortable sharing their ideas.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4401542\",\"duration\":80,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Personas\",\"fileName\":\"4304078_en_US_01_13_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"In this video, learn how to create and use personas, so you are able to generate specific personas that describe the different types of users being served with your product or service. Personas can be informed by a variety of UX research methods.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4958050,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Personas aren't a research method,\\nbut they are a tool that many UX researchers utilize\\nto help them describe the different types of users\\nthat an organization serves.\\nUX professionals will perform a variety of research tactics\\nto understand their key user bases\\nand the main differences between their behaviors,\\ngoals, and identifying usage.\\nFor instance, if you're working\\non a business expense tracking software,\\none persona might describe the usage\\nof a frequent business traveler\\nand another may describe a financial officer\\nwho needs to approve all of their reports.\\n\\nThey're both users of the product\\nbut have very different contexts, usages, and goals.\\nTo create the personas, you need to pull data\\nfrom your various research sources into a unified story\\nabout user skills, goals, environments, key behaviors,\\nand the context of your product in their life.\\nYou'll then refer to the personas\\nas you make design decisions.\\nYou'll typically create a document\\nthat summarizes the persona's key attributes\\nand differentiation points.\\n\\nThe goal is to help everyone\\nunderstand the different user bases to help guide decisions\\nthroughout the design and development process.\\nFor more information, check out our course\\non creating personas and don't forget\\nto check the additional resources list.\\n\"}],\"name\":\"1. Research Overview\",\"size\":62981746,\"urn\":\"urn:li:learningContentChapter:4401544\"},{\"duration\":631,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4404626\",\"duration\":231,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Setting research goals\",\"fileName\":\"4304078_en_US_02_01_MM30\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video discusses the importance of setting specific goals for user experience research so that you can best determine which method to use and get the most out of your research sets.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":13463823,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- The single most important step\\nwhen running effective UX research\\nis to define exactly what questions you're trying to answer\\nand forming those questions into particular goals.\\nYour specific goals will determine which methods to choose\\nand guide your overall approach to planning.\\nIt's likely that you might\\nhave many open questions you could explore,\\nso I recommend keeping a list of outstanding questions\\nand narrowing it down to just one at a time.\\nIf you're not sure where to begin,\\nyou can consider things like,\\nwhat are your organization's goals?\\nWhat do you already know about your user base?\\nWhat data do you not have?\\nWhat solutions already exist or have been proposed?\\nWhere have you heard that there are existing issues?\\nOnce you've identified open questions,\\nprioritize them with your design, development, product,\\nor business teams and other stakeholders.\\n\\nGenerally, I'd recommend prioritizing questions\\nabout who your users are and what they need\\nover specific design solutions.\\nBut the most important questions\\nare going to be dependent on your particular context.\\nNext, think about how you can delineate\\nspecific objectives to investigate.\\nFor instance, you might have a larger goal\\nof wanting to assess how user friendly your application is.\\nBreak that down into specific questions, like,\\nhow thoroughly does the onboarding process set users up?\\nAnd, how easy or difficult do users find\\ntheir most important task?\\nThe more you narrow things down,\\nthe easier it will be\\nto figure out what methodologies to use.\\n\\nFor instance, if a question involves how easy or difficult,\\nyou likely want to conduct some kind of usability test.\\nIf you want to see how habits change over time,\\nyou'll probably want to conduct a diary study.\\nYou can combine elements of different research methods\\nto efficiently answer your questions in one effort\\nif the methods align.\\nOr you can stack efforts to make sure\\nyou're thoroughly examining the questions at hand.\\nYou should also know there's almost never just one way\\nto answer a question.\\n\\nSometimes it's helpful to conduct multiple kinds of efforts\\nto examine a question thoroughly.\\nLet's imagine you're working on an e-commerce platform\\nthat is expanding their product line.\\nThe team is considering adding a new category of products\\nto their navigation structure.\\nYou might identify a handful of goals including:\\nassess the current navigation system,\\ndetermine the best way to integrate a new category,\\ntest various versions of a new navigation structure,\\nand validate a final proposal.\\n\\nTo best understand how well the existing navigation works,\\nyou could set up a tree test\\nand examine what areas people frequently get stuck on\\nor conduct a usability test\\nwhere you ask participants to find individual products.\\nTo understand where the new product category should fit,\\nyou could do an open card sort\\nwith all of the existing products and the new product\\nto see how users categorize on their own.\\nComing out of that, you might have multiple ideas\\nfor the best way to restructure,\\nso you could conduct a series of closed card sorts\\nor tree test various proposed structures.\\n\\nYou might then have a forerunner\\nand usability test the proposed structure\\nin the context of a prototype.\\nThere isn't always a clear-cut answer\\nand it's possible to combine approaches.\\nHaving clear goals anchors you back\\nto why you're conducting research\\nand how your team will use the information you gather.\\nLet's try setting a goal for something\\nthat you're currently working on.\\nIf you could learn anything about your users or product,\\nwhat would you want you know?\\nHow could you refine that target\\ninto a specific research objective?\\nWrite down your answers and in the next few videos\\nwe'll talk about how to find the best research method\\nfor your goals.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4405545\",\"duration\":178,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Qualitative vs. quantitative data\",\"fileName\":\"4304078_en_US_02_02_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video introduces one of the key distinctions in types of research, between quantitative and qualitative data. In this video, learn how to correctly choose and collect the right type of data to inform your specific research goals.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9389496,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- While the questions you're trying to answer\\nshould drive your methodology,\\nit's helpful to understand different types of research\\nand data as well.\\nOne thing to consider is whether your open question\\ncan be answered with quantitative or qualitative data.\\nQuantitative data is anything you collect\\nthat represents numeric information,\\nsuch as the percentage of site visitors\\nthat fill out a form\\nor users' perceived ease of use ratings.\\nQuantitative data is not based on opinion\\nand serves as an objective input to decision-making.\\n\\nIt's best at capturing trends of what is happening.\\nYou may even be able to get statistically relevant data,\\nthough keep in mind\\nthat you can misinterpret quantitative data\\nif you are working with a small data set.\\nCommon uses of quantitative data in UX research\\nare calculating the percentage of support complaints\\nthat are about a particular feature\\nor running an AB test to see which\\nof two versions of a button gets more clicks.\\nYou can gather quantitative data\\nfrom things like card sorts, surveys, usability studies,\\nclick tests and eye tracking studies.\\n\\nIf there is a count or a number, that is quantitative data.\\nOn the other hand, qualitative data is any other feedback\\nor information that can't be represented by numbers,\\nsuch as emotional responses or first impressions.\\nWe use this sort of information\\nto help uncover why things are happening\\nor dig deeper into the context of a situation.\\nWhen we refer to qualitative research,\\nwe're usually referring to smaller efforts\\nthat involve directly interacting with people.\\n\\nYou don't always have to be sitting next to them,\\nbut you need participants to be able\\nto express their thoughts directly,\\nwhether in text or verbally.\\nExamples of methods that allow you\\nto collect qualitative data are usability tests,\\nfocus groups, interviews, diary studies\\nand participatory design workshops.\\nYou may collect both quantitative\\nand qualitative information in one research effort.\\nFor example, when you perform a set of usability tests,\\nyou can measure the time it takes to complete a task\\nand ask open-ended questions to gather impressions.\\n\\nYou might also want to design a stacked research effort\\nthat combines various methods\\nto gather different kinds of data about the same problem.\\nFor instance, let's say\\nthat you've designed two different versions\\nof a signup form,\\nYou might conduct AB testing to monitor\\nhow many signups can be attributed to each form,\\nwhich is purely quantitative data.\\nThen to understand why the winning design was more engaging,\\nyou might plan some moderated usability sessions.\\n\\nThis combination of quantitative and qualitative data\\nwill help you understand the full picture.\\nBoth types of information are extremely helpful,\\nand it's important to understand\\nwhat you're looking for so you can design your studies\\nto best capture what you need.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4405546\",\"duration\":131,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Behavioral vs. attitudinal research\",\"fileName\":\"4304078_en_US_02_03_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video explains the distinctions between behavioral and attitudinal research. In this video, learn how to choose and apply the correct type of research to satisfy your unique research goals.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9299982,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- To plan effective research,\\nyou'll also want to consider whether you want\\nto observe people directly or ask for people's opinions.\\nBehavioral research is when you directly observe a person\\nand their actions.\\nAttitudinal research refers to asking people\\nto self-report their opinions in things like surveys,\\nfocus groups, or preference tests.\\nThere's some methodologies that end up being a blend\\nof observation and discussion.\\nFor instance, you may run a usability test\\nwhere you observe a user interact\\nwith a piece of software, which is behavioral research,\\nbut also ask them several follow-up questions\\nabout their expectations\\nor why they made certain choices,\\nwhich is more attitudinal data.\\n\\nUX professionals tend to rely more heavily\\non behavioral research because many times what people report\\nin attitudinal research does not match\\nwhat they actually end up doing in behavioral research.\\nPeople aren't usually intentionally lying,\\nbut we're exceptionally bad at remembering our experiences,\\nreflecting on our true behaviors,\\nand predicting any future actions.\\nFor instance, you might ask someone what they plan to buy\\non a trip to the grocery store.\\nThey might report that they're getting vegetables\\nand a protein to make for dinner.\\n\\nBut if you look at their receipts,\\nyou might find that they actually also purchased\\nice cream and chips.\\nThey may have intended to only purchase dinner ingredients,\\nbut of course that isn't quite accurate.\\nThat's not to say attitudinal research\\nisn't helpful though.\\nIt's important for an organization to know\\nwhen user's expectations don't match their behavior,\\nhow users perceive brands,\\nhow users expect something to work,\\nor their outlook on potential features.\\nFor instance, you could conduct an attitudinal method\\nlike a survey and uncover that a big percentage\\nof your user base has strict budget limitations\\nthat make it so that they have to cancel\\nand resubscribe only when they need certain features.\\n\\nObserving how they interact with the existing product\\nmay not have given you that insight.\\nThink back to the goal you set\\nabout the biggest open questions you have\\non what you're working on now.\\nWhat sort of information would give you\\nthe most accurate answer?\\n\"},{\"urn\":\"urn:li:learningContentVideo:4402656\",\"duration\":91,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Moderated vs. unmoderated research\",\"fileName\":\"4304078_en_US_02_04_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video discusses the differences between moderated and unmoderated research. In this video, learn how to choose and apply the appropriate research moderation\u2014or lack thereof\u2014to satisfy your research goals.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6650721,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- When you think of conducting research,\\nyou might assume you're directly interacting\\nwith a participant during a session.\\nThat's called moderated research.\\nThis is ideal, because you're present\\nto ask unscripted questions and dig deeper\\ninto interesting topics, though can be time consuming\\nand it's not always possible.\\nThe most common moderated methods\\nare usability tests and interviews.\\nUnmoderated research is completed\\nby a participant with no researcher present.\\nThese sessions can usually be completed faster\\nthan moderated sessions.\\n\\nYou can collect more information\\nin a shorter amount of time,\\nbut you still need plenty of time to review the data.\\nExamples include filling out a survey\\nor performing usability tasks\\nand answering predetermined questions.\\nIn unmoderated sessions, you need to be especially careful\\nto make instructions clear and have questions\\nthat don't lead participants.\\nYou also won't be able to explore as deeply\\nas if you were talking to the participant.\\nWe'll discuss more about crafting\\nand executing both moderated and unmoderated sessions well\\nin a later chapter.\\n\\nSome methods are best suited for one or the other,\\nand some methods lend themselves\\nto being done well either way.\\nMost UX practitioners recommend doing moderated\\nin-person research when possible\\nso that you can read participants' body language\\nand find opportunities to dig more deeply\\ninto follow-up questions.\\nHowever, if budget or resources\\nonly allow unmoderated research,\\nthat is certainly preferable\\nthan skipping research altogether.\\n\"}],\"name\":\"2. Choosing the Right Research Method\",\"size\":38804022,\"urn\":\"urn:li:learningContentChapter:4400491\"},{\"duration\":547,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4407457\",\"duration\":186,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"In-house vs. external\",\"fileName\":\"4304078_en_US_03_01_MM30\",\"demo\":true,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video discusses the differences between performing user experience research when you are working in-house at a company or serving a company externally, whether as a freelancer or consultant from an agency so that you can correctly staff and plan research sessions that are appropriately scoped to your goals.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12495289,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- As a UX researcher, the environment you work\\nin can have a pretty big impact on how you perform research.\\nThere's always some nuance in roles and projects\\nbut generally working internally\\nat an organization can look pretty different\\nthan serving as an outside UX resource.\\nWhen you work internally, you're more likely to\\nhave the opportunity to develop a deep understanding\\nof the product and build relationships with users.\\nYou may get to track their actions and responses over time\\nso you may choose long-tail methodologies\\nlike diary studies,\\nlongitudinal surveys where you ask the same question\\nor examine the same behaviors over a period of time,\\nregular benchmarking studies to see how experiences compare\\nover time or focus on uncovering new needs\\nwithin your user base.\\n\\nBecause you usually dive deeper\\ninto a specific user base and industry\\nwhen you work internally, you also have to be aware\\nof the potential for bias or missed opportunity.\\nYou may find yourself knowing the space\\nand interfaces so well that you inadvertently\\nlead participants in certain directions\\nor miss nuances in different kinds of users.\\nAdditionally, when you're intimate\\nwith the politics of a project\\nand know what would be best for your stakeholders or team\\nyou may find yourself favoring that solution.\\n\\nWe'll discuss how to ensure\\nthat you craft unbiased research plans later\\nbut it's important to be aware of the phenomenon.\\nTo further combat this\\nyou can ask another researcher to review your plans\\nand make sure you run a pilot study to flesh out any issues.\\nNow, let's talk about external UX researchers.\\nIn this role, you might serve\\nas an extra set of hands to an existing team\\nor help establish a whole new research practice.\\nFor purposes of this course\\nlet's assume the hiring organization is looking to\\nhelp answer a particular question regardless\\nof their structure or UX maturity.\\n\\nWhen an organization brings you\\nin to execute specific research\\nthere's almost always going to be a learning curve to\\nunderstand the nuances of the space.\\nThis can be good and that you may not be as\\nlikely to be biased and may offer a fresh perspective\\nbut you need to account for the extra prep time.\\nYou may also be less likely to have access\\nto an existing customer base\\nso there could be logistical challenges when finding\\nand scheduling the right kind of participants.\\nThere are ways to get representative-enough users\\nor recruit from existing databases\\nwhich we'll discuss in more detail as well.\\n\\nBeing an external UX researcher also means\\nthat you need to pay attention and cater your working style\\nto the existing structure in the organization.\\nSome organizations really value quantitative data\\nand they will have a bias\\ntowards polished reports that offer lots of graphs.\\nMeanwhile, others will focus more on qualitative feedback\\nand want you to work directly\\nwith design and development teams to figure out next steps.\\nWhile you shouldn't let an organization's biases\\ndecide the best methodology to answer questions,\\nit's helpful to understand their business needs\\nand take those\\ninto consideration when figuring out their research\\nand presentation methods that will be most useful\\nto the teams.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4402657\",\"duration\":223,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Agile vs. waterfall\",\"fileName\":\"4304078_en_US_03_02_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video discusses the need to consider the organizational environment when deciding what UX research methodology to employ at what time. Whether the organization follows waterfall, agile, lean, or some other development process will impact how you\u2019re able to incorporate UX methods into the process. In this video, learn how to choose the appropriate research methodologies to best suit your specific development processes.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12733085,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Regardless of your role within an organization,\\ntheir structure and approach to development\\ncan also impact how research is run.\\nSome organizations use a project management\\ndevelopment model called Waterfall.\\nIt has distinct stages for requirements gathering, design\\ndevelopment, and testing, which do not overlap.\\nIn this model, rigorous research is done\\nin the requirements gathering and design phase,\\nwhich is sometimes called discovery,\\nand then again at the very end of development.\\nIn contrast, many organizations have been turning\\nto the Agile methodology.\\n\\nIt adopts rapid iterative cycles of launching,\\nmeasuring, and pivoting as needed.\\nThere are no distinct sections for each phase.\\nThere are lots and lots of variations of Agile processes,\\nbut they're all designed to uphold the core Agile values,\\nincluding customer satisfaction, responding to feedback\\nor changing environments,\\nand releasing working code regularly.\\nBoth approaches have pros and cons.\\nThe key difference is that you're typically\\nable to do more rigorous testing in Waterfall environments,\\nbut only at the beginning and end.\\n\\nSo there isn't as much opportunity to learn along the way,\\nor implement recommendations.\\nIn Agile environments,\\nyou should be able to incorporate research more\\nconsistently, but you often have a shorter timeline\\nso you may need to reduce scope,\\nor alter traditional methodologies.\\nMany companies are moving toward Agile-like practices,\\nso it's helpful to understand the limitations.\\nLet's say that you're working\\non a new e-commerce platform for an existing brand.\\nIn the Waterfall process,\\nyou'd be able to conduct exploratory research\\nduring the requirements gathering phase.\\n\\nYou may be able to utilize methods\\nlike extensive in-person interviews, focused\\non understanding goals, or ethnographic observations\\nof existing customers' shopping experiences.\\nYou could focus on gathering\\nand analyzing all this information before any\\nof the rest of the team starts designing\\nor building anything.\\nIn traditional Waterfall,\\nyou then typically hand your insights\\nto the design team, who then begins their work.\\nYou're then brought in again at the end of\\nthe development cycle to do a final validation.\\n\\nBecause research is typically only done\\nat the very beginning and end,\\nthere's not usually an opportunity to make any changes\\nuntil the next Waterfall cycle has started.\\nIn an Agile environment,\\nthe whole team gets started designing\\nand building right away.\\nYou don't usually have the luxury of time to deeply\\nexplore user's needs and goals before anyone starts.\\nIn the example of the e-commerce platform,\\nyou might conduct just a few interviews to start,\\nand do so over the phone instead of\\ntaking the time to observe and talk in person.\\n\\nHowever, you get to keep working alongside\\nthe rest of the team.\\nSo you might do five interviews to start,\\nrun a diary study next, and then test\\nan early prototype of a solution.\\nThis iterative approach means that you can get\\nconsistent feedback as questions arise, and you\\ncan constantly validate if you're\\nheaded down the right path.\\nIf you identify usability issues in an early prototype,\\nyou can address it right away and test again to ensure\\nthat the new solution works better,\\nrather than waiting until development is complete\\nto find the issue.\\n\\nIt should be noted\\nthat there are several variations of both Waterfall\\nand Agile, and each company will have their own take.\\nThere are some Waterfall companies that are starting to\\nembrace iterative testing, and some Agile places\\nthat are incorporating some upfront research.\\nThere is no one size fits all solution.\\nUnderstanding the team processes\\nand development cycles can help you best identify\\nwhen and what kinds of research will make sense.\\nFor a deeper dive, check out my LinkedIn learning course\\nUX Research for Agile teams.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4400488\",\"duration\":138,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Determining project or product stage\",\"fileName\":\"4304078_en_US_03_03_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video discusses the importance of considering the stage of the project when deciding which UX research methods to employ. Typically, projects are in one of three categories; strategizing something new, actively developing, or assessing live performance. In this video, learn how to decide and implement appropriate user experience methodologies based on the stage your project is currently in.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8208142,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Regardless of the development environment,\\none of the most important steps\\nto determining research methodology is to examine\\nwhat stage in the product development cycle you're in.\\nAt a very high level,\\nyou're typically in one of three product stages.\\nStrategizing something brand new,\\nactively designing and building,\\nor assessing the performance of something live.\\nWhether it's a completely new service\\nor a new feature of a legacy software,\\nwhen you're strategizing about something new,\\nyou should focus your research\\non uncovering users' needs and goals,\\nfinding any areas for improvement from existing solutions,\\nand validating that your ideas serve the users\\nin some unique and meaningful way.\\n\\nWe generally say that this kind of research\\nis about understanding if you're building the right thing.\\nTo determine users' goals and motivations,\\nyou'll want to focus\\non utilizing qualitative attitudinal methods,\\nsuch as interviews.\\nTo understand their frustrations\\nor any gaps in service with existing solutions,\\nutilize more behavioral methods,\\nlike a moderated usability test.\\nDuring the active design and development stage,\\nyou're going to be trying to answer\\nwhether you're building it right.\\n\\nYou'll use information you collect during this period\\nto inform design and development decisions,\\nto optimize performance,\\nand to help set priority.\\nYou'll typically perform mostly behavioral research methods,\\nlike card sorts, task-based usability tests,\\nand AB tests to inform these decisions.\\nBut it can also be helpful to add some attitudinal methods,\\nlike desirability studies.\\nFinally, you want to focus on assessing your product\\nor service that is live.\\nYou'll want to focus on summarizing trends\\nand uncovering opportunities.\\n\\nYou're likely to utilize\\nquantitative behavioral research techniques,\\nlike AB tests or usage analytics,\\nto understand trends\\nand qualitative methods,\\nsuch as interviews or usability testing,\\nto uncover issues or gaps and find opportunities.\\nAgain, there is no exact formula\\nwhen selecting the best UX research method\\nat any given time.\\nUnderstanding a product's development stage\\ncan help you narrow down your goals\\nand the time constraints you're working under,\\nwhich can help guide your decision.\\n\\n\"}],\"name\":\"3. Environmental Considerations\",\"size\":33436516,\"urn\":\"urn:li:learningContentChapter:4403563\"},{\"duration\":1440,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4400489\",\"duration\":196,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Determining the right participants\",\"fileName\":\"4304078_en_US_04_01_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video discusses the importance of determining the right participants to include in your user experience research so that you can ensure that your participants represent your real or target users.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12615445,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- The foundation of effective research\\nrelies on the quality of its participants.\\nMake sure that you have the right number\\nand an accurate sample of your real or target users.\\nIf you're in the beginning stages\\nof defining your target user\\nand you don't have validated personas,\\nyou can create what are called proto-personas.\\nProto-personas are essentially descriptions of assumptions\\nthat you can use as hypotheses in your research.\\nThey're meant to align the team\\naround existing knowledge or guesses.\\n\\nYou can use the assumptions\\nto help guide your recruitment efforts,\\nbut keep in mind that you'll need to refine\\nas you learn more about your users.\\nIf you already have flushed out personas,\\nyou'll need to find representatives\\nof each of the different groups for your research.\\nFor instance, let's imagine you're working\\non an expense tracking application for businesses.\\nWhen you do research on a piece of the app\\nthat will be used by one persona group,\\nsuch as the review and approval system for managers,\\nyou'll want to include only people\\nwho would actually do that function.\\n\\nIf you're investigating functionality\\nthat might be used by multiple types of users,\\nlike anyone who needs to upload receipts,\\nyou'll want to make sure that you get users\\nfrom each group involved.\\nYou'll take the differentiating variables\\nfrom each user type to create screening questions,\\nwhich we'll talk about in the next section.\\nThe number of participants will vary greatly\\nwith the methodology.\\nQualitative methods like interviews and usability tests\\ncan be effective with just a few participants.\\nThere's a famous study that demonstrates\\nthat you'll identify about 80% of usability issues\\nafter talking with just five similar people.\\n\\nThat original study suggested\\nthat conducting multiple rounds of small iterative tests\\nwere more effective in capturing issues\\nthan conducting one much larger study.\\nBut most people just remember\\nthat five is the magic number of participants.\\nThis only applies when you're talking\\nabout the same kind of users.\\nIf you have multiple distinct user groups,\\nthe recommendation is to start with five\\nof each sort of user.\\nRemember that when you're looking to uncover issues\\nand insights, a small response is okay.\\n\\nIf even a few people share issues, goals, or motivations\\nthey may be worth addressing.\\nThat said, you should keep in mind\\nthat you could definitely miss some things\\nwith a small number of participants.\\nWhen measuring numerical data,\\nit's easy to get false results with really small numbers.\\nFor instance, you can't extrapolate that 60%\\nof a whole audience type will experience the same issue,\\nif you see that three of five\\nusability test participants do.\\nMany user experience methods\\ndon't require statistical significance,\\nthough it can be helpful\\nto calculate how many participants\\nwould be required to achieve it\\nor calculate how confident you can be\\nwith the number of participants that you have.\\n\\nIn many cases, you won't have time or budget\\nto reach as many people as recommended,\\nbut it can be helpful to set targets in budget.\\nThere are several online calculators that can help you.\\nI particularly like those at MeasuringU.com.\\nJust remember that having high quality participants\\nis more important UX research than quantity.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4400490\",\"duration\":186,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Finding and screening participants\",\"fileName\":\"4304078_en_US_04_02_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video discusses the best practices for finding and screening participants for user experience research sessions. Learn how to find participants and screen them to ensure that they represent your user base.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11499569,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Now that we know how many participants we need,\\nhow do we find the right people?\\nResearch participants are meant to represent your user.\\nWhile you might want your design to be easy enough\\nto be used by any person, the whole point\\nof user experience is to craft what you build\\nfor specific people who have particular sets\\nof knowledge, experiences, and outlooks.\\nIf you don't include those particular folks\\nin your research, you might still get some generic feedback\\nbut miss the nuances that will make your products stand out\\nfor your user base.\\n\\nThink back to the personas and the key attributes\\nthat distinguish each one.\\nWith the expense tracking app example,\\nyou might have some users\\nwho are frequent business travelers\\nwho always want to upload their numerous receipts on the go,\\nbut there may also be office workers\\nwho only purchase software for the company\\nand find it easiest to set aside one time each month\\nto process everything.\\nIn order to ensure\\nthat the right types of users are represented,\\nyou'll have to create a screener that attempts\\nto capture participants' roles and behaviors\\nwithout making the desired trait too obvious.\\n\\nA screener is basically just a very specialized survey,\\ndesigned to identify and include who you want to speak to.\\nYou want to keep it short\\nand focus it only on identifying key information.\\nCheck out the exercise files for an example\\nof a screener template.\\nFor more information on the best way\\nto screen and qualify participants,\\nyou can also check out a recording\\nof my past conference presentation.\\nOnce you have your screener set up,\\nyou'll need to start looking\\nfor people to get in contact with.\\n\\nIf you have access to an existing user base,\\nfind ways to reach out to them, like adding an invite link\\non your site or sending an email asking for volunteers.\\nIf you're working in-house or on an existing product,\\nit can be helpful to set up a system to constantly recruit\\nwith an ongoing screener that adds participants\\nto a database.\\nThat way, anytime you need to do research,\\nyou can search your database for a particular set\\nof characteristics and reach out to those who match.\\nIf you're working on a product\\nthat doesn't yet have users or you don't have access,\\nyou'll have to be a little bit more creative\\nabout finding the right participants.\\n\\nIf you have budget,\\nthere are participant recruiting firms you can hire\\nor you can do things like post ads\\nto relevant LinkedIn groups or Slack channels.\\nRegardless of whether your participants are existing\\nor potential users,\\nit's standard to offer monetary compensation for their time.\\nWhile you don't want participants\\nto be motivated solely by money,\\nincentives demonstrate your appreciation.\\nIncentives range widely based\\non the complexity of the tasks, length of time involved,\\nand the specificity of a persona type.\\n\\nFor instance, you might offer $10\\nfor any 40 plus aged participant to take a quick survey,\\nbut offer $250 when you need to spend an hour interviewing\\nand observing medical professionals.\\nFinding the right participants\\nand offering compelling incentives is a crucial step\\nto getting the most out of your research effort.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3891135\",\"duration\":0,\"visible\":false,\"requiredForCertificateOfCompletion\":null,\"name\":\"FAKE VIDEO DELETE - Participant\",\"fileName\":\"4304078_en_US_04_03_FAKE_AR\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"updateType\":\"ADDED\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":10,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":null,\"captionsStatus\":\"NOT_AVAILABLE\",\"cdnStatus\":\"NOT_ATTEMPTED\",\"size\":0,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"NEW\",\"transcript\":null},{\"urn\":\"urn:li:learningContentArticle:135008\",\"duration\":180,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Participant Screener Template\"},{\"urn\":\"urn:li:learningContentVideo:4403562\",\"duration\":140,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Scheduling participants\",\"fileName\":\"4304078_en_US_04_03_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"In this video, learn how to schedule participants for user experience research sessions. Discover tips to help maximize your chance of success.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9940578,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Scheduling participants seem straightforward,\\nbut I recommend carefully considering your schedule.\\nThis step is often overlooked,\\nbut very crucial in performing successful UX research.\\nThe first thing you need to consider is creating\\na schedule that will work well for your participants.\\nFor instance, if you need mothers of children\\nfrom ages 6 to 10,\\nit's unlikely that they'll be able to meet with you\\nthe first thing in the morning when they're trying\\nto get their kids ready for school.\\nOr, if you need to talk to legal professionals,\\nit's likely that they'll be busy\\nduring the normal work hours, and more free after 5:00 PM.\\n\\nSecondly, you'll want to try to schedule sessions\\nthat make it possible for you to invite team members\\nand stakeholders to observe.\\nWhile it's not always possible,\\nit's very helpful to allow others\\nto hear feedback firsthand,\\nand to be able to discuss additional questions\\nthat come up as you go.\\nYou also need to think about how you'll be able\\nto keep up with participants,\\nand interact with stakeholders.\\nFirst of all, I recommend scheduling ample time,\\nat least half an hour in between your sessions,\\nso you can rest, take time\\nto recap sessions, and redirect any efforts.\\n\\nThis gives you a buffer\\nin case a participant is early or late.\\nIt will also provide time to reset\\nor adjust technical elements, and take breaks,\\nso that you can stay focused throughout the day.\\nEven those of us who have many years of experience are often\\nexhausted by full days with back-to-back sessions.\\nTo that end, I also try to cap the number of sessions\\nI moderate a day to four.\\nIt's helpful to make sure you schedule debrief\\nsessions immediately following the conclusion,\\nso that you can share ideas,\\nwhile they're still fresh and to still key findings.\\n\\nIt's also important that the team takes time to discuss\\nfindings and their impact on possible solutions,\\nso that you make the best of what you find.\\nThe last thing to consider when scheduling\\nis that it's very rare\\nthat every participant scheduled will show up as planned.\\nPeople always run late,\\nor have things come up, or just not show up.\\nA good recommendation is to invite one extra participant\\nfor every five or so that you want to speak with.\\nTo offset the chances of no-shows,\\nI highly recommend reminder emails and phone calls\\na few days before and the day of the session.\\n\\nThe reminders help me feel prepared for the sessions too.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3891140\",\"duration\":0,\"visible\":false,\"requiredForCertificateOfCompletion\":null,\"name\":\"FAKE VIDEO DELETE Research Test\",\"fileName\":\"4304078_en_US_04_04_FAKE_AR\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"updateType\":\"ADDED\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":10,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":null,\"captionsStatus\":\"NOT_AVAILABLE\",\"cdnStatus\":\"NOT_ATTEMPTED\",\"size\":0,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"NEW\",\"transcript\":null},{\"urn\":\"urn:li:learningContentArticle:137013\",\"duration\":350,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Research Test Plan Template\"},{\"urn\":\"urn:li:learningContentVideo:4405547\",\"duration\":246,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Crafting the right questions\",\"fileName\":\"4304078_en_US_04_04_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video discusses the importance of asking the right questions for user experience research and crafting them in an unbiased and precise way so that you can collect and record the most accurate feedback possible to inform your project.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":15995235,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- When creating your research plan,\\nit's crucial to craft appropriate questions.\\nFirst, you want to be sure that your questions\\nare neutral and non-leading.\\nFor instance, if you're trying to understand\\nwhether participants are interested in a new feature,\\ndon't ask how much they like it.\\nSubconsciously, that question suggests\\nthat participants should like it,\\nand people may answer more positively than they really feel.\\nInstead, ask how they feel about it\\nwithout mentioning emotionally linked words.\\n\\nAnother way to get around biased questions is to frame\\nthe questions with both negative and positive responses.\\nDon't ask, \\\"How helpful is this feature?\\\"\\nInstead say, \\\"Is this feature helpful or unhelpful and why?\\\"\\nIt's a subtle shift, but making sure your questions\\ndon't lead participants one way or another\\nis very important.\\nYou also have to be careful that you craft questions\\nthat have the appropriate level of precision\\nfor people to be able to answer.\\n\\nIf you're simply interested in a status,\\nsuch as level of education or employment status,\\nthen go ahead and ask what is called a closed question.\\nThat is when you supply a set of answers\\nfor participants to select.\\nClosed questions are also useful\\nwhen you're trying to gather quantitative data,\\nsuch as how someone rates the ease of use\\nof a piece of software.\\nOtherwise, you'll want to ask more open-ended questions\\nwhich have no predefined answers.\\nThey're, by nature, more exploratory and allow users\\nto give details and context that even the most experienced\\nresearcher would probably not think to ask about.\\n\\nIt can be harder to analyze the data\\nfrom open-ended questions,\\nbut you get much richer qualitative data.\\nWhen it comes to researching behaviors,\\nunless you're directly observing participants,\\nask people about things that have happened recently\\nor that they do regularly so that they're able\\nto answer accurately.\\nFor instance, if you ask someone\\nwhat they ate for breakfast this morning\\nor what time they usually get to work,\\nthey should be able to answer that accurately.\\nHowever, if you ask someone what they ate for lunch\\nthree Tuesdays ago, they likely won't remember\\nbut will feel compelled to come up with something.\\n\\nSimilarly, people aren't good\\nat predicting their future behavior.\\nWhen asked, we humans usually say something\\nthat sounds reasonable and makes us feel good.\\nBack to that grocery shopping example from chapter two.\\nI will probably say that I'm only going to buy\\nhealthy food and necessities,\\nbut that is definitely not always what makes it home.\\nTo that end, remember to be sensitive\\nto potentially embarrassing or very personal topics,\\nsuch as finances or healthcare.\\n\\nJust like you don't want to be biased, you don't want\\nthe questions to seem as though they're passing judgment.\\nGive participants easy ways to opt out of questions.\\nOnly ask the questions that are really helpful to you,\\nand be careful with wording.\\nIt can also be helpful to let participants know why\\na certain piece of information\\nyou're asking for is necessary.\\nFor instance, if you're doing research on a fitness tracker\\nand are considering adding a feature to track food\\non the app, give participants a bit of context\\nso it doesn't seem like you're just being intrusive.\\n\\nFinally, try to find an appropriate balance\\nof getting detailed information and not\\noverwhelming participants or letting yourself get burnt out.\\nThere's no one magical time for each participant.\\nBut in general, unmoderated research sessions\\nshould be short, maybe five minutes for a survey\\nor 20 minutes for a usability test.\\nIf too long, participants are likely to become disengaged\\nand opt out partway through.\\nYou'll have better luck keeping participants engaged\\nfor longer when moderating sessions directly.\\n\\nBut in most cases, you'll still want to cap each session\\nto about an hour.\\nPlanning the questions that you need to ask to get the most\\nout of your research is one of the most vital steps\\nof any kind of user experience research.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4402658\",\"duration\":142,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Practicing\",\"fileName\":\"4304078_en_US_04_05_LA30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video discusses the importance of properly preparing and practicing while conducting user experience research. In this video, learn how to focus on logistics and pilot testing your study design in order to get the best possible results from your research sessions.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":29968453,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- I can't count the number of times I've had to go\\nto plan B, C, or D\\ndue to logistical issues.\\nTaking a small amount of preparation time\\ncan really ensure you get the most\\nout of your valuable research sessions.\\nWhile you can't always avoid issues,\\nit's important to make sure your wording\\nand the research logistics are completely smoothed out.\\nIf either of these points are lacking,\\nyou could get negative responses\\nthat don't actually represent the experiences\\nof participants.\\nAfter drafting your study,\\nI suggest reading the questions and instructions out loud.\\n\\nThat will help you check the clarity\\nand the tone of your interaction with participants.\\nYou absolutely should not skip this step\\nfor any unmoderated research\\nwhere you won't be present to guide users\\nor probe for understanding.\\nOne great way to catch any inconsistencies\\nor biased questions\\nand test the logistics is to run a pilot.\\nIn a pilot,\\nfor the real thing.\\nYou just do so with the expectation of testing the study\\nrather than collecting results.\\n\\nFor instance, if you're planning a remote usability study,\\nyou might need to test your prototype in many browsers\\nand on different devices,\\nensuring the sharing works smoothly,\\nand checking all of the recording equipment.\\nI like to ask a colleague who's familiar with the topic\\nbut not the particular project\\nto be my participant.\\nSome people prefer to recruit an extra participant,\\nbut I like being able to explicitly ask for feedback\\non the study design.\\nHave your participant respond\\nas though they are really participating\\nto ensure the questions flow well\\nand take about as long as you expected.\\n\\nI recommend running the pilot at least a day or two\\nin advance of the scheduled sessions\\nso that you have time to make adjustments.\\nI also recommend making a checklist of study day logistics\\nto ensure everything runs smoothly\\nand have backup batteries, cords,\\nand solutions for potential issues at the ready.\\nIf you can,\\ngive yourself some wiggle room\\nbefore the first sessions to retest things.\\nThink about a time that you had to scramble with logistics.\\nWe have all had\\nour screen share settings changed last minute\\nor our audio cut before a meeting.\\n\\nThings happen,\\nbut anything that you can do\\nto make yourself feel comfortable\\nand the logistics of a session run smoothly\\nwill help you get the highest quality results.\\n\"}],\"name\":\"4. Planning Effective Research\",\"size\":80019280,\"urn\":\"urn:li:learningContentChapter:4403564\"},{\"duration\":362,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4405548\",\"duration\":232,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Applying moderated research\",\"fileName\":\"4304078_en_US_05_01_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video discusses the right way to lead user experience research sessions during moderated research sessions in order to make sure that you get the most out of them. Explore tips on how to make sure you aren't leading participant responses.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":13820587,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- When moderating research sessions,\\nthe way you guide the conversation is just as important\\nas the quality of the questions that you write.\\nYou want your participants to feel comfortable\\nand engaged enough with you to share information,\\nso you have to set a friendly, approachable tone.\\nAt the beginning of every moderated session,\\nremind participants that there are no wrong answers,\\nthat you value their opinion,\\nand that your job is to uncover insights, good and bad.\\nRemember that you should be looked at as a neutral party.\\nIf you weren't involved in the creation\\nof whatever you're investigating, let participants know.\\n\\nRemind participants that you'd like them\\nto think aloud as they go.\\nThis is unnatural for most people,\\nso try giving them an example,\\nlike walking them through how you log into your email.\\nEncourage them to articulate their thoughts\\nthroughout the course of the session.\\nIf a participant gets stuck or asks for your guidance,\\nremain neutral and ask how they think\\nthey'd figure it out if you weren't there.\\nIf you're unsure that you understood what they said,\\nyou can use a simple technique called the boomerang,\\nwhere you reply with a neutral question.\\n\\nFor instance, if a participant asks,\\n\\\"Would I have to sign up for an account to buy this?\\\"\\nYou can reply by saying something like, \\\"What do you think?\\\"\\nOr, \\\"What would you try if you were at home?\\\"\\nIf a participant doesn't ask a specific question,\\nbut seems lost, you can use something called echoing,\\nwhere you repeat back what they said in question form.\\nFor example, if someone says,\\n\\\"Well, I'm looking for a register button,\\\"\\n\\\"but um, I'm not sure.\\\"\\n\\\"Well, I don't see...\\\"\\nYou could respond with something like, \\\"You don't see?\\\"\\nBy using the participant's own language,\\nyou're not leading them in any particular way.\\n\\nReplying with a question also makes it clear\\nthat the participant should further explain and articulate.\\nYou'll want to be sure your follow-up questions\\nare open-ended to probe into context.\\nI like to utilize a variation of the five whys technique.\\nThe basic technique is very straightforward.\\nEssentially, you ask why in response\\nto open-ended questions, usually up to five times.\\nI like to vary the wording to be more approachable\\nand build on past responses.\\nHere's a simplified example.\\n\\nYou might ask something like, \\\"How come you picked\\\"\\n\\\"this dish detergent?\\\"\\n\\\"It's the one I always get.\\\"\\n\\\"Tell me how it became the one you always get.\\\"\\n\\\"Well, that's the cheapest one.\\\"\\n\\\"Is being the cheapest your highest priority?\\\"\\n\\\"Yeah, I'm on a strict budget,\\\"\\n\\\"and I also don't really find a difference\\\"\\n\\\"between the expensive one and this.\\\"\\n\\\"Tell me more about how you figured that out.\\\"\\n\\\"Well, my mom always had the premium brand,\\\"\\n\\\"but when I started buying things on my own,\\\"\\n\\\"I tried this one and it seems to work just as well.\\\"\\nAsking all these follow ups gives you a much deeper\\nunderstanding of the context of their decision.\\n\\nThat said, you should try to talk\\nas little as possible as the moderator.\\nYou never want to cut off your participants,\\nand humans are naturally inclined to fill silence.\\nSome of the best qualitative insights\\ncome from allowing participants\\nto lead conversations in new directions.\\nListening closely to what participants are saying\\nallows you to come up with follow-up questions\\nthat dig deeper or wider than your original scope.\\nIn moderated sessions, don't worry\\nabout sticking exactly to the plan.\\nPart of the value of moderating\\nis the ability to uncover information\\nyou wouldn't have otherwise known to ask about.\\n\\nBecause moderating requires such focused\\nlistening and probing, it's extremely helpful\\nto have somebody else take notes,\\nor plan to record and review later.\\nI always record when I can anyway,\\nso that way I can reread the transcripts\\nand more easily grab quotes\\nor embed video clips into reports.\\nModerating research sessions well takes practice.\\nThese tips should set you up for success.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4405549\",\"duration\":130,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Applying unmoderated research\",\"fileName\":\"4304078_en_US_05_02_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video discusses the right way to lead user experience research sessions during unmoderated research sessions in order to make sure that you get the most out of them. Explore tips on how to make sure you aren't leading participant responses.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9179576,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- While you won't be present during unmoderated sessions,\\nit's your job as a researcher to set the right tone\\nand write clear introductions and instructions\\nso your unmoderated sessions run as smoothly as possible.\\nThe introduction of an unmoderated study is crucial\\nto set expectations\\nand help participants feel as comfortable\\nand primed to share as possible.\\nJust like in moderated studies,\\nremind participants that their feedback is valuable.\\nYou want to hear both positive and negative feedback\\nand that there is no such thing as a wrong opinion.\\n\\nBe especially careful to clearly set expectations\\nand explain instructions as simply\\nand completely as possible.\\nPlan to incorporate instruction reminders\\nthroughout the study and give participants a way\\nto reach out if they run into any issues.\\nThis can also remind participants\\nthat there are real people behind the questions.\\nPay attention to the tone and voice of all your wording\\nand aim for as simple and friendly as possible.\\nDefinitely make sure you get feedback\\non instructions and don't skimp on pilot testing.\\n\\nYou should also pay attention\\nto the flow of tasks and questions\\nand prioritize ordering them in a way\\nthat will feel natural to participants.\\nFor instance, you wouldn't ask someone\\nto assess the checkout process of an eCommerce site\\nbefore asking them to try searching for products.\\nParticipants may give you faulty negative feedback\\nif the flow of questions doesn't make sense.\\nIt also helps to break larger goals\\ninto many small discrete tasks,\\nespecially for unmoderated usability tests.\\nFor instance, rather than having one task\\nto search for a shirt, break that into many smaller tasks.\\n\\nOne task to find a shirt in their size,\\nanother to find their preferred color,\\nand finally, one to find a particular style.\\nBreaking up tasks ensures that participants\\nwill more fully consider each component\\nand you'll get more comprehensive feedback\\nthat participants may not think to share\\nif they're assessing the whole task at once.\\nGetting the most out of unmoderated research\\nrequires some different techniques from moderating sessions\\nso be sure to plan each research effort\\nwith these tips in mind.\\n\"}],\"name\":\"5. Executing Effective Research\",\"size\":23000163,\"urn\":\"urn:li:learningContentChapter:4405551\"},{\"duration\":1127,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4405550\",\"duration\":244,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Gathering and mining data\",\"fileName\":\"4304078_en_US_06_01_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video explores analyzing the data that comes out of user experience research and a general methodology that will enable you to break down your research data, gather, and mine for key takeaways.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":15680783,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Congratulations!\\nYou finished conducting your research.\\nWhew, sometimes that feels like the biggest hurdle.\\nBut now you need to figure out what to do\\nwith all the information you've collected.\\nYou need to tie all of the individual pieces\\nof data together to create meaningful, actionable insights.\\nIt's the onus of the user experience researcher\\nto not just report back facts\\nbut also synthesize data into information the team can use.\\nThe way that you analyze and synthesize data\\ndepends on the methodology, the type of data you collected,\\nand your overall context.\\n\\nWhen it comes to analysis,\\nthe core difference in analysis approach\\nis often whether you have quantitative or qualitative data.\\nRegardless of the type,\\nthe first thing you need to do\\nafter finishing a study is to gather\\nand organize all the data.\\nYou need to make sure you look at the full scope of data\\nbefore you make any conclusions.\\nIf you've done something with a quantitative data component,\\nlike a survey or A/B test,\\nyou'll probably be able to export a file of raw data.\\nIf you collected quantitative data\\nin something like usability test,\\nyou'll need to consolidate all the data into one place.\\n\\nI usually use a spreadsheet.\\nIf you only have quantitative data,\\nyou can generally jump into calculating from here.\\nIf you did research that involves qualitative data,\\nlike interviews or usability tests,\\nit's likely that you'll have a combination\\nof handwritten and typed notes\\nfrom a variety of people,\\ndigital, audio, and video files,\\nand possibly even papers filled out by participants.\\nWhen analyzing qualitative research,\\nI recommend making a big spreadsheet\\nwith a row for each participant,\\ntheir general demographic information,\\nand the notes from each participant session,\\nand links to any other files\\nor information pertaining to the research.\\n\\nHaving one big overview helps you take a look\\nat the big picture.\\nAfter you gather all the information,\\nmake time to immerse yourself in the data.\\nReview the different kinds of information you have gathered\\nand get familiar with both the big picture\\nand the individual details.\\nI recommend listening, watching,\\nand reading anything that you have\\nto ensure you're processing from all angles.\\nAt this point,\\nyou don't want to be passing judgment or looking for trends.\\nYou simply want to make sure that you're deeply familiar\\nwith all the different information available.\\n\\nThe next step in qualitative analysis\\nis to start breaking down the huge amount of information,\\nlooking for individual insights\\nand labeling them with a relevant code or tag.\\nI like to start with the original research goals,\\nbut make sure to leave room for the possibilities\\nof new important information too.\\nYou're still not yet assigning meaning\\nor coming up with solutions\\nbut identifying the valuable pieces of information you found\\nand framing them.\\nThis often means things like where people get stuck,\\ncommon routines or uses,\\ntransitions between tasks or thought processes,\\nworkarounds or shortcuts used,\\ndescriptive language,\\nor things that are deemed pleasing or frustrating.\\n\\nThere's no hard and fast rule\\nabout what makes something valuable,\\nso you'll have to defer to the context\\nof what you're working on to decide what's relevant.\\nLet's say you ran a usability test of a new mobile app.\\nYou might notice that none of the participants were able\\nto find the main menu the first time.\\nThat would definitely be a valuable individual finding,\\nand you might label it as something like navigation.\\nIf you were able to have team members observe sessions,\\nI recommend having this process occur\\nwith as much of the project team as possible.\\n\\nRemind everyone of the key goals.\\nThen have everyone mind their own notes\\nand identify individual findings and labels.\\nIncluding everyone helps to make sure\\nthat all parties are invested in the research process\\nand understand the full breadth of work.\\nIt also ensures that you don't miss any points of view.\\nAt this point,\\nyou're ready to start making connections\\nand translating what you found into meaningful takeaways.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4407458\",\"duration\":235,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Synthesizing data\",\"fileName\":\"4304078_en_US_06_02_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to organize data, spot trends, and put it into context.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":14567011,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Once you've gathered your data\\nand identified individual potential insights,\\nthe next step is to begin assessing what you have\\nand translating into meaningful insights.\\nIf you've collected quantitative data,\\nremember that synthesis is going to consist\\nof numeric computations.\\nYou might be looking for things like\\naverages or percentages.\\nMost of the time you don't need rigorous\\nstatistical analysis in UX research contexts.\\nAlso, most quantitative tools have some built-in analysis\\nand charting functions.\\n\\nFor instance, a lot of survey tools\\nwill be able to tell you the average\\nof a rating question or give you a breakdown\\nof how many participants answered a certain way.\\nWhile this information is valuable,\\nyou won't get the full picture if you stop there.\\nLet's say that you ask participants to rate their experience\\nwith an e-commerce site on a scale of one to seven.\\nMaybe the average is right in the middle at a 3.5,\\nbut every participant rated the site exceptionally well\\nor exceptionally poorly to get to that average.\\n\\nThat additional context tells a very different story\\nthan just reporting that everyone had an okay experience.\\nMake sure that you not only make calculations\\nbut look at the full picture.\\nTo organize qualitative data,\\nLETs a variation of card sorting to help organize findings.\\nBasically, you start looking at each point\\ngrouping related points together,\\nand then labeling the groupings\\nto create themes or categories.\\nI usually use the core goals as initial categories,\\nand then leave room to create new ones\\nthat don't map back to original objectives.\\n\\nInclude other team members as you can\\nand leave time to do a couple of rounds of sorting\\nand reframing to make sure that you aren't\\njust surfacing preconceptions or surface level insights.\\nThere are several digital tools for card sorting,\\nbut I find the physical process of sorting sticky notes\\nhelps me visualize the data\\nand spot trends more quickly.\\nAs you go, you'll start to spot connections,\\ntrends, and potential anomalies.\\nFor instance, maybe you'll see that all of the participants\\nof a usability to test had some trouble with navigation,\\nbut realize that the kind of issue they had\\ndepends on their job responsibilities.\\n\\nThen you can not only identify\\nthat you need to improve navigation,\\nbut draw conclusion that users work\\nexperience impacts expectations\\nand cater to that as you work on revisions.\\nYou can also use the sorting time to discuss\\nwhy each finding is important,\\nwhat it means in the context of the product or project,\\nand potential solutions or recommendations.\\nThis process can also help you think through the context\\nand crystallize findings into meaningful insights.\\nIf you're having trouble understanding\\nor articulating the context of your findings,\\nI recommend mapping the main takeaways\\nacross two dimensions that are important\\nto your project and examining the relationship\\nof where findings fall in the matrix.\\n\\nFor instance, if you are analyzing the data\\nfrom a usability test of an e-commerce site,\\nyou might map findings on a grid,\\nlabel the x-axis as impact the users,\\nand the y-axis as impact to business.\\nAnything that severely impacts\\nboth the user and the business,\\nlike the user not being able to find a product they need,\\nor not being able to check out,\\nwould be mapped in the top right corner.\\nAnything that is not that important\\nto either party would be mapped\\nin the bottom left corner, and so on.\\n\\nGoing through the process of determining\\nwhere each finding falls will help frame the context,\\nand once you've mapped everything,\\nyou'll get an image of the highest priorities.\\nSo remember, it's not just enough to report back hard facts.\\nYou need to give your team a deep understanding\\nof what you found and what it means\\nin the full picture of the product or project.\\nFor more detail, check out UX Deep Dive Analyzing Data.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4404627\",\"duration\":228,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Presenting and incorporating results\",\"fileName\":\"4304078_en_US_06_03_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"Learn how to document findings and format reports, incorporate results into team discussions, and keep track of past efforts.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":16073315,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- By now, you've done your research and analyzed your data.\\nYour next biggest task is to share your insights\\nand ensure that the recommendations\\nare actually implemented.\\nAfter all, research doesn't matter\\nif you don't use the information.\\nTo share learnings,\\nfind a format that will work for your particular team.\\nEvery team is different, but I've generally found\\nthat when the whole team can be involved\\nin the research process,\\nit's easier to build knowledge together.\\nThe outputs are usually more informal,\\nlike creating plain written docs\\nor even working directly to make design changes\\nwithout formal documentation.\\n\\nMany times, you're going to need to write up a formal report\\noutlining your findings and suggestions.\\nI strongly recommend creating an executive summary\\nof key information and findings\\nbecause most people will not have time\\nto read lengthy reports.\\nIn the body of the report,\\ninclude a mixture of visuals and texts\\nto appeal to the different ways\\nthat people best learn and interpret data.\\nFor instance,\\nor annotated screenshots of usability test findings.\\n\\nYou can also create a simple spreadsheet\\nof findings and recommendations\\nto give readers a quick way\\nto visualize highlighted takeaways.\\nAnother important practice\\nis to include relevant emotional quotes\\nor screenshots of participants' faces in your report.\\nIncorporating the emotional responses\\nof the people behind the findings\\nhelp team members connect the research to a broader context.\\nThe more you can get each member of your team\\nto understand and empathize with end users,\\nthe easier it will be\\nto get them to incorporate your recommendations.\\n\\nIn a report,\\nyou can also reference or link\\nto the research plans, related sites,\\nor summaries of previous research.\\nWe've attached a standard research report format\\nthat you can customize\\nto capture the outcome of your research.\\nWhile a report is useful as a summary deliverable\\nand to document findings,\\nI also implore you not to let a report be your only method\\nof sharing your findings.\\nOne of the most effective ways\\nto share your research findings\\nis to schedule a whole project team discussion\\nof key takeaways and their implications.\\n\\nDiscuss what you observed, why it matters to the team,\\nand what the team should do.\\nAs an example, if you found a key usability issue\\nof a checkout flow on an e-commerce page,\\nit's tempting to say something generic like,\\n\\\"It's difficult for users\\nto enter their credit card information correctly.\\\"\\nGiving additional context can be much more powerful.\\nTry something like,\\n\\\"It's difficult for customers\\nto enter their credit card because we ask for the date\\nin a format that does not match what they see on the card.\\n\\nMany participants get frustrated at this point\\nand drop out,\\nwhich results in abandoned sales\\nand a large potential loss of profit for the company.\\nWe should update the form so that the date selector\\nmatches what customers see on their cards\\nto maximize conversions.\\\"\\nRegardless of your final output or documentation format,\\nyou'll want to record key findings in a shared team wiki,\\nresearch database, shared document,\\nor even on a whiteboard.\\nKeep some sort of documentation of the main study details,\\nsuch as what interface was tested or who was interviewed,\\nso that you can look back at later times.\\n\\nWhile it may not be necessary for sharing current findings,\\nthere are often times\\nthat you want to revisit previous research\\nand it's much easier\\nto record a small amount of data as you go,\\nrather than try to remember or recreate after the fact.\\nHowever you decide to document results,\\nkeep in mind that the most important thing you need to do\\nis connect your data to the broader context of the business\\nand help other people understand why it matters\\nand what they should do about it.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3890127\",\"duration\":0,\"visible\":false,\"requiredForCertificateOfCompletion\":null,\"name\":\"FAKE VIDEO DELETE - Research Repot\",\"fileName\":\"4304078_en_US_06_04_FAKE_AR\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"updateType\":\"ADDED\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":10,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":null,\"captionsStatus\":\"NOT_AVAILABLE\",\"cdnStatus\":\"NOT_ATTEMPTED\",\"size\":0,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"NEW\",\"transcript\":null},{\"urn\":\"urn:li:learningContentArticle:140012\",\"duration\":420,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Research Report Template\"}],\"name\":\"6. Analyzing and Presenting Your Findings\",\"size\":46321109,\"urn\":\"urn:li:learningContentChapter:4403565\"},{\"duration\":64,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4401543\",\"duration\":64,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Next steps\",\"fileName\":\"4304078_en_US_07_01_MM30\",\"demo\":false,\"videoCreationMetadata\":{\"hasSlides\":false,\"assignedBy\":\"urn:li:member:-1\",\"assignedTo\":\"urn:li:member:-1\",\"solutionVideo\":false,\"challengeVideo\":false,\"includesPickups\":false,\"graphicsIncluded\":false,\"rawDurationSeconds\":0,\"handoutGraphicsIncluded\":false,\"includesAlternateFootage\":false},\"description\":\"This video concludes the user experience research fundamentals course by Amanda Stockwell, which covers commonly used user research methodologies, benefits of incorporating UX research, categories of research, considerations for determining what methods to use when, and an introduction to completing the first set of research.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5138615,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- One of my favorite things about UX Research is that people\\nfrom all different backgrounds can be successful\\nand there is no one direct path.\\nLearning about the different methodologies\\nand how to plan research efforts to gather accurate,\\nunbiased data is the first and biggest step.\\nThis course has given you the initial tools to\\nconduct research on your own.\\nYou now understand the main benefits\\nof performing user experience research,\\nthe different types of research methods, and the basics\\nof how to plan, run, analyze, and report them.\\n\\nNow that you know the fundamentals\\nit will take some practice to apply these things\\nin your own context.\\nI recommend looking\\nfor a chance to incorporate some research\\ninto your existing projects right away.\\nIf you're feeling unsure\\na good first method is a usability test.\\nFor more on how to run one\\ncheck out the foundations of UX Usability Testing course\\nor my deep dive on usability testing.\\nThank you for letting me be a part of your UX journey.\\nNow, I encourage you to dig in and get started.\\n\\n\"}],\"name\":\"Conclusion\",\"size\":5138615,\"urn\":\"urn:li:learningContentChapter:4405552\"}],\"size\":297171555,\"duration\":5851,\"zeroBased\":false},{\"course_title\":\"UX Research Methods: Interviewing\",\"course_admin_id\":546777,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":546777,\"Project ID\":null,\"Course Name\":\"UX Research Methods: Interviewing\",\"Course Name EN\":\"UX Research Methods: Interviewing\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"By taking the time to understand the needs and motivations of your users, you can develop better products that actually resonate with your target audience. In this course, learn the fundamentals of a core UX research method\u00e2\u20ac\u201dinterviewing\u00e2\u20ac\u201dthat can help you better understand the needs of your users.&lt;br&gt;&lt;br&gt;Amanda Stockwell explains what UX interviewing is, when UX professionals use interviews, and what kind of information you'll gather. She also takes you through how to prepare for interviews, moderate your sessions, and analyze your data.  After you wrap up this course, you'll be prepared to conduct UX interviews on your own.\",\"Course Short Description\":\"Learn the fundamentals of a core UX research method\u00e2\u20ac\u201dinterviewing\u00e2\u20ac\u201dthat can help you better understand the needs of your users.\",\"Content Type\":\"SKILLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":5287222,\"Instructor Name\":\"Amanda Stockwell\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"President of Stockwell Strategy\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2017-04-28T00:00:00\",\"Course Updated Date\":\"2022-11-16T00:00:00\",\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"Yes\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/ux-research-methods-interviewing\",\"Series\":null,\"Limited Series\":null,\"Manager Level\":\"General\",\"LI Level\":\"Intermediate\",\"LI Level EN\":\"Intermediate\",\"Sensitivity\":null,\"Internal Library\":\"Creative\",\"Internal Subject\":\"User Experience\",\"Primary Software\":null,\"Media Type\":\"Video\",\"Has CEU\":\"No\",\"Has Exercise Files\":\"No\",\"Visible Duration\":2121.0,\"Visible Video Count\":16.0,\"Contract Type\":\"STANDARD\"},\"sections\":[{\"duration\":45,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4371132\",\"duration\":45,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Interviewing for UX research projects\",\"fileName\":\"546777_en_US_00_01_2022Q4_WL30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"In this video, explore the scope and general coverage of this course, and decide whether it's appropriate for their goals.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8647698,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Interviews are one of many UX research methods  \\n and are used to gather general information  \\n about users and their needs, goals, motivations,  \\n or impressions of a product.  \\n Interviews are frequently used at the beginning stages  \\n of a new product or during the beginning  \\n of a redesign period.  \\n Hi, I'm Amanda Stockwell.  \\n Welcome to this course on interviewing users.  \\n In this course,  \\n I'll introduce the uses and benefits  \\n of conducting interviews,  \\n provide an overview of how to prepare,  \\n give tips for effectively moderating your sessions,  \\n and lastly, discuss how to analyze your data.  \\n This course is for anyone with a basic understanding  \\n of user experience who's interested  \\n in conducting interviews on their own.  \\n Let's take a look.  \\n \\n\\n\"}],\"name\":\"Introduction\",\"size\":8647698,\"urn\":\"urn:li:learningContentChapter:4368138\"},{\"duration\":389,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4368136\",\"duration\":59,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"What is UX interviewing?\",\"fileName\":\"546777_en_US_01_01_2022Q4_MM30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"In this video, explore the scope of effective interviewing for UX research projects, its benefits and potential issues, and how interviewing can benefit your own UX research.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2400104,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - A UX interview is like any interview.  \\n There are many variations, but at its simplest,  \\n a trained moderator guides an open-ended,  \\n one-on-one conversation with an existing or potential user.  \\n The technique is used  \\n by user experience research professionals  \\n to explore and understand user's general attitudes,  \\n their motivations, pain points,  \\n and current behavioral patterns.  \\n You can also interview business stakeholders,  \\n but the focus of this course  \\n will be on talking to the people  \\n who will ultimately use whatever you create,  \\n whether that's a service, a product, a website,  \\n or a new version of any of those things.  \\n For simplicity, we'll refer to these people as users  \\n throughout the course.  \\n You may use the information to help paint a picture  \\n of your users, build empathy for their struggles,  \\n identify opportunities to help them  \\n or formulate solutions to the opportunities you find.  \\n Interviews require no special equipment or tools.  \\n Typically you just need a plan, a way to take notes,  \\n and a way to record the sessions.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4370115\",\"duration\":70,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"The uses of UX interviews\",\"fileName\":\"546777_en_US_01_02_2022Q4_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, explore the various uses for interviews during UX research efforts, and where they fit within the research process in order to generate solid, objective results.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3274600,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Interviews are a method that are used to explore people.  \\n You'll be looking to gather general insights  \\n about people's attitudes and beliefs,  \\n rather than uncover hard data,  \\n such as how often a problem occurs.  \\n Interviews are very often used at the beginning of a project  \\n when you're trying to determine who will use what you build.  \\n Insights collected are often turned into personas,  \\n which are archetypes of your main users,  \\n split out by key behaviors and attributes.  \\n Personas are used as a tool  \\n to help everyone think of users the same way,  \\n to build empathy for those users across teams  \\n and to prioritize work  \\n based on the target persona being served.  \\n You may also conduct regular interviews with existing users,  \\n especially after growth has stalled,  \\n when there's about to be a redesign, or after a rebranding,  \\n or redesign has just occurred.  \\n Interviewing people regularly  \\n lets you understand how users are evolving,  \\n see how needs shift to keep up with changing times  \\n and allows you to gather general impressions  \\n of a brand or service after experience.  \\n You'll want to talk to both loyal, happy users  \\n to know what they love best about your service.  \\n And to dissatisfied users  \\n to understand what went wrong or what could be improved.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4370116\",\"duration\":168,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Limits for interviews\",\"fileName\":\"546777_en_US_01_03_2022Q4_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, explore the limits and limitations of interviewing for UX research, how those limitations affect potential uses of interviews and how to set appropriate limits for your own interviewing efforts.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8259604,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - While interviews are invaluable for understanding people,  \\n there are many things that interviews cannot tell you.  \\n Since humans are notoriously complex and varied,  \\n there's no single objective truth to uncover.  \\n That means you can't reach  \\n any sort of statistically significant conclusions,  \\n or use interviews to prove or disprove hypotheses.  \\n Interviews are not an evaluation tool,  \\n which means that they're not good  \\n for assessing the details of a solution.  \\n You can't find out things  \\n like whether a button should be a certain color,  \\n where an item should live within a navigation system,  \\n or the best label for a category.  \\n If you're interested in how well an interface performs,  \\n you need people to use the interface  \\n and observe them doing so, such as in a usability test.  \\n Interviews aren't great  \\n for understanding details of past experiences.  \\n People won't mean to lie to you,  \\n but our memories have limits,  \\n and it's very difficult to recall  \\n specific details of past events.  \\n People will tell a general story that leaves out details,  \\n or fill in generic details that seem to make sense.  \\n However, it's the small details of an experience  \\n that give you the most insight into what works well  \\n and what could be improved.  \\n Interviews also can't tell you  \\n what people will do in the future.  \\n Humans are bad at predicting their own behaviors.  \\n There's a big difference between  \\n what people think that they'll do  \\n and what they end up doing.  \\n They could be hoping that they'll behave differently,  \\n or their needs and context shift over time.  \\n People are especially bad at predicting their behavior  \\n for brand new products or services  \\n that they don't yet understand.  \\n Let's talk through an example.  \\n Say you're working on a new recipe application  \\n and you want to explore people's attitudes  \\n about meal preparation.  \\n If you ask someone about their dinner last Tuesday night,  \\n they might not even remember what they had,  \\n unless they have the same thing every single Tuesday,  \\n or some kind of special event, such as somebody's birthday.  \\n If you ask them to recall a general time  \\n that they made pasta,  \\n they'll probably walk you through the steps  \\n without much detail.  \\n Boiling the water, putting pasta in the water,  \\n then draining, and eating.  \\n However, if you're looking for opportunities to improve,  \\n you'll really want to understand  \\n the specific details of their experiences.  \\n So maybe you ask them to cook pasta on a particular night  \\n and interview them about it just after.  \\n Maybe they'll tell you  \\n that they accidentally set their timer to hours  \\n instead of minutes, and they overcooked the meal.  \\n That could be a cue that the interface for the timer  \\n could be made more intuitive,  \\n but it's not something that they tell you  \\n if you ask about the general process for making pasta.  \\n On the other hand, if you ask someone  \\n whether they'll eat a salad next Friday night,  \\n they might say they will and truly intend to follow through.  \\n But when Friday comes, maybe they've had a bad day  \\n and their spouse offers to take them out to pizza.  \\n Salad, out the door.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4374134\",\"duration\":92,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Interview moderation considerations\",\"fileName\":\"546777_en_US_01_04_2022Q4_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to plan and execute moderation during your research interviews in order to most effectively gain unbiased data and insight, and teach research team members how to do the same.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4460647,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - You can get the most out of interviewing  \\n when you're able to visit people in their home,  \\n place of work, wherever they might use your service  \\n so that you can observe them in their natural context.  \\n This is also called ethnography.  \\n Being in their space might make users more comfortable  \\n than meeting you in an office or lab setting,  \\n which means you may be able to dig deeper  \\n into sensitive topics.  \\n Being in their usual space also means  \\n that you can observe things about their setup  \\n that might affect how they use your product or how they act.  \\n For instance,  \\n you might notice that people have a cheat sheet of shortcuts  \\n on their desk,  \\n or you might see just how often someone gets interrupted  \\n during a particular process.  \\n Viewing the whole ecosystem a person operates in  \\n will help you understand how your product fits  \\n into their overall context.  \\n You'll find issues and uncover opportunities  \\n you may not even realize are related  \\n until you see them all together.  \\n If you aren't able to visit someone in their home or office,  \\n I still recommend conducting interviews in person  \\n when possible.  \\n It's easier to build trust and rapport in person.  \\n You can also much better read interviewees body language  \\n and facial expressions when you're in the same room.  \\n However,  \\n if time or budgets are very tight or you have users  \\n that are spread out,  \\n it may make sense to do remote interviews.  \\n The planning is the same, but for the session,  \\n use a video conferencing tool like WebEx or Skype  \\n or the phone.  \\n In most cases,  \\n the phone should be a last resort here  \\n as you really want to be able to see people's faces.  \\n \\n\\n\"}],\"name\":\"1. UX Interviewing: Overview\",\"size\":18394955,\"urn\":\"urn:li:learningContentChapter:4366298\"},{\"duration\":421,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4366295\",\"duration\":144,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Selecting interview participants\",\"fileName\":\"546777_en_US_02_01_2022Q4_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to effectively select participants for your study to both provide a good range of opinions and feedback, and accurately represent the demographics of the group or product being researched.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5556158,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Who you interview will depend on what you're trying  \\n to learn from the sessions.  \\n For the very beginning stages of a product  \\n with no existing users,  \\n you'll need to begin by making some educated guesses  \\n about the kind of users you want to target.  \\n Identifying the key attributes of users of competitors,  \\n or related products would be a great place to start.  \\n For instance, let's say you want  \\n to make a new kind of meal preparation application.  \\n You could look for people  \\n who actively search for recipes online  \\n or who are learning how to cook  \\n and recruit those people to start interviewing.  \\n At this stage,  \\n you'll need to interview more people  \\n and start with a broader set of participants  \\n to narrow things down.  \\n If you have an established company  \\n but don't understand the users very well,  \\n start by gathering all the information you  \\n and your team already have.  \\n You can look at analytics or usage data, exit surveys,  \\n product feedback, support tickets or complaints,  \\n and any other existing information.  \\n Use that data to start to make some hypotheses  \\n about the different types of users.  \\n For instance, if you're working on an eCommerce site,  \\n you might notice that there seems to be one set of people  \\n who come to the site,  \\n search a specific product and buy quickly.  \\n Maybe there's also another set of users  \\n who use browsing functions,  \\n visit a wide variety of products,  \\n and take a much longer time to purchase.  \\n Then find people to talk to that represent those two groups  \\n to further understand what their differences  \\n and similarities are  \\n and what other groups you may not have considered.  \\n If you already have established persona groups,  \\n you want to find users who are representative of each  \\n of the personas that are relevant to your research topics.  \\n You may also want to talk to people who are not yet users,  \\n but would fall into those persona categories,  \\n especially if you're exploring the signup process,  \\n onboarding or initial impressions.  \\n If you're losing customers,  \\n you may want to try to talk to those that have left,  \\n but be aware that they may be less willing to talk  \\n or they may have biased opinions.  \\n When it comes to the number of participants,  \\n there's no hard and fast rule.  \\n Because there's no objective truth  \\n to uncover from the interviews,  \\n there's no magic amount of people that will lead you  \\n to the right answer.  \\n I recommend aiming for at least five participants  \\n per persona group.  \\n That should be enough to start seeing patterns  \\n and key behaviors,  \\n and you can always add additional users if need be.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4366296\",\"duration\":151,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Recruiting interview participants\",\"fileName\":\"546777_en_US_02_02_2022Q4_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to both identify and recruit interview participants that match the unique needs of the study that you've determined in the previous video.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6691176,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - The process for recruiting interview participants  \\n is much like recruiting participants  \\n for any other type of UX research,  \\n you need to find actual or representative users.  \\n To do so, you need to create a screener,  \\n which is just a list of questions  \\n that will help you identify who is right for your study  \\n and weed out those who aren't a good fit.  \\n This is where it comes in handy  \\n if you already have personas created.  \\n A screener is very easy to build out  \\n if you already have a solid understanding  \\n of your target user.  \\n Even if you don't have formal personas,  \\n take some time to establish  \\n the top identifying characteristics  \\n of who you're trying to reach,  \\n such as their general technical skill  \\n or usage of a particular type of software.  \\n For instance, if you're working on an application  \\n that allows parents  \\n to schedule medical appointments for their family,  \\n you don't want to talk to a childless single person  \\n who has no idea  \\n what a parent might need to consider when scheduling.  \\n For more on screener creation,  \\n check out this article on UX Mastery.  \\n There are two common ways  \\n to find participants for user experience research studies,  \\n contact existing customers,  \\n or use a panel of available participants.  \\n If you have an existing product and users,  \\n you can invite them participate in a study  \\n via email, phone, or other regular communication channels.  \\n There are even tools that allow you to intercept live users  \\n of your website, or web application.  \\n Existing users will come to the interview  \\n with a predetermined outlook of the system,  \\n whether that's good or bad.  \\n This preconception can bias their feedback.  \\n That being said,  \\n if you're going to be working on a redesign,  \\n or a new section or feature of an existing system,  \\n I highly recommend reaching out to existing users.  \\n Another way of finding participants  \\n is to recruit from user or market research panels.  \\n Members of these panels may be easier to schedule,  \\n but they can also come with their own biases.  \\n Because they've signed up for the panel,  \\n they likely view giving you feedback as a job,  \\n and they know that they're judged  \\n based on their ability to give useful feedback.  \\n This means that sometimes they err on the side  \\n of providing only positive feedback.  \\n Luckily, there isn't really a desired outcome  \\n in an interview.  \\n If there is one,  \\n it's not as easy for participants to intuit.  \\n For more tips on recruiting research participants,  \\n I recommend  \\n Validating Product Ideas: Through Lean User Research  \\n by Tomer Sharon.  \\n Tomer provides a great overview  \\n of more techniques to find participants  \\n and some detailed descriptions  \\n of using social media to recruit.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4373145\",\"duration\":126,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Scheduling and incentivizing your participants\",\"fileName\":\"546777_en_US_02_03_2022Q4_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to efficiently schedule interviews with your participants and provide incentives to help assure their participation.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5718290,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Remember that your initial contact with research  \\n participants sets the tone for the study.  \\n Their first impression will be carried forward and impact  \\n how they respond during the sessions.  \\n So you'll want to start off on the right foot,  \\n and set clear expectations.  \\n Do your best to make it easy for people to participate.  \\n Provide clear context about the study, how they'll help you,  \\n and demonstrate how much you value their feedback.  \\n These things will help potential participants feel  \\n comfortable answering initial questions and may give them  \\n more motivation to participate.  \\n To increase the likelihood that a respondent will sign up  \\n to participate, you'll likely need to provide  \\n an incentive of some sort.  \\n There are several studies that show that  \\n monetary compensation, such as receiving cash  \\n or being entered into a lottery  \\n can make respondents more likely to participate in a study.  \\n There are debates about how much to offer,  \\n but my baseline compensation is 75 to $100 an hour  \\n for in-person studies, and about $50 an hour  \\n for remote studies.  \\n The sensitivity of the information discussed,  \\n and specialty of the persona will affect how much I offer.  \\n For instance, I typically pay participants in niche targets  \\n such as doctors or business executives,  \\n much more than general retail shoppers.  \\n Besides the obvious benefit, compensating research  \\n participants demonstrates that you  \\n value their time and their feedback.  \\n Knowing that they will get paid to help you,  \\n makes it more likely that they will indeed fulfill  \\n their obligations in the research.  \\n Whether that's calling into a conference line or actually  \\n showing up somewhere.  \\n To ensure that the maximum number of participants show up,  \\n I follow a few best practices when I recruit.  \\n Set clear expectations early on.  \\n Send calendar invites with frequent reminders.  \\n Provide clear arrival instructions.  \\n Give reminders about how important their feedback is,  \\n and remind them that they will be compensated.  \\n Because life happens, there are almost always a few  \\n no-shows in moderated sessions.  \\n My rule of thumb is to schedule an extra participant or two  \\n for every five scheduled.  \\n \\n\\n\"}],\"name\":\"2. Preparing Topics\",\"size\":17965624,\"urn\":\"urn:li:learningContentChapter:4368139\"},{\"duration\":388,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4368137\",\"duration\":162,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Planning your interviews\",\"fileName\":\"546777_en_US_03_01_2022Q4_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to plan out the structure of the interviews in a consistent manner between participants, in order to achieve consistent results and feedback.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5703514,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - When you start planning for interviews,  \\n you'll want to come up with a script  \\n that outlines a set of questions  \\n to cover the topics you'd like to discuss.  \\n Preparing the script is a way to define  \\n and prioritize the research goals  \\n and set a proposed structure for the conversation.  \\n You should use the script as a guide only  \\n and plan on asking follow up or separate questions  \\n as they arise naturally in the discussion.  \\n You may have hypotheses to explore,  \\n but remember that interviews should be used  \\n to explore how's and why's not definitively prove  \\n or disprove points.  \\n You may also want to run a flavor  \\n of ethnographic interview called a contextual inquiry.  \\n In a contextual inquiry,  \\n you go to the person's normal place of work  \\n or their home and have them walk you through a set of tasks.  \\n You observe their process  \\n and ask them follow up questions as you go.  \\n The sessions may vary greatly based on what the user does,  \\n but it's still helpful to have a script ready  \\n with a bank of topics to cover and questions to ask.  \\n I recommend first writing out  \\n the specific questions you want answered with the research,  \\n such as why someone signed up for a service  \\n or how they chose their subscription level.  \\n You can't get good information  \\n by directly asking those questions,  \\n but listing out the goals will give you  \\n a sense for how much you want to cover  \\n and help you prioritize the topics.  \\n There is no magic number of questions,  \\n but you typically want to plan  \\n for sessions to be about 30 to 60 minutes.  \\n I found that's usually about three main topics.  \\n You may need to skip some topics  \\n if you get deep into a discussion,  \\n so knowing what you absolutely must cover  \\n versus what is nice to have will help you  \\n regulate the discussion.  \\n When planning the flow of the discussion,  \\n start with an introduction that explains who you are,  \\n sets expectations for the session,  \\n and reminds participants how their input will help you.  \\n If you'll be recording the session  \\n or need any other forms signed,  \\n include that information upfront  \\n and make sure to ask for permission.  \\n You can write this out in the script  \\n to ensure that you don't forget any key points.  \\n Make the first questions easy  \\n for participants to answer and not too personal,  \\n such as explaining their job function.  \\n This will get the conversation started  \\n and help the participant feel comfortable talking to you.  \\n Then you'll want to move on  \\n to the meat of the interview,  \\n which will cover the key topics  \\n you've listed out.  \\n More on how to craft the best questions  \\n in the next section.  \\n Make sure that you build in time  \\n to wrap up the conversation  \\n with any lingering questions on your part.  \\n Give the participants time  \\n to make any other comments or ask questions  \\n as there might be something they've been thinking  \\n that you didn't think to ask about.  \\n This is also a good time to thank them  \\n and remind them how they're helping the team.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4373146\",\"duration\":226,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Crafting the interview questions\",\"fileName\":\"546777_en_US_03_02_2022Q4_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to write and fine-tune the questions used in the interview to help assure the right coverage of feedback and remove any bias or leading terms that might risk an objective response from participants.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10693909,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - To create the questions,  \\n start with a list of research goals you have  \\n and write out a series of questions  \\n that look at the issue with various angles.  \\n For instance,  \\n if you're trying to understand  \\n why someone signed up for your service,  \\n you might start with a simple question, like:  \\n How did you decide to pick the service?  \\n But you might also ask things like:  \\n What other services did you look at?  \\n Why didn't you choose those services?  \\n What were the biggest factors for you to decide?  \\n What were the pros and cons of each?  \\n How sure or unsure were you that you made the right choice?  \\n Who helped you decide?  \\n These questions all explore the same decision,  \\n but look at it from different angles.  \\n You can also ask for the same information in different ways  \\n to make sure that you're getting the whole story.  \\n Focus on creating open-ended questions,  \\n starting with who,  \\n what,  \\n where,  \\n when,  \\n or how.  \\n Just make sure that you ask one question at a time.  \\n For instance, you wouldn't want to ask,  \\n \\\"How do you find and share interesting articles?\\\"  \\n Instead, you'd want to first focus  \\n on asking about how they find articles  \\n and explore that thoroughly.  \\n Then, move on to the sharing task.  \\n Splitting the questions  \\n ensures that you'll uncover insights around both items  \\n and won't confuse your participants.  \\n Try to match the language style of your participants,  \\n and when in doubt, ask questions as simply as possible.  \\n I also like to have participants recall something  \\n and simply ask them to tell me about their experience.  \\n My favorite follow-up question is, \\\"Tell me more.\\\"  \\n Even if you think there's a simple answer to your question,  \\n people will always tell you more detail and context  \\n when you leave things open.  \\n You also bake in assumptions when you ask closed questions,  \\n and the point of conducting interviews  \\n is to uncover the things you don't already know.  \\n To that note, phrase the questions as neutrally as possible  \\n so you don't introduce your biases.  \\n You'll need to practice this when conducting the interviews,  \\n but it helps to start  \\n by writing the questions in a non-leading way.  \\n For instance, don't ask how frustrating it might be  \\n if someone receives an error when filling out a form.  \\n Rather, ask the participant  \\n to remember the last time that they got an error  \\n and tell you about it.  \\n Note that I didn't ask how they feel,  \\n but rather left it open  \\n to tell me anything that comes to mind.  \\n This way, you don't assume  \\n what participants were feeling or thinking,  \\n and you'll get information  \\n about what was most relevant to them at the time.  \\n You can also phrase the question  \\n with both the positive and the negative view embedded,  \\n like saying, \\\"How sure or unsure are you about your choice?\\\"  \\n It helps to ask participants about specific recent events.  \\n Remember that human memory has limits.  \\n People will unconsciously make up a story  \\n that makes the most sense to them  \\n and fill in what they can't remember.  \\n With the form error example,  \\n ask them first to recall the last time it happened to them,  \\n get them talking about the specific experience  \\n and what they were trying to do.  \\n You'll get much more specific truthful information  \\n if someone is recalling a specific interaction,  \\n rather than generalizing about all their past experiences.  \\n If you are exploring a particular interface or process,  \\n try the contextual inquiry approach  \\n and have participants walk you through the tasks  \\n they'd normally perform.  \\n Situations will likely come up  \\n that you hadn't considered asking about,  \\n and you'll get an even deeper look  \\n into the participant's true experience.  \\n Regardless of your research goals,  \\n having a set of open, non-biased questions  \\n will help you get the most out of your sessions.  \\n \\n\\n\"}],\"name\":\"3. Study Logistics\",\"size\":16397423,\"urn\":\"urn:li:learningContentChapter:4372125\"},{\"duration\":531,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4373147\",\"duration\":175,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"The session logistics\",\"fileName\":\"546777_en_US_04_01_2022Q4_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to plan and execute the overall logistics for your research session and each interview within, and provide a smooth process across the entire session for colleagues and participants alike.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7495358,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - I recommend recording interviews  \\n so that you can truly focus on the discussion.  \\n Then later, re-listen to key points and choose snippets  \\n to help describe key takeaways.  \\n When it's possible,  \\n I also like to have a teammate observe  \\n the session and take notes.  \\n They can focus on capturing details,  \\n and it's good to have a backup in case  \\n there are technical glitches with the recording.  \\n When the note-taker is physically present,  \\n you can switch moderating and note-taking to stay fresh.  \\n It can be nice to share the management of the logistics too.  \\n However, having two people present  \\n can be a little overwhelming for participants,  \\n and it is more costly to have two people travel,  \\n so the second person can also watch remotely.  \\n That means they can be in the next room  \\n or in a totally different location.  \\n To do so, you set up a laptop with the webcam facing  \\n the participant, and use a video conferencing tool  \\n to share the session.  \\n Recording also means that other teammates and stakeholders  \\n can observe the sessions live or watch after the fact.  \\n You can use the same video conferencing tools  \\n when you conduct remote interviews.  \\n Just be sure to test the setup.  \\n Leave time to fix technical glitches  \\n and provide clear instructions for participants.  \\n If you're observing and talking to participants  \\n in their usual space, you may not have a typical desk setup,  \\n so you may need to get creative about recording the session.  \\n The key things are to capture as much of the participants'  \\n facial expressions as possible without being intrusive,  \\n and to capture the audio of the session,  \\n I've found a GoPro camera set up on a tripod  \\n to be a good solution.  \\n You may also be able to set up a few cameras  \\n to take pictures at regular intervals.  \\n You may get some useless pictures,  \\n but you'll also get some authentic action shots.  \\n When I just need audio,  \\n I found a Livescribe pen to be very helpful.  \\n If you're going to be meeting your participant in-person,  \\n but not in their normal space,  \\n try to choose a neutral location that's conducive  \\n to a good conversation, such as a quiet coffee shop.  \\n I find it's easier to build rapport  \\n if you're able to sit around a small table  \\n or catty-corner with someone,  \\n rather than on opposite sides of the desk,  \\n as that can be intimidating.  \\n Play with the setup, depending on the location,  \\n to encourage participants to feel their most comfortable.  \\n Either way, I recommend taking several pictures  \\n of your setup so you can refer back on analyzing  \\n the sessions or planning your next.  \\n Regardless of the type of session you run,  \\n I always recommend running a pilot session with a teammate  \\n to test the camera position, audio, and video recording,  \\n and any video conferencing setup.  \\n Bring extra charging cables and batteries,  \\n and have backup plans for recording devices,  \\n bad connections, or pretty much anything else  \\n that could go wrong.  \\n Even experienced researchers will run  \\n into unexpected problems.  \\n It might seem like wasted time at the beginning,  \\n but it's always worth it in the end.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4374135\",\"duration\":186,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Conducting your interviews\",\"fileName\":\"546777_en_US_04_02_2022Q4_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to plan and execute the logistics of each interview consistently and accurately, in order to assure consistent and appropriate feedback.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9138403,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Conducting interviews well is a skill  \\n that is easy in theory, but difficult in practice.  \\n It's important to master the art of probing without leading  \\n to get the most out of the sessions.  \\n There are lots of things a researcher can do  \\n to ensure that they get the most out of UX interviews.  \\n First, it's important to set the stage correctly,  \\n as most participants won't be familiar with UX Research  \\n and they may feel uncomfortable or nervous.  \\n Briefly explain your role to participants, reminding them  \\n that you are there to learn about them, not to judge them,  \\n and that there are no right or wrong answers.  \\n Tell them that you may ask questions  \\n that seem obvious to them or ask questions multiple times  \\n to be sure that you're getting the full picture.  \\n Describe how you'll be taking notes  \\n or recording the sessions  \\n and what you'll do with the information.  \\n Make sure to get their permission,  \\n Give them logistical information  \\n such as how long you expect the session to take.  \\n And do all of this with a friendly tone  \\n to help participants feel more comfortable and open to you.  \\n Once the discussion gets started,  \\n remember that your main goal  \\n is to listen to participants, not to talk.  \\n Even if you've done a great job crafting the research plan,  \\n people will often tell you unexpected things  \\n that can be very useful.  \\n Instead of charging on to your next question in your plan,  \\n practice being silent and allow users  \\n to expand on their points.  \\n Silence is inherently uncomfortable for people,  \\n so participants will often keep talking  \\n and you'll uncover even more  \\n than you would've thought to ask about.  \\n You can encourage this kind of deep insight  \\n with a follow-up technique called the Five Why's.  \\n The Five Why's is a very straightforward technique  \\n used to explore cause and effect relationships.  \\n All you do is keep asking participants  \\n to expand on their previous point  \\n until you've reached a root cause or natural end.  \\n It won't always take you exactly five follow-up questions.  \\n It might be only three, or it might take more,  \\n but you want to keep digging until you learn something  \\n that speaks to the root of the problem  \\n or the beginning of a solution.  \\n Here's a shortened example from a series of interviews I did  \\n exploring a fitness application.  \\n What sorts of healthcare  \\n or fitness tools do you currently use?  \\n Well, I had a step tracker,  \\n but I don't really wear it anymore.  \\n Oh, why not?  \\n I guess I wanted more encouragement and some suggestions  \\n about how to meet the goals.  \\n Why did you want more suggestions?  \\n I never hit the goals.  \\n Oh, tell me more about that.  \\n Actually, the goals it set for me  \\n were higher than I ever intended to do.  \\n Oh, why didn't you change the goals?  \\n You can do that?  \\n It turns out that the person I was talking to  \\n had no idea that they could set their own goals,  \\n and the real problem was that the interface  \\n to set their goals was very hard to find and confusing.  \\n Each answer they gave me led to a further question,  \\n which eventually led to the root of their problem  \\n and the beginning of something that we could provide better.  \\n Figuring out the right follow-up questions  \\n and when to stop take some practice,  \\n but you'll uncover much deeper insight this way.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4371133\",\"duration\":170,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Remaining neutral during interviews\",\"fileName\":\"546777_en_US_04_03_2022Q4_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, explore the tips and insights to help you remain neutral during interviews, and not lead participants into specific outcomes or answers. This is critical for objective, actionable results.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7318888,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - When listening to participants,  \\n be sure to be fully engaged  \\n and not make assumptions about their answers.  \\n Their interpretation of something  \\n may be different from yours, so ask for details  \\n and be sure you're fully processing what they say.  \\n Paraphrase the main gist of what you think they're saying  \\n and repeat it back, then they can either expand more,  \\n clarify something that was off, or confirm what you thought  \\n and you can move on.  \\n If you're unsure about a word they used, what they said,  \\n or how they see or do something, ask,  \\n no matter how obvious it may seem  \\n or if you've asked it before.  \\n You might even want to purposely ask the same question  \\n a few different ways to be sure you don't miss anything.  \\n Communication is tricky and it's easy for people  \\n to gloss over the things that they know best.  \\n The whole point of an interview  \\n is to explore how your participant thinks,  \\n so get them to slow down.  \\n Remind them that you want to learn all about them  \\n and that they should treat you as complete beginners.  \\n Keep in mind that every participant  \\n has a different communication style  \\n and set of values and context,  \\n so what works for some participants  \\n may not work for another.  \\n Beside the obvious things like making sure your language  \\n and attire is appropriate for the setting,  \\n pay close attention to individual reactions  \\n and do your best to shift your style on the fly.  \\n For instance, if someone seems to be slow to open up,  \\n spend some extra time getting to know them  \\n and identify something that they seem passionate about  \\n before digging into details.  \\n To nudge people to talk more,  \\n you can also remind them how helpful their insight will be.  \\n You'll get the best insight  \\n when your questions flow naturally,  \\n which means order may vary greatly between participants.  \\n It helps to have the key questions memorized  \\n so that you can pull them in as it makes sense  \\n rather than planning to always ask the same thing  \\n in the same order.  \\n Remembering the key questions  \\n can also help you steer participants  \\n back to the main topics of conversation  \\n if they get distracted or off on a tangent.  \\n Finally, remember to be gracious and nonjudgmental,  \\n especially when discussing sensitive topics.  \\n Even if you're paying participants,  \\n they're giving you their time and opinions for your benefit.  \\n Participants are likely to share more  \\n if they feel like a valued partner,  \\n and they're likely to clam up  \\n if they feel judged or embarrassed.  \\n It takes some practice but remain neutral,  \\n control your reactions, and pick strategic times  \\n to remind participants that there are no right  \\n or wrong answers.  \\n Reminder, that when it's possible,  \\n have a colleague take notes  \\n so that you can focus on the person you're talking to.  \\n That will allow you to read more body language cues  \\n and the conversation should flow more smoothly.  \\n If you don't have that option,  \\n it's best to take minimal notes during the session  \\n and record the sessions so you can revisit details.  \\n \\n\\n\"}],\"name\":\"4. Executing the Interview\",\"size\":23952649,\"urn\":\"urn:li:learningContentChapter:4372126\"},{\"duration\":314,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4366297\",\"duration\":137,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Organizing and analyzing the data\",\"fileName\":\"546777_en_US_05_01_2022Q4_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to organize the data from your sessions into a consistent format that can be reviewed in batches, and individually.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5946907,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Once all the interviews are complete,  \\n you'll have to tackle organizing  \\n the data and synthesizing insights  \\n that the team can use moving forward.  \\n I recommend that you include  \\n as many people as you can who observed sessions,  \\n took notes, or otherwise related  \\n to the project in the initial sorting process.  \\n Organizing and synthesizing information together  \\n means that you'll gather everyone's point of view  \\n and the whole team will better appreciate  \\n the process and understand the outcomes of the research.  \\n You want to try to get everyone learning  \\n from the research together,  \\n rather than working in a vacuum  \\n and reporting back after the fact.  \\n However you took your notes,  \\n your team's first task is to deconstruct  \\n the massive notes you have into individual insights.  \\n Have each team member identify useful snippets  \\n of information such as what actions people take,  \\n what their biggest problems are,  \\n people's needs or goals,  \\n or particular quotes that capture a feeling or emotion.  \\n The key is to break everything down  \\n into singular facts that you can sort  \\n and combine to find patterns  \\n and synthesize deeper meaning.  \\n I like to write each finding on a single sticky note  \\n so I can start the next phase.  \\n Once you have individual pieces of data,  \\n use a wall or table, tie all the notes,  \\n and start grouping related items into themes,  \\n like an open card sort.  \\n Try having each sort and resort multiple times  \\n to see different connection points  \\n and explore different ways  \\n that you could view the information.  \\n After a few rounds from each person,  \\n you'll see what items always seem to fit together,  \\n and you can start talking  \\n about the meaning of main categories.  \\n You may end up with very high level categories,  \\n like overall user goals  \\n or break big categories into multiples,  \\n such as two main sets of goals.  \\n You might also be quite granular,  \\n like identifying issues with a specific part of a process.  \\n There's no right or wrong answer  \\n or target number of categories,  \\n but in general, the more you already know  \\n about your participants,  \\n the more granular your categories can be.  \\n Once you have the categories set,  \\n do one last group categorization  \\n to put each finding in a meaning bucket.  \\n At this point, you'll be able to view  \\n high level patterns and you'll be well prepared  \\n to pull deep insights from the data.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4374136\",\"duration\":177,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Summarizing your findings\",\"fileName\":\"546777_en_US_05_02_2022Q4_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to summarize the findings of your study into an easily consumed format with clear findings, objectives, and suggestions, to deliver in person or via digital means.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9207827,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Once everything is sorted,  \\n you still need to synthesize the data  \\n into actionable takeaways.  \\n Having just a list of general user goals or motivations  \\n doesn't necessarily tell you and your team what to do next.  \\n You'll want to look at each finding  \\n and discuss what it means for the team.  \\n You'll want to ask questions like:  \\n What opportunities to improve or offer new experience exist?  \\n How could those opportunities be tied to business goals?  \\n You don't need to define solutions right away,  \\n but you want to end up with a list of actions to take next.  \\n For instance,  \\n is lacking,  \\n and action items are to do a detailed usability test  \\n and to brainstorm compelling ways  \\n to move users from sign up to first action.  \\n The interviews might give you some ideas  \\n about how to improve the interaction,  \\n but you don't have to rely on them  \\n to prescribe the solutions.  \\n If your aim is to create personas,  \\n you'll want to go through the same data organization process  \\n with any quantitative data you have,  \\n such as site usage or demographics.  \\n Then, group all identifying characteristics,  \\n like context, behaviors, goals, motivations, and challenges.  \\n Once you've identified those patterns,  \\n summarize the different personas.  \\n You may want to find a representative picture  \\n or set of quotes  \\n and create stories that explain your product in their life.  \\n Your goal is to create a set of documents  \\n that describes the key differences between user types.  \\n You can learn more about personas  \\n in the course UX Design Techniques: Creating Personas.  \\n Once you've summarized your key takeaways,  \\n you need to be sure your insights get shared, digested,  \\n and used by the team.  \\n Involving as much of the team as possible  \\n in the data analysis  \\n means you can have an ongoing discussion  \\n about the interpretations  \\n and there's no need for a big reveal and a report.  \\n While you should still document the basic research plan  \\n and takeaways in case you want to revisit in the future,  \\n I always like to recommend having a research debrief  \\n to discuss takeaways and their implications,  \\n rather than relying on a report.  \\n You may also need to provide formal documents  \\n and deliverables, especially if you are a consultant.  \\n If so, I recommend following the same basic structure report  \\n that I recommend for all sorts of UX research:  \\n an executive summary of process and key findings,  \\n then a detailed description of methodology and analysis  \\n with a mixture of visuals and text  \\n to appeal to the different ways  \\n that people best learn and process information.  \\n For more in creating UX research reports,  \\n check out Presenting and Incorporating Results  \\n from UX Research Fundamentals.  \\n The most important thing is to ensure that the whole team  \\n understands the people you're building for  \\n and the insights you pulled from your research.  \\n You want to be sure that the information gets used,  \\n shape product, and design decisions moving forward.  \\n \\n\\n\"}],\"name\":\"5. Data Analysis and Summarization\",\"size\":15154734,\"urn\":\"urn:li:learningContentChapter:4371134\"},{\"duration\":33,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4374137\",\"duration\":33,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Taking your interviewing skills forward\",\"fileName\":\"546777_en_US_06_01_2022Q4_LA30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7219303,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Thanks so much for watching  \\n and learning about conducting interviews.  \\n This course should have given you all the information  \\n you need to get started planning,  \\n conducting and analyzing UX interviews.  \\n They can take some practice,  \\n but they're invaluable for understanding your users.  \\n In turn,  \\n you'll be able to craft experiences  \\n that better suit their needs and help your business succeed.  \\n For a fantastic deep dive into interviewing users,  \\n I recommend Steve Portigal's book, \\\"Interviewing Users.\\\"  \\n Thanks again and good luck getting started.  \\n \\n\\n\"}],\"name\":\"Conclusion\",\"size\":7219303,\"urn\":\"urn:li:learningContentChapter:4373148\"},{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:611871\",\"duration\":46,\"visible\":false,\"requiredForCertificateOfCompletion\":null,\"name\":\"Welcome\",\"fileName\":\"546777_00_01_WL30_welcome\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9258011,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Interviews are one of many UX Research methods,\\nand are used to gather general information\\nabout users and their needs, goals, motivations,\\nor impressions of a product.\\nInterviews are frequently used at the beginning stages\\nof a new product or during the beginning\\nof a redesign period.\\nHi, I'm Amanda Stockwell.\\nWelcome to this course on interviewing users.\\nIn this course, I'll introduce the uses and benefits\\nof conducting interviews, provide an overview\\nof how to prepare, give tips for effectively moderating\\nyour sessions, and lastly, discuss how to analyze your data.\\n\\nThis course is for anyone with a basic understanding\\nof user experience who's interested in conducting\\ninterviews on their own.\\nLet's take a look.\\n\\n\"}],\"name\":\"Introduction\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:611870\"},{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:611873\",\"duration\":59,\"visible\":false,\"requiredForCertificateOfCompletion\":null,\"name\":\"What is UX interviewing?\",\"fileName\":\"546777_01_01_MM30_Interviewing\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2918976,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- A UX interview is like any interview.\\nThere are many variations, but added simplest,\\na trained moderator guides an open-ended\\none-on-one conversation with an existing or potential user.\\nThe technique is used by\\nuser experience research professionals\\nto explore and understand users' general attitudes,\\ntheir motivations, pain points,\\nand current behavioral patterns.\\nYou could also interview business stakeholders,\\nbut the focus of this course\\nwill be on talking to the people\\nwho will ultimately use whatever you create.\\n\\nWhether that's a service, a product,\\na website, or a new version of any of those things.\\nFor simplicity, we'll refer to these people\\nas users throughout the course.\\nYou may use the information\\nto help paint a picture of your users,\\nbuild empathy for their struggles,\\nidentify opportunities to help them,\\nor formulate solutions to the opportunities you find.\\nInterviews require no special equipment or tools.\\nTypically you just need a plan,\\na way to take notes, and a way to record the sessions.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:611874\",\"duration\":70,\"visible\":false,\"requiredForCertificateOfCompletion\":null,\"name\":\"Uses of UX interviews\",\"fileName\":\"546777_01_02_MM30_uses\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Interviews are one of many user experience research methods. In this video, learn where and why UX professionals use interviews and what kind of information you'll gather.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3553741,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Interviews are a method that are used to explore people.\\nYou'll be looking to gather general insights\\nabout people's attitudes and beliefs\\nrather than uncover hard data\\nsuch as how often a problem occurs.\\nInterviews are very often used\\nat the beginning of a project\\nwhen you're trying to determine\\nwho will use what you build.\\nInsights collected are often turned into personas\\nwhich are archetypes of your main users\\nsplit out by key behaviors and attributes.\\nPersonas are used as a tool\\nto help everyone think of users the same way,\\nto build empathy for those users across teams\\nand to prioritize work\\nbased on the target persona being served.\\n\\nYou may also conduct regular interviews with existing users,\\nespecially after growth has stalled,\\nwhen there's about to be a redesign,\\nor after a rebranding or redesign has just occurred.\\nInterviewing people regularly let's you understand\\nhow users are evolving,\\nsee how needs shift to keep up with changing times,\\nand allows you to gather general impressions\\nof a brand or service after experience.\\nYou'll want to talk to both loyal, happy users,\\nto know what they love best about your service,\\nand to dissatisfied users,\\nto understand what went wrong\\nor what could be improved.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:611875\",\"duration\":168,\"visible\":false,\"requiredForCertificateOfCompletion\":null,\"name\":\"Interview limits\",\"fileName\":\"546777_01_03_MM30_limits\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Interviews are an incredibly valuable tool, but have limits and can't answer some questions. In this video, come to understand the information that an interview cannot tell you.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9228052,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- While interviews are invaluable for understanding people,\\nthere are many things that interviews cannot tell you.\\nSince humans are notoriously complex and varied,\\nthere's no single objective truth to uncover.\\nThat means you can't reach any sort of\\nstatistically significant conclusions\\nor use interviews to prove or disprove hypotheses.\\nInterviews are not an evaluation tool,\\nwhich means that they're not good for assessing\\nthe details of a solution.\\nYou can't find out things like whether a button\\nshould be a certain color, where an item should live\\nwithin a navigation system, or the best label\\nfor a category.\\n\\nIf you're interested in how well an interface performs,\\nyou need people to use the interface\\nand observe them doing so, such as in a usability test.\\nInterviews aren't great for understanding details\\nof past experiences.\\nPeople won't mean to lie to you,\\nbut our memories have limits, and it's very difficult\\nto recall specific details of past events.\\nPeople will tell a general story that leaves out details\\nor fill in generic details that seem to make sense.\\nHowever, it's the small details of an experience\\nthat give you the most insight into what works well\\nand what could be improved.\\n\\nInterviews also can't tell you\\nwhat people will do in the future.\\nHumans are bad at predicting their own behaviors.\\nThere's a big difference between what people think\\nthat they'll do and what they end up doing.\\nThey could be hoping that they'll behave differently,\\nor their needs and context shift over time.\\nPeople are especially bad at predicting their behavior\\nfor brand new products or services\\nthat they don't yet understand.\\nLet's talk through an example.\\nSay you're working on a new recipe application\\nand you want to explore people's attitudes\\nabout meal preparation.\\n\\nIf you ask someone about their dinner last Tuesday night,\\nthey might not even remember what they had,\\nunless they have the same thing every single Tuesday\\nor it's some kind of special event,\\nsuch as somebody's birthday.\\nIf you ask them to recall a general time\\nthat they made pasta, they'll probably walk you through\\nthe steps without much detail.\\nBoiling the water, putting pasta in the water,\\nthen draining and eating.\\nHowever, if you're looking for opportunities\\nto improve, you'll really want to understand\\nthe specific details of their experiences.\\n\\nSo many you ask them to cook pasta on a particular night,\\nand interview them about it just after.\\nMaybe they'll tell you that they accidentally\\nset their timer to hours instead of minutes,\\nand they overcooked the meal.\\nThat could be a cue that the interface for the timer\\ncould be made more intuitive,\\nbut it's not something that they tell you\\nif you ask about the general process for making pasta.\\nOn the other hand, if you ask someone\\nwhether they'll eat a salad next Friday night,\\nthey might say they will, and truly intend\\nto follow through, but when Friday comes,\\nmaybe they've had a bad day\\nand their spouse offers to take them out to pizza.\\n\\nSalad out the door.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:611876\",\"duration\":92,\"visible\":false,\"requiredForCertificateOfCompletion\":null,\"name\":\"Moderation considerations\",\"fileName\":\"546777_01_04_MM30_remote\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"You can perform interviews in person or remotely, and the best option will depend on your specific situation. In this video, understand the pros and cons of each.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4656259,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- You can get the most out of interviewing\\nwhen you're able to visit people in their home,\\nplace of work, or wherever they might they use your service\\nso that you can observe them in their natural context.\\nThis is also called ethnography.\\nBeing in their space might make users more comfortable\\nthan meeting you in an office or lab setting,\\nwhich means you may be able to dig deeper\\ninto sensitive topics.\\nBeing in their usual space also means\\nthat you can observe things about their setup\\nthat might affect how they use your product or how they act.\\n\\nFor instance, you might notice that people have\\na cheat sheet or shortcuts on their desk,\\nor you might see just how often someone\\ngets interrupted during a particular process.\\nViewing the whole ecosystem a person operates in\\nwill help you understand how your product\\nfits into their overall context.\\nYou'll find issues and uncover opportunities\\nyou may not even realize are related\\nuntil you see them all together.\\nIf you aren't able to visit someone in their home or office,\\nI still recommend conducting interviews\\nin person when possible.\\nIt's easier to build trust and rapport in person.\\n\\nYou can also much better read interviewee's body language\\nand facial expressions when you're in the same room.\\nHowever, if time or budgets are very tight\\nor you have users that are spread out,\\nit may make sense to do remote interviews.\\nThe planning is the same, but for this session,\\nuse a video conferencing tool\\nlike Web X or Skype or the phone.\\nIn most cases, the phone should be a last resort here,\\nas you really want to be able to see people's faces.\\n\\n\"}],\"name\":\"1. UX Interview Overview\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:611872\"},{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:611878\",\"duration\":144,\"visible\":false,\"requiredForCertificateOfCompletion\":null,\"name\":\"Participant selection\",\"fileName\":\"546777_02_01_MM30_choosing\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"The value you get from interviews is directly correlated to who you talk to in them. In this video, learn how to choose participants for your interviews.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6173332,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Who you interview will depend on\\nwhat you're trying to learn from the sessions.\\nFor the very beginning stages of a product\\nwith no existing users,\\nyou'll need to begin by making some educated guesses\\nabout the kind of users you want to target.\\nIdentifying the key attributes of users of competitors\\nor related products would be a great place to start.\\nFor instance, let's you say you want to make\\na new kind of meal preparation application.\\nYou could look for people who actively search\\nfor recipes online,\\nor who are learning how to cook,\\nand recruit those people to start interviewing.\\n\\nAt this stage you'll need to interview more people,\\nand start with a broader set of participants\\nto narrow things down.\\nIf you have an established company\\nbut don't understand the users very well,\\nstart by gathering all the information\\nyou and your team already have.\\nYou can look at analytics or usage data,\\nexit surveys, product feedback,\\nsupport tickets or complaints,\\nand any other existing information.\\nUse that data to start to make some hypotheses\\nabout the different types of users.\\n\\nFor instance, if you're working on an e-commerce site,\\nyou might notice that there seems to be one set of people\\nwho come to the site, search a specific product,\\nand buy quickly.\\nMaybe there's also another set of users\\nwho use browsing functions,\\nvisit a wide variety of products\\nand take a much longer time to purchase.\\nThen find people to talk to that represent those two groups\\nto further understand what their differences\\nand similarities are,\\nand what other groups you may not have considered.\\nIf you already have established persona groups,\\nyou want to find users who are representative\\nof each of the personas that are relevant\\nto your research topics.\\n\\nYou may also want to talk to people\\nwho are not yet users\\nbut would fall into those persona categories,\\nespecially if you're exploring the sign up process,\\non boarding or initial impressions.\\nIf you're losing customers\\nyou may want to try to talk to those that have left\\nbut be aware that they may be less willing to talk\\nor they may have biased opinions.\\nWhen it comes to the number of participants\\nthere's no hard and fast rule.\\nBecause there's no objective truth\\nto uncover from the interviews\\nthere's no magic amount of people\\nthat will lead you to the right answer.\\n\\nI recommend aiming for at least five participants\\nper persona group.\\nThat should be enough to start seeing patterns\\nand key behaviors\\nand you can always add additional users if need be.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:611879\",\"duration\":151,\"visible\":false,\"requiredForCertificateOfCompletion\":null,\"name\":\"Participant recruitment\",\"fileName\":\"546777_02_02_MM30_recruitment\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Finding the specific types of people you want to talk to can be one of the most difficult parts of UX research. In this video, learn about identifying, screening, and finding the proper people to interview.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7367271,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- The process for recruiting interview participants\\nis much like recruiting participants\\nfor any other type of UX research.\\nYou need to find actual or representative users.\\nTo do so, you need to create a screener,\\nwhich is just a list of questions\\nthat will help you identify who is right for your study\\nand weed out those who aren't a good fit.\\nThis is where it comes in handy\\nif you already have personas created.\\nA screener is very easy to build out\\nif you already have a solid understanding\\nof your target user.\\nEven if you don't have formal personas, take some time\\nto establish the top identifying characteristics\\nof who you're trying to reach,\\nsuch as their general technical skill\\nor usage of a particular type of software.\\n\\nFor instance, if you're working on an application\\nthat allows parents to schedule\\nmedical appointments for their family,\\nyou don't want to talk to a childless, single person\\nwho has no idea what a parent might need\\nto consider when scheduling.\\nFor more on screener creation,\\ncheck out this article on UX Mastery.\\nThere are two common ways to find participants\\nfor user experience research studies.\\nContact existing customers,\\nor use a panel of available participants.\\nIf you have an existing product and users,\\nyou can invite them to participate in a study\\nvia email, phone, or other regular communication channels.\\n\\nThere are even tools that allow you\\nto intercept live users of your website or web application.\\nExisting users will come to the interview\\nwith a predetermined outlook of the system,\\nwhether that's good or bad.\\nThis preconception can bias their feedback.\\nThat being said, if you're going to be working on a redesign\\nor new section or feature of an existing system,\\nI highly recommend reaching out to existing users.\\nAnother way of finding participants is to recruit\\nfrom user or market research panels.\\n\\nMembers of these panels may be easier to schedule,\\nbut they can also come with their own biases.\\nBecause they've signed up for the panel,\\nthey likely view giving you feedback as a job,\\nand they know that they're judged\\nbased on their ability to give useful feedback.\\nThis means that sometimes they err on the side\\nof providing only positive feedback.\\nLuckily, there isn't really a desired outcome\\nin an interview.\\nIf there is one,\\nit's not as easy for participants to intuit.\\nFor more tips on recruiting research participants,\\nI recommend Validating Product Ideas\\nThrough Lean User Research by Tomer Sharon.\\n\\nTomer provides a great overview\\nof more techniques to find participants\\nand some detailed descriptions\\nof using social media to recruit.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:611880\",\"duration\":126,\"visible\":false,\"requiredForCertificateOfCompletion\":null,\"name\":\"Participant scheduling and incentives\",\"fileName\":\"546777_02_03_MM30_scheduling\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"After all the work of finding participants, you want to be sure that they show up and participate in your study. In this video, learn about best practices for scheduling and incentivizing participants so they're most likely to participate.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6492170,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Remember that your initial contact\\nwith research participants sets the tone for the study.\\nTheir first impression will be carried forward\\nand impact how they respond during the sessions,\\nso you'll want to start off on the right foot\\nand set clear expectations.\\nDo your best to make it easy for people to participate,\\nprovide clear context about the study, how they'll help you,\\nand demonstrate how much you value their feedback.\\nThese things will help potential participants\\nfeel comfortable answering initial questions,\\nand may give them more motivation to participate.\\n\\nTo increase the likelihood that a respondent\\nwill sign up to participate,\\nyou'll likely need to provide an incentive of some sort.\\nThere are several studies that show\\nthat monetary compensation,\\nsuch as receiving cash or being entered into a lottery,\\ncan make respondents more likely to participate in a study.\\nThere are debates about how much to offer,\\nbut my baseline compensation is 75 to $100 an hour\\nfor in-person studies,\\nand about $50 an hour for remote studies.\\nThe sensitivity of the information discussed\\nand specialty of the persona, will affect how much I offer.\\n\\nFor instance, I typically pay participants in niche targets,\\nsuch as doctors or business executives,\\nmuch more than general retail shoppers.\\nBesides the obvious benefit,\\ncompensating research participants demonstrates\\nthat you value their time and their feedback.\\nKnowing that they will get paid to help you,\\nmakes it more likely that they will indeed\\nfulfill their obligations in the research.\\nWhether that's calling into a conference line\\nor actually showing up somewhere.\\nTo ensure that the maximum number of participants show up,\\nI follow a few best practices when I recruit.\\n\\nSet clear expectations early on.\\nSend calendar invites with frequent reminders.\\nProvide clear arrival instructions.\\nGive reminders about how important their feedback is.\\nAnd remind them that they will be compensated.\\nBecause life happens, there are almost always\\na few no-shows in moderated sessions.\\nMy rule of thumb is to schedule an extra participant or two,\\nfor every five scheduled.\\n\\n\"}],\"name\":\"2. Topic Preparation\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:611877\"},{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:611882\",\"duration\":162,\"visible\":false,\"requiredForCertificateOfCompletion\":null,\"name\":\"Planning interviews\",\"fileName\":\"546777_03_01_MM30_planning\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Identifying the key research goals and planning sessions to cover those topics will help you run interviews most effectively. In this video, learn how to prepare a script for your interview so the conversation flows smoothly.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6149650,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- When you start planning for interviews,\\nyou'll want to come up with a script\\nthat outlines a set of questions\\nto cover the topics you'd like to discuss.\\nPreparing the script is a way to define\\nand prioritize the research goals\\nand set a proposed structure for the conversation.\\nYou should use this script as a guide only\\nand plan on asking follow-up or separate questions\\nas they arise naturally in the discussion.\\nYou may have hypotheses to explore, but remember\\nthat interviews should be used to explore how's and why's\\nthat definitively prove or disprove points.\\n\\nYou may also want to run a flavor of ethnographic interview\\ncalled a Contextual inquiry.\\nIn a Contextual inquiry, you go\\nto the person's normal place of work or their home\\nand have them walk you through a set of tasks.\\nYou'll observe their process\\nand ask them follow-up questions as you go.\\nThe sessions may vary greatly based on what the user does.\\nBut it's still helpful to have a script ready,\\nwith a bank of topics to cover and questions to ask.\\nI recommend first writing out the specific questions\\nyou want answered with the research,\\nsuch as why someone signed up for a service\\nor how they chose their subscription level.\\n\\nYou can't get good information\\nby directly asking those questions,\\nbut listing out the goals will give you\\na sense for how much you want to cover\\nand help you prioritize the topics.\\nThere is no magic number of questions,\\nbut you typically want to plan for sessions\\nto be about 30 to 60 minutes.\\nI've found that's usually about three main topics.\\nYou may need to skip some topics\\nif you get deep into a discussion,\\nso knowing what you absolutely must cover,\\nversus what is nice to have,\\nwill help you regulate the discussion.\\n\\nWhen planning the flow of the discussion,\\nstart with an introduction that explains who you are,\\nsets expectations for the session,\\nand reminds participants how their input will help you.\\nIf you'll be recording the session\\nor need any other forms signed,\\ninclude that information upfront\\nand make sure to ask for permission.\\nYou can write this out in the script\\nto ensure that you don't forget any key points.\\nMake the first questions easy for participants\\nto answer, and not too personal,\\nsuch as explaining their job function.\\n\\nThis'll get the conversations started\\nand help the participant feel comfortable talking to you.\\nThen you'll want to move on to the meat of the interview,\\nwhich will cover the key topics you've listed out.\\nMore on how to craft the best questions in the next section.\\nMake sure that you build in time to wrap up the conversation\\nwith any lingering questions on your part.\\nGive the participants time to make any other comments\\nor ask questions, as there might be something\\nthey've been thinking that you didn't think to ask about.\\n\\nThis is also a good time to thank them\\nand remind them how they're helping the team.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:611883\",\"duration\":226,\"visible\":false,\"requiredForCertificateOfCompletion\":null,\"name\":\"Crafting the questions\",\"fileName\":\"546777_03_02_MM30_crafting\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Asking questions in the right way can help you get the most out of interviews. In this video, learn how to craft questions that will get you the most honest, detailed responses.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11790487,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- To create the questions,\\nstart with the list of research goals you have\\nand write out a series of questions\\nthat look at the issue with various angles.\\nFor instance, if you're trying to understand\\nwhy someone signed up for your service,\\nyou might start with a simple question\\nlike how did you decide to pick this service\\nbut you might also ask things like\\nwhat other services did you look at,\\nwhy didn't you choose those services,\\nwhat were the biggest factors for you to decide,\\nwhat were the pros and cons of each,\\nhow sure or unsure were you that you made the right choice,\\nwho helped you decide?\\nThese questions all explore the same decision\\nbut look at it from different angles.\\n\\nYou can also ask for the same information in different ways\\nto make sure that you're getting the whole story.\\nFocus on creating open-ended questions\\nstarting with who, what, where, when, why or how.\\nJust make sure that you ask one question at a time.\\nFor instance, you wouldn't want to ask\\nhow do you find and share interesting articles?\\nInstead, you'd want to first focus\\non asking about how they find articles\\nand explore that thoroughly then move onto the sharing task.\\n\\nSplitting the questions\\nensures that you'll uncover insights around both items\\nand won't confuse your participants.\\nTry to match the language style of your participants\\nand when in doubt, ask questions as simply as possible.\\nI also like to have participants recall something\\nand simply ask them to tell me about their experience.\\nMy favorite followup question is tell me more.\\nEven if you think there's a simple answer to your question,\\npeople will always tell you more detail and context\\nwhen you leave things open.\\n\\nYou also bake in assumptions when you ask closed questions\\nand the point of conducting interviews\\nis to uncover the things you don't already know.\\nTo that note, phrase the questions as neutrally as possible\\nso you don't introduce your biases.\\nYou'll need to practice this when conducting the interviews\\nbut it helps to start by writing the questions\\nin a non-leading way.\\nFor instance, don't ask how frustrating it might be\\nif someone receives an error when filling out a form\\nrather ask the participant\\nto remember the last time that they got an error\\nand tell you about it.\\n\\nNote that I didn't ask how they feel but rather left it open\\nto tell me anything that comes to mind.\\nThis way, you don't assume what participants were feeling\\nor thinking and you'll get information\\nabout what was most relevant to them at the time.\\nYou can also phrase the question\\nwith both the positive and the negative view embedded\\nlike saying how sure or unsure are you about your choice?\\nIt helps to ask participants about specific recent events.\\nRemember that human memory has limits.\\n\\nPeople will unconsciously make up a story\\nthat makes the most sense to them\\nand fill in what they can't remember.\\nWith the form error example,\\nask them first to recall the last time it happened to them.\\nGet them talking about the specific experience\\nand what they were trying to do.\\nYou'll get much more specific truthful information\\nif someone is recalling a specific interaction\\nrather than generalizing about all their past experiences.\\nIf you are exploring a particular interface or process,\\ntry the contextual inquiry approach\\nand have participants walk you through the tasks\\nthey'd normally perform.\\n\\nSituations will likely come up\\nthat you hadn't considered asking about\\nand you'll get an even deeper look\\ninto the participant's true experience.\\nRegardless of your research goals,\\nhaving a set of open, non-biased questions\\nwill help you get the most out of your sessions.\\n\\n\"}],\"name\":\"3. Study Logistics\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:611881\"},{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:611885\",\"duration\":175,\"visible\":false,\"requiredForCertificateOfCompletion\":null,\"name\":\"Session logistics\",\"fileName\":\"546777_04_01_MM30_logistics\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"The set up of an interview can impact how comfortable you and your participant are, which impacts how much value you're able to get from a session. In this video, learn what logistical considerations you'll need to make for the smoothest interview session\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7333014,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- I recommend recording interviews\\nso that you can truly focus on the discussion.\\nThen later, re-listen to key points\\nand choose snippets to help describe key takeaways.\\nWhen it's possible,\\nI also like to have a teammate\\nobserve the session and take notes.\\nThey can focus on capturing details,\\nand it's good to have a backup\\nin case there are technical glitches with the recording.\\nWhen the note taker is physically present,\\nyou can switch moderating and note taking to stay fresh.\\nIt can be nice to share the management\\nof the logistics too.\\n\\nHowever, having two people present\\ncan be a little overwhelming for participants\\nand is more costly to have two people travel.\\nSo, the second person can also watch remotely.\\nThat means they can be in the next room\\nor in a totally different location.\\nTo do so, you set up a laptop\\nwith the webcam facing the participant\\nand use a video conferencing tool\\nto share the session.\\nRecording also means that other teammates and stakeholders\\ncan observe the sessions live\\nor watch after the fact.\\nYou can use the same video conferencing tools\\nwhen you conduct remote interviews.\\n\\nJust be sure to test the setup.\\nLeave time to fix technical glitches\\nand provide clear instructions for participants.\\nIf you're observing and talking to participants\\nin their usual space,\\nyou may not have a typical desk setup,\\nso you may need to get creative\\nabout recording the session.\\nThe key things are to capture\\nas much of the participant's facial expressions\\nas possible without being intrusive\\nand to capture the audio of the session.\\nI've found a GoPro camera setup on a tripod\\nto be a good solution.\\n\\nYou may also be able to set up a few cameras\\nto take pictures at regular intervals.\\nYou may get some useless pictures,\\nbut you'll also get some authentic action shots.\\nWhen I just need audio,\\nI found the Livescribe pen to be very helpful.\\nIf you're going to be meeting your participant in person\\nbut not in their normal space,\\ntry to choose a neutral location\\nthat's conducive to a good conversation,\\nsuch as a quiet coffee shop.\\nI find it's easier to build rapport\\nif you're able to sit around a small table\\nor catty-corner with someone,\\nrather than on opposite sides of the desk\\nas that can be intimidating.\\n\\nPlay with the setup depending on the location\\nto encourage participants to feel their most comfortable.\\nEither way, I recommend taking several pictures\\nof your setup so you can refer back\\nwhen analyzing the sessions or planning your next.\\nRegardless of the type of session you run,\\nI always recommend running a pilot session\\nwith a teammate to test the camera position,\\naudio and video recording,\\nand any video conferencing setup.\\nBring extra charging cables and batteries\\nand have backup plans for recording devices,\\nbad connections, or pretty much anything else\\nthat could go wrong.\\n\\nEven experienced researchers\\nwill run into unexpected problems.\\nIt might seem like waste of time at the beginning,\\nbut it's always worth it in the end.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:611886\",\"duration\":186,\"visible\":false,\"requiredForCertificateOfCompletion\":null,\"name\":\"Conducting interviews\",\"fileName\":\"546777_04_02_MM30_conducting\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"The quality of your interviewing skills directly impacts how useful the information gathered is. In this video, learn to set the stage correctly and ask and follow up to questions effectively.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9453469,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Conducting interviews well is a skill\\nthat is easy in theory, but difficult in practice.\\nIt's important to master the art of probing\\nwithout leading to get the most out of the sessions.\\nThere are lots of things a researcher can do to ensure\\nthat they get the most out of UX interviews.\\nFirst, it's important to set the stage correctly,\\nas most participants won't be familiar with UX research\\nand they may feel uncomfortable or nervous.\\nBriefly explain your role to participants,\\nreminding them that you are there to learn about them,\\nnot to judge them and that there are\\nno right or wrong answers.\\n\\nTell them that you may ask questions that seem obvious\\nto them or ask questions multiple times to be sure\\nthat you're getting the full picture.\\nDescribe how you'll be taking notes or recording\\nthe sessions and what you'll do with the information.\\nMake sure to get their permission.\\nGive them logistical information,\\nsuch as how long you expect the session to take\\nand do all of this with a friendly tone\\nto help participants feel more comfortable and open to you.\\nOnce the discussion gets started,\\nremember that your main goal is to\\nlisten to participants, not to talk.\\n\\nEven if you've done a great job crafting the research plan,\\npeople will often tell you unexpected things\\nthat can be very useful.\\nInstead of charging on to your next question\\nin your plan, practice being silent\\nand allow users to expand on their points.\\nSilence is inherently uncomfortable for people,\\nso participants will often keep talking and you'll uncover\\neven more than you would have thought to ask about.\\nYou can encourage this kind of deep insight\\nwith a follow-up technique called the 5 Whys.\\n\\nThe 5 Whys is a very straightforward technique\\nused to explore the cause and effect relationships.\\nAll you do is keep asking participants\\nto expand on their previous point\\nuntil you have reached a root cause or natural end.\\nIt won't always take you exactly five follow-up questions.\\nIt might be only three or it might take more,\\nbut you want to keep digging until you learn something\\nthat speaks to the root of the problem\\nor the beginning of a solution.\\nHere's a shortened example from a series of interviews\\nI did, exploring a fitness application.\\n\\nWhat sorts of healthcare or fitness tools\\ndo you currently use?\\nWell, I had a step tracker,\\nbut I don't really wear it anymore.\\nOh, why not?\\nI guess I wanted more encouragement\\nand some suggestions about how to meet the goals.\\nWhy did you want more suggestions?\\nI never hit the goals.\\nTell me more about that.\\nActually, the goals it set for me\\nwere higher than I ever intended to do.\\nOh, why didn't you change the goals?\\nYou can do that?\\nIt turns out that the person I was talking to\\nhad no idea that they could set their own goals\\nand the real problem was that the interface\\nto set their goals was very hard to find and confusing.\\n\\nEach answer they gave me led to a further question,\\nwhich eventually led to the root of their problem\\nand the beginning of something that we could provide better.\\nFiguring out the right follow-up questions\\nand when to stop takes some practice,\\nbut you'll uncover much deeper insight this way.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:611887\",\"duration\":170,\"visible\":false,\"requiredForCertificateOfCompletion\":null,\"name\":\"Remaining neutral\",\"fileName\":\"546777_04_03_MM30_neutral\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"It can be easy to lead participants unintentionally in interviews. In this video, learn tips to remain neutral to get the most honest, unbiased feedback.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7692371,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- When listening to participants,\\nbe sure to be fully engaged and not make assumptions\\nabout their answers.\\nTheir interpretation of something\\nmay be different from yours, so ask for details\\nand be sure you're fully processing what they say.\\nParaphrase the main gist of what you think they're saying,\\nand repeat it back.\\nThen, they can either expand more,\\nclarify something that was off,\\nor confirm what you thought, and you can move on.\\nIf you're unsure about a word they used, what they said,\\nor how they see or do something, ask,\\nno matter how obvious it may seem,\\nor if you've asked it before.\\n\\nYou might even want to purposely ask the same question\\na few different ways to be sure you don't miss anything.\\nCommunication is tricky, and it's easy for people\\nto gloss over the things that they know best.\\nThe whole point of an interview is to explore\\nhow your participant thinks, so get them to slow down.\\nRemind them that you want to learn all about them,\\nand that they should treat you as complete beginners.\\nKeep in mind that every participant\\nhas a different communication style,\\nand set of values and context,\\nso what works for some participants\\nmay not work for another.\\n\\nBeside the obvious things, like making sure your language\\nand attire is appropriate for the setting,\\npay close attention to individual reactions\\nand do your best to shift your style on the fly.\\nFor instance, if someone seems to be slow to open up,\\nspend some extra time getting to know them\\nand identify something that they seem passionate about\\nbefore digging in to details.\\nTo nudge people to talk more, you can also remind them\\nhow helpful their insight will be.\\nYou'll get the best insight when your questions\\nflow naturally, which means the order may vary greatly\\nbetween participants.\\n\\nIt helps to have the key questions memorized\\nso that you can pull them in as it makes sense,\\nrather than planning to always ask the same thing\\nin the same order.\\nRemembering the key questions can also\\nhelp you steer participants back\\nto the main topics of conversation\\nif they get distracted or off on a tangent.\\nFinally, remember to be gracious and non-judgmental,\\nespecially when discussing sensitive topics.\\nEven if you're paying participants,\\nthey're giving you their time and opinions for your benefit.\\nParticipants are likely to share more\\nif they feel like a valued partner,\\nand they're likely to clam up\\nif they feel judged or embarrassed.\\n\\nIt takes some practice, but remain neutral,\\ncontrol your reactions, and pick strategic times\\nto remind participants that there are no right\\nor wrong answers.\\nReminder that when it's possible,\\nhave a colleague take notes\\nso that you can focus on the person you're talking to.\\nThat will allow you to read more body language cues\\nand the conversation should flow more smoothly.\\nIf you don't have that option, it's best to take\\nminimal notes during the session\\nand record the sessions so you can revisit details.\\n\\n\"}],\"name\":\"4. Interview Execution\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:611884\"},{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:611889\",\"duration\":137,\"visible\":false,\"requiredForCertificateOfCompletion\":null,\"name\":\"Organizing and analyzing data\",\"fileName\":\"546777_05_01_MM30_analyzing\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Once you've completed the interviews, you need to be able to organize and understand the data collected. In this video, learn to break down and organize data so you can look for patterns and insights.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6542089,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Once all the interviews are complete\\nyou'll have to tackle organizing the data\\nand synthesizing insights\\nthat the team can use moving forward.\\nI recommend that you include\\nas many people as you can who observed sessions,\\ntook notes, or are otherwise related to the project\\nin the initial sorting process.\\nOrganizing and synthesizing information together\\nmeans that you'll gather everyone's point of view,\\nand the whole team will better appreciate the process\\nand understand the outcomes of the research.\\nYou want to try to get everyone learning\\nfrom the research together\\nrather than working in a vacuum\\nand reporting back after the fact.\\n\\nHowever you took your notes,\\nyour team's first task is to deconstruct\\nthe mass of notes you have into individual insights.\\nHave each team member identify\\nuseful snippets of information,\\nsuch as what actions people take,\\nwhat their biggest problems are,\\npeople's needs or goals,\\nor particular quotes that capture a feeling or emotion.\\nThe key is to break everything down into singular facts\\nthat you can sort and combine to find patterns\\nand synthesize deeper meaning.\\n\\nI like to write each finding on a single sticky note\\nso I can start the next phase.\\nOnce you have individual pieces of data,\\nuse a wall or table to lay out all the notes\\nand start grouping related items into themes,\\nlike an open card sort.\\nTry having each person sort and resort multiple times\\nto see different connection points\\nand explore different ways\\nthat you could view the information.\\nAfter a few rounds from each person,\\nyou'll see what items always seem to fit together,\\nand you can start talking about the meaning\\nof main categories.\\n\\nYou may end up with very high level categories,\\nlike overall user goals,\\nor break big categories into multiples,\\nsuch as two main sets of goals.\\nYou might also be quite granular,\\nlike identifying issues with a specific part of a process.\\nThere's no right or wrong answer,\\nor target number of categories.\\nBut in general, the more you already know\\nabout your participants,\\nthe more granular your categories can be.\\nOnce you have the categories set\\ndo one last group categorization\\nto put each finding in a meaning bucket.\\n\\nAt this point you'll be able to view high level patterns.\\nYou'll be well-prepared to pull deep insights from the data.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:611890\",\"duration\":177,\"visible\":false,\"requiredForCertificateOfCompletion\":null,\"name\":\"Summarizing findings\",\"fileName\":\"546777_05_02_MM30_summarizing\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Research is powerful only when it's shared with and used by a team. In this video, learn how to summarize and share what you've found to improve your products.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10123029,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Once everything is sorted,\\nyou still need to synthesize the data\\ninto actionable takeaways.\\nHaving just a list of general user goals or motivations\\ndoesn't necessarily tell you and your team what to do next.\\nYou'll want to look at each finding\\nand discuss what it means for the team.\\nYou'll want to ask questions like\\nwhat opportunities to improve\\nor offer a new experience exist,\\nhow could those opportunities be tied to business goals?\\nYou don't need to define solutions right away\\nbut you want to end up with a list of actions to take next.\\n\\nFor instance, you may learn\\nthat your application's onboarding process is lacking\\nand the action items are to do a detailed usability test\\nand to brainstorm compelling ways\\nto move users from sign up to first action.\\nThe interviews might give you some ideas\\nabout how to improve the interaction\\nbut you don't have to rely on them\\nto prescribe the solutions.\\nIf your aim is to create personas,\\nyou'll want to go through the same data organization process\\nwith any quantitative data you have\\nsuch as site usage or demographics\\nthen group all identifying characteristics\\nlike context, behaviors, goals, motivations and challenges.\\n\\nOnce you've identified those patterns,\\nsummarize the different personas.\\nYou may want to find a representative picture\\nor set of quotes\\nand create stories that explain your product in their life.\\nYour goal is to create a set of documents\\nthat describes the key differences between user types.\\nYou can learn more about personas\\nin the course UX Design Techniques Creating Personas.\\nOnce you've summarized your key takeaways,\\nyou need to be sure your insights get shared,\\ndigested and used by the team.\\n\\nInvolving as much of the team as possible\\nin the data analysis means you can have\\nan ongoing discussion about the interpretations\\nand there's no need for a big reveal in a report.\\nWhile you should still document\\nthe basic research plan and takeaways\\nin case you want to revisit in the future,\\nI always like to recommend having a research debrief\\nto discuss takeaways and their implications\\nrather than relying on a report.\\nYou may also need to provide formal documents\\nand deliverables especially if you're a consultant.\\n\\nIf so, I recommend following the same basic structure report\\nthat I recommend for all sorts of UX research,\\nan executive summary of process and key findings\\nthen a detailed description of methodology and analysis\\nwith a mixture of visuals and text\\nto appeal to the different ways that people best learn\\nand process information.\\nFor more on creating UX research reports,\\ncheck out presenting and incorporating results\\nfrom UX Research Fundamentals.\\nThe most important thing is to ensure that the whole team\\nunderstands the people you're building for\\nand the insights you pulled from your research.\\n\\nYou want to be sure that the information gets used,\\nshape product and design decisions moving forward.\\n\\n\"}],\"name\":\"5. Data Analysis and Summary\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:611888\"},{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:611892\",\"duration\":33,\"visible\":false,\"requiredForCertificateOfCompletion\":null,\"name\":\"Next steps\",\"fileName\":\"546777_06_01_LA30_nextsteps\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7744886,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Thanks so much for watching\\nand learning about conducting interviews.\\nThis course should've given you all the information you need\\nto get started planning, conducting,\\nand analyzing UX interviews.\\nThey can take some practice,\\nbut they're invaluable for understanding your users.\\nIn turn, you'll be able to craft experiences\\nthat better suit their needs,\\nand help your business succeed.\\nFor a fantastic deep dive into interviewing users,\\nI recommend Steve Portigal's book, Interviewing Users.\\n\\nThanks again and good luck getting started.\\n\\n\"}],\"name\":\"Conclusion\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:611891\"}],\"size\":107732386,\"duration\":2121,\"zeroBased\":false},{\"course_title\":\"UX Deep Dive: Usability Testing\",\"course_admin_id\":2825368,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":2825368,\"Project ID\":null,\"Course Name\":\"UX Deep Dive: Usability Testing\",\"Course Name EN\":\"UX Deep Dive: Usability Testing\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"Take a deep dive into usability testing techniques and methodologies for user experience (UX) design projects with research expert Amanda Stockwell. In this course, you can learn which types of tests\u00e2\u20ac\u201dremote or in person, moderated or unmoderated, task-based or unstructured\u00e2\u20ac\u201dto use for specific types of projects and users. Amanda also shares tips on conducting usability tests, from recruiting participants to moderating sessions. Plus, learn how to analyze and present the results of your testing to the rest of your organization.\",\"Course Short Description\":\"Take a deep dive into usability testing techniques and methodologies for user experience (UX) design projects.\",\"Content Type\":\"SKILLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":5287222,\"Instructor Name\":\"Amanda Stockwell\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"President of Stockwell Strategy\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2020-05-07T00:00:00\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"Yes\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/ux-deep-dive-usability-testing\",\"Series\":\"Deep Dive (X:Y)\",\"Limited Series\":null,\"Manager Level\":\"General\",\"LI Level\":\"Beginner + Intermediate\",\"LI Level EN\":\"Beginner + Intermediate\",\"Sensitivity\":null,\"Internal Library\":\"Creative\",\"Internal Subject\":\"User Experience\",\"Primary Software\":null,\"Media Type\":\"Video\",\"Has CEU\":\"Yes\",\"Has Exercise Files\":\"Yes\",\"Visible Duration\":1618.0,\"Visible Video Count\":10.0,\"Contract Type\":\"STANDARD\"},\"sections\":[{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2306398\",\"duration\":45,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"All about usability testing\",\"fileName\":\"2825368_00_01_WL30_welcome\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Get an introduction to the course and whet your appetite for the rest.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8882377,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Usability testing is one  \\n of the most commonly used UX research methods,  \\n and for good reason.  \\n Usability testing is the gold standard  \\n for evaluative research, and it's a flexible enough method  \\n to gather a variety of data.  \\n It's pretty easy to get started,  \\n but it's also easy to get caught up in some common pitfalls.  \\n I'm Amanda Stockwell.  \\n Welcome to the Usability Test Deep Dive.  \\n This course is for those of us who are already familiar  \\n with the basics of usability testing,  \\n and want to level up skills  \\n to be even more effective researchers.  \\n Join me as I discuss strategic considerations  \\n and practical tips to help you get the most out  \\n of your usability testing efforts.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2306399\",\"duration\":54,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Recap of usability testing\",\"fileName\":\"2825368_00_02_MM30_recap\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4011520,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - A usability test is simply a tool to evaluate the ease  \\n of use of a product, service, or interface.  \\n At the core, a usability test involves observing  \\n representative users as they perform tasks,  \\n and assessing their experience and interactions.  \\n Like most UX tools, there are many variations,  \\n and it's important to understand those nuances  \\n so you can plan for your particular situation.  \\n While the general goal of usability testing  \\n is to assess usability, you might be doing so  \\n in vastly different contexts that change  \\n how you ought to plan, run, and analyze the sessions.  \\n If you're not already familiar with usability testing,  \\n now would be a great time to check out UX Foundations:  \\n Usability Testing, which covers the basics.  \\n In this course, I want to guide you through a discussion  \\n of different types of usability tests and their usage,  \\n and share things I've learned over more  \\n than a decade conducting usability tests.  \\n \\n\\n\"}],\"name\":\"Usability Testing\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:2307412\"},{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2309095\",\"duration\":265,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Usability test locations\",\"fileName\":\"2825368_01_01_MM30_locations\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Learn about the difference between remote and in-person testing and how to identify what circumstances are better suited for each.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":15703297,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Before we start diving into the specifics  \\n of running usability tests,  \\n let's take a step back to examine  \\n the types of usability tests, so we can understand  \\n the nuances and set ourselves up for success.  \\n The first variant in the usability test is location.  \\n Usability tests are traditionally conducted in person,  \\n meaning that you are physically sitting  \\n next to the participant during the session.  \\n In-person sessions have traditionally been run  \\n in a usability lab, where you have a dedicated room  \\n for the moderator and participant  \\n that has audio and video recording,  \\n and another room for observers,  \\n where the information is streamed.  \\n Yes, I'm talking the dreaded one-way mirror set up.  \\n These Labs might be at a third-party research facility,  \\n or even just a dedicated room of an office.  \\n If you don't have a lab, or need to bring the research  \\n to the participants, you might still conduct the sessions  \\n physically next to the participants.  \\n That could be as simple as sitting next to someone  \\n at their desk, or meeting them at a third-party location  \\n like a library or coworking space.  \\n You can still record audio and maybe video.  \\n It's just not quite as formal of a dedicated space.  \\n In recent years, it's also become much more possible  \\n and popular conduct usability tests remotely,  \\n meaning that you're connected digitally,  \\n but not physically present with the participants.  \\n There are many good video conferencing tools  \\n that allow you to see participants' faces  \\n and share and record the screen of any member of the party.  \\n So how to decide where to conduct sessions?  \\n Well, the answer as with most things in UX,  \\n is that it depends.  \\n Being in the same space as your participants  \\n has several benefits and is often seen as the gold standard.  \\n One large benefit is that you can more easily  \\n build rapport with participants.  \\n You can shake their hand, look them in the eye,  \\n smile and greet them.  \\n You may make a bit of small talk and be able  \\n to feel them out before you get too far into the session.  \\n More on this later.  \\n You can also observe their body language  \\n and facial expressions, which don't always match  \\n what they'll say.  \\n We'll talk more about that too.  \\n The lab setting is great for this kind of close observation  \\n and allows you to easily record audio and video  \\n so you can widely share and later revisit the sessions.  \\n It's also easier to use lower fidelity artifacts  \\n like paper prototypes if you're physically with someone  \\n and can provide some extra context.  \\n However, a lab isn't the ideal setting when the context  \\n someone is working in will greatly impact  \\n how they use something.  \\n Say you're working on improvements to a traffic  \\n and navigation app.  \\n How someone acts looking at an app while sitting  \\n at a table, may be very different than when  \\n they're trying to navigate rush hour traffic in their car.  \\n The category of research where you observe people  \\n in their own space is called ethnography.  \\n While it can create logistical challenges,  \\n it can also help you paint a richer picture  \\n of your user and how they use your product in context.  \\n If you don't have the budget to conduct formal recruiting,  \\n or don't have access to a dedicated space,  \\n you might use the guerrilla tactics of intercepting people  \\n in a public setting.  \\n Recruiting and conducting sessions in public spaces  \\n is best for when your product doesn't require  \\n particular domain expertise, you're not testing  \\n particularly sensitive material,  \\n and your budget doesn't leave you another option.  \\n On the other hand, even if you do have the opportunity  \\n to meet participants in person,  \\n remote sessions can have some advantages.  \\n The first is that remote work allows you  \\n to access participants who are geographically spread out  \\n without extra time or costs.  \\n The world is ever shrinking, and many of our products  \\n and services serve a large base of people.  \\n It's essential to be sure that you're incorporating  \\n feedback from multiple cultures, locations and contexts  \\n so as not to bias your results.  \\n Conducting sessions remotely can also save  \\n both the research team and the participant's time.  \\n You cut out commuting and set up time,  \\n and it can allow the researcher to more flexibly schedule  \\n sessions over a period of time.  \\n You could even conduct a few sessions  \\n of a research series in person and a few remotely,  \\n in order to access the participants you need.  \\n Or alternate between in-person and remote efforts  \\n depending on timing and resources.  \\n Consider switching it up occasionally to try out  \\n different methods and compare the results.  \\n Before you plan your usability test,  \\n carefully consider the context of your project  \\n and what location would be most beneficial and realistic.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2306400\",\"duration\":225,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Moderated vs. unmoderated usability tests\",\"fileName\":\"2825368_01_02_MM30_unmoderated\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Learn about the difference between moderated and unmoderated testing and to identify what circumstances are better suited for each.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12549796,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Along with the option to conduct sessions remotely,  \\n more and more tools have been popping up  \\n to conduct unmoderated sessions,  \\n where you write out individual tasks for the users,  \\n and the participants complete each task on their own time.  \\n A tool provides the instructions, shows the questions,  \\n and records the actions of the user.  \\n There is no direct interaction between the participants  \\n and the researcher, which means that you need to plan  \\n unmoderated sessions even more carefully.  \\n They're also most appropriate for certain scenarios only.  \\n Because you pre-write the introduction, the core tasks,  \\n and the followup questions, unmoderated tests  \\n are best for live or very functional work  \\n that requires very little explanation.  \\n When you show a low fidelity or early stage prototype  \\n in person, you can explain limitations and provide context  \\n along the way.  \\n It's possible to navigate around known issues  \\n or work around empty areas when you moderate.  \\n Unmoderated sessions are best suited  \\n for straightforward, clear tasks  \\n that don't leave much room for interpretation,  \\n like assessing how easily someone can find  \\n a certain sort of a product on an eCommerce page,  \\n or how long it takes to check out  \\n on one site versus another.  \\n Participants are frequently put into artificial situations  \\n in usability tests anyway, but without a moderator present,  \\n it's even easier to fake things or tune out.  \\n Tasks that require emotional engagement or creativity  \\n are unlikely to get an authentic response  \\n in an unmoderated test.  \\n You also need to carefully construct the tasks  \\n to be sure they will get you the results you want.  \\n Turning goals into clear tasks already takes practice  \\n to master, and all the normal best practices apply.  \\n But writing unmoderated tasks is even more difficult.  \\n You have to explicit about you want the participant to do  \\n and when they should stop.  \\n And provide clear, specific, and realistic instructions,  \\n all without being too obvious.  \\n Make sure the tasks are written  \\n as directions, not questions.  \\n And be precise in the instruction.  \\n Let's say we were testing the LinkedIn Learning site.  \\n A good task might be something like,  \\n find a UX related LinkedIn Learning course  \\n you haven't yet watched, and stop when you get  \\n to a brief description of the course.  \\n Remember, participants won't have a chance to clarify,  \\n and you won't have a chance to probe.  \\n So if they misinterpret, the task may be wasted.  \\n It's especially important to pilot test unmoderated studies  \\n so that you can get the most authentic useful feedback.  \\n You also don't get the chance to probe,  \\n so make sure you include followup questions  \\n that are just as thoughtfully crafted.  \\n With all those limitations in mind,  \\n unmoderated studies also have some great benefits.  \\n You can run sessions in parallel and therefore collect  \\n many responses in a short amount of time.  \\n You save time and have access to a much larger  \\n and more spread out participant base  \\n than you might otherwise.  \\n You can usually offer a lower incentive  \\n to save yourself some money as well.  \\n I've used unmoderated studies to get super quick feedback  \\n from across the globe literally overnight.  \\n Everything from response to a new design direction,  \\n to interpretation of messaging options, to gut-checking  \\n which of an interaction pattern best suited our goals.  \\n These broad, quick studies have been especially useful  \\n when working in agile settings,  \\n and we needed data super fast.  \\n I also like to use unmoderated studies  \\n when I'm benchmarking and comparing the results over time.  \\n That makes it easy to set up  \\n and assures the questions remain consistent.  \\n As always, carefully consider the core goal  \\n and context of your research goals  \\n to determine the right kind of test for you.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2306401\",\"duration\":172,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Using usability tests to explore\",\"fileName\":\"2825368_01_03_MM30_explore\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Learn about the difference between totally task-based sessions and more unstructured usability tests and how to decide what format works for what situations.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12105218,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - As we've discussed,  \\n usability tests involve observing representative users  \\n as they perform tasks.  \\n We typically think of this as evaluative research,  \\n which is meant to assess how well a solution works.  \\n We've also been discussing the need to carefully determine  \\n and craft realistic scenarios and tasks  \\n for the users to complete.  \\n But what if you don't know  \\n what tasks your users are trying to do in real life?  \\n What if you don't know what a realistic scenario is?  \\n There are other research methods  \\n like diary studies or contextual inquiries,  \\n to help you uncover user needs and behavior,  \\n but you can also modify usability test efforts  \\n to be more generative and help you learn  \\n about user's contexts.  \\n To do so, you'll remove the very defined tasks  \\n from your plan.  \\n You'll still have research goals and target areas to cover,  \\n but the tasks will be more general  \\n and more focused on hearing from the user  \\n how they accomplished a goal,  \\n than assessing a particular path for interaction.  \\n For instance, in a traditional test of an e-commerce site,  \\n you might have one task that is dedicated  \\n to assessing the search function and one that is designed  \\n to get participants to browse with categories.  \\n In a more exploratory usability test,  \\n you might ask users  \\n to generally identify a product that fits their needs  \\n and then observe which path they take,  \\n probing along the way  \\n to understand why they did it that way, what's preferable,  \\n and understand their decision-making process.  \\n You still want to understand  \\n how well the process works for them,  \\n but you're also evaluating the product or service  \\n more holistically and getting feedback  \\n about what they really do,  \\n rather than breaking it down to assess one piece at a time.  \\n Because of the need to follow up,  \\n you'll need to moderate this kind of exploratory test  \\n and be ready to be flexible during the sessions.  \\n You may end up uncovering totally new insights  \\n or discovering areas  \\n that you hadn't realized needed attention.  \\n Let's say you're working on a presentation tool  \\n and ask people to tell you about the images they include.  \\n You might've thought  \\n you wanted to explore the editing process  \\n but find out that your users  \\n actually don't really like to add pictures.  \\n Your new goal becomes to better understand that decision  \\n and learn more about their context,  \\n rather than to assess the ease of use of the feature,  \\n they wouldn't use.  \\n This sort of exploratory formative usability testing,  \\n can be done at any time there is an existing solution  \\n and you want to learn more  \\n about real behavior or motivation users have.  \\n That doesn't necessarily mean  \\n you have to test something live,  \\n but is often done in early stages of a redesign,  \\n assessment of a live product or early in the process  \\n of building something brand new.  \\n Exploratory unstructured usability testing,  \\n isn't the be-all and end-all way  \\n to understand user's contexts  \\n but it can be an extra approach in your research toolbox.  \\n \\n\\n\"}],\"name\":\"1. Which Type of Test?\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:2309097\"},{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2306402\",\"duration\":225,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Participant recruiting considerations\",\"fileName\":\"2825368_02_01_MM30_recruit\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Learn about choosing and recruiting the right kind and number of participants for sessions. Get a better understanding of who to target and how many people to include in your studies.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":13320962,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Many people who are new to usability testing  \\n struggle most with questions about the participants.  \\n Who should you target?  \\n How many participants do you need?  \\n And how do you find them?  \\n There's plenty of material that can guide you  \\n through the basics.  \\n Understanding nuances can help you ensure  \\n you get the right people in your study,  \\n and therefore, the highest quality results for your team.  \\n One of the most common questions is who to recruit  \\n and how exact do you need to be  \\n in recruiting representative users.  \\n Lots of new researchers assume  \\n that you can include any general participant  \\n to identify usability issues.  \\n If you're working on something like voting machines  \\n or a general e-commerce site,  \\n then yes, your audience truly could be just about anyone.  \\n Maybe you just need to know which  \\n of two Add to Cart interactions is easier.  \\n Any member of the public should be able to provide you  \\n some feedback there.  \\n But more than likely, you're building something  \\n for a specific group of people  \\n who have a particular set of knowledge and experiences  \\n that impacts how they interact.  \\n Let's say you're working on a portal for medical providers  \\n to communicate context about diagnoses to their patients.  \\n Nurses and doctors are likely  \\n to use a more clinical set of language  \\n and have a deeper understanding  \\n of how to categorize ailments than a typical patient.  \\n But the portal needs to work for both type of user.  \\n Sure, a random person could give you feedback  \\n on the input part of the tool.  \\n And you'd likely identify some core issues.  \\n But you're likely going to miss nuances in the feedback  \\n that a medical professional would be able to provide.  \\n The closer your test participants are  \\n to the real users, the more authentic their feedback  \\n and higher the quality of insights you'll gain.  \\n If you have multiple different sets of user types,  \\n like the patients and providers here,  \\n make sure that you recruit participants from each group  \\n to include in your study.  \\n That leads me to my next recruiting tip,  \\n which is around the number you really need to include.  \\n You've probably heard the rule  \\n that you ought to have five users in your usability study.  \\n I'm not here to fight with that.  \\n But I want to shed a little extra light and clarity  \\n so that you can make the best choice for your work.  \\n That rule came from work that Jakob Nielson  \\n and Tom Landauer did in the '90s.  \\n They created a mathematical model that suggests  \\n you can find 85% of usability problems  \\n after five similar participants.  \\n They suggested that instead of conducting single,  \\n large usability tests, the most effective route  \\n would be to conduct smaller, iterative studies  \\n with three to five participants each  \\n to maximize cost and benefit.  \\n If there are distinct user types,  \\n they suggest three to four participants  \\n from each category per round.  \\n Over the years, that extra contact has been lost  \\n and people just hear that five is the magic answer.  \\n Five participants is a good starting point.  \\n But please keep in mind that you will not find  \\n every issue after talking to that few participants.  \\n Furthermore, the rule only applies  \\n when you're talking about the same type of user.  \\n And if you're looking to establish baselines  \\n or compare quantitative data,  \\n you're likely going to want to increase  \\n that number even more.  \\n A good gut check on the right number of participants  \\n is feedback repetition.  \\n Once you start to hear the same thing over and over,  \\n you probably ought to spend your time addressing feedback  \\n rather than collecting more.  \\n If you have a more diverse set of users than you thought,  \\n that could be eight or 10 or even more sessions.  \\n If you start to hear all the same things  \\n after just a few participants,  \\n you can feel confident that you need to address  \\n those items first.  \\n Recruiting the right participants  \\n and getting the right sample size is key  \\n to making sure your usability sessions  \\n are the most effective for you.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2307411\",\"duration\":148,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Usability test logistics and preparation\",\"fileName\":\"2825368_02_02_MM30_test\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Explore broad considerations for planning and running sessions and some things to avoid. Prepare to run effective, efficient sessions.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7995222,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - While it may seem obvious, carefully thinking  \\n through the logistics and small details of your study  \\n can really impact the quality of the data you gather.  \\n The schedule of the sessions is one  \\n of the easiest things for you to control,  \\n and can help make sure you get the most  \\n out of your sessions.  \\n I don't recommend more than six sessions  \\n in a day if you can help it.  \\n Moderating requires deep attention and it can be exhausting.  \\n We'll talk more about moderation tips,  \\n but schedule-wise, the most effective tactic is  \\n to spread sessions out over at least a few days.  \\n I also recommend giving yourself ample time  \\n in between sessions.  \\n You'll need this time to break for the obvious things,  \\n like snacks, but you can also use this time  \\n to take care of distractions, like email,  \\n touch base with teammates and stakeholders,  \\n and adjust anything within the test.  \\n I especially like to schedule a quick debrief  \\n with observers after each session  \\n to capture first impressions  \\n and discuss anything we might want to adjust  \\n for the next round.  \\n This built-in time also gives you wiggle room,  \\n if someone ran late or you're having trouble  \\n getting a chatty participant to wrap up.  \\n You'll also want to think through how you communicate  \\n with observers and stakeholders during the sessions.  \\n I'd always recommend recording the sessions  \\n and sharing the video with team members,  \\n but it's also good to livestream  \\n and allow others to have the opportunity  \\n to ask you questions or suggest followups in realtime.  \\n You might want to set up a group chat or text.  \\n Just make sure you don't get too distracted  \\n during the session.  \\n I recommend that observers document all their questions  \\n and notes along the way, then send one communication  \\n to the moderator to circle back to  \\n at the end of the session.  \\n Sometimes the questions end up being answered,  \\n or a new thread is uncovered, but it ensures  \\n that the stakeholders are engaged and have the opportunity  \\n to ask for followup.  \\n I'd recommend that you test this communication method  \\n while you're testing the other logistics of your study.  \\n If you're in-person, that means things  \\n like making sure the video and audio are recording correctly  \\n and placement of chairs works.  \\n If you're using a remote tool  \\n or conducting an un-moderated session,  \\n be sure to walk through all the programs and logins.  \\n No matter what, run a pilot study.  \\n This will help you double check logistical things  \\n like accounts, connections, and recording settings,  \\n catch any unclear questions or awkwardness  \\n in the question order, and get the truest sense of timing.  \\n A little extra preparation  \\n before running usability tests makes them go much smoother.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2306403\",\"duration\":232,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Tips for moderating effective usability sessions\",\"fileName\":\"2825368_02_03_MM30_tips\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Discover specific tips for moderating sessions in an unbiased, effective way. These tips will help you ensure that you are getting the most authentic feedback so that your sessions are most valuable to you and your teams.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":15387906,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Effectively moderating usability tests  \\n is more art than science,  \\n and is deceptively simple-seeming.  \\n The best way to get better at running usability tests  \\n is to practice, but make sure you keep these tips in mind.  \\n It's very important to set the stage with participants  \\n and focus on building rapport early.  \\n The first few minutes of a session set the tone,  \\n so aim to help the participants feel  \\n as comfortable as they can.  \\n Clearly describe who you are, what your goal is,  \\n and what your expectations are about the session.  \\n Reiterate that you are not testing them,  \\n but you're looking for honest feedback on what works well  \\n and, more importantly, what doesn't.  \\n Let them know that you might ask follow-up questions  \\n that seem obvious, or abstain from  \\n answering their questions right away.  \\n They're free to ask for clarification,  \\n but you won't lead them down a particular path.  \\n Assuming that you aren't the one who designed  \\n what you'll be testing, let them know that you'll  \\n be passing on the feedback to the team,  \\n and that it's your job to make the overall product better.  \\n Err on the side of more explanation than not,  \\n since it's likely that participants won't  \\n be super familiar with the process,  \\n and that can be some social pressure  \\n in the situation to get things right.  \\n During the sessions, use the tasks and the test plan  \\n as a guide but not as rote text.  \\n The best feedback comes from authentic experience,  \\n so if the opportunity comes to cover a task out of order,  \\n go for it.  \\n You may also hear feedback about a related area,  \\n or unexpected path that you may want to explore.  \\n Use your judgment and don't abandon the goals of the study.  \\n But be prepared to be flexible.  \\n Actively remind yourself to relax as much as possible  \\n and allow yourself to be personable.  \\n Participants will take their social cues from you.  \\n If you appear comfortable,  \\n they will automatically be more so.  \\n Just be mindful of your reactions.  \\n For instance, if you vigorously nod when they  \\n start talking about things they like,  \\n they'll continue to do so.  \\n Try to keep a neutral expression and tone.  \\n And importantly, remember to talk as little as possible.  \\n You want to make sure the participants understand  \\n what you're asking them to do and then you want  \\n to give them space to go through,  \\n talk aloud, and work things out.  \\n Silence is uncomfortable for humans.  \\n And that's exactly the point.  \\n See?  \\n Didn't you think something was wrong?  \\n We're hardwired to want to fill empty space.  \\n You want to give the participants the opportunity  \\n to fill that space, rather than doing so yourself.  \\n This prevents you from biasing or leading the participants,  \\n and allows you to uncover new information from them.  \\n It's okay to repeat information back to participants  \\n in order to be sure you've heard them correctly.  \\n Ask for clarifications, or probe on an answer.  \\n In fact, you'll often get the most insightful information  \\n by following up on a response and getting people  \\n to explain the context behind it.  \\n Aim for open-ended questions and allow the user  \\n to guide where the discussion goes.  \\n If you get too off track, you can navigate them back  \\n with an orienting question about the original task,  \\n or prompting them to move on to the next.  \\n I highly recommend watching recorded sessions of yourself.  \\n It feels totally awkward,  \\n but even if you think you've done pretty well,  \\n you're likely to spot a place you could improve.  \\n Nearly every researcher I know has cringed through hours  \\n of watching themselves, and been able to improve their flow.  \\n When reviewing, pay attention to  \\n the ebb and flow of conversation,  \\n rather than the respondents particular answers.  \\n Notice where you jump in early, and look for areas  \\n you could've stepped back or provided more guidance.  \\n Moderating well is a tricky balance  \\n of guiding the discussion without leading  \\n to answers or getting too far off course.  \\n Give yourself time to prepare,  \\n find opportunities to practice,  \\n and constantly evaluate your sessions to improve.  \\n \\n\\n\"}],\"name\":\"2. Running the Tests\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:2306405\"},{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2309096\",\"duration\":216,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Identifying and sharing true insights\",\"fileName\":\"2825368_03_01_MM30_insight\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Dive into the details of analyzing different sorts of collected data and discover the necessity of collaborating to be sure insights found can be acted upon. This information should help you build knowledge around data analysis and support for ongoing research within your organization.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":13091244,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Regardless of what sort of usability test your ran,  \\n you're likely to end up with a big set of raw data  \\n to analyze and synthesize into findings and recommendations.  \\n There's a lot of content out there  \\n about how to analyze usability test data,  \\n but the bigger challenge and real opportunity  \\n is in prioritizing your insights  \\n and turning them into actionable change.  \\n To help with this, I like to categorize insights  \\n by size and impact,  \\n and adjust how I present them accordingly.  \\n Very generally, I think of insights being on a continuum  \\n or immediate term practical application  \\n to longer term larger scale impact.  \\n On the immediate term end,  \\n you might have things like users expecting  \\n a different interaction for a particular pattern,  \\n or going to the wrong spot  \\n to look for something consistently.  \\n You know you can provide a tactical recommendation  \\n that would address that issue  \\n with a relatively small effort.  \\n For instance, say we were running a test  \\n on an account settings page  \\n and found that users got confused between two icons.  \\n We could recommend changing at least one of the icons  \\n and then retesting.  \\n For this sort of feedback, I clearly identified the issue,  \\n the recommendation, the next step,  \\n and then I often share directly with the team  \\n to make changes.  \\n In the right circumstances, I'll even go so far  \\n as to immediately add it to the backlog  \\n for the team who would address it.  \\n While, of course you want there to be wide visibility  \\n into what you've found,  \\n your primary goal with this sort of finding  \\n is to provide straightforward, tactical advice  \\n that the team can implement right away.  \\n On the other end of the spectrum are larger scale insights  \\n that might influence the direction  \\n of the whole product or project.  \\n You might not know an immediate solution  \\n or even know the impact,  \\n but you've gotten a clue that you need to dig deeper.  \\n For instance, you might learn that your target users  \\n can easily perform the tasks that you've asked them to do,  \\n but they report that their goals are shifting  \\n and they don't do some of those tasks anymore.  \\n In this case, there won't be straightforward recommendations  \\n for the team to take next.  \\n Instead, you're likely going to shift into advocate mode,  \\n pushing for further, deeper research  \\n to help guide the next steps.  \\n You still want to report what you've found,  \\n but you want to present the findings as a pathway to explore,  \\n not as final steps.  \\n This means the format to share your insights may change.  \\n Rather than writing a straightforward report  \\n or adding items to a backlog,  \\n you might want to make presentations to larger teams  \\n or higher level stakeholders,  \\n or schedule brainstorming sessions.  \\n Especially when presenting the sort  \\n of larger, more strategic insight,  \\n it's important to tailor the information to your audience  \\n and find ways to connect it to larger business  \\n and emotional context.  \\n This is where it might be useful  \\n to have video of a frustrated user  \\n or a sound clip declaring total disinterest.  \\n You should always be serving as the champion for the users,  \\n but insights that require further work  \\n also require further advocacy.  \\n You're also likely to have insights  \\n that fall in the middle of the spectrum.  \\n Say you've clearly identified a core usability issue  \\n but you're not sure of the design pattern to move forward  \\n and need to advocate some more solution exploration.  \\n No one kind of insight is more important than the other.  \\n It's important to understand the relative categories  \\n and be pragmatic for the situation that you're in.  \\n Remember that the format of sharing your findings  \\n is more dependent on the team and organizational structure  \\n than the type of finding.  \\n It's your job to help your team understand  \\n and utilize what you've learned in a way that makes sense.  \\n \\n\\n\"}],\"name\":\"3. Analyzing the Test\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:2309098\"},{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2306404\",\"duration\":36,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Practice makes perfect\",\"fileName\":\"2825368_04_01_LA30_practice\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8009131,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Thank you so much for tuning in  \\n to my usability testing course.  \\n This course should have given you practical tips  \\n to improve your research practices,  \\n and gain the best insights from your testing efforts.  \\n If you have specific questions for me,  \\n ask in the Q&A section of this course.  \\n I may end up doing a follow up video  \\n that answers common questions.  \\n And know that this is just one  \\n of a series of deep dives into research best practices.  \\n So be on the lookout for other courses  \\n to improve your research endeavors.  \\n As with all research,  \\n the best way to improve is to practice.  \\n So get out there and start testing.  \\n \\n\\n\"}],\"name\":\"Conclusion\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:2307413\"}],\"size\":0,\"duration\":1618,\"zeroBased\":false},{\"course_title\":\"Remote User Testing with UserTesting.com\",\"course_admin_id\":3005392,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":3005392,\"Project ID\":null,\"Course Name\":\"Remote User Testing with UserTesting.com\",\"Course Name EN\":\"Remote User Testing with UserTesting.com\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"Knowing how to conduct effective user tests gives you an upper hand in product development. No matter what your product or service is, fixing problems with it early in the design process is cheaper and easier than after it\u00e2\u20ac\u2122s been launched.&lt;br&gt;&lt;br&gt;In this course, UX expert Lija Hogan shows you how to conduct effective moderated and unmoderated remote user tests with UserTesting.com. Learn about the basics of gathering insights from people and how it supports design projects. Explore the differences between moderated and unmoderated testing techniques, utilizing both qualitative and quantitative methods. Get tips on how to structure moderated and unmoderated remote user test sessions, recruit the right participants, and conduct your own user tests on the UserTesting platform, gathering insights and planning for action to drive better design for better results.\",\"Course Short Description\":\"Learn about how to plan, structure, and conduct moderated and unmoderated remote user tests with UserTesting.com.\",\"Content Type\":\"TOOLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":20577000,\"Instructor Name\":\"Lija  Hogan\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"Customer Experience Consultant\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2022-01-24T00:00:00\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"Yes\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/remote-user-testing-with-usertesting-com\",\"Series\":\"Project\",\"Limited Series\":null,\"Manager Level\":\"Individual Contributor\",\"LI Level\":\"Beginner + Intermediate\",\"LI Level EN\":\"Beginner + Intermediate\",\"Sensitivity\":null,\"Internal Library\":\"Creative\",\"Internal Subject\":\"User Experience\",\"Primary Software\":\"Adobe XD\",\"Media Type\":\"Video\",\"Has CEU\":\"No\",\"Has Exercise Files\":\"Yes\",\"Visible Duration\":5233.0,\"Visible Video Count\":25.0,\"Contract Type\":\"PERPETUAL\"},\"sections\":[{\"duration\":654,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3047260\",\"duration\":88,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Get feedback from users remotely\",\"fileName\":\"3005392_en_US_00_01_WX30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"This video describes the value of understanding users and the experience they have using products and services in the locations where they actually live: in their homes, offices, and other locations. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4350476,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Lija] We live in a world  \\n where the cost of fixing an error after development  \\n is 100 times that of fixing it before development.  \\n And, where on average,  \\n every dollar invested in UX brings $100 in return.  \\n These impressive statistics point to the fact  \\n that it's important to get customer feedback,  \\n not just because it improves  \\n the aesthetic appeal of a design,  \\n but because there is real business value  \\n in creating resonant customer experiences.  \\n This course will help you to reach both of those goals.  \\n Hi, I'm Lija Hogan,  \\n Customer Experience Consultant at UserTesting.  \\n I have years of experience doing research  \\n alongside people across a number of industries and contexts,  \\n as well as teaching people how to do it.  \\n During this course, I'll be sharing with you best practices  \\n and strategies to launch tests using user testing  \\n that will help you to surface feedback  \\n that you can use in your work every day.  \\n These skills include selecting  \\n the right strategy to collect feedback,  \\n setting up tests that are efficient to review  \\n and sharing that feedback with your colleagues.  \\n Join me in my course and learn how to listen to people,  \\n those who are reading the words you're writing,  \\n buying things, using your websites,  \\n or who are using apps or other products you're designing  \\n to get meaningful feedback about your ideas and work  \\n that will make it better before it gets subjected  \\n to the greatest of tests,  \\n actually being used by your users.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3043281\",\"duration\":159,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Why feedback is so powerful, especially now\",\"fileName\":\"3005392_en_US_00_02_XR30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"This video explains how the impact of the global Covid pandemic has accelerated digital transformation and how exploration of user needs and usability has become critical to ensuring that people can successfully interact with each other, with businesses, and with government, and can participate in education.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5907640,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Speaker] Up until about a decade ago,  \\n most user experienced researchers either brought people  \\n into labs to do tests,  \\n or they went to people's offices or homes.  \\n In an age where product development has accelerated  \\n and we find ourselves building products and services  \\n for global audiences and needing to empower more people  \\n to collect insights,  \\n the improvements in remote technologies have enabled us  \\n to choose when we need to be in the same place  \\n and when we don't need to.  \\n So why is remote research so important now?  \\n The global pandemic has changed the landscape.  \\n With rolling shutdowns,  \\n travel bans,  \\n and remote work,  \\n most of what we do happens remotely.  \\n As the situation evolves,  \\n and we move into a time when hybrid work from home  \\n and office will be the new model,  \\n it's clear that some of the things we've done to connect  \\n with people over the past year will persist into the future.  \\n Let's talk about the power of remote research.  \\n First, it is asynchronous.  \\n That means that you can be doing basically anything else  \\n at the same time that one  \\n or more people are answering questions  \\n or doing tasks on their own.  \\n It expands your reach globally.  \\n Rather than spend time flying  \\n to a lab location in another city or country,  \\n people can complete tests in their own homes  \\n with your guidance.  \\n Also, since many of us are still subject to travel bans  \\n or work from home,  \\n lab research has become impractical  \\n if not impossible.  \\n It also broadens your reach across communities.  \\n Sometimes it's harder to cross cultural  \\n or religious barriers in person.  \\n Remote testing enables you to scale up your work  \\n to ask new questions of groups  \\n that you may not have been able to talk to.  \\n For all these reasons,  \\n remote research is also more efficient,  \\n cost and time savings are significant.  \\n Finally, keep in mind  \\n that remote research includes a variety  \\n of strategies like surveys, interviews,  \\n usability testing, diary,  \\n and longitudinal studies among others.  \\n User testing can be used across many of these contexts  \\n and more,  \\n but there is one final consideration.  \\n Sometimes there is just no replacement for being there.  \\n When you need to see the context and be  \\n in the moment alongside someone.  \\n Remote research can and should be just a part  \\n of the journey to make that connection.  \\n So remote research helps you to get feedback  \\n from people across environments, time,  \\n and contexts using a number of strategies.  \\n Use it wisely to understand your users before, during,  \\n and after your design and development efforts.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3046253\",\"duration\":181,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"About the UserTesting platform\",\"fileName\":\"3005392_en_US_00_03_XR30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7064760,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] You're ready to get feedback from customers.  \\n But first, what is UserTesting?  \\n UserTesting is a platform that connects companies to people  \\n around the world to get their feedback,  \\n surface needs and goals, and to provide context  \\n about products and services.  \\n Researchers, designers, marketers, product managers,  \\n and many others use the platform to talk to people,  \\n show them design approaches or concepts,  \\n have people give tours of their environments  \\n by turning on their forward-facing cameras  \\n on their mobile devices,  \\n or watch them using digital products  \\n with their own equipment in their own homes.  \\n How does it work?  \\n First, create a test plan  \\n that walks people through questions  \\n or asks them to perform tasks.  \\n You can test anything you can make available  \\n on the internet.  \\n Then, find the right people to talk to.  \\n Use the UserTesting Contributor Network  \\n or connect with your own audiences.  \\n People will complete the tasks  \\n or answer questions through self-guided video recordings  \\n or through live conversations.  \\n When the videos have been uploaded to your dashboard,  \\n you can review them to find insights  \\n that matter to your team by using metrics and transcripts  \\n to find moments of interest or feedback quickly,  \\n viewing summaries of feedback with visualizations,  \\n and watching videos to see what the experience is like  \\n for your users.  \\n Finally, you can share what you've learned with your team  \\n by downloading, sharing, or exporting videos  \\n or highlight reels or written data.  \\n Integrations with tools like Slack, Jira, and Trello  \\n enable you to tell the story of your experience  \\n quickly and easily.  \\n What do people use UserTesting to learn about?  \\n Many designers and product people use UserTesting  \\n throughout the development life cycle  \\n to surface what the right thing is to build,  \\n and then validate that the right design choices  \\n will result in that thing being built right.  \\n Designers and UX researchers test the experience  \\n of using products or finding information  \\n at any stage in their process,  \\n surfacing and addressing user experience issues  \\n before any code is written,  \\n all the way through validating  \\n a design approach before launch.  \\n Marketing teams use the platform to test language,  \\n imagery, brand assets, email,  \\n anything that can be described or shown in images,  \\n audio, and video.  \\n Finally, executives can build empathy with customers  \\n by connecting to them on a regular basis  \\n through empathy hours or otherwise leveraging  \\n the voice of customers to make business decisions.  \\n The bottom line is that UserTesting  \\n can be used to explore a wide variety of questions,  \\n anything from what pricing model  \\n would best align with your value proposition  \\n to the best way to streamline checkout and beyond.  \\n Your team's imagination is the limit.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3045228\",\"duration\":226,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"The ethics of connecting with people\",\"fileName\":\"3005392_en_US_00_04_XR30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6717965,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] When working with people,  \\n it's critical to ensure that you're doing your best  \\n to act responsibly and in the best interests  \\n of all of your stakeholders.  \\n This includes your customers, employer,  \\n colleagues, the public, but most importantly,  \\n the people you're connecting with.  \\n While many safeguards, particularly around consent  \\n and privacy standards, are built into user testing,  \\n the platform also enables you to have  \\n a lot of freedom around how to guide people through tests.  \\n It helps to bring a mindset  \\n of thoughtful empathy to the table.  \\n The User Experience Professionals Association, or UXPA,  \\n adopted a code of conduct in 2005  \\n that includes the following principles.  \\n I recommend that as you adhere to these principles  \\n as you plan and execute your work,  \\n as they represent the best practices  \\n developed by UX researchers.  \\n If you find yourself in a situation  \\n where you don't know the answer, find a trained researcher  \\n to advise you on the best next steps.  \\n First, act in the best interest of everyone.  \\n Some examples of how to do this:  \\n work with other practitioners to critically review  \\n your work, avoid coercing people by offering  \\n inappropriate incentives, and only do work  \\n that you're capable of, and trained to do.  \\n Be honest with everyone.  \\n You should never deliberately mislead people  \\n about your motives and expected outcomes.  \\n Your recommendations should be consistent  \\n with best practice, or reviewed by qualified professionals.  \\n Do not harm, and if possible, provide benefits.  \\n Be mindful that sometimes, you should not be  \\n soliciting feedback if doing so  \\n imposes physical, mental, or emotional stress.  \\n Take care to support the individual,  \\n and sometimes specialized needs of children,  \\n the elderly, and the disabled.  \\n Act with integrity.  \\n Treat everyone you work with respectfully.  \\n Never make derogatory comments about anyone  \\n you're working with, or use material  \\n that might be harmful or damaging  \\n to a person or group of people.  \\n Avoid conflicts of interest.  \\n Sometimes you should not be the one  \\n who is connecting with a person or group of people  \\n for any number of reasons.  \\n Work with your colleagues to figure out  \\n an alternative solution.  \\n Respect privacy, confidentiality, and anonymity.  \\n Make every effort not to reveal anyone's identity  \\n or personally identifiable information,  \\n either as part of a test, or to stakeholders,  \\n unless you have express permission.  \\n User testing manages informed consent  \\n as a condition of joining the contributor network,  \\n but as you write questions, and publish clips or reports,  \\n make sure that you can respect contributors' privacy.  \\n Provide all resultant data.  \\n It's tempting to make your work look good.  \\n However, one of the great benefits of testing  \\n your approaches or ideas with people  \\n is that you surface problems before they become  \\n barriers in a launched product.  \\n Report both the positive and the negative feedback.  \\n That's a lot to remember, but a great reminder  \\n that the foundation of any great product,  \\n service, and experience is a real connection  \\n and focus on the people who will be using it.  \\n Talk to the other researchers and designers  \\n you work with to address any questions you might encounter.  \\n You might also connect with your local UXPA, IXDA,  \\n or design meetup communities to get ideas.  \\n For more information, refer to the UXPA  \\n Code of Professional Conduct at  \\n uxpa.org/uxpa-code-of-professional-conduct.  \\n \\n\\n\"}],\"name\":\"Introduction\",\"size\":24040841,\"urn\":\"urn:li:learningContentChapter:3042276\"},{\"duration\":267,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3045229\",\"duration\":148,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"How can you use UserTesting to learn about your users?\",\"fileName\":\"3005392_en_US_01_01_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"This video goes over the types of research objectives people typically use remote research to understand: who, what, when, where, why, how.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4571149,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Narrator] One of the most common challenges  \\n that UX researchers share with me  \\n is that their stakeholders come to them wanting a survey  \\n to understand usability issues with their experience.  \\n For many reasons, this is an approach that would fail.  \\n So they spend a lot of time explaining  \\n why surveys don't help you to understand usability issues  \\n or provide a 360 degree view of user needs.  \\n There are some things that UserTesting is perfect  \\n to help you understand about your users.  \\n Of course, that means that there are questions  \\n that other platforms, strategies,  \\n or tools would be better options to use.  \\n Let's start with the sorts of questions UserTesting  \\n is best used to understand.  \\n We frequently structure our testing  \\n around the journalistic questions  \\n that we're all familiar with:  \\n who, what, when, where, why, and how.  \\n As someone who is interested in human behavior,  \\n I also add in how many.  \\n UserTesting is best used to understand these questions:  \\n Stories that inform us about who our users are  \\n and what they need.  \\n What our users want, need, and expect.  \\n Also descriptive information  \\n about what their experience is like.  \\n The impact of the context of use,  \\n or really how can we understand the circumstances  \\n of where someone is using our products and services.  \\n Why people are behaving or thinking a certain way.  \\n This is probably the focus area  \\n that people use UserTesting to understand most frequently.  \\n And how are people using our products now  \\n or how do they expect to use them?  \\n UserTesting is not typically used to answer questions  \\n that requires statistically significant answers.  \\n For example, demographic segmentation data  \\n or data about when or how many certain types of people  \\n are using your digital products  \\n are questions better answered by behavioral analytics  \\n or data that tells us what people are doing now, or surveys.  \\n More tactically, you can test words, video,  \\n interactions in the app, website, or mobile site,  \\n billboards and brochures,  \\n pretty much anything that you can describe  \\n and provide access to through the internet.  \\n The bottom line is that UserTesting is best used  \\n to connect with small groups of people  \\n from whom you want to gather  \\n a lot of rich, contextual information.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3048278\",\"duration\":119,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"When to do what: Moderated versus unmoderated remote testing\",\"fileName\":\"3005392_en_US_01_02_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"This video shows you how to select which technique fits your research objective: moderated or unmoderated testing.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3731240,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] You've decided you're going to get feedback  \\n from users.  \\n Great.  \\n Now comes a critical decision.  \\n Do you need to be there to guide someone through a test  \\n or interview or not?  \\n Here are some considerations  \\n for choosing the right approach.  \\n Unmoderated testing can be used to support  \\n a variety of approaches, including surveys,  \\n interviews, usability, prototype, and concept testing,  \\n and even diary studies.  \\n It's great for when you don't have a lot of time.  \\n You want to draw participants from a wide geographic area.  \\n You need to keep travel costs low or cannot travel.  \\n If you want to have a large number of participants,  \\n for example, for our quantitative benchmark study.  \\n And if having a moderator in the room  \\n increases the chance of bias.  \\n By contrast, moderated testing should be used  \\n when you need to communicate nuances in an interaction  \\n that you're testing.  \\n For instance, when you have a low fidelity prototype  \\n that requires someone to fill in the gaps,  \\n when you want to have a more exploratory conversation  \\n with follow-ups that are tailored to the context,  \\n or if you need to control access to sensitive information,  \\n such as personally identifiable information, or PII,  \\n or new unreleased features.  \\n There's also a case to be made  \\n for using both approaches together.  \\n You might want to test the opposite approach  \\n to pilot a test, for example.  \\n Here's how that works.  \\n You can test a script for a moderated study  \\n to ensure the terminology makes sense  \\n so that you reduce the risk of wasting time with people  \\n when you meet.  \\n You might also consider moderating a pilot test  \\n of large scale or quantitative studies.  \\n Again, this helps to reduce the risk  \\n of having poorly written questions  \\n or missing critical follow-up questions.  \\n So, think about which strategy might work for you.  \\n Both can be helpful.  \\n \\n\\n\"}],\"name\":\"1. About Remote Testing\",\"size\":8302389,\"urn\":\"urn:li:learningContentChapter:3045232\"},{\"duration\":2829,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3042273\",\"duration\":437,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Observe the \\\"do\\\", Listen to the \\\"say\\\": How to structure an unmoderated usability test\",\"fileName\":\"3005392_en_US_02_01_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Learn how to write a solid unmoderated qualitative usability test.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":14752100,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Announcer] Getting feedback  \\n about the experience of completing a task  \\n is about creating an understanding  \\n of what your users need,  \\n what elements of the experience are important to them,  \\n their capabilities and their limitations.  \\n Add in the complexity of balancing the business goals  \\n and objectives of the team managing a project  \\n with those user goals.  \\n While this sounds like a lot to think about  \\n to get meaningful insights,  \\n you need to consider both perspectives.  \\n First, you must figure out what you need to know.  \\n Typically usability testing of interactive experiences  \\n focuses on surfacing feedback about areas of opportunity,  \\n pain points, or weaknesses in your design solution.  \\n You should not be testing to prove a point or to tell  \\n everyone that your design is perfect.  \\n Focus on improvement.  \\n This is a three-step process.  \\n First, you plan what you want to learn,  \\n who you want to test with  \\n and what sort of feedback you need.  \\n Then you launched the test  \\n after inputting all the required information  \\n into user testing.  \\n Finally, you review the feedback.  \\n The official ISO definition of usability  \\n is the extent to which a product can be used  \\n by specified users to achieve specified goals  \\n with effectiveness, efficiency, and satisfaction  \\n in a specified context of use.  \\n Typically you want to learn whether people understand  \\n the information provided  \\n and the outcomes they should expect as a result  \\n of completing the task successfully.  \\n You also want to know whether they can complete the task,  \\n how long it takes  \\n and how satisfied they were with the experience.  \\n What you are doing is creating evidence  \\n to help you to understand the usability of your product  \\n by having someone complete a task,  \\n and then asking them directly for feedback about it.  \\n You're also observing what they do  \\n and comparing what they are saying  \\n to what they are doing to surface any differences.  \\n So at base, your test will be to ask people  \\n to complete a task and then ask for feedback.  \\n Simple.  \\n The typical test takes about 15 to 20 minutes  \\n for a participant to complete.  \\n You might have them answer a few warmup questions  \\n to learn more about them and their experience.  \\n Then have them complete a few tasks  \\n and provide direct feedback about their experience.  \\n Finally, wrap up with some follow-up questions  \\n to make sure that you've captured  \\n all of their impressions and ideas.  \\n Here's how you do it.  \\n First, you need to decide  \\n where you're going to start people.  \\n You can start on a blank page  \\n and ask some interview style questions first.  \\n For example, about their previous experiences  \\n doing the same task or their job role,  \\n or you can start by taking them to the start of that task.  \\n Set the stage by giving them  \\n just enough context to make the scenario realistic for them.  \\n You want to set expectations about what they will be doing  \\n and let them know that you're looking  \\n for their honest feedback  \\n and any details required to help them engage naturally.  \\n Here are some examples scenarios.  \\n Next provide instructions  \\n about what you would like for them to do.  \\n Use the task questions  \\n so that when you review the feedback on the metrics tab,  \\n you can see how people completed the task  \\n by reviewing the path.  \\n This information is available  \\n only if participants encountered two or more screens  \\n and are using the Chrome browser on the desktop  \\n or for mobile tests of websites.  \\n Interactive path flows are not captured  \\n for mobile apps or native browsers for mobile web tests.  \\n When providing instructions for a task,  \\n you might want to know how people problem solve.  \\n This means that while you might set a goal  \\n for them to achieve,  \\n you want to see how they get there.  \\n And it doesn't matter whether they visit specific pages  \\n along the way, and they might even get lost.  \\n Here's some examples of this exploratory type of task.  \\n By contrast, you might want to make sure  \\n that people are seeing certain pages.  \\n In this case, make sure that your task  \\n provides just enough guidance to position people  \\n to find these pages on their own.  \\n As people reach each milestone,  \\n add one to three questions to gather feedback  \\n before you have them go on to the next step of the task.  \\n Here are some examples of this more directive task flow.  \\n Also a quick way to capture information  \\n about whether participants  \\n thought they completed the task successfully  \\n and how difficult or easy they found it to be  \\n is to check the task metrics boxes  \\n for success and difficulty.  \\n This way you can compare what people perceive  \\n to what you observe.  \\n Keeping in mind that sometimes people  \\n think they are successful at completing a task  \\n when they really aren't and vice versa.  \\n Next, you want to be sure that you ask for feedback.  \\n You can do this by using verbal response questions,  \\n written questions, multiple choice questions,  \\n or rating scale questions.  \\n Remember that with any question you use,  \\n you will get verbal feedback.  \\n So when you make the choice about which question to use,  \\n you're really making it easier to surface insights faster,  \\n with more structured information  \\n that you can see before you watch any videos  \\n if you use other question types  \\n than for verbal response questions.  \\n Verbal questions are great  \\n for prompting people to tell stories.  \\n Written questions enable you to capture quotes,  \\n short words and phrases  \\n that help you to spot patterns quickly.  \\n Multiple choice questions enable you  \\n to surface trends and patterns  \\n by prompting people to explain their reasoning.  \\n Starting with a characterization of their answer  \\n or to self-report tools, experiences, expectations,  \\n or other categories that are of interest to you.  \\n Rating scale questions enable you to understand  \\n how strongly people feel about a concept.  \\n Use the average to understand  \\n overall positive or negative feelings.  \\n Listen to outliers to learn how and why  \\n they might've rated things differently than others.  \\n Wrap up your test by asking one to three questions  \\n that let people provide feedback  \\n that they might not already have shared.  \\n This lets people share ideas  \\n or react to the overall experience.  \\n Here are some examples of wrap-up questions.  \\n Great.  \\n Now, launching a test can be as simple  \\n as asking someone to complete a task  \\n and observing them as they do it  \\n and asking for their feedback.  \\n The more times you launch a test,  \\n the better you will get at asking questions  \\n in the way that gets you the result you're looking for.  \\n So try it.  \\n Write a simple test  \\n and send it to one person  \\n just to see what happens.  \\n Then tweak the questions  \\n and send it out to more people.  \\n The best way to learn is to practice.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3042274\",\"duration\":212,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"The short test: How to structure an unmoderated quantitative test\",\"fileName\":\"3005392_en_US_02_02_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Find out how to write a solid quantitative usability test.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6968097,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Narrator] Sometimes, you need to get  \\n a larger number of people to validate a design approach.  \\n For example, you need to make a go or no-go decision,  \\n or to feel confident in a high risk situation,  \\n you want to get more data from a large number of participants  \\n to ensure stakeholders feel comfortable with your solution,  \\n and that it's usable under all conditions.  \\n This is when you need to do quantitative  \\n or large sample testing.  \\n In this case, you need to write a structured test  \\n that relies mostly on feedback  \\n that is more quantitative in nature.  \\n This minimizes the amount of video watching you need to do  \\n and creates outputs that are best communicated  \\n using charts, graphs, tables,  \\n and maybe a few quotes or videos for color.  \\n Tasks should be planned with clear success criteria  \\n and use written, multiple choice and rating scale questions  \\n to capture feedback in an easy to digest manner.  \\n Also, you'll usually only test a task  \\n that takes a short time to complete.  \\n Participants have the choice  \\n about whether to stop at the five minute mark.  \\n This is a great use of the short test feature.  \\n Set the stage by giving just enough context  \\n to make the scenario realistic.  \\n You want to set expectations about what people will be doing  \\n and let them know that you're looking  \\n for their honest feedback  \\n and any details required to help them engage naturally.  \\n When testing at scale, time on task  \\n is typically a critical metric that you want to capture.  \\n The best way to capture this data  \\n is to instruct people not to talk  \\n as they are completing a task,  \\n this results in the best, most consistent data.  \\n When you review the feedback on the metrics tab,  \\n you can see how people completed the task.  \\n Keep in mind that this information is available  \\n only if participants encounter  \\n two or more screens and are using the Chrome browser  \\n on the desktop or for mobile tests of websites.  \\n Interactive path flows are not captured for mobile apps  \\n and native browsers for mobile web tests.  \\n Task success is also critical.  \\n So provide clear instructions about where to stop.  \\n You will want to compare  \\n participant's perceived task success,  \\n and difficulty to your observations.  \\n So be sure to turn on those questions, next,  \\n you will want to ask followup questions  \\n using mostly written, multiple choice  \\n and rating scale questions.  \\n You may use up to five questions.  \\n So be sure to pick ones that help you to measure  \\n participant's perceptions of the experience.  \\n Examples include satisfaction, efficiency, usefulness,  \\n or emotion, as well as capture their feedback  \\n about the usability of the experience.  \\n You will use the average to understand  \\n overall positive or negative feelings.  \\n You should also assess the distribution of answers  \\n to learn whether there are outliers and to dig into why.  \\n The great thing about this approach is that it's simple  \\n and focused on how usable the experience is.  \\n You might consider using this approach  \\n to test any design quickly,  \\n not just in situations where you want to test  \\n with large groups of people.  \\n It's also a great way to learn how to do quick observations  \\n and to practice writing effective tests.  \\n Remember to pilot test your test with one person  \\n to be sure your tasks and questions  \\n are understandable before you launch it.  \\n And as always, the best way to get good at this  \\n is to practice.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3048279\",\"duration\":223,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Compare two experiences: Direct comparison\",\"fileName\":\"3005392_en_US_02_03_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"You may often need to test two or more experiences. This video explains the unique value that comparative testing, across both experiences and time, and shows you how to bring that value to your organization.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7284235,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] When you're contemplating  \\n more than one design approach,  \\n it is helpful to understand the benefits  \\n and disadvantages of both.  \\n In some cases, you want to learn which version to choose  \\n and why.  \\n Testing two experiences at once can be accomplished  \\n in a couple of ways.  \\n One approach is to have one group of people  \\n compare two versions of a design solution,  \\n a direct comparison.  \\n This enables you to get feedback  \\n that requires them to choose their preferred version  \\n and describe what they like and don't like  \\n about both approaches.  \\n The best practice is to counter balance  \\n which version is shown first to each user to manage bias.  \\n User testing handles this for you  \\n by showing half of the participants version A first  \\n and the other half version B first.  \\n To do this, you will need to select your audience  \\n and then set up a test using the balanced comparison option.  \\n Once you turn this on,  \\n you will see that there are four sections to the test.  \\n The first section is preliminary tasks.  \\n This is where you can ask warm-up interview style questions  \\n or you can have people complete a task  \\n that prepares them for the rest of the test.  \\n The next section is group A tasks.  \\n Typically, you will want to start with instructions  \\n to complete a task or to show an asset like a prototype.  \\n Then, ask follow up questions.  \\n You might want to ask rating scale questions  \\n about perceptions, such as ease of use, efficiency,  \\n satisfaction or value so that you have some directional  \\n and easily comparable information.  \\n Remember, you're not doing quantitative testing here.  \\n In addition, be sure to ask qualitative verbal response  \\n or written response questions so that you get solid feedback  \\n about why people prefer a version.  \\n In an alternative approach that yields good information  \\n about what people notice and understand,  \\n you might just ask them to just describe what they see.  \\n Observe what people do and listen to what they say  \\n and compare their reactions and feedback  \\n to your expectations.  \\n The next section is group B tasks.  \\n Again, you will want to provide the appropriate instructions  \\n to complete a task or show an asset.  \\n A competing prototype, for example.  \\n You should use the exact same follow-up questions  \\n about the experience so that you can compare feedback  \\n and perceptions directly.  \\n The final section is for wrap-up tasks.  \\n Here, ask for feedback that requires people  \\n to compare the approaches and pick their preferred version  \\n using a multiple choice question.  \\n And be sure to ask about why the winning approach  \\n is so compelling.  \\n Comparing experiences can be tricky.  \\n Sometimes you may not get definitive answers.  \\n It can seem like both approaches might work.  \\n First, take another look at the feedback  \\n and the test itself.  \\n Did people react to the design elements  \\n that were different naturally?  \\n Was the difference so subtle that it did not register?  \\n Did you ask questions that yielded direct feedback  \\n about what you wanted to learn?  \\n Is there feedback you can take from both experiences  \\n and test in a consolidated and revised iteration?  \\n You can also try adding a few more participants  \\n to establish whether there is a clear winner.  \\n If you still get ambiguous results,  \\n then you have a few options.  \\n Testing at scale might make sense,  \\n given your need for a definitive answer, your timeline,  \\n and budget.  \\n Otherwise, partner with a UX researcher to review  \\n and use the qualitative feedback you've gotten  \\n to decide what to do next.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3043282\",\"duration\":231,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Compare two experiences: Indirect comparison\",\"fileName\":\"3005392_en_US_02_04_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"To reduce bias, you may need to test two or more experiences with different groups of people. This video shows the best methods to identify winning approaches.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7732870,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] When you're contemplating more  \\n than one design approach,  \\n it's helpful to understand the benefits  \\n and disadvantages of both and to do this separately  \\n with different groups of people.  \\n Let's talk about the indirect test.  \\n The advantage of the indirect test  \\n is that you have two different groups  \\n of people who are looking at the different approaches.  \\n The chances of bias are reduced  \\n because they are only seeing one option.  \\n You also have a larger number of participants,  \\n so you can get more feedback overall.  \\n Also, this approach enables you to test longer,  \\n more complicated tasks or complex experiences  \\n that require longer interactions.  \\n In this case,  \\n you will need to set up two different tests on the platform.  \\n Be sure to create titles for the tests  \\n that are similar enough to one another  \\n so that you know they are related.  \\n In the first test,  \\n be sure to create a set of questions  \\n and instructions that you can easily reproduce  \\n for both versions of the test.  \\n Good verbal, written, multiple choice,  \\n and rating scale questions that you will use in both tests  \\n to ensure that you can compare the two approaches.  \\n For the second test,  \\n you can use the same script that you created  \\n for the first one by using the duplicate function.  \\n Then replace the URL and tasks  \\n or update instructions or questions as needed  \\n to ensure they make sense and account  \\n for any unique features of the other approach.  \\n Launch both tests and review the metrics data separately.  \\n You should be looking at the data for each of the questions  \\n to see if there are substantive differences in the feedback  \\n for both approaches.  \\n This means that it can be even more important to ensure  \\n that you have a clear sense of what success looks like  \\n or what elements of the approaches you want  \\n to understand best.  \\n Because the differences between design approaches  \\n are often so subtle that people do not react to them,  \\n you might need to ask specific questions about  \\n what you want to know.  \\n To test the best approach to ensuring  \\n that you get this information,  \\n pilot each test with at least one participant  \\n and review the data with an eye toward  \\n whether they are reacting to the elements  \\n of the design that you wish to get feedback about.  \\n You can also download the tests  \\n and compare the data using Excel.  \\n Comparing experiences can be tricky.  \\n Sometimes you may not get definitive answers.  \\n It can seem like both approaches might work even  \\n if you're testing them indirectly.  \\n First, take another look at the feedback  \\n and the test itself.  \\n Did people react to the design elements  \\n that were different naturally?  \\n Was the difference so subtle that it did not register?  \\n Did you ask questions that yielded direct feedback about  \\n what you wanted to learn?  \\n Review the qualitative information  \\n to see what was clear or not  \\n and what worked well or did not.  \\n Make sure you understand the why's  \\n and the reasoning that people shared.  \\n You can also try adding a few more participants  \\n to establish whether there is a clear winner.  \\n If you still get ambiguous results,  \\n then you have a few options.  \\n Testing at scale might make sense,  \\n given your need for a definitive answer,  \\n your timeline, and budget.  \\n Keep in mind that sometimes you might learn  \\n that really both approaches are just fine.  \\n I recommend using the snowball sample approach  \\n and adding a smaller group of participants.  \\n For instance, 10 at a time rather than launching  \\n to 100 people all at once just  \\n to see if I can spot a trend earlier.  \\n Otherwise partner with a UX researcher  \\n to review and use the qualitative feedback you've gotten  \\n to decide what to do next.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3044242\",\"duration\":172,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"How to test language, messaging, or copy\",\"fileName\":\"3005392_en_US_02_05_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Connect with how people understand language by using approaches that both expose them to a draft version and that language, or by having them co-create that language alongside you.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5794148,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Finding the right way  \\n to communicate complicated or important ideas  \\n can be challenging.  \\n Testing the language, or even having people help you  \\n to create that language is easily done using user testing.  \\n Testing the language once you have written it  \\n is fairly straight forward.  \\n You show people the language,  \\n and then ask questions about it.  \\n You can show the language in a document,  \\n or a live website by linking to a URL,  \\n or even use a written question for short passages.  \\n Frequently, you want to know  \\n if people understand the language.  \\n Rather than ask them directly if they understand it,  \\n have them describe what you've just shown them  \\n using their own language.  \\n Use a written question and instruct them  \\n about how you want them to structure their feedback.  \\n Use a rubric, how you want people to describe the concept,  \\n to determine whether or not they get it.  \\n When you review their feedback,  \\n you will then have an understanding  \\n of what meaning they took from what they saw.  \\n You might want to learn how they feel about the language.  \\n You could use multiple choice questions  \\n to ask what words they associate with the language,  \\n or to determine whether they like it and why.  \\n Or use rating scale questions to ask how strongly they feel.  \\n When you wish to co-create language,  \\n there are some different strategies that you can use.  \\n First, you must have some sort of prompt.  \\n This can take the form of a written description  \\n of the concept you wish to create language around,  \\n or some other sort of media, like a video, audio clip,  \\n or an image.  \\n Remember, as long as the media is accessible  \\n via the internet, you can test it.  \\n You can choose to use a written question  \\n to capture the language.  \\n Alternatively, you can provide instructions for people  \\n to create their own copy of the document from a template,  \\n using their own user testing ID to name that copy.  \\n This enables them to have more space to write.  \\n In this case, you can start with a prompt, a description,  \\n video, audio, or image that they will then create copy  \\n around that best communicates what they are seeing.  \\n This strategy of having people create their own copies  \\n of a template document can also be used  \\n for other advanced copy testing,  \\n such as highlighter testing or Cloze testing.  \\n In a nutshell, whenever you are testing language,  \\n you should ask yourself what you need to learn beyond,  \\n do people like it?  \\n Learn how people understand and describe the language,  \\n and determine whether their reactions  \\n are what you intended for them to be.  \\n Follow up by asking how they feel about it.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3043283\",\"duration\":240,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"How to test imagery, video, and audio\",\"fileName\":\"3005392_en_US_02_06_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Visual language is as critical a part of the experience as the written language. Color, imagery, and other rich media can help people to understand complex information more effectively. This video explains how to test visual language using strategies that target both discrete elements and more holistic experiences.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7912886,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Narrator] Often, we want to understand  \\n how people react to visual language,  \\n which might include color, font, imagery,  \\n or rich media such as audio or video,  \\n or how it all works together.  \\n Testing in this context is a matter  \\n not just of showing people the asset  \\n and asking for general feedback.  \\n You should also consider two more things.  \\n Whether you need to focus on a single part of the experience  \\n or the higher level holistic experience.  \\n Basically you'll be showing people an asset  \\n and asking for feedback,  \\n but how you ask for the feedback  \\n and what elements you elect to show at once,  \\n or together, or at a time,  \\n will impact the feedback you get.  \\n So what does asset mean?  \\n Assets can take a variety of forms.  \\n You might have specific images like icons, pictures,  \\n or webpages,  \\n or rich media like video or audio.  \\n If you want to understand elements of the experience,  \\n such as how color is communicating the urgency  \\n of the message  \\n or whether the font is consistent  \\n with your professionally cheeky voice,  \\n you will need to ask direct questions about them.  \\n Let's start with the smaller, more discrete elements  \\n of the experience.  \\n Show them the asset.  \\n Then ask them to describe the whole thing,  \\n what they think it means, how it makes them feel.  \\n Rather than asking them directly if they understand it,  \\n have them describe what you've just shown them  \\n using their own language.  \\n Then direct their attention  \\n to the specific element you care about,  \\n whether that's the color, font, or layout.  \\n Make sure that you're asking them to observe  \\n and describe that element first.  \\n And if you're interested, how they feel second.  \\n To do this, use a written question and instruct them  \\n about how you want the descriptive feedback.  \\n Use a rubric how you want people to describe the concept  \\n to determine whether or not they get it.  \\n When you review their feedback,  \\n you will then have an understanding  \\n of what meaning they took from what they saw.  \\n You should focus on why they found the element  \\n to be compelling or not.  \\n Are the words they use positive, negative, or neutral?  \\n Be sure to use automatic highlight reels to listen  \\n to all of the people talking through their answers.  \\n You can use multiple choice questions  \\n to ask what words they associate with the visuals  \\n or to determine whether they like them and why.  \\n You will use those descriptions to inform  \\n how you further evolve the design approach.  \\n Rating scale questions are helpful  \\n to learn how strongly they feel about the element.  \\n Choose a focus area that aligns with your project goals.  \\n Some examples for visual and rich media areas of interest  \\n include aesthetics, appeal, credibility,  \\n or brand perception.  \\n When testing rich media such as video or audio,  \\n be sure to direct them to the appropriate URL  \\n where they can access it first.  \\n Then have them watch or listen.  \\n Next, follow up with questions  \\n to understand their experience.  \\n Start with asking them to describe what they have just seen.  \\n Use questions that support a focus  \\n on what you want to learn about.  \\n For example, can they describe a concept  \\n that was just explained in the video?  \\n What do they think that commercial was for?  \\n Consider using verbal or written questions  \\n to capture this feedback.  \\n Optionally, you can follow up with multiple choice questions  \\n to understand in a more structured way how people perceived  \\n or felt about the experience.  \\n In a nutshell, whenever you are testing language,  \\n you should ask yourself what you need to learn beyond,  \\n \\\"Do people like it?\\\"  \\n Learn how people understand and describe the language  \\n and determine whether people's reactions  \\n are what you intended for them to be.  \\n Then, follow up by connecting to how they feel about it.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3043284\",\"duration\":224,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"The efficient test\",\"fileName\":\"3005392_en_US_02_07_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Sometimes, we need to save time. This video shares tips and tricks for how to write the most efficient test to capture the feedback you need.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7010644,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Sometimes, you have a lot of time  \\n to spend reviewing feedback.  \\n Other times, you need an answer much more quickly.  \\n And when you're thinking about your timelines,  \\n know that there are many right ways to connect with users.  \\n By choosing to both structure your test,  \\n and your approach to reviewing the feedback,  \\n you can spend the appropriate amount of time  \\n based on your goals, what the team needs to learn,  \\n and your timeline.  \\n I think about this as figuring out along a continuum  \\n that ranges from less structured  \\n to more highly structured tests,  \\n what the best strategy for you is going to be.  \\n Unstructured tests typically are more exploratory in nature.  \\n In these situations, you want to discover how people  \\n are problem solving by observing  \\n their most natural behavior.  \\n They might bypass milestones  \\n that you would typically consider critical to an experience,  \\n and not even notice a difference.  \\n The feedback in these tests must be collected  \\n by spending time actually watching the videos, taking notes,  \\n comparing your observations,  \\n or what you're seeing people doing  \\n to what people are perceiving or reporting  \\n and what they're saying.  \\n This approach is also best when you have a lot of time,  \\n need a lot of detail to understand users' goals and needs,  \\n or when you need a lot of evidence or examples or stories,  \\n and maybe even some ideas that are going to support  \\n improvements or additions or innovations  \\n that you want to make to the customer experience.  \\n Typically, participants answer rating scale,  \\n multiple choice, or written questions.  \\n Once they have completed a task.  \\n Highly structured tests, provide more guidance  \\n and structure, stopping participants at key milestones,  \\n as they complete a process to check in with them.  \\n And this is an approach that's really useful  \\n when you need to get a lot of detailed feedback  \\n at every step along the way of a particular process.  \\n It's also helpful if you want to surface information  \\n using approaches that are less reliant on watching video,  \\n and when you want to benchmark the experience or test  \\n with a larger number of people.  \\n Typically, people will answer a larger proportion  \\n of rating scale, multiple choice, or written questions  \\n during the processes of completing a task,  \\n as well as afterwards,  \\n by comparison to those less structured tests.  \\n Automatic highlight reels are generated  \\n for each question by default.  \\n So you can quickly watch everyone answer  \\n each one of the questions,  \\n regardless of which strategy you use.  \\n And this is an efficiency that is common  \\n to both of those approaches  \\n that enables you to quickly compare  \\n and review feedback.  \\n In either case, you can be very strategic  \\n so that you can surface just enough evidence  \\n that you need to tell the effective story for your team.  \\n Each of the question types that user testing offers  \\n provides a unique value and can be used to help you  \\n to understand the experience in different ways.  \\n So based on your goals, choose the options  \\n that are going to help you collect the feedback you need.  \\n The bottom line is that you can make strategic choices  \\n when writing a test to minimize the amount of video  \\n that you have to watch,  \\n or to quickly find moments  \\n that you might even want to watch multiple times.  \\n Consider using a variety of questions  \\n to help you surface insights more quickly.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3043285\",\"duration\":295,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"What am I seeing? Assessing tasks\",\"fileName\":\"3005392_en_US_02_08_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"People are often concerned with how to make sense of the videos and data they receive. This video covers strategies to observe what people are doing.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9351524,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Usability testing involves watching people  \\n as they complete a task, observing the choices they make,  \\n and then listening to their reasoning as they think aloud.  \\n The task question enables you to focus  \\n on understanding behaviors.  \\n That's it's unique value.  \\n The benefit of using the task question  \\n over the verbal question is that  \\n when you get to the metrics tab,  \\n you can also see interactive path flows.  \\n This surfaces patterns of behaviors  \\n so that you can spot them before you start watching videos.  \\n This data is only captured  \\n when participants encountered two or more screens  \\n and are using the Chrome browser  \\n on the desktop for mobile tests on websites.  \\n They're not captured for mobile apps  \\n or for native browsers during mobile web tests.  \\n It really matters where you start participants.  \\n You can control this using the URL task.  \\n Be mindful of this fact that  \\n if you have URLs that differ based on geographic location  \\n or because of content management system settings,  \\n the paths may look more unique than they actually are.  \\n Interactive path flows help answer questions like,  \\n did people use the same or different strategies  \\n to complete a task?  \\n Did anyone take extra, unnecessary steps?  \\n Where did people leave the most straight forward paths?  \\n Was every one successful?  \\n What did they do when they were not successful?  \\n Or even how many steps did it take for each person  \\n to complete those tasks?  \\n And why? Why is a follow-up  \\n to all of those questions.  \\n This means that before you start reviewing the data,  \\n you should have a clear sense  \\n about what success should look like,  \\n and then what the acceptable paths should be.  \\n In addition, you can also drill down to specific pages  \\n and see how people felt  \\n or quickly watch the videos associated  \\n with those moments to see what the experience was like.  \\n Here are the things you should be looking for.  \\n When people don't use the path you expect for them to,  \\n pay attention to why they got lost.  \\n Was there a control that was missing?  \\n Did they miss an instruction or a link?  \\n Was it too far down the page, for example.  \\n Is it possible the path is more efficient  \\n than the one that most other people take  \\n for those unique folks?  \\n Then think about what you might do  \\n to help them stay on track, get on track or even rethink  \\n how it is that you're structuring that task.  \\n People don't always know when they've made a mistake.  \\n However, you have an expectation  \\n of what success should look like.  \\n So what are the choices, information, and controls  \\n that contributed to that mistake?  \\n Did people notice the right information?  \\n If they do understand that they made a mistake,  \\n what options are available for them to recover from it?  \\n Is the messaging you provide sufficient?  \\n And what could you do to prevent the mistake?  \\n When people say they don't like something, they mean it,  \\n but you to understand, not just they didn't like it,  \\n but why?  \\n So listen to their reasoning  \\n and make sure that you create a list  \\n of all of the participants  \\n and what they report they don't like.  \\n When people talk slowly or pause  \\n when they're completing a task,  \\n it means that they're cognitive load.  \\n So that's really the amount of information  \\n that your working memory can manage at once  \\n has reached a point where it's taking all of their focus  \\n to complete the task or understand the information.  \\n Because your goal is to make things as simple as possible,  \\n pay attention to those moments when people are thinking  \\n and stop talking as they complete a task.  \\n Most of the time people don't click on help text  \\n or read instructions completely.  \\n So, if and when they do,  \\n it's a sign that there's an area of opportunity  \\n to either add information to the page or streamline a flow.  \\n When people say something as easy,  \\n but struggle through a task as you watch them complete it,  \\n it's a signal that usability could be improved.  \\n When they talk about their intent,  \\n but actually do something that appears inconsistent  \\n with that intent, consider why they are confused.  \\n Are there sufficient form fields, for example.  \\n Or do people expect to go one place,  \\n but end up on an unexpected page, why?  \\n Finally, when people make recommendation,  \\n listen to what they say.  \\n While it does not mean  \\n that you must act on the recommendation.  \\n Use your professional judgment to determine  \\n how to address their concern.  \\n While you were watching video of people completing tasks,  \\n and this is something you should do  \\n as this is some of the most important feedback  \\n that you can gather from a usability test.  \\n You can also capture quotes and create lists and counts  \\n of the patterns that you're seeing.  \\n Pain points, ideas,  \\n as well as how many people experience them all.  \\n The bottom line is that the task question  \\n is the most efficient way to add real streamlining options  \\n to your usability test as you gather feedback.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3042275\",\"duration\":162,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"What am I hearing? Deep listening for verbal questions\",\"fileName\":\"3005392_en_US_02_09_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Critical listening means listening to what people are saying as well as how they are saying it. Learn critical cues that help you to understand what people really mean.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4985136,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] The unique value of verbal response questions  \\n is that they're the best way to elicit stories.  \\n Because people are prompted to speak freely,  \\n they provide detail using their own words  \\n based on their experiences and perspectives.  \\n So use these questions judiciously.  \\n This means that you plan to invest the time  \\n to truly listen to what people are saying and interpret it.  \\n It also means that you should use this opportunity  \\n to carefully structure questions  \\n that elicit the sort of feedback that you're looking for,  \\n whether it's stories, examples or descriptions.  \\n That said, there are a few strategies  \\n that you can use to help make this process more efficient.  \\n First, you can watch videos at real-time speed,  \\n or more quickly, by managing the playback speed,  \\n scan transcripts to get a sense of what people said,  \\n capture quotes,  \\n or quickly fast-forward to moments of interest  \\n by finding keywords of interest.  \\n Watch the automatic highlight reels of all participants  \\n to capture their free form lists and counts of the ideas  \\n or thoughts that participants share.  \\n The side benefit of hearing everyone react  \\n to the same question at the same time  \\n is that you can quickly compare what they said  \\n and listen for patterns.  \\n Make sure that you're intentional about capturing counts  \\n of how many times people bring up the same topics.  \\n Structure your note-taking to be sure  \\n that you assess each person using one list of topics.  \\n You can use hashtags to create clips,  \\n using some of those topic names,  \\n and quickly find your way back to moments of interest.  \\n But what are you really listening for?  \\n You should take into account two things.  \\n First, the tone of voice that people are using.  \\n So do they sound unsure or frustrated or happy?  \\n And then you should also listen  \\n to the actual words that they're using.  \\n One quick shortcut is to use keyword wraps  \\n to get a sense for what adjectives people use.  \\n It's a great way to listen for overall  \\n positive, negative or neutral feeling  \\n and actually to see that before you're watching the video.  \\n And then, when you watch the video,  \\n you can really understand the full story and context.  \\n Verbal response questions are a natural opportunity  \\n to find compelling quotes.  \\n You can create your own clip or highlight reel  \\n to share this feedback with your colleagues  \\n or even just copy the language into your reports.  \\n When you make strategic choices about writing a test,  \\n you can carve out the time to listen to verbal responses.  \\n Make a plan to ensure that you can spend  \\n that time doing that deep listening.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3045230\",\"duration\":83,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"How strongly do people feel? Understand ratings\",\"fileName\":\"3005392_en_US_02_10_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Rating scale questions are a quick way to understand the intensity of feeling around a concept. With qualitative feedback, this information is directional, meaning that you get a sense of what people are feeling. Learn strategies to understand when and how to leverage this type of question.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3125602,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Rating scale questions enable you  \\n to assess the strength of feeling  \\n around people's perceptions of the experience.  \\n They're really an entry point to understand  \\n where there are points of friction  \\n or to help you find moments  \\n where you might want to watch video of individuals  \\n or even groups of participants  \\n to understand their perceptions of the experience better.  \\n While averages, or means, are interesting,  \\n they really only provide directional information  \\n in this setting.  \\n You just have too few people in the typical qualitative test  \\n to be able to be confident that the data  \\n are truly representative of your target users.  \\n You can find the average in the Excel download,  \\n but you should spend your time looking  \\n at the distribution of answers,  \\n meaning how many people rated something high, low  \\n or somewhere in the middle.  \\n You can then compare this information  \\n to your expectations, or a benchmark.  \\n You may quickly watch the videos  \\n of everyone using automatic highlight reels,  \\n or just the outliers to see  \\n why their feedback differed from others.  \\n Rating scale questions are best used  \\n when you need a quick way to gauge strength of feeling,  \\n when you are comparing two different approaches  \\n or when you are benchmarking an experience over time.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3047261\",\"duration\":122,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Multiple choice questions: Quick trends and patterns\",\"fileName\":\"3005392_en_US_02_11_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Multiple choice questions help you to understand preference, spot patterns, and help people to characterize their experience or reasoning. Learn how to understand this information effectively.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4315828,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Multiple choice questions  \\n are a great way to ask some types  \\n of survey-style questions  \\n so that you can assess the frequency  \\n and distribution of answer choices.  \\n You might choose to ask people  \\n to report what tools they're using,  \\n what elements of the experience they found appealing,  \\n or to explain their reasoning,  \\n while also enabling them to characterize  \\n or categorize your feedback  \\n to support really quick assessment and review.  \\n Also, you can use multiple choice questions  \\n as a quiz to determine if people found the correct answer  \\n or information in the case  \\n that you're trying to learn whether information's findable.  \\n Some best practices to keep in mind.  \\n Give people an out.  \\n There should be an answer choice  \\n that lets people know they don't know,  \\n have another idea or that none of the answers apply.  \\n Ensure answer choices are mutually exclusive  \\n and also, avoid questions that enable people  \\n to predict which answer you expect for them to choose.  \\n Finally, make sure that you prompt people  \\n to talk about their answer.  \\n All of this makes the process  \\n of reviewing data much more efficient  \\n because you can see the counts  \\n and distribution of answer choices  \\n before you watch videos.  \\n And when you watch those automatic highlight reels  \\n of participants, you can capture some feedback  \\n and more evidence around the topics  \\n that people might have surfaced  \\n in the context of other questions.  \\n You might want to use more multiple choice questions  \\n during mobile tests as replacements  \\n for written questions.  \\n This is a more effective way  \\n of managing the limited text input on small devices  \\n when you want to replace written questions  \\n and have a sense of how people might answer.  \\n Multiple choice questions are great  \\n because they enable you to surface patterns quickly  \\n and they obviously naturally create accounts for you.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3048280\",\"duration\":119,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Written questions: Quick quotes, tone, and language\",\"fileName\":\"3005392_en_US_02_12_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Written questions are a great way to capture quotes, capture tone and language, or understand feeling in people's chosen language. Learn strategies to optimize your use of these questions.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5022051,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Written response questions help you  \\n to understand tone as well as elicit feedback  \\n around the language and word choice at a glance.  \\n The unique value of them is that you can read faster  \\n than you can listen,  \\n which means that you can use the metrics page  \\n to quickly read through what people have written  \\n and then decide whether or not you want to watch  \\n the accompanying video.  \\n When writing these questions,  \\n think about providing guidance about  \\n just how much feedback you want.  \\n For example, you can ask people to only provide  \\n about two to three sentences  \\n or a couple of words or even phrases  \\n in order to describe something that they've seen.  \\n Another strategy is to use written questions  \\n to capture quotes.  \\n You can leverage smart tags,  \\n which surface and categorize the adjectives that people use,  \\n to understand the sentiment that's reflected  \\n in the language that people are using.  \\n You can also download the Excel report  \\n to look at things in a little bit more detail  \\n and get quicker access to those quotes.  \\n One other strategy that you can leverage  \\n written response questions for  \\n is as a quick way to check whether people  \\n have made it to a critical milestone  \\n that's required as they are completing a task.  \\n You can also have people write lists or descriptions  \\n in response to images or concepts  \\n that you have just shown them,  \\n in their own language.  \\n One final consideration.  \\n When using written questions during mobile tests,  \\n keep in mind that typing on mobile devices  \\n is more challenging than it is  \\n on a typical desktop or laptop keyboard.  \\n Written questions are an effective way  \\n to capture what people think.  \\n Use them as a way to create insights  \\n that are easy to review and also to share.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3043286\",\"duration\":309,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"The unmoderated interview\",\"fileName\":\"3005392_en_US_02_13_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"It is not always necessary to interview people live. Sometimes, to capture information more efficiently and to reduce bias, you might want to have people answer questions in a self-guided interview. Learn strategies to adapt your interview guide to this setting.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9526627,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Narrator] Unmoderated interviews provide you  \\n with an opportunity  \\n to hear people's perspectives and stories  \\n without having someone there to listen  \\n and drive the conversation  \\n and that means that as a result,  \\n these often encourage people to be even more open and direct  \\n in their feedback.  \\n So why might you choose to do them?  \\n There are a great number of reasons,  \\n but I think the most important ones are really about  \\n sometimes it's important to have someone not be  \\n in the room so that you don't have an issue  \\n around moderator bias.  \\n Sometimes people can be a distraction  \\n because they say things or react in a way  \\n that makes people feel judged.  \\n The second piece is sometimes you need to get a lot  \\n of feedback very quickly and not having a moderator  \\n in the room means that you can potentially have people all  \\n over the world in a very short period of time,  \\n or even asynchronously at the same time providing feedback.  \\n When you want to gather feedback from a large number  \\n of people, this also extends your reach.  \\n Finally, this gives you the opportunity  \\n to capture the experience that people have  \\n in their own homes.  \\n So think about using show and tell as a strategy.  \\n So you don't just have to have people talk to the camera,  \\n but you also might have them show  \\n what their experiences are like  \\n or what they are doing in order to complete tasks  \\n in their own space or gather information on their own terms.  \\n When you're thinking about how to structure the interview,  \\n interviews in both the moderated and unmoderated setting  \\n look quite similar,  \\n and the chief difference is that  \\n when you don't have someone there,  \\n you don't have the ability to go off on tangents.  \\n So you have to think about what are the things that you  \\n would naturally want to follow up on and make sure  \\n that everybody answers that question.  \\n So let's talk about each one of these question types.  \\n The first is introductory questions,  \\n which should be setting expectations  \\n about what people are going to be doing  \\n and setting them at ease.  \\n Think about this as you're being a host.  \\n So since more frequently on the User testing platform,  \\n they're completing tasks,  \\n telling them upfront that they're just going to be speaking  \\n is important if that's what they're going to be doing.  \\n So obviously if that's not going to be true for your test,  \\n you'll be wanting to set different expectations.  \\n Warm up questions should be focused on letting people talk  \\n in more detail about their experience, their backgrounds,  \\n or attributes or perspectives that connect them  \\n to the topic areas that they will be discussing  \\n and it's a great way to help to validate  \\n that the right people have qualified to take the test  \\n and are providing you with your feedback.  \\n Some of the considerations for top priority questions are  \\n that everybody who's going to be participating  \\n should be able to answer them.  \\n And you want to ensure that all of your research goals  \\n and objectives, so everything that you want insights about  \\n are going to be covered in this area  \\n so that you get answers to the critical questions  \\n that you want to understand better.  \\n You don't have to use just verbal questions.  \\n So think about using other question types,  \\n such as written response or multiple choice  \\n as a means of not only gathering information,  \\n but also breaking it up because sometimes when people  \\n just talk, it gets a little bit challenging  \\n to stay on track.  \\n So changing things up can be useful.  \\n When you shift gears into the deep focus questions,  \\n you might do a mix of asking people to talk about examples  \\n and stories and provide descriptions of what's they've done  \\n in the past,  \\n but also asking them to think about higher level thematic  \\n questions.  \\n And a couple of examples of those might be around.  \\n How do you typically do something?  \\n So find the answers to the questions that you might have,  \\n or what resources might you typically use.  \\n Finally, at the end of the unmoderated interview,  \\n you want to provide people with space to share things  \\n that might've come to mind,  \\n but that you might not have asked as direct questions.  \\n And finally thank them.  \\n Obviously you're hosting that session  \\n and even if you're not present in the room with them,  \\n you still have a responsibility to ensure  \\n that they feel like they've closed out the experience  \\n successfully.  \\n Unmoderated interviews help people  \\n to connect with user needs quickly  \\n and the insights from these conversations end up being used  \\n across a number of different deliverables,  \\n including personas or as a means of connecting  \\n to potential areas of focus for new, feature,  \\n or product design.  \\n And finally, just having people talk  \\n and share is an effective empathy building strategy.  \\n \\n\\n\"}],\"name\":\"2. Remote Unmoderated Testing\",\"size\":93781748,\"urn\":\"urn:li:learningContentChapter:3045233\"},{\"duration\":749,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3048281\",\"duration\":150,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Set up a live conversation on UserTesting\",\"fileName\":\"3005392_en_US_03_01_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Setting up the time to speak with people is straightforward in the UserTesting platform. This video provides pointers on how to do this most effectively.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4784309,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] When you want to have  \\n a live conversation with your users,  \\n user testing helps connect you to the right people  \\n and schedule a convenient time for everyone.  \\n You have the option of leveraging the user testing  \\n contributor network, or inviting people  \\n using your own custom networks,  \\n or even inviting people directly using email.  \\n The process of scheduling interviews is straightforward.  \\n First, you need to select an audience.  \\n The same options that are available for unmoderated tests  \\n are also available for live conversations  \\n or moderated tests.  \\n Then, you will need to provide availability.  \\n You should plan to log in about 15 minutes early,  \\n and depending on the type of account you have,  \\n will need to be present for the interviews.  \\n Block enough time to accommodate at least the interview  \\n and buffer time for all of your participants.  \\n So for example, if you want to do interviews  \\n with five people with a 30 minute buffer  \\n between each interview, you'll need to schedule at least  \\n seven and a half hours.  \\n You may schedule 30 or 60 minute interviews.  \\n Depending on the type of account you have,  \\n you might be able to schedule interviews  \\n of up to 120 minutes.  \\n It's recommended that you give yourself a break  \\n in between interviews, just in case one runs late,  \\n or you want to debrief with your team.  \\n You may schedule on the same day  \\n or at any point in the future.  \\n To avoid having interviews start  \\n immediately after you've launched a test,  \\n you may adjust the advance notice setting.  \\n Check the time zone.  \\n Pick one that's convenient for you and for your audience,  \\n based on your respective geographic locations.  \\n Finally, the easiest part is selecting the time blocks.  \\n Be sure to provide sufficient availability  \\n during time periods where it's practical  \\n for you to do the interviews.  \\n And you may schedule interviews for the weekends.  \\n Consider having observers join you.  \\n The system will generate links for each session,  \\n which you may then invite observers to join.  \\n Be sure that you set expectations with observers  \\n about their role in the sessions.  \\n Setting up time to talk one-on-one with your users is easy,  \\n and lets you focus on planning for your conversation.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3048282\",\"duration\":309,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"The interview: How to prepare\",\"fileName\":\"3005392_en_US_03_02_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Interviewing people can seem intimidating. This video equips you with planning and preparation strategies that will enable you to conduct successful interviews.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9036983,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Live conversations or moderated interviews  \\n are a popular way to build empathy with your users.  \\n The user testing platform helps you to recruit  \\n and schedule with the right audience.  \\n You get to decide how you spend your time together.  \\n Live conversations are perfect for giving you  \\n the flexibility you need to build rapport,  \\n pick up on subtle cues and hints like body language  \\n or hesitation that you might want to follow up on,  \\n ar when you need to be able to shift gears  \\n and learn about topics or concerns that might be  \\n unique to maybe even just one person.  \\n There is no rule that says that you must have  \\n a long interview guide.  \\n You might even just go in with the intention of learning  \\n about how people are accomplishing their goals,  \\n or what challenges or unmet needs they have.  \\n In that case, all you need to do is prepare a few questions  \\n that help you to set the tone for the conversation.  \\n And, obviously, set that intention.  \\n However, in cases where you want to spend time with people  \\n who are hard to recruit, have some specific questions  \\n that you would want to ensure that you ask everyone  \\n in a consistent way, or to plan for a larger team  \\n to share the responsibility of leading the interviews,  \\n you should develop a more formal interview guide.  \\n Interviews, regardless of whether there's someone there  \\n to moderate, can look very similar across both  \\n the unmoderated and moderated setting.  \\n For moderated tests, in addition to the guide,  \\n you should be intentional about planning specific  \\n follow-up opportunities, as well as questions,  \\n to be sure that you take advantage of your time together  \\n to intentionally probe and go off-script.  \\n Make sure you join the call at least 10 to 15 minutes early.  \\n Many people also join early, so plan to be ready to start  \\n when they join to build rapport.  \\n So, plan how you want to set expectations  \\n for your time together, introduce yourself,  \\n and also the project that you're working on.  \\n Warm-up questions also help build rapport  \\n and get people used to talking to you.  \\n Use them as an opportunity to learn more about  \\n the experience, perspectives, and attributes  \\n that they're bringing to the conversation.  \\n Top priority questions are the must-asks.  \\n Make sure that everybody can answer them,  \\n and that you cover all of the objectives  \\n that your team really wants to focus on.  \\n It's also a great idea to actually write out follow-up  \\n questions that anticipate digging in on some of  \\n the specific areas of focus that are particularly important  \\n for you and your team.  \\n Deep focus questions may lead you to expose stories  \\n or specific examples, or at a higher level to explore themes  \\n that might have come up earlier as part of  \\n those top priority questions.  \\n Again, you want to be intentional about those follow-ups  \\n to ensure that you consistently dig into key areas  \\n across some or all of your participants.  \\n Finally, you'll wrap up your time together by offering  \\n the opportunity for people to share feedback that they  \\n haven't yet already and thanking them for their time.  \\n So here are a few tips to make the most  \\n of these conversations.  \\n First, you want to be sure that you have a plan  \\n for taking notes.  \\n You can do this both live in the platform,  \\n or use a strategy with your team that's offline,  \\n like in a document, for example, a shared document.  \\n You might also want to have an observer take notes  \\n during the session so that you can focus  \\n on the conversation.  \\n Obviously, you don't want to bias people,  \\n so avoid leading questions,  \\n and only ask one question at a time.  \\n It's okay to redirect people, so make sure that you think  \\n about how you want to do that ahead of time.  \\n A great example of that is,  \\n that's a really great point,  \\n but we really need to focus on this other topic.  \\n Let's talk about this.  \\n The other thing you might want to do is repeat  \\n what people say as you understand it,  \\n to confirm that you understood, really,  \\n what it is that they intended to share with you.  \\n One of the great benefits of actually being there  \\n in the moment is that you can use people's body language  \\n or other cues, like tone of voice or how they're leaning  \\n or even just the types of words that they're using,  \\n to identify opportunities to probe and follow up.  \\n And then, you don't want to use yes or no questions.  \\n If you're really interested in that,  \\n I would recommend using a survey instead.  \\n That's a better use of your time.  \\n Bottom line, the best way to get good at this  \\n is to practice.  \\n You might consider having a researcher or a more experienced  \\n interviewer support you as a coach  \\n for your first few interviews.  \\n Attend a few interviews before you do one on your own.  \\n Practice taking notes and pay attention  \\n to what the moderator is doing.  \\n The more experience you gain, the better you'll be.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3046254\",\"duration\":290,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Testing complex flows or ideas\",\"fileName\":\"3005392_en_US_03_03_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Moderated testing enables you to guide participants or follow up to gather more nuanced feedback from participants. This video shows you how to plan and prepare to conduct live tests of design documentation or live experiences.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9328994,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Usability testing of interactive experiences  \\n focuses on surfacing feedback about areas of opportunity,  \\n pain-points or weaknesses in your design solution.  \\n When you have a design approach that's not fully developed,  \\n that's complex or that requires a lot of logistical support  \\n or where you want to just have  \\n a lot of follow-up conversation, it's a perfect candidate  \\n for testing using live conversation.  \\n This gives you the flexibility  \\n to manage a more interactive and nuanced test.  \\n As you're thinking about what you're going to do  \\n during your time with your participants,  \\n focus on improvements.  \\n This is really a three-step process.  \\n First, you plan what you want to learn,  \\n who you want to test with  \\n and what sort of feedback you need.  \\n Then you schedule the test and plan this script,  \\n and finally run the test and gather and review the feedback.  \\n Make sure that you plan how to introduce yourself  \\n and set expectations  \\n about how you're going to spend your time together.  \\n You might have people answer a few warmup questions  \\n to learn more about them and their experience.  \\n Set the stage by giving them just enough context  \\n to make the scenario realistic for them.  \\n Next, provide instructions  \\n about what you would like for them to do,  \\n they should be step-by-step and quite simple  \\n so that people can remember what they need to do.  \\n You might even want to create a document  \\n that they can refer to and reread  \\n as they are completing the test.  \\n Typically, you want to learn  \\n whether people understand the information provided  \\n and the outcomes they should expect  \\n as result of completing the task successfully.  \\n So the structure of the live conversation type  \\n of moderated test looks very similar  \\n to that of an unmoderated test,  \\n beyond those additional logistical things  \\n that you might need to cover  \\n and the fact that you can be there to ask those probes  \\n and follow-up questions in real time.  \\n You'll want to ensure that you track  \\n whether people can complete the task, how long it takes,  \\n and here you're going to have to define  \\n how you're going to time that manually.  \\n So what's the beginning and the end of the task,  \\n what that means,  \\n and then ask how satisfied people were with the experience.  \\n Keep in mind that sometimes  \\n rather than answering people's questions,  \\n you might want to ask them  \\n what they think the answer is first  \\n that helps you to understand their reasoning  \\n and if they still require your assistance to move on,  \\n you can provide that support.  \\n Depending on the complexity of the tasks,  \\n you may schedule 30 or 60 minutes sessions.  \\n Some accounts allow for up to 90 to 120 minute long tests.  \\n So follow up with your support team  \\n to determine what's possible for you.  \\n During that time, you can have people complete the tasks,  \\n do a little bit of an interview, answer a follow-up survey  \\n or whatever it is that you need to do  \\n in order to get the feedback that you're looking for,  \\n some mix of all of those things, or even just one of them,  \\n but most typically for a usability test,  \\n you do want to make sure  \\n that you have people complete those tasks  \\n and collect information about those pain-points.  \\n Wrap up your task by asking one to two questions  \\n that let people provide feedback  \\n that they might not already have shared.  \\n This lets people share ideas  \\n or react to the overall experience.  \\n While it can be intimidating to plan for a test  \\n where you're working with a person in a live setting,  \\n it's totally fine to practice and get better at it  \\n as you go along.  \\n The best way to learn is to practice.  \\n Just understand that it is acceptable to redirect people  \\n if they get lost in certain circumstances,  \\n because you don't want to give them too much help,  \\n you can help to show them where to start or continue  \\n if they get off track,  \\n and also if you need to shift gears or end the call early,  \\n because you get the feedback that you need  \\n before the end of your allotted time,  \\n that's perfectly acceptable.  \\n The best way to learn is to practice,  \\n observe a more seasoned researcher  \\n and then conduct some simple tests with some coaching first.  \\n And as I said before, as you get more practice,  \\n you will be come a lot more comfortable  \\n and be able to exercise your judgment  \\n around when it's appropriate for you to jump in  \\n and when you should also let people  \\n try to resolve whatever challenges  \\n they come across on their own.  \\n \\n\\n\"}],\"name\":\"3. Remote Moderated Testing\",\"size\":23150286,\"urn\":\"urn:li:learningContentChapter:3043288\"},{\"duration\":601,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3047262\",\"duration\":395,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Find the right participants\",\"fileName\":\"3005392_en_US_04_01_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Frequently, you should test your experiences and designs with your customers, or with those who could become customers. This video shows you how to determine how to screen for the people who have the right attitudes, experiences, behaviors, or characteristics to participate in your test.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12491790,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Narrator] There are very few,  \\n if any experiences that are intended to be used  \\n by almost everyone.  \\n This means that most of the time,  \\n it's important to test your product, imagery language,  \\n and other ideas with the intended audience.  \\n The user testing panel is global in scale,  \\n and offers a number of people  \\n who have a wide range of needs, goals,  \\n experiences, behaviors, and preferences.  \\n Once you've run a test and have participants  \\n you might want to follow up with,  \\n you have a couple of options.  \\n You can create a panel with multiple participants  \\n that you might want to have  \\n participate in multiple tests in the future.  \\n This is helpful, for example,  \\n if you want to quickly find the same people  \\n who provide great feedback to test again with,  \\n and again with them.  \\n You can also reach out to individual participants  \\n by using specified participants.  \\n In addition, you have several options  \\n to test with your own participants  \\n who might be your own colleagues or customers  \\n whose contact information  \\n you have already collected elsewhere.  \\n When you test with the user testing contributor network  \\n or with your own custom network,  \\n people around the world may qualify  \\n to answer screener questions  \\n based on their demographic information,  \\n which they provided when they joined.  \\n By default, if you do not select any demographic filters,  \\n anyone around the world may qualify to take your test.  \\n Be mindful that your segmentation is meaningful.  \\n For example, if gender is not significant for you,  \\n then don't use it.  \\n Finally, it's a best practice  \\n to be as inclusive as possible  \\n so that you get a good representation of perspectives.  \\n Once people have met your demographic requirements,  \\n you may answer screener questions to qualify  \\n to take your test.  \\n So let's talk more about how demographics  \\n and screener questions work together.  \\n First, use summer graphics  \\n to find people who are located  \\n in the relevant geographic regions, who are the right age,  \\n or who have the right income or employment status  \\n that you need, among other important attributes.  \\n By default, anyone who takes a test  \\n associated with your company's account  \\n cannot take another test within 360 days.  \\n But you can update this fresh eyes setting for your company  \\n or for yourself by contacting the user testing support team.  \\n You can test with people who speak English, Spanish, French,  \\n and German, by using the language requirement filter.  \\n Keep in mind that to test with people who speak Chinese,  \\n Brazilian, Portuguese, and Japanese,  \\n you must use the invite network, also known as my recruit.  \\n Screener questions enable you to ask many types of questions  \\n and qualify the right people  \\n based on what answer choices they choose.  \\n Depending on what type of account you have,  \\n there's no limit on the number of questions you can ask,  \\n but keep in mind that it will take longer to fill your tests  \\n if you have more than six or so of them.  \\n The average test fills in about two hours.  \\n So if you see that your test  \\n is taking longer than that to fill,  \\n you might want to double check the number of questions,  \\n and also how you structured them.  \\n You have the ability to ask either a single select  \\n or multi-select questions.  \\n For single select answer choices,  \\n you may elect to accept or reject participants  \\n depending on which one they choose.  \\n For multi-select answer choices,  \\n people may choose more than one response.  \\n Those who select reject answer options  \\n will be immediately disqualified,  \\n but those who select may select choices  \\n will qualify to answer more screeners or to take the test.  \\n People must choose all of the responses  \\n labeled as more select to be qualified to take a test.  \\n A few pointers about qualifying the right people.  \\n Everyone gets one chance to answer each screener question.  \\n They don't get to try again.  \\n For this reason you want to disqualify  \\n as many participants early,  \\n so they don't waste their time trying to qualify  \\n by answering a large number of questions.  \\n Use jargon strategically.  \\n Fake brand or company names, fictitious job titles,  \\n and other industry jargon can help you to disqualify people  \\n who are not in the know.  \\n Use seven to 10 answer choices at most per question  \\n to avoid choice fatigue.  \\n Also, provide mutually exclusive answer options  \\n that do not overlap.  \\n Provide an out like I prefer not to answer  \\n or none of the above so that respondents have an option  \\n if the given choices don't apply to them,  \\n or if they're confused,  \\n otherwise they might pick a random answer choice  \\n and inappropriately qualify.  \\n Avoid leading questions.  \\n By not telegraphing your intended qualifying answer choices,  \\n people will be empowered to answer honestly,  \\n and qualify for tests that are appropriate.  \\n On a related note, use yes and no questions strategically.  \\n People have a 50/50 possibility of answering correctly,  \\n so frame these questions carefully  \\n and put them in the flow of your screener,  \\n where it will disqualify people appropriately.  \\n Finally, avoid double barreled questions  \\n that touch upon two factors, but allow only one answer.  \\n Not only will this confuse you  \\n because you won't know which of the two factors  \\n or if both are true,  \\n but it can also end up qualifying the wrong people.  \\n So let's take a quick look at an example  \\n of how to translate a description of the people  \\n you want to test with,  \\n to demographics and screener questions.  \\n First use demographics.  \\n Filter for people who are parents, and who are in the US.  \\n Then ask some screener questions.  \\n You might choose to ask about future travel intent.  \\n You might also ask about what mode of travel,  \\n and finally, you might ask whether they would consider  \\n your company to book with.  \\n Again, while that's a lot to remember,  \\n keep in mind that once you create the perfect screeners,  \\n you can save them as either saved questions  \\n or saved audiences for your own or your team's future use.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3045231\",\"duration\":206,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"How many and who?\",\"fileName\":\"3005392_en_US_04_02_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Efficient testing means choosing just the right number to provide enough evidence for you to make decisions. Depending on how much time you have and your goals, this number might vary. This video covers what considerations you should take into account as you're deciding how many people should complete your test.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6038542,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Some feedback is better than none most  \\n of the time.  \\n After all, your design solution  \\n will be tested by your users when it becomes public,  \\n so it's better and less expensive  \\n to make it as easy to use and understandable as possible  \\n before you release it.  \\n In a perfect world,  \\n you would test everything with your target users.  \\n In reality, you might find this difficult to do  \\n for many reasons,  \\n including limited timelines, resources  \\n or access to the right people.  \\n This means that you will have to right size your approach  \\n with those things in mind.  \\n Sometimes your stakeholders might question  \\n how reliable your insights are based on their perception  \\n that statistical significance is always required.  \\n It is not.  \\n If you're looking to uncover pain points  \\n as you design and build products,  \\n on UserTesting, we typically see five  \\n to eight people provide feedback for each test.  \\n They will find the most critical pain points  \\n and you'll be able to do more rounds of testing  \\n as you make improvements.  \\n You're not trying to make a point.  \\n Instead, you're trying to get quick feedback  \\n to make incremental improvements to a design.  \\n For interviews to gather information  \\n about user needs and experiences,  \\n we see tests include 10 to 15 people.  \\n This gives you more chances  \\n to uncover a broader variety of perspectives.  \\n The number of people you might test with  \\n to gather insights about language,  \\n imagery or other rich media typically ranges  \\n between 5 to 15 people,  \\n depending on timeline.  \\n Because timelines are usually quite short,  \\n we usually see tests at the lower end of that range.  \\n If you're trying to understand performance measures  \\n in usability tests, such as tests, success,  \\n timeline tasks or perceptions  \\n of the experience with a minimal level of confidence,  \\n say a 15% confidence interval,  \\n about 40 users should suffice.  \\n To get to lower confidence intervals,  \\n like 5 or 10%, you would need  \\n to do some mathematical modeling  \\n to understand the size of your overall audience  \\n and some other factors to arrive  \\n at the right number.  \\n If you're doing comparative testing or benchmarking,  \\n or other types of advanced testing,  \\n this mathematical modeling becomes a requirement.  \\n These typically require larger numbers of participants,  \\n at least 100 and more in some cases.  \\n Card sorting typically requires at least 30 participants  \\n to support your ability to spot patterns.  \\n Finally, some audiences are harder to connect with.  \\n There may not be many people in the world  \\n who have the specific attributes  \\n and perspectives you want to target  \\n or they may be hard to reach.  \\n In those cases, you might connect with proxy users.  \\n For example, for doctors,  \\n you might substitute medical students.  \\n Or if you decide to invest the time  \\n to recruit C level executives,  \\n you should plan to conduct a live conversation with them  \\n to maximize your ability to tailor the conversation.  \\n It is possible to test consistently  \\n with larger groups of people  \\n but there are trade-offs.  \\n If your team is insistent about having more feedback,  \\n work with them to figure out what they would find useful  \\n and negotiate those trade-offs.  \\n \\n\\n\"}],\"name\":\"4. Finding the Right People\",\"size\":18530332,\"urn\":\"urn:li:learningContentChapter:3045234\"},{\"duration\":133,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3043287\",\"duration\":133,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Next steps\",\"fileName\":\"3005392_en_US_05_01_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5779880,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Getting feedback from the people  \\n for whom you design and build products, experiences,  \\n language, rich media, among other things,  \\n changes your experience about how to approach your work.  \\n When you see things through the eyes of people  \\n who don't have your level of experience or knowledge,  \\n your motivation to simplify the experience  \\n and remove barriers grows.  \\n Deciding when and how to look for insights  \\n beyond your opinion and that of your team  \\n pushes you to create more compelling  \\n and innovative solutions.  \\n The most successful businesses and organizations  \\n invest a lot of energy in understanding  \\n how to balance user needs and business goals  \\n by building connections to their audiences.  \\n You've reached the end of this course,  \\n but I encourage you to make this the start of a journey  \\n to learn more about how to connect with people.  \\n To help you along the way,  \\n I've created a question bank that you can use  \\n as you write tests,  \\n to find ideas for how to ask people  \\n about your work effectively.  \\n It also includes recommendations  \\n for how to review that feedback.  \\n UserTesting also provides dozens of templates  \\n that cover the most common tests that we see people run.  \\n And those are accessible from within the platform.  \\n University.usertesting.com offers a number  \\n of more advanced courses,  \\n and you can always find quick solutions to challenges  \\n at help.usertesting.com.  \\n If you're seeking training credentials  \\n or updates about trends,  \\n some good places to start include  \\n the Nielsen Norman group at nngroup.com,  \\n and the User Experience Professionals Association  \\n at uxpa.org  \\n Rosenfeld Media at rosenfeldmedia.com  \\n is a solid resource for UX books, conferences,  \\n and to connect with other practitioners  \\n in subject area focused communities.  \\n Also, talk to researchers at your company  \\n or at local meetups.  \\n They will have a lot of wisdom and guidance to share.  \\n I hope that this course has inspired you  \\n to build empathy with your audiences.  \\n I encourage you to practice  \\n and further develop your skills.  \\n That's the best way to hone your approach.  \\n \\n\\n\"}],\"name\":\"Conclusion\",\"size\":5779880,\"urn\":\"urn:li:learningContentChapter:3044243\"}],\"size\":173585476,\"duration\":5233,\"zeroBased\":false},{\"course_title\":\"Agile UX Research\",\"course_admin_id\":3910287,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":3910287,\"Project ID\":null,\"Course Name\":\"Agile UX Research\",\"Course Name EN\":\"Agile UX Research\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"This course explores how the user experience research (UXR) practice fits into agile development approaches so that teams can understand their users and build better products. Join instructor Amanda Stockwell as she outlines the foundational concepts of agile and associated practices like scrum and shares best practices from her experiences of integrating UX research efforts into those systems. Learn tips to assemble the right teams, set up logistics for efficient collaboration, establish a cadence that embraces continuous learning, and more. Along the way, discover best ways to adapt research methods for agile workflows and keep insights flowing in practice. Ideal for UX designers, product managers, scrum masters, and any professional eager to better understand how UXR can fit into agile, this course can help you successfully integrate practices to ensure your teams actively gather the feedback needed to stay truly agile.\",\"Course Short Description\":\"Learn the fundamentals of agile methodologies and how to best incorporate user experience (UX) research processes into the approach.\",\"Content Type\":\"SKILLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":5287222,\"Instructor Name\":\"Amanda Stockwell\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"President of Stockwell Strategy\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2024-11-26T00:00:00\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"Yes\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/agile-ux-research\",\"Series\":\"Persona\",\"Limited Series\":null,\"Manager Level\":\"Individual Contributor\",\"LI Level\":\"Intermediate\",\"LI Level EN\":\"Intermediate\",\"Sensitivity\":null,\"Internal Library\":\"Creative\",\"Internal Subject\":\"User Experience\",\"Primary Software\":null,\"Media Type\":\"Video\",\"Has CEU\":\"No\",\"Has Exercise Files\":\"No\",\"Visible Duration\":2431.0,\"Visible Video Count\":18.0,\"Contract Type\":\"PERPETUAL\"},\"sections\":[{\"duration\":52,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:5989078\",\"duration\":52,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"The agile development approach\",\"fileName\":\"3910287_en_US_00_01_VT\",\"demo\":true,\"videoCreationMetadata\":{\"rawDurationSeconds\":349,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\\n\\n3 FULL READ-THROUGHS; PLEASE USE THIRD VERSION\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3139243,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- The Agile development approach continues to be one\\nof the most popular ways software teams organize\\nthemselves and their work.\\nAgile is a framework that encourages collaboration\\nand response to changing needs.\\nSo integrating UX research ought\\nto be a natural fit in practice.\\nSuccessfully doing so can be a real challenge.\\nIf you're brand new to UX Research,\\nconsider watching my UX Foundation's research course\\nbefore diving in here.\\nHi, I'm Amanda Stockwell.\\nI've worked with dozens of software teams over the last\\ndecade and a half, and seen plenty of examples of\\nwhat works well and what you might want to avoid.\\n\\nIn this course, I'll cover a broad overview\\nof the Agile approach and associated practices,\\nrecommended logistics for team setup and cadence,\\nand tips to alter traditional research practices\\nto best fit an agile environment.\\nAre you ready?\\nLet's do this.\\n\"}],\"name\":\"Introduction\",\"size\":3139243,\"urn\":\"urn:li:learningContentChapter:5989079\"},{\"duration\":468,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:5990081\",\"duration\":209,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Agile and scrum overview\",\"fileName\":\"3910287_en_US_01_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":336,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"After this video, you'll be able to explain the concepts of agile and scrum\u2014and how both relate to UX projects\u2014so you're able to envision and brainstorm ways it can be applied to your own teams and projects.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9348131,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Before we talk too much about incorporating UX research\\ninto Agile practices,\\nlet's take a step back and look at Agile.\\nTraditionally, software development happened\\nin distinct phases, first gathering requirements,\\nthen discovery and design,\\nmoving next to implementation,\\nbefore testing and releasing.\\nRequirements remained static once set,\\nand often led teams to build products\\nthat ultimately didn't get used.\\nIn 2001, a group of frustrated developers met\\nto discuss alternate paths forward.\\n\\nThey agreed that software development was too focused\\non rigid plans and documentation and not on driving value.\\nSo the Agile Manifesto was born,\\nstating a shared set of values to guide software teams.\\nThe core values described in the Agile Manifesto\\nare individuals and interactions\\nover processes and tools,\\nworking software over comprehensive documentation,\\ncustomer collaboration over contract negotiation,\\nand responding to change over following a plan.\\n\\nThere are also 12 detailed principles\\nthat expand on the values, outlining a commitment\\nto a way of working that honors this theory.\\nThe intention was never to prescribe particular processes,\\nbut rather to provide guidance\\non working more efficiently and flexibly.\\nMore than two decades later, teams of every size and shape\\nuse variations of iterative development processes\\nbased on these values and call themselves Agile.\\nThese teams might use a variety of specific frameworks\\nto guide themselves and organize their work.\\n\\nOne framework, Scrum, is so popular\\nthat many of its practices\\nhave become synonymous with Agile.\\nScrum teams are made up of the individual contributors\\ndesigning and building things,\\na product owner who's responsible for managing the backlog\\nand representing needs of both users and the business\\nand a Scrum master who helps facilitate\\nand is intended to remove barriers from the team.\\nScrum calls for teams to break down work\\ninto chunks called stories,\\nregularly estimate the effort to complete those stories\\nand prioritize the most important elements.\\n\\nThen plan work into short chunks of time called sprints.\\nAt the end of each sprint,\\nthe team should theoretically be able\\nto ship anything they build.\\nScrum also defines a workflow cadence,\\nincluding planning meetings at the beginning\\nof every sprint cycle, daily standup meetings\\nto check progress, reviews to demonstrate what was completed\\nand retrospectives for the team to reflect\\non the prior sprint and discuss any process changes\\nthat need to be made.\\nEach team sets their own definition of done\\nor standard set of acceptance criteria across stories\\nand code is released only if the product owner agrees\\nthat a story meets his criteria at the end of a sprint.\\n\\nScrum prescribes meeting cadence and process,\\nbut puts a large focus on the team to organize themselves,\\nalter practices to best fit their context\\nand adjust to changing needs or requirements.\\nIn recent years, Large Scale Scrum, or LeSS,\\nhas risen in popularity, looking to offer clarity\\non how to scale Scrum across teams at a big organization.\\nIt's based on the same ideals as traditional Scrum,\\nbut provides guidance on additional roles and ceremonies\\nto help coordinate efforts.\\n\\nUnderstanding the basics of Agile provides insight\\non the way that most software teams work now.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5987083\",\"duration\":194,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Other frameworks\",\"fileName\":\"3910287_en_US_01_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":529,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"After this video, you'll be able to describe several examples of alternate development frameworks to get a sense of how scrum and agile differ from one another, and the unique benefits of agile.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8011051,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- There are many other popular frameworks in Agile\\nsuch as Kanban, extreme programming,\\nfeature-driven development, and lean development.\\nEach of these supports the core Agile values,\\nbut suggest different specific processes,\\nroles, or ceremonies.\\nFor instance, Kanban calls for a continuous flow of work\\nand just limiting the number of items in progress,\\nplus allows for code releases as soon as an item is done.\\nWhen talking about Agile practices,\\nyou may also hear the terms Lean, lean development,\\nlean UX, and lean Startup.\\n\\nThese terms often get used interchangeably with Agile,\\nbut have some distinct elements.\\nIn general, the term Lean is used to refer\\nto holistic business\\nand management practices that aim\\nto maximize customer value while minimizing waste.\\nThe approach is derived\\nfrom lean manufacturing best practices,\\nand promotes organizational efficiency.\\nLean Development is a software-specific approach\\nto implement the ideas behind lean.\\nThe Approach recommends practices\\nthat focus on increasing efficiency\\nand value, removing waste, and designing the system\\nand teams in place to maximize those efforts.\\n\\nLean UX is the term for altering UX methods\\nto become faster, focused\\non collaboratively visualizing ideas\\nand gathering feedback as soon as possible\\nwithin a hypothesis framework\\nrather than general exploration.\\nMeanwhile, the Lean Startup approach is a broader business\\nand product development strategy.\\nIt pulls inspiration from lean manufacturing principles,\\nbut emphasizes incorporating cycles of experimentation\\nto inform business decisions and decrease risks.\\nThese are not mutually exclusive practices.\\n\\nTeams often combine elements from the different frameworks\\nto suit their needs.\\nFor example, an organization may embrace the ideas\\nof including constant experimentation from the lean startup,\\napproaches to reduce waste from lean\\nand use Scrum practices\\nto organize their teams and work structure.\\nThere have also been efforts\\nto make Agile practices scale more widely\\nacross large organizations, so you may see references\\nto the Scaled Agile Framework known as SAFe.\\nSAFe combines principles from Lean, Agile, and DevOps,\\nand is focused on helping organizations\\nintegrate best practices to be more responsive\\nto changing needs and technologies.\\n\\nThe suggested home\\nof UX practices has shifted throughout iterations of safe,\\nbut generally calls for Lean UX practices.\\nThis is a good time to point out that Agile, safe,\\nand most of the other frameworks were made by developers\\nfor other developers.\\nThey don't necessarily accommodate UX workflows very well.\\nIt's also important to know\\nthat there is no one single correct implementation\\nof Agile approaches other than the shared practices\\nof having self-organizing cross-functional teams\\nthat focus on adapting to changing needs\\nand frequently delivering value.\\n\\nTherefore, there's also no one single set of processes\\nthat I recommend to facilitate research integration.\\nMy suggestions are relevant to Agile settings\\nregardless of the specific framework used.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5990080\",\"duration\":65,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Why development and business process matters to UX\",\"fileName\":\"3910287_en_US_01_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":127,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"After this video, you'll be able to describe how development and business processes relate and interact with the UX process, so you're able to better integrate stakeholders into the process.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3308255,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Because traditional agile teams value frequent release\\nof working code, there are no distinct stages for discovery,\\nresearch, and requirements definition, design, development,\\nand testing like in traditional software\\ndevelopment approaches.\\nFor those of us in user experience,\\nthis means we no longer have dedicated time upfront\\nto thoroughly explore users\\nor perform extensive discovery research,\\nand we'll often figure out the specifics\\nof a design just in time for development to begin,\\nthis means we need to adjust our traditional methods\\nto fit in shorter timeframes\\nand work in parallel with the rest\\nof the cross-functional team.\\n\\nLooking for ways to build in time to get feedback\\nand integrate changes as necessary.\\nThat can be scary,\\nbut it also means that we get the chance to respond\\nto rapidly changing needs of users, teammates,\\nand business stakeholders.\\nIn fact, this ability to learn along the way\\nand respond to change as one of the core tenets\\nof working in Agile, if done well, we can constantly uncover\\nand act on opportunities to improve the user experience.\\n\"}],\"name\":\"1. Background\",\"size\":20667437,\"urn\":\"urn:li:learningContentChapter:5987084\"},{\"duration\":735,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:5989077\",\"duration\":159,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"UX in agile\",\"fileName\":\"3910287_en_US_02_01_VT\",\"demo\":true,\"videoCreationMetadata\":{\"rawDurationSeconds\":301,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"After this video, you'll be able to select the right members for your team to take the most advantage of the agile process.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8800531,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- One of the biggest questions\\naround incorporating UX research into agile teams\\nis how to structure those teams.\\nThere are debates about whether agile teams\\nshould have embedded UXers\\nor a separate team of cross-functional UX professionals.\\nThere's also larger ongoing debates\\nabout what skill sets UX professionals should have,\\nwhich is especially relevant when planning agile teams.\\nThe best solution is going to depend on the size\\nand type of the organization,\\nas well as how mature the UX practices are there.\\n\\nHowever, it's important to keep a few facts\\nin mind when shaping your own UX team structure.\\nUX represents a diverse set of skill sets.\\nNo one should ever be testing their own designs,\\nand a successful UX research practice addresses\\nboth short and long-term needs.\\nWe'll talk a bit more about setting research cadence later.\\nBecause UX is actually an umbrella term for a large set\\nof research and design disciplines and a diverse skillset,\\nevery UX professional has a slightly different slice\\nof experience and expertise.\\n\\nSome UXers do generalize and have a broad set of skills,\\nbut they're still likely to be stronger in one area\\nor another and tend to lean more towards research\\nand strategy skills or design skills.\\nMost of the agile framework documentation seems\\nto gloss over this fact, generally referring\\nto anything related to design\\nor research in the bucket of UX.\\nIt can sound beneficial\\nto have one single UX person tackle everything,\\nbut that's just not often feasible.\\nNo matter how experienced the UX professional.\\n\\nWe need time to collaborate with business\\nand technical teams, as well as think\\nabout the big picture strategy,\\nconduct foundational research to understand\\nproblem space and user base,\\nformulate specific solutions,\\nexplore individual ideas, set and measure benchmarks,\\nand drive standards for cohesion.\\nThat's too big of a job for one person,\\nboth metaphorically and practically.\\nEven if time and skillset was not an issue,\\nit's not a good idea for people to be solely responsible\\nfor research on a product that they are also designing,\\nespecially the evaluation components of research.\\n\\nPeople are inherently biased\\nand it's impossible to remain completely objective\\nwhen assessing your own work.\\nNo matter how much you attempt to offset bias,\\nwhen you create something you won't be able to help\\nassuming that it's the best solution.\\nThe diverse skills and conflicting interests\\nof UX professionals means they shouldn't be allotted\\nto teams the same way as developers are on an agile team.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5990078\",\"duration\":182,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Team structures\",\"fileName\":\"3910287_en_US_02_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":249,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"After this video, you'll be able to define and set the logistics for participants in your agile processes to assure a smooth environment for creativity and collaboration.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9525935,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Given that UXers have such diverse skills\\nand shouldn't be assessing their own work,\\nhow should they be incorporated into agile teams?\\nI've seen the following team structures be most successful.\\nTwo full UX professionals embedded\\nin each cross-functional team.\\nOne who focuses more on research\\nand one who focuses more on design.\\nThe team members definitely have some skill overlap\\nand collaborate on sketches, prototypes,\\nand actually running research,\\nbut there is separation of who owns visuals\\nand who owns research.\\n\\nBoth the researcher and designer\\nare fully dedicated team members,\\nparticipating in all team activities like stand-ups\\nand retrospective meetings.\\nIn this case, I recommend\\nthat the researchers split their efforts\\nbetween short-term experimentation and validation\\nand ongoing exploratory research.\\nWhen that's not an option, I recommend\\nthat each team has a full-time designer\\nand a research unit that floats between the teams.\\nResearchers can and still should collaborate with the rest\\nof the team,\\nbut they aren't fully devoted to a single team.\\n\\nI especially like when researchers\\nare able to work in pairs,\\nand divide and conquer the work across no\\nmore than three teams.\\nPairs can still split their work between short\\nand long-term research efforts\\nfor the teams that they serve.\\nIn very small companies\\nor organizations that are new to UX,\\nI have seen Agile teams rely solely on UX generalists.\\nI'm not generally in favor of hiring these UX unicorns,\\nin part because of the inherent bias I mentioned when\\ntesting one's own work.\\n\\nI also advise against this\\nbecause it can be incredibly stressful for that person\\nand they can burn out quickly.\\nThat's not to say that a single person can't be experienced\\nin any area of UX,\\nbut that it isn't optimal to put all\\nof the UX activities onto a single person's plate.\\nIf there is no option to hire a research specialist,\\nI recommend embedding generalists\\non each cross-functional team\\nand having the generalist partner up\\nto collaborate on research efforts,\\nespecially validation and evaluation work.\\n\\nPartnering helps offset bias\\nof designers testing their own work\\nand allows UXers to collaborate\\nwith others in their discipline.\\nI recommend that UX professionals be embedded\\non Agile teams.\\nBeing a part of the team helps UX be recognized\\nas an integral part of the process,\\nhelps build trust between UX and other disciplines,\\nallows UXers to develop product specific knowledge,\\nand provides the opportunity for teams\\nto perform ongoing experimentation.\\nIt's imperative\\nthat creating a good experience becomes the responsibility\\nof everyone on a team with each set\\nof expertise contributing in its own way.\\n\\nFor instance, the designer may be responsible\\nfor figuring out how a page is laid out,\\nbut it's up to the developers to make sure\\nthat it works correctly and speedily.\\nThis is a cultural shift,\\nand having UX team members\\ntruly integrated helps build that mindset.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5977392\",\"duration\":104,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Set experimentation cadence\",\"fileName\":\"3910287_en_US_02_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":173,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"After this video, you'll be able to set an appropriate cadence for your project to make sure sprints support a strong iterative development process.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5813875,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- One of the main benefits\\nof embedding UXers on agile teams\\nis the ability to collect feedback\\nto help make timely design and product decisions.\\nFor example, you could run a usability test\\nto figure out which version of an interaction\\nto implement the next sprint.\\nThis kind of tactical, evaluative work\\nis usually focused on assessing existing solutions\\nor validating hypotheses about new solutions.\\nTo enable research to happen quickly enough,\\nset a regular, predictable,\\nfrequent cadence for experimentation.\\n\\nThis holds teams accountable\\nfor incorporating experimentation,\\nprovides visibility, consistency,\\nand the opportunity to collaborate,\\nand helps ease some of the logistical pain\\nof conducting frequent research.\\nGo ahead and commit\\nto some sort of experimentation every cycle\\nand make sure that it gets integrated into the team's plan.\\nFor instance, if you're on a scrum team\\nwith three-week sprints,\\nyou could set the second Thursday of every sprint\\nas a research day.\\nIf you don't use sprints,\\nyou can still dedicate a particular time to research,\\nsuch as the third Wednesday of each month.\\n\\nAim to build in time for research sessions like this\\nat least once a month\\nso the team's questions are never left open long.\\nJust be sure researchers aren't working in isolation\\nor too far removed from the rest of the team's schedule.\\nSometimes there is a push for the UX team to work far ahead\\nto inform design decisions\\nbefore the developers get involved,\\nbut that can ultimately end up creating more work\\nto build understanding and buy-in during a handoff\\nand perpetuate silos.\\nLooking ahead is important,\\nbut so is staying in touch\\nwith the current needs of the team.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:5989076\",\"duration\":124,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Account for foundational research\",\"fileName\":\"3910287_en_US_02_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":246,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6525183,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- One of the main challenges of Agile teams\\nis that they are typically focused on just-in-time tactics.\\nBut some of the most useful research work\\nis ongoing in-depth foundational work.\\nThis kind of research was traditionally only done\\nat the beginning of a project to provide direction,\\nbut should be conducted regularly\\nto make sure you're learning about evolving markets,\\ntechnologies, and needs and context of your user base.\\nThis is the sort of research\\nthat will drive product strategy\\nby uncovering opportunities\\nand making sure that you're building things\\nthat people actually want and will use.\\n\\nYou may also want to dedicate some time to benchmarking,\\nor measuring experience and performance over time.\\nThere is sometimes a push for this work\\nto be squeezed into a sprint zero,\\nwhich is the dedicated setup time\\nbefore any code progress is made in the Scrum process.\\nUsing that time to conduct foundational research\\ncan be helpful,\\nbut you shouldn't limit your learning opportunities.\\nTo make sure exploratory work gets done,\\nset a cadence for conducting this kind of work,\\njust like you do for just-in-time work.\\n\\nFor instance, you can make sure that every eighth sprint,\\nyou'll be conducting interviews, site visits,\\nor benchmarking studies\\nto understand your user's current context of use.\\nPut all kinds of research work\\nin the same backlog as the rest of the team\\ninstead of a separate UX backlog\\nso that it's visible\\nand you can align research efforts\\nwith the rest of the team.\\nThe specific cadence\\nthat will work for your teams will vary.\\nIf you're earlier in the product development cycle,\\nor about to embark on a redesign effort,\\nyou'll likely need to spend more time\\non understanding users and their needs\\nto uncover opportunities.\\n\\nIf you're actively redesigning a widely used product,\\nyou'll want to make sure\\nyou're doing a lot of the evaluative testing\\nto ensure that changes are well-received.\\nIf you're expanding an existing product,\\nyou might want to focus\\non benchmarking the experience over time.\\nThe most important thing is to be sure to find a balance\\nof tactical and strategic work.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5988066\",\"duration\":166,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Logistics of securing research participants\",\"fileName\":\"3910287_en_US_02_05_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":274,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8728735,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- One of the hardest parts of conducting any research,\\nlet alone research on a regular basis,\\nis finding, screening, and scheduling participants.\\nTo help with this, I recommend two things.\\nBuild a panel of willing participants\\nand proactively schedule research sessions\\non your designated research times.\\nA panel is a list of people\\nwho have expressed interest in providing you feedback.\\nIf you have existing users, you can set up a screener survey\\nand invite people to sign up\\nvia your company's normal communication channels,\\nlike emails, post it on your website\\nor social media outlets,\\nintercept visitors for particular pages,\\nor invite customers who contact support.\\n\\nYou can also recruit people\\nwho aren't yet customers or users.\\nFor instance, let's say that you are building an application\\nto help fitness enthusiasts find new classes.\\nYou might ask a local gym\\nif you can put up a poster inviting people,\\nfind a Facebook group for fitness instructors,\\nor create a post with specific fitness hashtags.\\nThe best way to recruit\\nis going to depend on your user base,\\nso be willing to experiment with different sources.\\nIt's really helpful to continually recruit people\\nand build up a pool of people you can contact over time.\\n\\nThe panel can be as simple as a spreadsheet,\\nor you can integrate into an existing CMS,\\nif you have access.\\nThe screener should be aimed at identifying\\nwho you want to talk to and who you want to screen out.\\nIf you have existing personas,\\nit's great to use the screener\\nto try to identify which persona type of person fits.\\nIf you get lots of participants\\nthat don't fit a particular persona type, it might be a clue\\nthat you need to revisit or add to your personas.\\nIf you don't have any personas,\\nyou may be able to use the data you collect\\nto help you identify trends.\\n\\nJust be aware that you may bake bias into your results\\nbecause panel members\\ntend to already be engaged with your brand.\\nRegardless of who you're inviting to research sessions,\\nif you have designated research blocks,\\nyou can proactively recruit and schedule participants.\\nYou can use a scheduling tool like Calendly\\nto set times that work for you and let participants sign up.\\nTools like this will send confirmations and reminders\\nand allow participants to reschedule if need be.\\nOne helpful tip, try to schedule sessions in a time\\nthat's likely to be convenient for the participants.\\n\\nFor example, if you need to talk\\nto parents of school-aged children, it may not make sense\\nto schedule sessions in the early morning\\nwhen they're likely to be rushing to get kids ready.\\nYou can also use remote tools with built-in panels\\nto avoid these logistic headaches altogether.\\nBut of course, you don't have as much control\\nover who you include.\\nMore on what types of research to do, and when, coming up.\\n\"}],\"name\":\"2. Team Preparation\",\"size\":39394259,\"urn\":\"urn:li:learningContentChapter:5987085\"},{\"duration\":557,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:5990079\",\"duration\":90,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Choose a research method\",\"fileName\":\"3910287_en_US_03_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":123,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"After this video, you'll be able to select the right research method to best support your team and project in an agile cadence and workflow.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4587327,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- It's crucial to successful UX research\\nto choose the right methods at the right times,\\nand this can be especially confusing in an agile setting.\\nThe good news is that all the same rules\\nof UX research considerations apply\\nregardless of the setting.\\nOnce you figure out your research goal,\\nthe same methods you traditionally use will still apply.\\nYou still need to consider the product development stage\\nand identify the riskiest open questions,\\ndetermine whether you're looking for trends or reasons,\\nthink through whether you need\\nto look at behaviors or attitudes,\\nnarrow down specific questions to answer,\\nconsider the context you need\\nto investigate your open question,\\nand then choose a method\\nthat will help you answer your questions appropriately\\nand fit into the context of your work environment.\\n\\nYou still want to think first about your research goal\\nand what you're trying to learn,\\nand let that guide which method\\nis the best fit for your question.\\nMy UX Foundations: Research course\\ngoes over how to choose your method in detail\\nif you need to brush up.\\nAnd the Nielsen Norman Group\\nhas a great summary to reference.\\nYou'll probably have to adapt traditional UX methods\\nto fit into an agile setting.\\nBecause there's not dedicated time to research\\nand an initiative to always march towards releasing code,\\ntimelines for research are compressed,\\nand there's pressure to get feedback faster and faster.\\n\\nChoosing the right methods\\nwill make sure you're collecting the right data\\nto inform your team's work,\\nand not wasting time.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5977391\",\"duration\":176,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Set narrow goals and hypotheses\",\"fileName\":\"3910287_en_US_03_02_VT\",\"demo\":true,\"videoCreationMetadata\":{\"rawDurationSeconds\":293,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"After this video, you'll be able to craft strong hypothesis statements to be vetted by the team, so there are strong objectives for each sprint.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8689022,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- One way to narrow the research scope\\nto fit into Agile settings is\\nto break down your research goals into the smallest\\npossible questions.\\nYou won't miss out on answering questions\\nbecause you're doing research all the time,\\nand sometimes you can combine small individual\\nresearch goals.\\nWhen doing evaluation work,\\nI recommend creating hypotheses.\\nThis recognizes assumptions,\\nframes the research,\\nand helps the team analyze more quickly.\\nI like to use the following framework adapted from lean\\nstartup practices.\\n\\nIf we do build or provide this thing,\\nthen these people will do some desirable outcome.\\nWe'll know this is true when we can measure X thing.\\nThe do, build, or provide section refers\\nto the solution you're proposing.\\nThese people represent your actual or target users.\\nThe sum desirable outcome is what you want people to do\\nand an explanation of the value of that action.\\nThe measure of success is a way to set your goal\\nto feel comfortable whether or not you move forward.\\n\\nYou may be able to pull numbers from business partners like\\nan amount of money to make something worth an investment.\\nThat would also set you up well\\nto prove the return on investment in UX activities.\\nWhen you don't have those numbers,\\nmake an educated guess.\\nYou can alter the framework to fit your purposes,\\nbut framing research this way helps you quickly identify\\ntarget participants, what data you need to collect\\nand barometers of success.\\nLet's say that you're working on an application\\nthat allows small businesses to manage their expenses\\nand you want to introduce a new recurring invoice feature,\\nbut you need to figure out the best place for it to live.\\n\\nIf you turn that goal into a hypothesis,\\nit might look something like this.\\n\\\"If we put the recurring invoices link in the sales portion\\n\\\"of the navigation,\\n\\\"micro-business owners will be able\\n\\\"to find the new feature easily.\\n\\\"We'll know this is true when 80%\\n\\\"of people asked to look for it\\n\\\"will be able to find it on the first try.\\\"\\nYou might then conclude that you need to make a prototype\\nof the new navigation structure\\nand run a usability task with a task\\nof finding recurring invoices.\\nTaking note of whether people find it on the first attempt.\\n\\nWhen doing exploratory research,\\nyou won't be able to set a cut and dry hypothesis,\\nbut you can still state your assumptions\\nand narrow your goals\\nto help you frame your research.\\nBe clear about what questions you want answered\\nand what decisions you want to make using\\nthe information you gather.\\nYou don't want to go into exploratory research trying to prove\\nor disprove a point,\\nbut being explicit about your guesses can\\nhelp you avoid bias.\\nRegardless of the kind of research,\\nthere's likely going\\nto be pressure to go as quickly\\nas possible to fit into Agile.\\n\\nNarrowing your research goals\\nand identifying hypotheses\\nwill help you plan, run,\\nand analyze efforts more quickly.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5987082\",\"duration\":137,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Balance rigor and speed\",\"fileName\":\"3910287_en_US_03_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":276,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"After this video, you'll be able to balance the needs of rigor and speed to find the right cadence for your team to build quality products.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7904588,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- In addition to focusing your research goals,\\nyou may need to get creative\\nabout how you employ research methods\\nto maximize findings in minimal time.\\nIt may take some getting used to for those of us\\nwho come from a rigorous research background,\\nbut there are many ways to flex methods\\nto adapt to shorter timeframes.\\nYou can run sessions remotely instead of in person,\\nreduce the number of sessions overall,\\nrun unmoderated studies, utilize lower fidelity prototypes,\\nrecruit participants in an unusual way,\\nsuch as on social media\\nor intercepting in a public location,\\nor any combination of these methods.\\n\\nThese are all common ways to shorten the timeframe\\nand investment into traditional research activities.\\nTo decide what to alter, keep your research goal in mind\\nand look for opportunities to cut\\nwhile still answering your key questions.\\nFor instance, maybe a usability test a specific interaction\\nwith colleagues who aren't familiar with the project\\ninstead of recruiting outside users.\\nMaybe you moderate participants through a test\\nwith a paper prototype or non-interactive wire frames.\\n\\nMaybe you conduct interviews over video conferences\\ninstead of visiting a person's workplace.\\nReducing scope this way\\noften means that we're relying more\\non remote and unmoderated methods.\\nThere are well-documented cons\\nto not being able to interact face-to-face with a user,\\nbut if your choices are to skip research sessions\\nor alter them some, definitely choose the latter.\\nAll the typical best practices\\nfor conducting research still apply.\\nJust be sure to balance the shortcuts you make\\nand not compromise the rigor of your study too much.\\n\\nFor instance,\\nif you're going to perform interviews remotely,\\nmaybe you can do more of them,\\nor pair unmoderated card sorts and tree tests.\\nCheck out my UX Foundations course\\nfor more detail in choosing methods,\\nor my deep dive courses for method-specific hints.\\nThere are always trade-offs,\\nbut the beauty of performing research in an agile setting\\nis that you're never done.\\nEach set of research should help you feel more confident\\nin your decisions.\\nBut if you're ever unsure of next steps,\\nyou can always plan to recover open questions\\nin your next round of research.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:5986093\",\"duration\":154,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Perform research together\",\"fileName\":\"3910287_en_US_03_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":239,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"After this video, you'll be able to set up and manage shared research sessions with participants to get the most collaboration possible in an agile, rapid process.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8699091,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- The same best practices\\nfor conducting UX research apply in any setting.\\nYou need to ask questions in a neutral way,\\nmake sure participants feel comfortable\\nand engaged in sessions,\\nand be sure that you inspire participants\\nto dig deeper without leading them.\\nThere's detailed information and tips to conduct UX research\\nin chapter four of my UX Foundation's research course.\\nThe one key difference in conducting research\\nin an agile setting is that you have a better opportunity\\nto include the rest of the team.\\nI can't stress enough how important it is to take advantage\\nof agile's emphasis on cross-functional collaborative teams\\nand get as many members of your team\\nas possible involved in the process.\\n\\nOne of the best ways to get team members involved\\nis to include a discussion about research priority\\nin the team's planning sessions.\\nYou can have people add open questions\\nto your team's backlog, and the research questions\\ncan be prioritized just like any other sort of work.\\nThis helps everyone view research\\nas a fundamental part of the team\\nand gives all an opportunity\\nto have their questions answered.\\nYou'll also want to incorporate team members\\ninto the process of conducting research as much as possible.\\nWhen team members observe research,\\nI like to have a shared spreadsheet\\nwhere anyone can add their notes.\\n\\nI typically list each participant in a row\\nand the key hypotheses across the top\\nthat you can break down the spreadsheet in any way\\nthat makes sense for your team.\\nBeyond the logistical help,\\nincluding the team members in research helps everyone see\\nthe value of research and ultimately saves time.\\nHere's why, a lot of non-UX researchers\\nare removed from the people who use what they create.\\nDevelopers and stakeholders might read reports\\nor hear stories about users' frustrations,\\nbut there is nothing quite as illuminating\\nas watching someone grimace their way\\nthrough an interface to build empathy.\\n\\nIn fact, another team member may pick up on something\\nthat you miss or be able to provide a different perspective\\nthat will help you come up with better solutions.\\nWhen the whole team is involved in the research process,\\neach person can observe and learn at the same time.\\nGetting everyone to learn together means everyone\\nunderstands the findings more deeply and immediately.\\nEveryone can start to see how their work contributes\\nto a person's overall experience.\\nIncluding the team in research sessions also means\\nthat you can spend less time documenting what happened\\nand communicating it back to the team.\\n\\nWe'll talk more about analyzing\\nand synthesizing the data you collect in the next section.\\n\"}],\"name\":\"3. Research Adaption\",\"size\":29880028,\"urn\":\"urn:li:learningContentChapter:5991015\"},{\"duration\":583,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:5987081\",\"duration\":175,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Analyze together\",\"fileName\":\"3910287_en_US_04_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":414,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"After this video, you'll be able to interpret and create overviews of your research findings, so you can quickly come to high-level directions and signals for your team.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7587122,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- A group debrief can help you efficiently interpret data\\nand move on to next steps.\\nSet aside at least an hour after data collection\\nand invite everyone who is able to participate.\\nHave everyone share their key thoughts\\non each goal or hypothesis and any additional observations.\\nDiscuss the priority of each finding,\\nand then end with a brainstorming session\\non the highest-priority items.\\nI typically begin by giving everyone three to five minutes\\nto write down individual observations.\\nPeople can include anything that they noted\\nor think is worth discussing,\\nwhether it was directly related to a hypothesis\\nor a new observation.\\n\\nThink back to the hypothesis\\nwe said about business expenses.\\nMaybe you observed that people who sold products\\nwanted recurring invoices,\\nbut each of the service provided\\nnoted that they never have a need\\nto send a recurring invoice.\\nYou'll want to pay special attention\\nto common use cases and routines,\\nthe context in which people work,\\ntransitions between use cases,\\nthe language people use,\\nworkarounds or shortcuts that people find,\\nwhere people get stuck or interrupted,\\nand things that are especially annoying or pleasing.\\n\\nOnce everyone's noted their observations,\\nyou can begin to organize.\\nI like to conduct an exercise like affinity mapping\\nto group the information.\\nYou combine related observations and spot trends, outliers,\\nand get a big overall picture\\nof all the information you collected.\\nYou can reorganize a few times to look at different angles.\\nIt's important to pay attention to the discussion\\nand explore different perspectives.\\nWhen you've written a clear, concise hypothesis,\\nand designed your research well,\\nit should be pretty easy to interpret the results.\\n\\nThink back to that same hypothesis\\nabout adding recurring invoice functionality\\nto an expense management tool.\\nIf we put the recurring invoices link\\nin the sales portion of the navigation,\\nmicro-business owners\\nwill be able to find the new future easily.\\nWe'll know this is true\\nwhen 80% of people asked to look for it\\nwill be able to find it on the first try.\\nIf you usability test to prototype with 10 people\\nand nine of them find it right away,\\nyou can say you proved your hypothesis\\nand implement the solution.\\n\\nNote that this doesn't mean that 90% of people\\nwill always find the new functionality,\\njust that you've met the criteria to move forward.\\nSometimes the findings don't point you\\nin such a clear direction, or open up even more questions.\\nThese areas can become your targets\\nfor next rounds of research,\\nand you can use the rest of the meeting\\nto discuss the priority of the findings.\\nDo you care what your business software users eat for lunch?\\nProbably not, but should you pay attention\\nto the observation that many of your users\\ngo out to business meals and attempt\\nto keep track of their expenses on their phone?\\nMore likely.\\n\\nThere are a variety\\nof prioritization exercises you could use,\\nbut I often find a team conversation sufficient\\nto agree on key takeaways.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5984186\",\"duration\":106,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Immediately responding to feedback\",\"fileName\":\"3910287_en_US_04_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":321,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7193095,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- If there are clear problems identified during a debrief,\\nyou can use some of the session to brainstorm solutions\\nthat address experience and design\\nbut also take into account technical feasibility\\nand business considerations.\\nThen you won't have to worry about convincing people\\nto buy into your recommendations\\nor tell you that a suggestion can't be built,\\nbecause the whole team will be there\\nto come up with the next steps.\\nRather than ending the research sessions with a report,\\nyou can end with the team\\nhaving a shared understanding of findings\\nand the beginnings of a plan for next steps.\\n\\nEveryone learning together\\nmeans there can be less opinion-based debate\\nand more database decisions,\\nwhich lets you all move faster.\\nYou might want to incorporate the research debrief\\nas part of the planning session\\nfor the next iteration of work.\\nSince there's already time set aside for teams to plan\\nin most variations of agile,\\nyou won't be asking\\nfor additional meeting time from your team.\\nJust be careful to keep the focus\\non understanding the data you just collected\\nand setting the frame\\nfor the work that needs to be done next,\\nrather than trying to completely solve issues\\nthen and there.\\n\\nIf you're not doing concurrent sessions,\\nyou may also want to schedule debrief sessions\\nafter each participant\\nand see if there's anything minor\\nyou could change between sessions to improve the experience.\\nFor instance, if two users in a row can't find an item,\\na developer or designer might be able\\nto quickly update a prototype\\nthat you can show the next participant.\\nThat way, you don't spend a whole chunk of time\\nconfirming that something is broken.\\nRather, you can get some rapid feedback\\non different versions\\nand pick a direction based on the data you collect.\\n\\nThe ability for the whole team to see feedback in real time\\nand immediately address\\nis one of the most beneficial aspects\\nof incorporating research regularly.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5977390\",\"duration\":156,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Integrate results\",\"fileName\":\"3910287_en_US_04_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":375,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"After this video, you'll be able to clearly integrate the results of your sprint back into the iterative agile process, so you can assure productive sprints downstream.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6545535,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- If you're able to successfully include the team\\nin the research process, you should be able\\nto spend less time documenting findings\\nand convincing the team to appreciate it.\\nHowever, you'll still need to spend some time making sure\\nthat the research gets fully incorporated\\nand shared broadly.\\nYou'll want to briefly document what research you've done\\nand what you learned in case team members shift,\\npriorities change, or you simply don't have time\\nto address all your findings.\\nPlus, you need to find ways to document what you've done\\nfor posterity's sake, or in case there's a stakeholder\\nor team member that couldn't be involved.\\n\\nThe best way to document\\nand communicate will depend on your specific team.\\nI typically first create a brief summary\\nthat highlights the key research questions\\nand hypotheses, what was found,\\nnext steps, links to any related documents or pictures\\nand a designated leader.\\nI keep this in a living spreadsheet\\nthat gets updated every research cycle\\nso that people can see how things evolve.\\nI simplify that documentation even more\\nand send an email that summarizes just the key\\nresearch goal, finding and next steps.\\n\\nThese emails are quick\\nand in the same format every time\\nso that people know what to look for.\\nThe key is to keep this process brief.\\nAim for the summary to take no more than 15 minutes to write\\nand five minutes to read.\\nI also recommend adding any follow-up work\\nto your team's backlog,\\nrather than creating a separate UX backlog\\nto keep it visible to the whole team\\nand have it prioritized along with other types of work.\\nThis will reinforce the importance of your efforts, as well\\nas including the whole team in those efforts.\\n\\nIt allows other team members to account\\nfor the time they may spend participating\\nin research efforts.\\nWhen in doubt about what to add to the backlog,\\none fallback is to repeat past research efforts.\\nRepeating research efforts makes planning incredibly easy,\\nhelps you build confidence in your results,\\nand helps you establish baselines\\nso you can compare the experience over time.\\nIf your team uses retrospectives,\\nyou can also use those meetings\\nto keep UX research findings top of mind.\\nIn a retrospective, the team reflects on team interactions,\\ntools, and processes, and what could be done better\\nmoving forward.\\n\\nIf your team has a Wiki\\nor other tool that they use to keep track\\nof retrospective outcomes, you can add a line\\nor two for UX summary so that discussion topics aren't lost.\\nAgain, you'll need to adjust communications\\nto your particular team,\\nbut the goal is to develop a culture\\nwhere everyone is invested in creating the best possible\\nexperience and where everyone sees how research supports\\nthat goal.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5986092\",\"duration\":146,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"AI in agile\",\"fileName\":\"3910287_en_US_04_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":492,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8649067,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- It may be tempting to turn to ai to speed up UX practices\\nto make them better fit agile processes.\\nWhile I certainly appreciate ways to speed up,\\ngenerative AI has some limitations to be aware of\\nwith respect to research.\\nFirst, there are data privacy concerns\\nwith uploading your data into tools.\\nAI works by iterating its model based on new data,\\nwhich means your proprietary or confidential information\\ncould be used to train their model.\\nMany of the paid tools are starting to offer data controls,\\nbut it's likely you'll need to work\\nwith your organization's privacy, security,\\nand or legal teams to formulate guidelines.\\n\\nBecause AI tools use past data to spot trends\\nand make predictions, they may also carry over past biases\\nor holes in data.\\nFor instance, if a model was trained on UX best practices\\nfor North American enterprises,\\nit may not be at all applicable for someone living in Asia\\nworking in a startup.\\nA model may not recognize an extension\\nof a pattern that doesn't share the same context\\nor generalize patterns too much to provide any real insight.\\nFor instance, an AI tool might be able to quickly identify\\nthat 10 of 15 interview participants report\\nusing the same video conference tool,\\nand also identify\\nthat 12 participants work remotely on a regular basis,\\nbut not make any connection between the two points,\\nor give you any indication of what those things mean\\nfor your particular setting.\\n\\nDespite their power, AI tools still have limited ability\\nto synthesize and account for context,\\nmeaning they're likely\\nto help summarize information or spot trends,\\nbut won't necessarily identify truly new insights\\nnor interpret the results.\\nIn fact, a good way to think about\\nwhat generative AI tools do is simply\\npredict the next likely word\\nbased on statistics of what has already happened.\\nThat's great, but you still need a human to make connections\\nbetween data points, business context,\\nand technical feasibility,\\nand collaboratively create solutions\\nthat take all of that into account,\\nwhich is paramount in an agile setting.\\n\\nI recommend using AI for repeatable routine tasks\\nthat don't require interpretation\\nand that you as a human will still review,\\nlike creating transcripts out of audio recordings.\\nI don't recommend AI tools for data synthesis\\nand decision making, least not yet.\\n\"}],\"name\":\"4. Analyze Research\",\"size\":29974819,\"urn\":\"urn:li:learningContentChapter:5987086\"},{\"duration\":36,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:5987080\",\"duration\":36,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Next steps\",\"fileName\":\"3910287_en_US_05_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":105,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2440268,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Thanks so much for watching\\nand learning about ways\\nto successfully integrate UX research practices\\ninto an agile environment.\\nThis course has given you plenty of ideas about how\\nto structure your teams,\\nand set logistics to encourage research integration\\nand specific tips to get you started\\nplanning, executing,\\nand analyzing research in an agile way.\\nYou'll likely need to experiment to find the exact setup\\nthat works best for your organization.\\nIf you ever have specific questions,\\nfeel free to reach out to me directly on LinkedIn.\\n\\nThank you again for watching this course, and good luck.\\n\"}],\"name\":\"Conclusion\",\"size\":2440268,\"urn\":\"urn:li:learningContentChapter:5991016\"}],\"size\":125496054,\"duration\":2431,\"zeroBased\":false},{\"course_title\":\"Practical A/B Testing\",\"course_admin_id\":4493001,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":4493001,\"Project ID\":null,\"Course Name\":\"Practical A/B Testing\",\"Course Name EN\":\"Practical A/B Testing\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"A/B tests, when done correctly, can give you valuable insights into your data and transform your digital products. In this course, learn how to set up A/B tests with tech expert Oluchukwu Okpala. Join Oluchukwu as she explains the basics of A/B testing, its key benefits to digital projects, and its common applications. Learn how to set objectives and measurement indicators for your tests, define your control and treatment groups, and determine variables to test. Plus, find out about the proper ways to set up tests and assign participants and how to analyze and interpret the results of your testing. Finally, Oluchukwu explains some strategies for iterating and optimizing your tests.\",\"Course Short Description\":\"Learn how to set up A/B tests with tech expert Oluchukwu Okpala.\",\"Content Type\":\"TOOLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":20554010,\"Instructor Name\":\"Oluchukwu Chioma Okpala\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"Software Engineer\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2024-05-06T00:00:00\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"Yes\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/practical-a-b-testing\",\"Series\":\"Project\",\"Limited Series\":null,\"Manager Level\":\"Individual Contributor\",\"LI Level\":\"Intermediate\",\"LI Level EN\":\"Intermediate\",\"Sensitivity\":null,\"Internal Library\":\"Creative\",\"Internal Subject\":\"User Experience\",\"Primary Software\":\"VWO\",\"Media Type\":\"Video\",\"Has CEU\":\"No\",\"Has Exercise Files\":\"No\",\"Visible Duration\":2866.0,\"Visible Video Count\":17.0,\"Contract Type\":\"PERPETUAL\"},\"sections\":[{\"duration\":50,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3895077\",\"duration\":50,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Learning about practical A/B testing\",\"fileName\":\"4493001_en_US_00_01_VT\",\"demo\":true,\"videoCreationMetadata\":{\"rawDurationSeconds\":370,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"Get introduced to the topics found in this course about the value and practical uses of A/B testing.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3181630,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Hello, wonderful people.\\nWelcome to our practical A/B testing course.\\nTogether we are diving head first\\ninto the world of A/B testing,\\nwhere we will harness the power of VWO\\nto surcharge your website's conversion rate\\nand optimization efforts.\\nBut wait, there is more.\\nGet ready to dive deep into analyzing data\\nand turning insights into action.\\nBy the end of this course,\\nyou'll be fluent in the language of A/B testing,\\nand armed with the skills to make informed decisions\\nthat can take your digital product to the next level.\\n\\nSo let's roll up our sleeves, embrace the challenges,\\nand turn every test into a triumph.\\nI am Oluchukwu, and I couldn't be more thrilled\\nto be your guide on this exciting journey.\\nAre you ready to make\\nyour A/B testing journey extraordinary?\\nLet's do this.\\n\"}],\"name\":\"Intro\",\"size\":3181630,\"urn\":\"urn:li:learningContentChapter:3895078\"},{\"duration\":684,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3897076\",\"duration\":163,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"What is A/B testing?\",\"fileName\":\"4493001_en_US_01_01_VT\",\"demo\":true,\"videoCreationMetadata\":{\"rawDurationSeconds\":179,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"Learn about the concept, value and practical uses of A/B testing so that you have context for the rest of this course.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4215842,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Let's start by giving a definition to A/B testing,\\nalso referred to as A/B/n test or split testing.\\nIt is also called the univariate test\\nbecause the concept should test only one change at a time.\\nIn fact, let's break it down\\nin a way that is easier to grasp.\\nNow, picture this:\\nA/B testing is like having a couple of different versions\\nof your website or app\\nand seeing which one gets the golden star.\\nIt's all about comparing tweaks\\nor changes to find out which one works best.\\n\\nIn the world of marketing,\\nuser experience design and website optimization,\\nA/B testing is the go-to method.\\nYou throw a couple of variations of your webpage\\nor element into the ring\\nand see which one comes out on top for hitting your goals.\\nNow, here is the kicker.\\nYou're usually just comparing two versions\\nagainst each other,\\nhence, the A versus B thing.\\nBut hey, you can get fancy\\nand throw in more variations if you're feeling adventurous.\\nCall it A/B/C/D testing if you like.\\n\\nBut remember, keep it simple.\\nTesting too many changes at once can make it tricky\\nto figure out what's actually making the difference.\\nNow, here is where things get really cool,\\nPersonalized A/B testing.\\nThis is like tailoring those different versions\\nto suit individual users.\\nYou're crafting experiences that speak differently\\nto different groups\\nbased on who they are, what they like,\\nand how they behave online.\\nFor instance, let's say you're running an online store.\\n\\nWith personalized A/B testing,\\nyou might tweak layout or content of your site\\ndepending on where your users are located\\nor what they've bought before.\\nIt's all about making sure everyone gets the VIP treatment.\\nBut fair warning:\\nDiving into personalized A/B testing\\nisn't exactly a walk in the park.\\nIt's worth noting that implementing personalized A/B testing\\ncan be complex as it requires collecting\\nand analyzing a bunch of user data,\\ncreating multiple variations for different groups,\\nand effectively managing the testing process\\nto ensure statistically significant and reliable results.\\n\\nSo there you have it.\\nA/B testing and its personalized sidekick in a nutshell.\\nIt's all about fine-tuning your online presence,\\nensuring you're hitting the right notes\\nwith your audience,\\nand ultimately winning big\\nin the game of conversions and engagement.\\nNow let's delve deeper into the benefits\\nand importance of A/B testing.\\nBuckle up because we are about to uncover the secrets\\nto making informed decisions, optimizing user experiences,\\nand achieving better results across the board.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3899064\",\"duration\":214,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Benefits and importance of A/B testing\",\"fileName\":\"4493001_en_US_01_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":373,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"Learn how to further explain the benefits of A/B testing and it's importance to modern digital projects so you are able to justify the effort within your teams and organizations.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5538393,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Presenter] So now that we've got a handle\\non what A/B testing is all about,\\nlet's dive into why it is such a game-changer.\\nLet's talk about some of the benefits\\nand importance of A/B testing.\\nFirst is the data-driven decision-making.\\nWith A/B testing, it's a goodbye to guess work.\\nA/B testing lets you make decisions based on hard data,\\nnot just hunches.\\nIt's like having a crystal clear roadmap\\ninstead of wandering around in the dark.\\nAs an organization,\\nit helps you to understand the actual interaction\\nand how your application users\\nactually engage with your app.\\n\\nThe next advantage is iterative improvement.\\nHave you ever heard the saying continuous improvement?\\nA/B testing is like its poster child.\\nBy understanding how users interact with your app,\\nyou can keep tweaking and fine-tuning to make things better\\nand better over time.\\nA/B testing is widely used in marketing\\nto optimize conversion rates\\nas it helps you identify the version\\nthat encourages more conversions,\\nthereby leading to a more steady growth and optimization.\\n\\nIt can be employed to improve user experience\\nby comparing different design elements, layouts,\\nand user interface changes\\nto see which phone resonates best with your users.\\nNext is for conversion rate optimization,\\notherwise called CRO.\\nIf you're in the marketing game, you would love this one.\\nSo A/B test helps you figure out what makes people click,\\nsign up, or even buy your product.\\nIt's like having a magic wand\\nfor turning browsers into buyers.\\n\\nA/B testing also helps you in risk mitigation\\nbecause big changes can be scary, right?\\nSo A/B testing lets you dip your toe in the water\\nbefore taking the plunge.\\nIt's like trying out a new recipe\\non a small scale before serving it up to a big dinner party.\\nWay less nerveracking.\\nFor experiments that resulted in very negative results,\\nyou could imagine what the impact of your app users\\nor even revenue could have been\\nif you had carelessly released\\nwithout running an impact or performance A/B test.\\n\\nSo basically it helps organizations to validate hypothesis.\\nHave you got a wild idea?\\nJust test it out.\\nA/B testing lets you see if your theories hold water\\nin the real world.\\nIt's like being a scientist in a lab,\\nexcept instead of test tubes,\\nyou're messing around with website buttons\\nand ad copies.\\nAnother noteworthy advantage\\nis optimized resource allocation.\\nTime and money are precious resources for every company.\\nSo A/B testing helps you spend them wisely\\nby focusing on strategies\\nand elements that have been proven to be successful.\\n\\nIt's like having a personal assistant\\nwho tells you which projects are worth your time\\nand which ones are duds.\\nIt fosters continuous improvements.\\nWe are all about progress here.\\nA/B testing encourages a culture of always getting better.\\nIt's like having a built-in feedback loop\\nthat pushes you to keep innovating and trying new things.\\nIt also helps you in gaining competitive edge.\\nIf you want to stay ahead of the curve,\\nA/B testing is your secret weapon.\\nBy staying nimble and responsive to changes,\\nyou can outmaneuver the competition and come out on top.\\n\\nIt's a user-centric approach,\\nso happy customers, happy life.\\nA/B testing helps you keep your audience front and center,\\ndelivering experiences that keep them coming back for more.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3893069\",\"duration\":157,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Real-world applications of A/B testing\",\"fileName\":\"4493001_en_US_01_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":196,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"Learn about the real world applications of A/B testing and how you are used within digital projects so you have a strong sense as to how this course will benefit your efforts.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3781568,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Now that we've got a solid grasp\\non why A/B testing is a big deal,\\nlet's dive into some real world applications\\nacross different industries and domains.\\nOne of the coolest things about A/B testing\\nis that it's not just some shots in the dark.\\nYou're not relying on random datasets\\nor asking strangers what they think about your app.\\nNope.\\nYou're actually using real visitors\\nwho are checking out your digital products.\\nThat means you're getting the real deal,\\nthe actual behavior and interaction\\nof your users with your app.\\n\\nAt my previous role at an e-commerce\\nand retail company, for example,\\nwe had introduced\\na spiffy new Topics For You feature to our app.\\nSo we run an A/B test.\\nAfter giving it a run for about two weeks,\\nwhich, by the way, is the sweet spot\\nfor getting the best results,\\nwe found out that the test variant outperformed\\nthe control variant by a solid 3.4%,\\nwhich translates to a win.\\nWe saw more users clicking to action,\\nmore items added to carts,\\nand fewer folks bailing out mid-process.\\n\\nThe cherry on top is that our revenue shot up\\nby a whooping 8%, all while making our users happier\\nand the app easier to use.\\nBut that's not all we've tested.\\nWe've doubled in different product page layouts,\\nimages, tags, and call-to-action buttons,\\nall to figure out what gets those conversion rates soaring.\\nAnd it's not just e-commerce\\nthat benefits from A/B testing.\\nDigital marketing gets a boost too.\\nFrom testing different ad copies,\\nheadlines and imageries, to tweaking email subject lines\\nand content, A/B testing helps marketers dial in\\non what really resonates with their audience.\\n\\nThen, there is content creation and publishing.\\nBy experimenting with headlines, article structures,\\nand content formats, publishers can keep readers hooked\\nand don't even get me started on social media.\\nPlaying around with post formats,\\nimages and captions can be a game changer for engagement.\\nEven in healthcare and medicine, A/B testing plays a role,\\nwhether it's testing patient communication method,\\nor experimenting with messaging\\nto encourage healthier behaviors,\\nA/B testing can make a real difference.\\n\\nSo there you have it.\\nJust a taste of how A/B testing is making waves\\nin the real world.\\nWith its versatility and power\\nto drive data-driven decisions,\\nit's no wonder A/B testing is good tool\\nacross industries and business functions.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3894065\",\"duration\":150,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Key concepts and terminology\",\"fileName\":\"4493001_en_US_01_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":180,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"Learn about the key concepts and tenets of A/B testing and the terminology used, so you can absorb the material this course appropriately.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3371565,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Before delving\\ndeeper into the course material,\\nlet's get acquainted\\nwith the fundamental concepts and terminologies\\nthat will guide our journey.\\nFirst up, we have variations.\\nVariations are the different versions\\nof the content being tested.\\nIn your typical AB test, you would find two variations,\\nA, the control or original version,\\nand B, the variant with changes.\\nMore complex tests might draw in additional variations\\nlike A, B, C, or A, B, C, D.\\n\\nAs we mentioned earlier,\\nthe control group acts as the baseline\\nagainst which we measure the performance of the variants,\\nwhile the variant group experiences the modified content\\nto test the impact of changes.\\nNext, let's talk about conversion rates.\\nThis is like the percentage of users\\nwho take a desired action, such as making a purchase,\\nsigning up, or clicking on a link or button\\nout of the total number of users in a group.\\nIt's a crucial metric for gauging the success of an AB test.\\n\\nAB testing usually kicks off with a hypothesis,\\nwhich predicts which version will perform better and why.\\nThink of a hypothesis as a statement or assumption\\nabout how changes would affect user's behavior.\\nAnd for larger scale applications,\\ndetermining the sample size is key.\\nThis refers to the number of users\\nin the control and variant group\\nparticipating in the AB test.\\nA larger sample size boosts the reliability of results\\nand enhances the ability to detect even subtle changes.\\n\\nNow, let's talk about an alternative to AB testing,\\nmultivariate testing.\\nHere we are testing multiple changes simultaneously\\nin different combinations.\\nIt's handy when you want to understand\\nhow various variables interact to influence user behavior.\\nAnd lastly, we need to consider experiment duration.\\nThe length of the time an AB test runs\\nis crucial to run tests for a sufficient duration\\nto factor in potential variations\\nin user behavior over time.\\n\\nBut generally, experts recommend running each test\\nfor an average of two weeks.\\nThese concepts and terms lay the groundwork for AB testing\\nand forming the backbone of how we design, execute,\\nand interpret the results of our test\\naccurately and effectively.\\nSo if you're ready to dive in and become an AB testing pro,\\nlet's get started.\\n\"}],\"name\":\"1. Introduction to A/B Testing\",\"size\":16907368,\"urn\":\"urn:li:learningContentChapter:3894070\"},{\"duration\":471,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3898071\",\"duration\":210,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Setting clear objectives and goals\",\"fileName\":\"4493001_en_US_02_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":312,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"Learn how to set clear objectives and goals for your testing so you have strong guidance for the project and can assure the right results.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6561933,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Establishing precise and\\npersonalized objectives and goal for AB testing is crucial\\nfor successful experimentation\\nand gaining valuable insights.\\nThis objective not only provide clarity,\\nbut also serve as a guiding light,\\nensuring that your testing efforts align seamlessly\\nwith your specific digital product goals\\nand user expectations.\\nIn this course, our aim is to transform my portfolio website\\ninto a more engaging platform\\nthat not only captivate visitors,\\nbut also fosters meaningful interactions.\\n\\nThe goal is to create an immersive experience\\nthat effectively showcases my work\\nand allowing visitors to gain insight into my experience,\\nmy motivation, and my ability\\nto tackle real world challenges.\\nAdditionally, I want to make it easy for them\\nto be able to connect with me on LinkedIn\\nand explore my GitHub profile, while also providing access\\nto information about past collaborations.\\nUltimately, the objective\\nis to increase the number of visitors\\nwho click on the CTA button to view my portfolio\\nor to contact me.\\n\\nTo achieve these objectives,\\nI would implement a subtle button impactful change,\\naltering the naming of my buttons\\nto sound more action oriented.\\nBy doing so, I aim to gauge\\nwhether the new naming will prompt my website visitors\\nto click more frequently.\\nMy hypothesis is straightforward.\\nAdjusting the text on the call to action buttons\\nwill result in a higher click through rate.\\nThis approach allows for a focused experiment,\\nhoning in on a specific element\\nof the user experience\\nwith the potential to yield significant improvements.\\n\\nBy testing different button names,\\nI can directly access the effectiveness\\nin driving engagement and achieving my desired outcomes.\\nUltimately, the goal is to optimize user interaction\\non my website, encouraging visitors to take action\\nand explore further.\\nThrough thoughtful experimentation and analysis,\\nI aim to uncover insights\\nthat would inform future design decisions\\nand enhance the overall effectiveness\\nof my portfolio website.\\nIn a broader context,\\nit's essential to understand\\nthe specific business goals you aim to achieve.\\n\\nWhether it is boosting conversion rates,\\nenhancing user engagement, increasing revenue,\\nor reducing bounce rates,\\nyour AB testing objective should directly align\\nwith these goals.\\nThese key metrics will serve as a benchmark\\nfor evaluating effectiveness of your test.\\nFor example, if the primary goal is to boost signups,\\nthe pivotal metrics might be the conversion rate\\nfrom landing page visitors to registered users.\\nFurthermore, developing clear\\nand testable hypothesis is critical.\\n\\nThis hypothesis should outline the changes you believe\\nwill lead to desired improvements.\\nFor instance, for testing a new headline,\\nthe hypothesis might be changing the headline to benefits\\nwill lead to a higher click-through rate.\\nIn our case, the hypothesis is that\\nchanging the text on our CTA buttons\\nwould increase visitors engagement on my website.\\nBy setting clear objectives and goals\\nfor AB testing, we establish a solid foundation\\nfor data-driven decision making and optimization.\\n\\nClear objectives not only guide the testing process,\\nbut also contribute to meaningful insights\\nand better business outcomes.\\nLet's dive in and start optimizing.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3893070\",\"duration\":152,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Setting clear and measurable key performance indicators (KPIs)\",\"fileName\":\"4493001_en_US_02_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":301,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"Learn how to define and measure clear KPIs (key performance indicators) for your tests so you have a clear framework and scale for it's success.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3931315,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Presenter] To accurately assess the impact\\nof the changes implemented on my website,\\nit's crucial to establish clear\\nand measurable key performance indicators, KPIs.\\nThese KPIs serve as vital benchmark\\nfor evaluating the success of our A/B testing experiment,\\noffering a quantitative way\\nto track the effects of our modifications\\nand ascertain whether our tests\\nhave achieved the desired outcomes.\\nDefining specific and well-defined KPIs is paramount.\\nAvoiding vague or generic metrics\\nensures that we obtain actionable insights.\\n\\nFor instance, instead of a broad objective,\\nlike increase visitors engagement,\\nwe opt for a more precise target,\\nsuch as increase visitors engagement by 15%.\\nThis enables us to have a tangible measure\\nagainst which we can test our changes.\\nOur chosen KPI directly aligned\\nwith the changes on examination.\\nFor instance, if we are testing alterations\\nto a checkout process,\\nrelevant KPI may include cut abandonment rates,\\ncheckout completion rates, and revenue per transaction.\\n\\nAdditionally, it's essential to establish\\nwhat level of improvement in the KPI constitutes success\\nfor our A/B test.\\nThis could be a percentage increase,\\na specific target value, or another benchmark,\\nindicating a meaningful impact.\\nFor this cause, we will consider any discernible difference\\nbetween the control and variant group,\\ndeeming a visible increase in click rates\\non the variant group as a success.\\nFurthermore, as we progress through the course,\\nwe will not only focus on primary KPIs\\nreflecting our main objectives,\\nbut also track secondary metrics.\\n\\nThese secondary metrics offer additional insights,\\nenabling us to comprehend the broader impact of our changes.\\nSubsequently, we will leverage these insights to refine\\nand adjust our objective and goals,\\nensuring they remain aligned with evolving business needs.\\nAs we deepen our understanding\\nof user behavior and preferences,\\nwe will refine our testing strategy accordingly.\\nBy setting clear and measurable KPIs,\\nwe establish a robust framework\\nfor evaluating effectiveness of our A/B testing endeavors.\\n\\nThis well-defined KPIs empower us to track progress\\nto evaluate results\\nand to make data-driven decisions that propel us\\ntowards the achievement of our business objectives.\\nLet's embark on this journey of optimization\\nand discovery together.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3896070\",\"duration\":109,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Defining the control group and treatment group(s)\",\"fileName\":\"4493001_en_US_02_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":223,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2740814,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] In our A/B testing scenario,\\nlet's refine the definitions\\nof our control group\\nand the treatment group to center them\\naround the user experience.\\nThe control group serves\\nas our baseline in the A/B test, comprising users\\nexposed to the current version of my portfolio app\\nwithout alterations.\\nThis group acts as our reference points,\\nenabling us to gauge natural behavior\\nand responses within their existing environment.\\nConversely, the treatment group introduces\\nus to an experimental version of our portfolio app,\\nfeaturing alterations or enhancements.\\n\\nWhile we could incorporate multiple test groups\\nwith varied variations, for simplicity's sake,\\nin this course, we will stick to a straightforward approach.\\nBy maintaining consistency in the control group,\\nwe can confidently attribute any observed differences\\nin user behavior or outcome\\nto the variations in introduced in the treatment groups.\\nIn addition to understanding the role of the control\\nand treatment groups,\\nit's important to consider the randomization process\\nused to assign users to each group.\\n\\nRandomization ensures that users are allocated\\nto groups impartially, minimizing bias\\nand ensuring the validity of the experiment.\\nBy precisely defining\\nand customizing these user segments,\\nwe can methodically evaluate the impact\\nof our proposed changes.\\nThis allows us to access whether these modifications\\nresult in improvements\\nor potentially adverse effects on user behavior,\\nthe engagement, and other relevant metrics.\\nAdopting this user-centric approach empowers us\\nto make informed decisions based on data,\\nultimately optimizing our portfolio app\\nto deliver the most satisfying\\nand effective user experience possible.\\n\\n\"}],\"name\":\"2. Defining Objectives and Hypotheses\",\"size\":13234062,\"urn\":\"urn:li:learningContentChapter:3895079\"},{\"duration\":989,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3894066\",\"duration\":231,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Choosing a testing platform or tool\",\"fileName\":\"4493001_en_US_03_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":653,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"Learn how to choose a testing platform or tool that fits your specific needs so that you can have a consistent environment for testing.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8089684,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Let's now delve into the critical process\\nof choosing the best platform for conducting our AB testing.\\nAs we navigate this decision making journey,\\nwe will consider three key factors.\\nThe first is the ease of implementation and use.\\nOur priority is to find a platform that allows us\\nto set up experiments swiftly\\nwith minimal training or technical complexities.\\nThis ensures that we can hit the ground running\\nand start gathering valuable insights\\nwithout unnecessary delays.\\n\\nWe also want a platform that integrates\\nwith Google Analytics.\\nSeamless integration\\nwith Google Analytics is paramount for us.\\nThis integration streamlines the analysis\\nof experiment results,\\nempowering us to derive actionable insights\\nand make informed decisions based on data.\\nAnd the last thing we are looking out for\\nis cost effectiveness.\\nWe are keen on finding a tool\\nthat offers economical pricing plans or even free options.\\nCost effectiveness is crucial\\nfor ensuring accessibility without straining our budget,\\nallowing us to maximize the values\\nof our experimentation efforts without breaking the bank.\\n\\nWith this criteria in mind,\\nwe'll evaluate three prominent options\\nABTasty, Optimizely, and VWO as potential choices.\\nSo first, let's explore ABTatsy website.\\nTheir offerings include web experimentation\\nand personalization, which align well with our needs.\\nHowever, going over to the pricing platform,\\nthere is no immediate information\\non the different plans they have,\\nwhich is a concern to me as transparency\\nis essential in our decision making process.\\n\\nWe have to fill out and submit this form first\\nand wait for them to get back to us with the pricing.\\nSo this is a no-no for me.\\nMoving on to Optimizely,\\na well-established platform\\nin the experimentation space as well.\\nLooking over to their product page,\\nthey offer web experimentation.\\nSo heading over to the web experimentation page,\\nwe could even see a demo on how to set up the experiment\\nand how to configure our experiments,\\nwhich is a good thing.\\n\\nThis aligns with our ease of implementation and use factor.\\nSo going over to the pricing page now,\\nthe custom pricing model\\nfor web experimentation raises questions\\nabout cost transparency and affordability.\\nWe again have to send a request to be able\\nto get our pricing plan.\\nSo this is another pass.\\nSo finally, we turn to VWO.\\nHovering over the capabilities,\\nwe see that they also offer web experimentation\\nand their product,\\nand heading over to their product offering,\\nwe see that their pricing plan is visible to us,\\nwhich is a good thing.\\n\\nWe even have a free option which can take up to 50K users.\\nFor the sake of our course,\\nthis is very much within what we want.\\nSo these are all the offerings we are going to be getting\\nwith our free startup package.\\nAnd yeah, this looks very much like what we are looking for,\\nso we are going to be opting in for VWO.\\nBut the thing is, all these three options\\nboost seamless integration with Google Analytics,\\nensuring smooth analysis of experiment results,\\nand facilitating data-driven decision making.\\n\\nAs you consider your specific needs\\nand budget constraints,\\nI recommend exploring each option\\nfor the free trial and demos.\\nThis hands-on approach will enable you\\nto make an informed decision that aligns\\nwith your goal and requirements,\\nultimately maximizing the value\\nof your experimentation efforts.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3894067\",\"duration\":246,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Integrating testing tools with your webapp\",\"fileName\":\"4493001_en_US_03_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":651,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"Learn how to integrate testing tools with your web app so that you are able to accurately capture testing results and details for later dissemination.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9729934,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Let's take our personalized A/B testing setup\\nto the next level by seamlessly integrating\\nthe powerful VWO testing tool into our web app.\\nAs we navigate through the setup process,\\nwe'd explore the various features\\nand considerations involved in this integration.\\nWith my VWO already primed and logged in,\\nI would head straight to the testing section.\\nHere we are presented with a literary of options,\\nranging from traditional A/B tests,\\nto a more advanced multivariate test, and split URL test.\\n\\nEven tests specific to mobile apps.\\nSo this diverse array of testing method\\nallows us to tailor our experiments\\nto suit the specific needs and objectives of our web app.\\nScrolling down further, we encounter\\nthe Personalization option, although it's not free.\\nHowever, for the scope of this course,\\nthis limitation is acceptable.\\nWe'll focus primarily on the A/B testing capabilities\\nfor the purpose of this course.\\nHowever, it's valuable to know the additional features\\nVWO offers for future experimentation.\\n\\nNow delving into the Configuration tab,\\nwe will navigate to the Website and Apps tab,\\nand if we had previous projects set up already,\\nwe would see them here.\\nBut since we don't have any setup previously set up,\\nwe have to create a new integration here.\\nWe want to integrate our web app, so we select on Website,\\nand then click on Next.\\nHere we're going to be adding the domain to the website\\nwe are trying to connect this VWO SmartCode with.\\n\\nSo I'm going to paste my the URL to my website,\\nand then click on Add Domain.\\nSo this will take some time to analyze my URL\\nand generate the right SmartCode\\nfor me to integrate my app into my VWO.\\nSo now a SmartCode has been generated for us.\\nThis snippet acts as a backbone for our integration,\\nfacilitating seamless communication\\nbetween our web app and the VWO testing platform.\\nBefore proceeding, it's crucial to consider\\na few very important points.\\n\\nUsers of Firefox or Safari may encounter limitations\\nwith VWO functionality in incognito mode.\\nAnd additionally, it's recommended to avoid\\nusing tag managers, like Google Tag Managers,\\nfor installing VWO to prevent any potential issues,\\nsuch as page flickering, or conflict with other scripts.\\nNow, I'll copy the generated code\\nand navigate to my web app's code base,\\nand then paste this code at the top of my page\\nright after the opening of my head tag.\\n\\nI'm going to format this properly.\\nSo placing the script at the top of the script tag\\nin the route HCMF file ensures that the configuration\\nexecutes seamlessly upon loading the webpage.\\nAfter making necessary adjustments,\\nI would just save the changes.\\nI would commit my changes as well.\\n\\nAnd then push my changes to my repository.\\nSo by seamlessly integrating VWO into our web app,\\nwe are not only enhancing our A/B testing capabilities,\\nbut also laying the foundation\\nfor data-driven decision making and continuous optimization.\\nThis step is pivotal in maximizing the impact\\nof our experimentation efforts,\\nand driving meaningful improvements to our web app.\\n\\nNow that we've integrated our VWO SmartCode\\nwith our code base, let's now embark\\non this journey with confidence,\\nknowing that our testing efforts are poised\\nto make a significant impact on the success of our web app.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3893071\",\"duration\":410,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Creating the test groups\",\"fileName\":\"4493001_en_US_03_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":669,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"Learn how to assign your participant to testing groups so your test is populated with great subjects that can add meaningful value to the results.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":13185702,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] So let's select the A/B test\\nfrom our dropdown, and then click on the Create button\\nin order to create a new experiment.\\nThis is where we are going to define our audience.\\nSo for a start, we need to enter the URL to the websites\\nthat we want to test here.\\nSo I'll go ahead and add the URL to my website.\\nI'm going to leave it as the default,\\nand then I would go ahead and click on the Next button.\\nIt's going to take me to this page where I see the control.\\n\\nThe original content of my website\\nis going to be assigned to the control.\\nSo we can take a view.\\nIt's going to launch me into this editor\\nwhere I can edit the content of my page.\\nOkay, we don't need to make any modifications here\\nbecause this is our control.\\nSo I'm going to go ahead and click\\non the Add Variation button.\\nIt automatically creates a new variation for us.\\nSo I'm going to go ahead and click on the Edits button.\\n\\nSo this is going to launch us into the HTML editor\\nwhere we will be able to edit each of the sections\\nof the web app that we want to edit.\\nSo I'm going to start with the \\\"Hire Me\\\" button.\\nI'm going to be changing this\\nfrom \\\"Hire Me\\\" to \\\"Connect With Me\\\"\\nbecause I think that sounds more suggestive.\\nSo I would click on Edit HTML,\\nand then change it to \\\"Connect With Me.\\\"\\nI'll click on the Done button to save my changes.\\n\\nI'm also going to change\\nthe \\\"View Portfolio\\\" button to \\\"View My Project,\\\"\\nbecause \\\"View My Project\\\" is more suggestive to the action\\nthat I want users to perform on the buttons on my website.\\nSo I'm going to click on Done as well.\\nAnd finally, I'm going to change\\nthe \\\"Get In Touch\\\" to \\\"Send A Message.\\\"\\nAnd then I'll click on the Done button as well.\\nSo after I'm done with changing the text,\\nI'm now going to assign a track click,\\nor track event, on each of the buttons.\\n\\nWhen you want to assign a track event,\\nit'll automatically create a new metric\\nfor you if you don't have any metric yet.\\nSo I'm going to be renaming this metric to \\\"Button Click,\\\"\\nand then I'll do the same for the rest of the buttons.\\nI'm going to add a track event,\\nand then I'll select from the already existing metric\\nand then select Button Click.\\nI'll do the same for this button as well.\\nSelect the existing, and then select Button Click.\\n\\nSo once we are satisfied with the alterations,\\nwe are going to proceed to the next steps\\nwhere we define the metrics and objectives for our tests.\\nSo I'm going to go ahead and click on the Save\\nand Continue button.\\nIt then launches us to the metrics page.\\nAs we can see, the Button Click\\nis already assigned as the primary metric.\\nSo I'm going to go ahead and create a new metric\\nfor my secondary metric.\\nSo I would click on Add Secondary Metric,\\nand then I have metrics\\nthat I've already created from my previous experiments.\\nIf you want to create a new metric,\\nyou can click on the Create a New Metric button\\nand then Add a New Metric.\\n\\nSo in the secondary metric, I have a couple of metrics\\nthat I've created in my previous experiments\\nwhich matches what I want to create again.\\nSo instead of recreating a new metric,\\nI'm going to be selecting Increase User Engagement,\\nbecause I want to increase the general engagement\\nof users on my website.\\nSo I'm going to either choose\\nto set this as a primary metric,\\nor continue with it as the secondary metric.\\nSince we are more interested in tracking\\nthe number of clicks on the buttons on our website,\\nwe are going to be leaving\\nthe Button Click as the primary metric,\\nand maintaining the User Engagement as a secondary metric.\\n\\nSo I'm going to save this, and then back to my metrics.\\nSo why we could delve deeper\\ninto creating additional metrics\\nfor more comprehensive analysis,\\nwe will stick with this for now.\\nIn a more professional environment,\\nyou would typically have multiple metrics tracking.\\nYou could have metrics that are tracking the page view.\\nYou could have metrics that are tracking\\nthe engagement or button click, or even form submission,\\nwhatever it may be.\\nSo I'm going to go ahead and give a name to my campaign.\\n\\nUsually, because I have other campaigns\\nthat have been created previously,\\nit automatically assigns this Campaign 5,\\nbecause this is the fifth campaign I'm creating.\\nSo I'm going to click on the Edit button\\nand change this to \\\"My Website Engagement.\\\"\\nAnd then I'm also going to make sure\\nthat I'm going to be testing with all the traffic.\\nYou can choose the type of traffic\\nthat you want to test with here.\\nYou can choose a social traffic, or referral,\\nor search, or whatever it might be.\\n\\nYou could also choose your device type.\\nIf you want to test it on a specific type of device,\\nyou choose that here.\\nSo for this course, we are going to be rolling out\\na hundred percent of our users,\\nalthough in real world scenarios,\\ngradual rule out increments are common\\nfor testing configuration, robustness.\\nSo I'm going to be assigning this a hundred percent.\\nIn our variations, we already distributed\\nthis a hundred percent of users into 50% to the control,\\nand 50% to the variation.\\nSo when we are done setting up this experiments,\\nwe can click on Review, where we see a general summary\\nof all the configuration that we've done.\\n\\nOur website's URL, our control, and variant,\\nand all the metrics that we've set.\\nWe have the Button Click, which is our primary metric,\\nand the User Engagement, which is our secondary metric.\\nWe are using standard audience,\\nbecause we want all visitors to be added to this experiment.\\nWe are rolling out a hundred percent of our traffic,\\nand this is the date that we are creating this campaign.\\nSo we have all this information.\\nSo when I click on the variation,\\nit also shows us a preview of the variation and the control,\\nor if we want to randomize it, we can also click on Random\\nto get a preview of a random variation,\\nbetween the control and the variation.\\n\\nSo I'm going to select the control,\\nand we're going to do a quick preview.\\nSo this is going to give us a status quo,\\nthe original version of my web app.\\nAnd then if I select the variation,\\nit's going to give us the, yeah,\\nthe modified, or the altered version of our website.\\nSo this is how we want it to be.\\nSo once we are done setting up all the configurations,\\nwe are going to click on the Start button.\\nAnd now our experiment has been launched.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3894068\",\"duration\":102,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Testing duration and collecting data\",\"fileName\":\"4493001_en_US_03_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":175,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"Learn how to set an appropriate duration for your tests and schedule participants to assure a smooth testing session with no surprises. Learn how to collect test data alongside tracking metrics so that you can begin collating the results for analysis.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2887827,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] So, now that we've got our variation set up\\nand our tracking metrics in place, let's talk about strategy\\nfor how long we are going to run this experiment\\nand how we are going to gather all the juicy data.\\nIn the world of professional testing,\\nit's pretty much a golden rule\\nto let your experiment run for at least two weeks.\\nThat's the sweet spot for getting enough data\\nto make solid decisions and really trust the results.\\nSo instead of just winging in\\nand starting and stopping whenever we feel like,\\nit's way smarter to set a schedule ahead of time.\\n\\nThis helps us to stick to a plan\\nand ensure that we are collecting data\\nfor the right amount of time.\\nTo set up our schedule,\\nwe will dive into the Configuration tab.\\nAnd then hit on More configurations,\\nand then to the Schedule section.\\nNow, fair warning, this feature might be behind a paywall,\\nso you're going to be needing a paid version to access it.\\nAlternatively, if you're a big player with lots of users,\\nyou can set your experiment\\nto run based on how many people you want to participate.\\n\\nIt's a common approach for the big dogs\\nwho already know how much data they need\\nto rock solid results.\\nSo by establishing a clear schedule\\nand data collection strategy,\\nwe're laying the groundwork for a successful experiment.\\nThis systematic approach ensures\\nthat we gather actionable insights with a defined timeframe,\\nenabling us to make informed decisions\\nand drive meaningful improvements to our web app.\\nLet's now proceed with confidence,\\nknowing that our testing efforts are poised for success.\\n\\n\"}],\"name\":\"3. Implementing A/B Testing\",\"size\":33893147,\"urn\":\"urn:li:learningContentChapter:3895080\"},{\"duration\":456,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3893072\",\"duration\":126,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Statistical analysis of A/B test data\",\"fileName\":\"4493001_en_US_04_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":180,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"Learn how to analyze the statistics from your A/B test so you can prepare the data to start interpreting results and drawing conclusions.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3884844,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Now that we have run the experiment\\nfor two weeks,\\nlet's now take a look at the statistical data generated\\nby the users of my portfolio website.\\nWe have a total of 58 users who visited my website\\nwith a total expected conversion rate of 14.61%.\\nExpected conversion rate is like the median conversion rates\\nyou can expect from the variation.\\nThe control had 23.72%\\nand the variant had only 5.92%,\\nand there was a negative 74.85% potential improvement\\nin the user engagement.\\n\\nThis clearly implies a negative performance.\\nSo scrolling down to the graph,\\nthe graph visualizes this performance better,\\nand in a few moments we will decipher each data point story.\\nJust feel free to explore the graph's various facets.\\nYou can switch to the box plot\\nto see the graph in a bar chart\\nor the probability density tab for an area chart,\\ndepending on which one\\nis more visually understandable to you.\\nBack to the date range,\\nyou could also toggle between conversion rates,\\nconversions, and visitors,\\nand you can even choose the day-wise breakdown\\nor accumulative sum for a progressive engagement snapshot.\\n\\nThis table and graph only shows data generated\\nby the primary metric, which is the button click.\\nNow, heading over to the secondary metric,\\nwhich is our engagement metric\\non our site, we could see a similar data\\nas on the button click metric.\\nThis time around we have a 26.81% expected conversion rate\\nfor the control, and 20.01% for the variant\\nwith a higher probability of 27%\\nto beat baseline compared to that of the button click,\\nwhich was 2.16%.\\n\\nBut then what does this data actually mean?\\nWe are going to dissect it further in the next video.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3893073\",\"duration\":211,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Interpreting results and drawing conclusions\",\"fileName\":\"4493001_en_US_04_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":300,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"Learn how to interpret the results of your A/B test and begin drawing general conclusions from those results, so you can then validate your conclusions for wider dissemination.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6449741,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Now that we've taken a look at the data,\\nlet's now dive deeper into what each of the data means.\\nLet's go through each of the data in the columns\\nand try to analyze them.\\nIn each of the metrics, we have 58 unique visitors.\\nAnd for the control, it shows that 31 out of those visitors\\nwe have shown the control version.\\nAnd out of those 31 users,\\nonly seven had engaged with the buttons.\\nLikewise, for the variation, 27 had seen the variance,\\nand out of those 27, only one user\\nhad engaged with the button.\\n\\nThis then implies that the text we changed\\nmade it more discouraging for the users\\nto click on the button.\\nAnd this is entirely against the expectations\\nwe had set at the beginning, right?\\nBut hey, this is where the beauty\\nof A/B testing shines through.\\nIt gives us real world insight,\\nrather than just banking on assumptions\\nthat it would always be a positive impact.\\nMoving on to next column,\\nwe have a 2.16% probability to beat the baseline,\\nwhich means that we have a 2.16% chance of the variation\\nperforming better than the baseline.\\n\\nWe have a negative improvement of 74.85%,\\nwhich means that the median improvement\\nyou can expect over the baseline\\nif you implement the variation is a -74%.\\nThis clearly means that the variation\\nwould reduce the quality of the application.\\nWe also have a 23.72%, and 5.92% conversion rates\\nfor the control and variations respectively,\\nwhich brings to a total expectation rate\\nof 14.61% conversion rate.\\n\\nSimilarly, for the engagement metric,\\nwe can see that eight out of 31 users\\nof the control version engaged with the website.\\nEngagement on the website\\nmeans that visitors have submitted a form,\\nor performed a mouse up or mouse down event,\\nor navigational elements such as anchors,\\nor buttons and imputes.\\nVWO records a conversion\\nas soon as the mouse down or mouse up event occurs.\\nThis means that most of the users\\nbarely scroll through the page.\\n\\nAlso for the variation,\\nfive out of 27 users engaged with the page.\\nSo in total, only 13 people out of 58\\nactually engaged with my webpage.\\nWe also have a 27% probability of the variation\\nperforming better than the control,\\nand also a -25.24% expected improvements\\nyou can expect over the baseline\\nif you implement the variation.\\nEach of them have an expected conversion rate of 26.81%\\nand 20.01% respectively,\\nand a 23.04% of total expected conversion rates.\\n\\nNow that we've poked around in all this data,\\nit's crystal clear that our experiment\\ndid not hit the mark, but hey,\\nthat's just the part of the journey.\\nAs a business owner, this is where you roll up your sleeves,\\nhead back to the drawing board\\nand start fine tuning those changes.\\nIt's all about trial and error,\\ntweaking things here and there\\nuntil we find the golden ticket.\\nAnd hey, stay until the next video.\\nWe are going to dive deeper into the limitations,\\nunraveling what might have thrown us off,\\nand discussing what could have caused\\nour experiment to stumble.\\n\\nIt's all about learning and growing.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3900093\",\"duration\":119,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Validating results and addressing limitations\",\"fileName\":\"4493001_en_US_04_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":144,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"Learn how to validate and confirm results while addressing any key limitations discovered in the testing, to ensure accurate and well-scoped conclusions can be drawn from it.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3687498,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Now that we have established\\nthat our experiment failed,\\nfailure can be a valuable teacher\\nif you're willing to learn from it.\\nSo let's break down what went wrong\\nand how we can turn this setback\\ninto an opportunity for improvement.\\nFirstly, you hit the nail on the head\\nby pointing out that the text changes\\nmight have not been as engaging as we hoped.\\nIt's crucial to craft messaging that resonates with users\\nand encourages them to take action.\\nPerhaps we didn't fully understand\\nour audience's need or preferences,\\nleading to a disconnect between the changes we made\\nand their expectations.\\n\\nSecondly, the small sample size definitely played a role\\nin the unreliability of our results.\\nWith such a limited number of users,\\nit's harder to draw meaningful conclusions\\nand detect subtle changes.\\nScaling of the experiment to include a larger\\nand more diverse pool of participants\\nwould provide more robust data\\nand a clearer picture of user behavior.\\nIn a more practical situation,\\nthere will be thousands or even millions of users\\nto distribute the control and variance\\nin order to gain more trustworthy data.\\n\\nSo furthermore, the duration of the experiment\\nis also worth reevaluating.\\nTwo weeks may not have been sufficient time\\nto capture meaningful insights,\\nespecially if user behavior fluctuates over time.\\nExtending the duration\\nor running multiple iterations of the experiment\\ncould help mitigate the impact of short-term fluctuations\\nand provide a comprehensive understanding\\nof user engagement patterns.\\nSo what's the takeaway here?\\nFailure isn't the end,\\nit's an opportunity to iterate and improve.\\n\\nBy learning from our mistakes,\\nwe can refine our approach, better understand our users,\\nand ultimately create a more effective\\nand engaging application.\\nLet's use this experience as a motivation to push forward,\\narmed with new insights\\nand a commitment to continuous improvement.\\n\"}],\"name\":\"4. Analyzing and Interpreting Test Results\",\"size\":14022083,\"urn\":\"urn:li:learningContentChapter:3893074\"},{\"duration\":216,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3898072\",\"duration\":129,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Recap of A/B test course setup process\",\"fileName\":\"4493001_en_US_05_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":349,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"Get an encapsulated overview of the process for A/B testing that was explained in this course, so you can easily share what you've learned with your team members.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3008835,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Presenter] Now that we've delved into the intricacies\\nof introducing statistical deviations\\ninto our A/B test experiment,\\nlet's take a moment\\nto recap the meticulous process we followed\\nto set up this insightful test.\\nOur journey commence\\nby establishing a crystal clear objective,\\ndefining the very essence of what we aim\\nto achieve with our webpage.\\nTo bring precision to our endeavor,\\nwe carefully set measurable KPIs,\\nkey performance indicators,\\nthat would act as our guiding beacons\\nthroughout the experiments,\\nallowing us to quantifiably track our expectations.\\n\\nWith a thoughtful eye on our unique use case,\\nwe meticulously evaluated various A/B testing platforms.\\nThis thoughtful analysis empowered us\\nto make an informed decision,\\nultimately leading us to select the robust VWO platform\\nas our testing ground.\\nHere, we seamlessly created an account,\\nensuring a seamless integration\\nto configure our A/B test experiment.\\nAs architects of our experiments,\\nwe crafted distinct test groups,\\neach representing a unique facet of our user base.\\n\\nA crucial step ensued:\\ndetermining the optimal duration for our A/B test.\\nThis strategic decision allowed us\\nto strike the right balance,\\nensuring the collection of comprehensive data\\nover a meaningful timeframe.\\nWith the stage set, our A/B test unfolded\\nand we embarked on a journey of data gathering and analysis.\\nThe insights harvested during this phase\\nbecame the compass guiding us\\ntowards crucial business decisions.\\nBy meticulously deciphering the data,\\nwe unveiled patterns, trends,\\nand performance differentials that became the bedrock\\nfor informed data-driven optimization.\\n\\nIn essence, our A/B test set up process\\nwasn't merely a technical procedure.\\nIt was a strategic orchestration aimed at refining\\nand personalizing user experiences,\\nelevating our webpage performance,\\nand ultimately steering our business\\ntowards greater success.\\n\"},{\"urn\":\"urn:li:learningContentVideo:3894069\",\"duration\":87,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Reviewing key concepts and takeaways\",\"fileName\":\"4493001_en_US_05_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":151,\"solutionVideo\":false,\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"Get an overview of the key concepts and takeaways from the A/B testing process that are most meaningful so you can create A/B tests with confidence.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2114423,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- [Instructor] Now let's distill some key takeaways.\\nWe have seen the variations are the heartbeats\\nof AB testing, representing the different renditions\\nof the content under examination.\\nA serves as the stable baseline,\\nwhile B introduces changes serving as the variants.\\nFor more intricate tests, we might delve into A, B, C,\\nor even A, B, C, D scenarios.\\nThe control group establishes the baseline performance,\\nwhile the variant group experiences the modified content,\\nallowing us to gauge the impact of alterations.\\n\\nWe also looked at the conversion rates, a pivotal metric,\\nwhich reflects the percentage\\nof users taking a desired action out of the total group.\\nIt's our litmus test for the success of an AB test,\\nproviding tangible insights into user engagement.\\nWhile exploring the nuances of running AB test,\\nwe've learned that a designated duration\\nand sample size account\\nfor potential shifts in user behavior,\\nensuring robust results.\\nI trust this course has offered valuable insights\\nas you embark on the journey of crafting more refined,\\ntestable, and user focused products.\\n\\nFeel free to connect with me on LinkedIn at Oluchi Okpala,\\nand don't hesitate to share this insightful course\\nwith your friends and colleagues.\\nI'm wishing you an inspired journey ahead.\\nUntil next time, take care and stay curious. Bye.\\n\"}],\"name\":\"Conclusion\",\"size\":5123258,\"urn\":\"urn:li:learningContentChapter:3897077\"}],\"size\":86361548,\"duration\":2866,\"zeroBased\":false},{\"course_title\":\"UX Foundations: Analyzing User Data\",\"course_admin_id\":3905267,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":3905267,\"Project ID\":null,\"Course Name\":\"UX Foundations: Analyzing User Data\",\"Course Name EN\":\"UX Foundations: Analyzing User Data\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"We live in an increasingly data-driven world, and more and more, companies are turning to user data to drive their decision making\u00e2\u20ac\u201dand measure their success. However, getting research done can be the easy part. How do you integrate research into your UX practices? What do you do with all the data you\u00e2\u20ac\u2122ve gathered? Turning raw data into valuable, actionable insights is a skill that often gets overlooked when learning about UX. In this course, Amanda Stockwell shows you how to analyze and synthesize the data you\u00e2\u20ac\u2122ve collected to turn it into useful, powerful insights.\",\"Course Short Description\":\"Learn how to analyze and synthesize the data you\u00e2\u20ac\u2122ve collected to turn it into useful, powerful insights.\",\"Content Type\":\"SKILLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":5287222,\"Instructor Name\":\"Amanda Stockwell\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"President of Stockwell Strategy\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2024-11-08T00:00:00\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"Yes\",\"Has Challenge/Solution\":\"No\",\"LIL URL\":\"https://www.linkedin.com/learning/ux-foundations-analyzing-user-data\",\"Series\":\"Foundations\",\"Limited Series\":null,\"Manager Level\":\"Individual Contributor\",\"LI Level\":\"Intermediate\",\"LI Level EN\":\"Intermediate\",\"Sensitivity\":null,\"Internal Library\":\"Creative\",\"Internal Subject\":\"User Experience\",\"Primary Software\":null,\"Media Type\":\"Video\",\"Has CEU\":\"No\",\"Has Exercise Files\":\"No\",\"Visible Duration\":1642.0,\"Visible Video Count\":11.0,\"Contract Type\":\"PERPETUAL\"},\"sections\":[{\"duration\":50,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:5977399\",\"duration\":50,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Analyze user data with a UX approach\",\"fileName\":\"3905267_en_US_00_01_VT\",\"demo\":true,\"videoCreationMetadata\":{\"rawDurationSeconds\":103,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - Good but going for great!\\n\\nTake 2 - (G)\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"This video introduces the course and helps frame your expectations for the course.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3394772,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- These days, (bright music)\\nit feels like every organization\\nis striving to be more user-driven\\nand looking for ways to measure their success.\\nCompanies are launching surveys\\nand running regular usability tests.\\nIt's great to see organizations turning to data\\nrather than hunches or instincts\\nto drive their decision-making.\\nBut sometimes getting research done can be the easy part.\\nWhat do you do with all of the data you've gathered,\\nespecially qualitative data?\\nTurning raw data into valuable,\\nactionable insights is a skill\\nthat often gets skipped when learning about UX.\\n\\nThis course will provide an in-depth discussion\\nof how to analyze and synthesize the data you've collected\\nand turn it into useful, powerful insights.\\nJoin me as I discuss ways\\nto understand the information you've collected\\nand craft plans to act on your findings.\\n\"}],\"name\":\"Introduction\",\"size\":3394772,\"urn\":\"urn:li:learningContentChapter:5984195\"},{\"duration\":383,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:5987094\",\"duration\":198,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Set objectives\",\"fileName\":\"3905267_en_US_01_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":448,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"This video describes the necessity for setting clear research goals and gives a framework for setting appropriate objectives.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11412994,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- The success of your research efforts\\nbegins before you collect a single piece of data.\\nYou need to set clear research goals\\nand design the proper kind of study\\nto answer your questions.\\nIf you don't capture the right sort of data,\\nit doesn't really matter how thorough your analysis is.\\nThis seems obvious, but it's easy to get caught in the trap\\nof applying the same methods all the time.\\nTo identify research questions,\\nconsider the stage of the product lifecycle you're in.\\nBusiness goals, what you already know\\nabout users and solutions,\\nand any hypotheses about problem areas.\\n\\nIt's okay if you have a wide range of open questions,\\nbut you want to prioritize one topic at a time\\nbecause different research methods are best suited\\nfor different kinds of questions.\\nThe more granular your goals, the easier it will be to plan\\nan effective research effort, and the easier it will be\\nto analyze that data later.\\nIf you're in an exploration phase\\nwhere you don't know your users or their context,\\nor what problems to solve, your focus is necessarily broad.\\n\\nYou should still prioritize research goals\\nby figuring out what is most important for the project.\\nLet's say you're working on a mobile application\\nfor a grocery store, and they want to provide\\nin-store benefits for frequent shoppers.\\nYou might want to explore things\\nlike people's shopping patterns,\\nwhat planning tools they use,\\nand what sorts of perks they find valuable.\\nSometimes it's easier to identify and rule out the things\\nthat you don't need to explore.\\nLike maybe you already have really good data\\nabout what products sell best on different days,\\nor decide that you only want to focus on people\\nwho spend a certain amount per week.\\n\\nThink about prioritizing the things\\nthat would be the worst to get wrong\\nor have the biggest impact\\non the decisions you need to make.\\nIf you're doing more solution-focused work,\\nit can be especially useful to craft a hypothesis\\nto frame your research questions\\nand narrow the scope of your effort.\\nI like to use the following template to set a hypothesis.\\nIf we do, build, or provide X thing,\\nthen these people will do some desirable outcome.\\n\\nWe'll know this is true when, some actionable metric.\\nThe do, build, or provide X thing\\ndescribes a solution or service you might offer,\\nlike what channel to use for communications\\nor a specific interaction in an interface.\\nThese people are a description of your target user.\\nYou may start with guesses\\nor have empirically driven definitions of your user base.\\nMaybe you're doing this research to flesh that out.\\nThe do some desirable outcome component\\nis what you want your user to do, like making a purchase.\\n\\nThis should be an indication of your progress\\ntowards business success and help you make a decision\\nfor future direction.\\nWhen you're in an exploratory or formative stage,\\nyou won't want to limit yourself to specific solutions,\\nbut you should still narrow your focus of exploration\\nand set an explicit goal.\\nUltimately, setting clear research objectives\\nwill bring clarity to everyone\\nabout why you're doing research\\nand ensure that you're collecting the right sort of data\\nto answer your open questions.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:5989093\",\"duration\":185,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Different data types\",\"fileName\":\"3905267_en_US_01_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":412,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"This video discusses what it means for data to be quantitative or qualitative, and how that sort of data impacts how you plan and analyze.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11035783,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- We often think of data as being concrete and calculable,\\nbut in user experience, we're frequently exploring people,\\nseeking to understand their goals and outlooks,\\nor assessing relative experience.\\nYou might hear about a distinction\\nbetween quantitative and qualitative data.\\nQuantitative is just a way to describe\\nthat you're gathering counts or numbers,\\nlike the percentage of conversions\\nor the time it takes to complete something.\\nQuantitative data is unambiguous,\\nbut you still need context to interpret the data.\\n\\nFor instance, if an updated e-commerce site gets 100 sales\\nin a week, is that good or bad?\\nWell, it depends on a lot of factors,\\nlike how many sales did they have in the weeks before?\\nHow big were the purchases?\\nWere there any promotions or special dates about the week?\\nThe count is concrete, but the context still matters.\\nSo where do we turn for that context?\\nOften it's qualitative data, which is just the term used\\nto describe every other kind of data\\nthat can't be objectively measured.\\n\\nThings like descriptions of experience,\\nvaluations of the feature set,\\npreferences among interactions,\\nobservations of frustration points, that kind of thing.\\nWe often hear that quantitative measures tell us\\nwhat is happening, and qualitative data tells us why.\\nSome methods allow you to collect both kinds of data,\\nand some are more focused on one or another.\\nFor instance, in a usability test,\\nyou might collect a quantitative measure,\\nlike how long it takes people to perform tasks,\\nbut you might also gather anecdotes\\nabout how useful a feature is\\nor where else someone expected something to live,\\nwhich is qualitative data.\\n\\nThings like interviews are focused\\non qualitative information and rarely include whole numbers,\\nwhereas a multi-variate test is focused on measuring\\npercentages of actions in variations of a design.\\nNeither type of data is fundamentally better than the other.\\nJust depends on your goals.\\nIn fact, I'd say that you should be careful\\nto collect both types of data and balance\\nthe information you're getting, to put it into context.\\nIt's important to understand measurements\\nand what's happening,\\nand even more important to learn about underlying reasons\\nand explanations for trends.\\n\\nThe most important part is tying whatever you're measuring\\nback to your original research goal\\nand ultimately, the overall goals you have for your product.\\nQuantitative analysis is often fairly straightforward,\\nand consists of calculating whatever figures you need.\\nPure counts, percentages of clicks,\\naverages of rating, that kind of thing.\\nBecause of that, I'm going to focus the rest\\nof the course on working with qualitative data,\\nwhich is often much messier and more complicated.\\n\\nWe're also going to skip over data collection\\nfor this course.\\nIf you need more information on running studies,\\nI recommend checking out my courses on interviewing,\\ncard sorting and foundational research.\\n\"}],\"name\":\"1. Research Goals and Hypotheses\",\"size\":22448777,\"urn\":\"urn:li:learningContentChapter:5991030\"},{\"duration\":859,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:5977400\",\"duration\":206,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Break down qualitative data\",\"fileName\":\"3905267_en_US_02_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":589,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"This video discusses the first step of analyzing qualitative data, which is breaking down everything you've found into individual snippets of information.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10945046,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Collecting even a small amount\\nof qualitative data can seem overwhelming.\\nWith just five interview\\nor usability test sessions, you might have pages of notes\\nor transcripts, hours of recordings, and dozens of images.\\nHow do you approach all this information?\\nFirst, consolidate all of the data\\nand decide how you're going to interact with it.\\nIf you have access to data analysis software like Dovetail,\\nyou may want to import everything there.\\nSome folks prefer to dump things into spreadsheets\\nor visualization tools or print everything out.\\n\\nThis is a matter of preference,\\nbut if you're collaborating, make sure you agree on a method\\nas a team so that everyone has the same access,\\nand you have a plan for ultimately combining your work.\\nNext, immerse yourself in the raw data.\\nYou and your team members can read through notes,\\nrewatch videos, listen to recordings or review transcripts.\\nBe sure to look at the data multiple ways.\\nEven if you learn information best in one style or another,\\nyou may pick up on different nuances by watching,\\nlistening, and reading.\\n\\nEveryone processes information differently,\\nbut you can build a deeper perspective\\nand understanding just by examining the same piece\\nof information in different ways.\\nBefore you go any further, it might also be helpful\\nto review your research objectives and specific goals.\\nThis may help you start to think about the context\\nof the data and next steps.\\nJust be careful not to start drawing conclusions\\ntoo quickly.\\nOne of the best things about research,\\nespecially exploratory research, is that you're likely\\nto uncover questions\\nand information that you didn't even know to look for.\\n\\nNext, mine the data to pinpoint specific observations.\\nWalk through everything and identify individual, granular\\nobservations without yet assigning judgment\\nor thinking about solutions.\\nWhen looking through data, pay special attention\\nto things like common uses and routines,\\nthe context in which people work, transitions\\nbetween items, workarounds or shortcuts,\\nplaces people get stuck, frustrated, or interrupted,\\nthe language used,\\nthings that are especially annoying,\\nthings that are especially pleasing,\\nthings you've never heard or seen,\\nor contradictory feedback.\\n\\nRemember, at this point,\\nyou're simply identifying observations.\\nYou don't yet need to make connections,\\ndecide how important effect is, or figure out a solution.\\nYou may end up with highlighted transcripts, sticky note\\nannotations, a spreadsheet, or even a list of notes.\\nThe format is more about personal\\npreference than anything else.\\nJust make sure you're consistently capturing\\nthe core information.\\nWhile you're mining and breaking down the data,\\nyou might find yourself starting to group these nuggets\\nby research goal, type of finding, or some emerging themes.\\n\\nResist the urge to do this too early.\\nThis part of the process should be done individually so\\nthat each team member can look at the from their own\\nperspective, then come together to compare findings\\nbefore layering on any meaning or deciding priority.\\nAnalysis is a term often used to describe the process\\nof moving from raw data to insights.\\nThis first part I've described here is simply analysis,\\nwhere we've broken down the data.\\nThe next part is where we synthesize, making connections\\nand turning the data into meaningful takeaways.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:5991029\",\"duration\":170,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Tag qualitative data\",\"fileName\":\"3905267_en_US_02_02_VT\",\"demo\":true,\"videoCreationMetadata\":{\"rawDurationSeconds\":460,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"This video discusses adding tags to qualitative data, which is a way to layer on information to categorize and start to recognize patterns within the dataset.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9546182,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Once you've identified observations, it's time\\nto start assessing your data.\\nThere are multiple approaches to move from raw data\\nto insights, like content analysis and narrative analysis.\\nOne of these more specific processes may be applicable\\nto your research methods,\\nbut I'm going to walk through a general framework that works\\nfor just about every set\\nof qualitative UX data I've worked with.\\nFor those of us research nerds,\\nit's basically a thematic analysis framework\\nwith a lens of grounded theory.\\nThis approach uses tagging\\nand a series of affinity mapping exercises\\nto identify clusters\\nor themes within the data with opportunities\\nto let insights emerge throughout the process.\\n\\nFirst, it's time to tag\\nor code these insights with labels that help you frame them.\\nSort of like you might assign a keyword to an article.\\nFor instance, a course like this,\\nmaybe tagged UX research or qualitative data.\\nThe specific labels can either describe the data\\nor start to layer on an interpretation.\\nDescriptive tagging is more about identifying\\nwhat is happening by variable, such as noting specific tools\\nthat get used in a process.\\nThematic or interpretive tagging starts to connect a finding\\nto a larger meaning that is abstracted from the raw data.\\n\\nYou may decide to preset tags\\nor codes that you know you want to look for,\\nwhich is called deductive coding.\\nThis can help you save time\\nand can make sure that you have a lens to connect data back\\nto your research goals.\\nJust make sure they aren't too narrow\\nor too representative of preconceived notions.\\nFor instance, you could start with pain points\\nas a general category that doesn't assign value,\\nbut don't start with something like irritation\\nwith a signup process.\\nI recommend letting tags evolve as you look\\nthrough the data, which we call inductive coding.\\n\\nOne of the most valuable parts\\nof qualitative research is uncovering the opportunities\\nyou didn't know existed.\\nI very often begin with a set of descriptive tags\\nthat I know I wanted to pay attention to,\\nand then let additional thematic tags emerge as I go.\\nYou may also end up having multiple codes that feel relevant\\nfor an individual nugget.\\nFor instance, you might have a general code\\nto capture pain points\\nand another thematic tag about a user's context\\nthat both apply to the same negative information.\\n\\nOne of the most interesting things\\nto look at later is actually the cross section of tags,\\nso don't feel like you need to pick only one.\\nNo tag is right or necessarily more useful than the other.\\nDon't worry too much about distinguishing\\nwhat type of code you're using.\\nJust try to look at both facts and context\\nand be consistent.\\nIt's essential to apply the tags consistently,\\nespecially if you're doing this process as a team.\\nI suggest keeping a code glossary where codes are defined,\\npossibly with examples.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5987095\",\"duration\":96,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Prune and sort qualitative data\",\"fileName\":\"3905267_en_US_02_03_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":317,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"This video discusses the next step in qualitative data analysis, where you can start to sort out information you don't need and make initial groupings to begin identifying relationships between the data.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5380479,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- During or following the coding process,\\nyou can also start to prune things out\\nsince not every single fact is relevant\\nto your business goals or research objectives.\\nFor example, let's say you've interviewed\\na bunch of customer support reps.\\nMaybe you happen to notice that all the reps you talk to\\nhave the same color phone case.\\nThat might be an interesting coincidence,\\nbut doesn't really relate to their experience\\nwith the tracking software that they use.\\nIf you're working in a data analysis tool,\\nthere will be a way for you to add codes at the start\\nand as you go,\\nand most tools will automatically group the information\\nwith the same code.\\n\\nIf you're manually coding,\\nI recommend having some sort of way to visualize the codes,\\nlike different color sticky notes or text highlights.\\nOnce you have things coded,\\nyou'll want to group the nuggets together.\\nAt this stage, I simply mean put all of the information\\nwith the same tags in the same space.\\nIf something has multiple tags,\\nI make copies and represent in each category,\\nbut keep all the tags attached so you don't lose context.\\nWe traditionally think of doing this\\nby cutting snippets out of transcripts\\nand making sticky notes and physically grouping items,\\nbut you can also do this visually with tools like Mural\\nor even in columns and rows of a spreadsheet.\\n\\nYou are likely to have started to see patterns emerge\\nas you tag and do this first sort,\\nbut you can still be a ways away from recognizing\\ntruly new insights or impactful opportunities.\\nNext, we'll dive into steps\\nto more deeply synthesize findings\\nso you don't overlook connections\\nor rely too heavily on preconceived notions.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5984194\",\"duration\":168,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Insight synthesis\",\"fileName\":\"3905267_en_US_02_04_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":887,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\\n\\nTake 1a-1_PU - (G)\\n- PU for second half of movie.\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":true,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"Explore one of the main approaches used to process qualitative data, so you are able to draw insights from the data you collect.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9306494,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Once you have initial groupings,\\nexamine the findings one at a time,\\nlooking for similarities, connections, and patterns.\\nYou may end up making new subgroups\\nor start to visualize things\\nlike the frequency of a pain point.\\nThen, you'll want to start comparing the groups\\nand do the same process,\\nlooking for connections and patterns across the groups.\\nYou may want to create additional tags\\nif you notice something new,\\nlike how big an impact a particular issue has\\non different kinds of users.\\nYou'll also want to look for new ways to group the items,\\nvariations within the groups or other connections.\\n\\nMake sure to do this sorting process collaboratively,\\nand give yourself ample time.\\nDo more than one round of sorting,\\nas the first grouping will almost always\\nmost closely match your preconceptions.\\nThe process of re-sorting and re-framing\\nwill help lead to the deepest insights.\\nThe discussion around what lives where\\nand how to interpret things\\nis often the most valuable part of this process.\\nBe sure to pressure test your groups as you go.\\nFor instance, if you think you have four major themes,\\nbut there's a lot of discussion or disagreement\\nabout one of the categories,\\nmaybe it's time to split it up,\\nor maybe there isn't much discussion\\nabout what goes into the four categories,\\nbut there's a lot of data that doesn't fit any of those.\\n\\nKeep an open mind,\\nand be willing to iterate on the groupings.\\nYou may want to consider conducting some cross-tabulation\\nto look at how the different groups\\ncompare across specific variables.\\nVery basically, you look at more than one variable\\nin the same table.\\nFor instance, you might want to break down\\nwhat banking activities someone does on their phone\\nversus on their desktop,\\nand compare where they're more likely to do what.\\nThis will help you better understand\\nhow the groups are the same or different,\\nidentify outliers or surprises,\\nand feel more confident about your groupings overall.\\n\\nRemember that frequency doesn't necessarily imply importance\\nor relevance to your business goals.\\nIt could be that just a few of your participants\\nshare a piece of feedback,\\nbut it turns out that those are the most valuable customers,\\nor it could be that many participants have a shared request,\\nbut it's not technically feasible to build.\\nYou'll have to use a combination of the facts you gathered\\nand your knowledge of the business context\\nto frame your work.\\nUnfortunately, there's no set amount of iterations\\nthat will magically get you to your deepest insights.\\n\\nYour goal is to come up with a framework\\nthat helps you place what you found in context,\\nand be able to tell relevant stories.\\nSometimes it takes two rounds in a day,\\nsometimes that takes five rounds over a few weeks.\\nIf at all possible,\\nerr on the side of giving yourself more time in this space.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5990087\",\"duration\":219,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"AI for speed?\",\"fileName\":\"3905267_en_US_02_05_VT\",\"demo\":true,\"videoCreationMetadata\":{\"rawDurationSeconds\":460,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"Gain a better understanding of the various uses of AI tools to analyze data, so you are able to leverage the benefits and avoid the drawbacks of this type of analysis.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12233328,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- With the recent developments in generative AI tools\\nlike Copilot, it may be tempting to upload raw data\\nand ask for an interpretation,\\nbut it's important to understand the limitations of AI\\nso you don't compromise your results.\\nGenerative AI tools run on models\\nthat learn from the data it's been fed\\nand make predictions about what should come next.\\nEssentially, they use statistics\\nto make a guess based on the data it already has.\\nBecause they're designed to intake data\\nto adjust their models,\\nyou may not be able to use identifying customer\\nor proprietary company data, even with a paid version.\\n\\nYou could scrub your data to remove identifying information,\\nbut that can be time consuming and nuance can get lost.\\nI recommend working closely with your organization's privacy\\nand or legal teams to develop guidelines.\\nFor one thing, qualitative data comes in a variety\\nof formats, audio, video, screenshots or images, texts,\\nand you need all of these kinds of data\\nto build a whole picture.\\nAs of the summer of 2024,\\nthere aren't any widely available tools\\nthat will analyze videos and tie the audio\\nor timestamped text transcripts to the visuals,\\nwhich means you'd be missing important context.\\n\\nFor instance, if you only read the transcripts\\nof a usability test session without reviewing the video,\\nyou'd miss important observations about\\nwhat the participant was looking at\\nor how they were interacting with the product, which is one\\nof the fundamental benefits of doing behavioral research.\\nI wouldn't analyze usability test data from transcripts\\nalone, and I definitely wouldn't trust an AI tool's\\ninterpretation of only one slice of the data.\\nSince AI models are designed to learn from past data,\\nthe quality of the output is strongly tied\\nto the data involved in the training.\\n\\nThat data could very well be biased, limited,\\nor lacking context.\\nFor instance, an AI model may know the design best practices\\nfor an e-commerce site in Europe or North America,\\nbut those tenets may not be at all applicable in an\\neducation app in Asia.\\nThere's likely something unique about your specific user set\\nresearch goal or business context\\nthat means past data is only so relevant.\\nWe're usually trying to identify that unique nuanced context\\nwe're learning that will allow us to come up\\nwith something brand new.\\n\\nOf course, it's helpful to look back at patterns,\\nbut an AI can't infuse the context-specific insight\\nthat will help you uncover new opportunities.\\nGenerative AI tool outputs also vary\\ngreatly on your prompts.\\nWhile the conversations feel real,\\nthey're still just programs\\nwith very literal interpretations.\\nA slight change in the way you phrase a question\\nmight result in quite a different response.\\nMost importantly, the AI tools are good at summarizing data\\nand recognizing simple patterns,\\nbut not at putting things into context\\nor interpreting meaning.\\n\\nIt might be easy to confuse a general summary\\nand an actual insight,\\nbut the difference is context and impact.\\nFor example, an AI tool might be able to quickly identify\\nthat 10 to 15 participants report using the same video\\nconference tool and that 12 of your participants\\nwork remotely.\\nIs there a connection between those two facts,\\nand if so, what is it?\\nWhat do those two facts mean for you and your team?\\nHow will those learnings be received\\nby your different stakeholders?\\nOnly a human can layer on that valuable context,\\nand we'll talk more about that next.\\n\\n\"}],\"name\":\"2. Gathering and Organizing\",\"size\":47411529,\"urn\":\"urn:li:learningContentChapter:5987096\"},{\"duration\":303,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:5991028\",\"duration\":188,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Filter into actionable insights\",\"fileName\":\"3905267_en_US_03_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":538,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"This video discusses the process of layering context and meaning to tell a story about the insights found during qualitative research so that findings can be best digested by teammates.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9801869,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Once you've identified patterns and themes,\\nyou'll want to start looking for connections\\nbetween what you found\\nand your business goals and research objectives.\\nThis is the part that makes your research a powerful tool\\nto build a shared understanding and drive change.\\nThis is where you get to answer the questions you posed\\nat the beginning\\nand shine a light on anything additional you found.\\nRevisit your research objectives,\\nand compare them to the themes identified.\\nSometimes the connection between open questions\\nand findings are pretty obvious,\\nbut sometimes you need to do a little extrapolation.\\n\\nLet's look at an example.\\nIn a past project,\\nI worked with a health insurance company\\nthat wanted to reduce support and printing costs.\\nWe sought to understand\\nhow their members interacted with them\\nduring different life stages\\nand serious medical events.\\nEveryone was overwhelmed with the amount of documentation,\\nwhich is directly tied to reducing printing costs.\\nAn obvious suggestion might be\\nthat they could consolidate forms\\nand offer more information online.\\nOn the other hand,\\nthe interactions with support were varied and complex\\nand totally dependent on many situational factors.\\n\\nThere couldn't be just one solution\\nthat would address all cases.\\nWe then brainstormed ideas to further explore.\\nIt is not enough to just identify facts.\\nUltimately, you want to build\\nand tell a story about what you found\\nso that people can digest, interpret,\\nand act on the information.\\nYou want to provide context about the findings\\nand what it means, why your team should care,\\nand what you might want to do next.\\nFor instance, what if I give you these two figures?\\nScenario one is 5 to 10%,\\nand scenario two is 65 to 70%.\\n\\nWhat does that mean?\\nWhich one is better?\\nWell, on their own,\\nthose numbers don't really mean anything.\\nNow, what if I frame the information like this?\\nA Stanford article reports\\nthat people remember just 5 to 10% of raw data,\\nbut they remember 65 to 70% of facts given to them\\nin story form.\\nUsing the power of storytelling can help people understand\\nand digest your findings.\\nStories are made up of a few parts,\\na beginning that sets context,\\nan incident that causes a series of actions,\\nsome sort of dramatic peak, and a resolution.\\n\\nThink of this as a framework to introduce your findings,\\ntheir impact to users and business,\\nand then what your team might need to do\\nto create resolution.\\nYou can also tap into emotion,\\nwhich is a powerful force of persuasion.\\nYou don't want to overindex\\nor manufacture emotion where there isn't,\\nbut a little can go a long way.\\nDemonstrating the face of a very frustrated user\\nor mapping someone's tumultuous emotions\\nduring a process can be very powerful.\\n\\nIt's important to reiterate that you might end up\\nwith more open questions to explore.\\nIn this case,\\nyou can always design another research effort\\nto inform next steps.\\n\"},{\"urn\":\"urn:li:learningContentVideo:5989092\",\"duration\":115,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Document work\",\"fileName\":\"3905267_en_US_03_02_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":388,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":true,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"This video discusses considerations for documenting and sharing insights so the whole team has access to new insights and can make more informed decisions.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6529611,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Be sure to pay attention\\nto how you document what you found\\nand intend to share with others.\\nThere's no one right way,\\nand as always, it depends on the audience and the context.\\nYou have to consider who needs to take in this information,\\ntheir technical expertise and familiarity with the work,\\nand what else the deliverable will be used for.\\nFor instance, if you know that a report\\nwill be used in an executive presentation\\nof people unfamiliar with the project,\\nyou'll do things very differently\\nthan if you're producing a quick readout\\nfor your own products team.\\n\\nI've done everything from compiling results\\nand simple emails, writing up summaries and wikis,\\npresenting visual decks, and writing 50-page text reports.\\nThat 50 pager wasn't my favorite to produce,\\nbut it was right for the client I was working with.\\nRegardless of the format, you want your research deliverable\\nto follow any of the standard principles of good design.\\nIt should be easy to digest and navigate,\\nerr on the side of using simple language where possible,\\ninclude visuals and graphics as appropriate,\\nand lay things out in a way\\nthat will be easy to read and scan.\\n\\nI always prefer to share research results in person\\nand have a chance to talk through findings,\\nrather than just distribute an artifact.\\nIt gives you a chance to discuss and connect with the team,\\neven if you also intend to send out copies later.\\nAgain, remember that this is your chance\\nto make connections for your team\\nand help them build empathy and understanding.\\nThis is your chance\\nto help your team make sense of what you found\\nand forge a path forward.\\nYou'll also want to consider\\nhow to ensure insights are shared widely\\nand stay top of mind,\\nso they can be utilized and built on over time.\\n\\nIf you're not already,\\nyou may want to consider creating a research repository\\nto store and manage research outputs,\\nso everyone has access and visibility.\\n\"}],\"name\":\"3. Insights\",\"size\":16331480,\"urn\":\"urn:li:learningContentChapter:5990088\"},{\"duration\":47,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:5986105\",\"duration\":47,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Next steps\",\"fileName\":\"3905267_en_US_04_01_VT\",\"demo\":false,\"videoCreationMetadata\":{\"rawDurationSeconds\":92,\"solutionVideo\":false,\"editingNotes\":\"Take 1 - (G)\",\"handoutGraphicsIncluded\":false,\"assignedBy\":\"urn:li:member:-1\",\"includesPickups\":false,\"challengeVideo\":false,\"hasSlides\":false,\"graphicsIncluded\":false,\"assignedTo\":\"urn:li:member:-1\",\"includesAlternateFootage\":false},\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3221987,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"- Thanks so much for taking some time\\nto better understand how to use the data\\nthat's collected in user experience research efforts.\\nTurning raw data into deep insights and actionable steps\\nis often one of the hardest parts\\nof successfully integrating research into your practice.\\nThis course has given you an approach\\nto make sense of any sort of data at your fingertips.\\nBut as always,\\nthe best way to learn is often to try yourself.\\nI really recommend practicing on old data\\nif you don't have anything new to review.\\n\\nYou never know what you may learn.\\nAnd remember, this is just one\\nof a series of UX research deep dives.\\nCheck out my other courses here on LinkedIn Learning.\\nFeel free to share your experiences with me on LinkedIn.\\nThanks again and good luck.\\n\"}],\"name\":\"Conclusion\",\"size\":3221987,\"urn\":\"urn:li:learningContentChapter:5991031\"}],\"size\":92808545,\"duration\":1642,\"zeroBased\":false}],\"id\":null,\"product\":\"Pro Cert\",\"status\":\"Curation\"}"