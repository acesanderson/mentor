"{\"title\":\"Anaconda Python for Data Science Professional Certificate\",\"courses\":[{\"course_title\":\"Introduction to Data Science\",\"course_admin_id\":4457428,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":4457428,\"Project ID\":null,\"Course Name\":\"Introduction to Data Science\",\"Course Name EN\":\"Introduction to Data Science\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"&lt;p&gt;The world of data science is reshaping every business, regardless of industry, location, or role. And there\u2019s never been a better time to get up to speed and learn the basics of this booming field. In this course, designed specifically for beginners, explore the world of data science, its opportunities and innovations, and the fundamental skills required for success.&lt;/p&gt;&lt;p&gt;Join Python trainer and data science expert Lavanya Vijayan as she shares what data science is and how it differs from other common data-related careers. Discover some of the most important tools used in the trade to develop your understanding of data libraries and data manipulation. Along the way, get an introduction to exploratory data analysis, data cleaning, data visualization, sampling, testing, estimating, and more. By the end of this course, you\u2019ll know how to use inference and statistical analysis to make more reliable predictions for your business.&lt;/p&gt;&lt;p&gt;This course is part of a &lt;a href=https://www.linkedin.com/learning/paths/anaconda-python-for-data-science-professional-certificate target=_blank&gt;Professional Certificate&lt;/a&gt; from Anaconda.&lt;/p&gt;&lt;p&gt;This course was created by &lt;a href=https://www.onlymadecraft.com target=_blank&gt;Madecraft&lt;/a&gt;. We are pleased to host this training in our library.&lt;/p&gt;&lt;img src=https://media.licdn.com/media/AAYAAgCwAAoAAQAAAAAAAHppnBQxgeyWS2CsU3aDDPcMgw.jpg alt=Company logo for Madecraft; the letter M configured as part of a printing press width=20% height=20% /&gt;\",\"Course Short Description\":\"Get to know the exciting world of data science in this beginner-friendly course.\",\"Content Type\":\"SKILLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":\"21401000, 20516011\",\"Instructor Name\":\"Madecraft Licensor, Lavanya Vijayan\",\"Instructor Transliterated Name\":\", \",\"Instructor Short Bio\":\"Full-Service Learning Content Company|Technical Curriculum Architect and Data Science Instructor at Madecraft\",\"Author Payment Category\":\"LICENSED, NONE\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2023-07-31\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"Yes\",\"Has Challenge/Solution\":\"Yes\",\"LIL URL\":\"https://www.linkedin.com/learning/introduction-to-data-science-22668235,https://www.linkedin.com/learning/introduction-to-data-science-revision-2023\",\"Series\":\"One-Off\",\"Limited Series\":null,\"Manager Level\":\"Individual Contributor\",\"LI Level\":\"Beginner\",\"LI Level EN\":\"Beginner\",\"Sensitivity\":null,\"Internal Library\":\"Technology\",\"Internal Subject\":\"Data Science\",\"Primary Software\":null,\"Media Type\":\"Video\",\"Has CEU\":\"Yes\",\"Has Exercise Files\":\"Yes\",\"Visible Duration\":7255.0,\"Visible Video Count\":34.0,\"Learning Objectives\":null,\"Contract Type\":\"LICENSED, NO_CONTRACT\",\"Certifications\":\"PMI:Project Management Institute (PMI)\u00ae:4101QQ766E\",\"Framework Topic\":null,\"Automatic Caption Translations\":\"Global Captions\",\"Automatic Metadata Translations\":\"Global Metadata\",\"Gen AI Feature Flag\":null,\"Hands-On Practice\":null,\"Hands-On Practice Library\":null,\"Unlocked for Viva Learning\":\"Global Captions\",\"Free Course\":null,\"Certification Library\":\"Certifications\",\"Github Codespace\":null,\"Skills Count\":1,\"Skills\":\"Data Science\",\"Skills EN\":\"Data Science\",\"Content Manager\":\"Steve Weiss\",\"Acquisition Manager\":\"Kim Norbuta\",\"Framework Subject\":null},\"sections\":[{\"duration\":55,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4487774\",\"duration\":55,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Beginning your data science exploration\",\"fileName\":\"4457428_en_US_00_01_WL24\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Data science is a vast field, with plenty of opportunities and exciting innovations happening. After this course, you'll be able to define data science, recognize the data science lifecycle, and utilize fundamental skills in data science. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1527871,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"In the world today, it's hard to find a hotter\\nfield than data science.\\nIt's a fast-growing field that is reshaping the world. From\\nself-driving cars to helping treat cancer,\\nthe applications of data science are vast and powerful,\\nand taking time now to learn data science helps you open doors and\\nunlock opportunities that can help advance your career.\\nMy name is Lavanya Vijayan.\\nI'm a programming and data science instructor and an advocate\\nfor Stem education.\\nIn this course, I'll share the foundations\\nof data science, what it is, and how it's applied.\\n\\nThen I'll help you understand data design and introduce you to the\\ncomputational tools that are fundamental to data science.\\nFinally, you'll go through the stages of the data science\\nlifecycle.\\nBy the end of this course, you'll have a better understanding\\nof data science and you can begin to craft your journey to becoming\\na data scientist yourself.\\nSo let's get started.\\n\"}],\"name\":\"Introduction\",\"size\":1527871,\"urn\":\"urn:li:learningContentChapter:4488795\"},{\"duration\":401,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4493806\",\"duration\":235,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Demystifying data science\",\"fileName\":\"4457428_en_US_01_01_LA24\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Data science is rapidly increasing in popularity and demand and is a valuable skill as both a career or a skill within an existing role. After watching this video, you'll be able to define data science and its core principles.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6942964,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"There are many definitions out there for data science.\\nI like the definition given by Joseph Gonzalez,\\nwho's a professor at UC Berkeley.\\nAccording to him, data science is the application of\\ndata-centric computational and inferential thinking to understand\\nthe world and solve problems.\\nData scientists have a unique role in industry,\\ngovernment, and other organizations,\\nand that role is different from the roles of others,\\nsuch as data engineers,\\nstatisticians, and business analysts.\\n\\nThe first difference I want to help you understand is a\\ndifference between data scientists and data engineers.\\nData engineers work to make sure data flows smoothly between the\\nsource and the destination.\\nNow, the source is where data is collected,\\nand the destination is where data is extracted and processed.\\nData scientists work to make sure that value is extracted\\nfrom data smoothly.\\nData engineers optimize data flow while data scientists optimize\\ndata processing and data scientists work with data\\nengineers as well as business people to define metrics,\\nestablish how data is collected,\\nand ensure that data science processes work well with\\nenterprise data systems.\\n\\nAnd when data scientists and data engineers work together,\\nit's important for the data scientists to write code that's\\nreusable by the data engineers.\\nThe next difference I want to help you understand is the difference\\nbetween data scientists and statisticians.\\nNow, the amount of data that data scientists work with\\nis often massive, so they spend a lot of time with\\ntasks like large scale data collection and data cleaning.\\nMeanwhile, statisticians rely on more traditional and smaller scale\\nmethods of data collection, such as surveys,\\npolls, and experiments.\\n\\nData scientists try out different methods to create machine\\nlearning models, and then they choose the method\\nthat results in the best model.\\nOn the other hand, statisticians work on improving\\none simple model to best fit the data,\\nand data scientists do more than just analyze data.\\nThey also implement algorithms that process data automatically.\\nAnd this enables data scientists to provide automated predictions\\nand actions. To help bring this to life,\\nI want to give you some examples of the types of things that data\\nscientists can automate through data analysis and algorithms,\\nsuch as analyzing NASA pictures to find new planets or asteroids or\\nautomated piloting planes, cars and more.\\n\\nYou can automate book recommendations on Amazon or\\nfriend recommendations on Facebook.\\nYou can use automation and computational chemistry to\\nsimulate new molecules for cancer treatment.\\nAnd automation can help with early detection of an epidemic or\\nestimating the value of houses in the US in real-time,\\nlike on Zillow, or matching a Google AD with a\\nuser and a web page to maximize the chances of a conversion.\\nAutomation can help return highly relevant results to Google\\nsearches or detect credit card fraud and tax fraud and automation\\neven helps with weather forecasts.\\n\\nThe next difference I want to help you understand is the difference\\nbetween data scientists and business analysts.\\nBusiness analysts focus on database design and\\nROI assessment.\\nAnd some business analysts work on finance\\nplanning and optimization and risk management and others manage\\nprojects at a high level.\\nNow, data scientists can help business analysts.\\nFor example, data scientists can help automate the production of\\nreports and speed up data extraction.\\nAccording to data scientist, Vincent Granville,\\nthe collaboration between data scientists and business analysts\\nhas helped business analysts extract data that's 100 times\\nlarger than what they're used to and ten times faster.\\n\\nSo there you have it.\\nThe power of data science is changing our world,\\nand that's a great reason for you to continue learning.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4492758\",\"duration\":112,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"The value of data science\",\"fileName\":\"4457428_en_US_01_02_LA24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Data science can be used across numerous fields and offers important benefits to the world around you. After watching this video, you'll be able to explain the value of data science.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3456120,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"The data stored and used by the world has dramatically\\nincreased each year.\\nAnd the good news is data sets in the right hands can help predict\\nand shape the future.\\nThink about it. Companies use data to run and grow their\\neveryday business,\\nand data science can help companies make quicker and better\\ndecisions which can take them to the top of their market.\\nAlso, data science affects many areas of our everyday lives.\\nFor example, it's already used in areas such as quick and\\neasy customer service, intelligent navigation,\\nrecommendations, and voice to text.\\n\\nData science has other uses, such as helping to improve the\\nresolution of an image and detecting fraud by analyzing the\\nbehavior of financial institutions in real-time.\\nData Science also has applications in robotics and thus has the\\ncapacity to help do things like assisting elderly people and\\npeople with disabilities.\\nData science can have positive contributions to society.\\nOne of them is reshaping industries like health care.\\nThe amount of data produced by patients and illnesses\\nrises by the second,\\nopening new opportunities for better structured and more\\ninformed health care.\\n\\nThe challenge is to carefully analyze the data in order to be\\nable to recognize problems quickly and accurately,\\nsuch as diagnosing medical conditions and predicting\\ndangerous seismic events.\\nData science also has the power to save rare species.\\nComplex predictive models and algorithms can create insights and\\nhelp scientists analyze threats to wildlife and create a solution\\nthat can save animals.\\nData science is redefining how people and organizations solve\\nchallenging problems and understand their world.\\n\\nThe more you understand data science,\\nthe more you'll be equipped with the tools to improve your\\ncommunity and make the world a better place.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4487773\",\"duration\":54,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Defining the data science life cycle\",\"fileName\":\"4457428_en_US_01_03_LA24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Data scientists follow a specific workflow. After watching this video, you'll be able to describe the data science lifecycle and the main goal of each stage.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2230072,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Data\\nand it's called the Data Science Life Cycle.\\nIn this course, you'll learn more about this\\nprocess and what each stage of it entails.\\nBut for now, I'll give you a quick preview.\\nThe first stage of the data lifecycle is to formulate a\\nquestion you have or a problem you want to solve.\\nNext, you acquire and clean data that is relevant to your\\nquestion or problem.\\nThird, you conduct exploratory data analysis.\\nFourth, you would use prediction and inference to draw conclusions\\nfrom the data.\\n\\nNow, it's common for you to discover more questions you have\\nor problems you need to solve after the fourth stage.\\nSo you would go through the process repeatedly,\\nand that's why there's a positive feedback loop.\\nThe data science lifecycle is critical to how data scientists\\napproach their work,\\nand now you know the major stages of this process.\\n\"}],\"name\":\"1. Defining Data Science\",\"size\":12629156,\"urn\":\"urn:li:learningContentChapter:4491769\"},{\"duration\":392,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4487772\",\"duration\":240,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Reducing bias with probability sampling\",\"fileName\":\"4457428_en_US_02_01_LA24\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Data design, the process of data collection, is important in data science. After watching this video, you'll be able to use data design to reduce sampling biases.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7695281,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Data design is the process of data collection.\\nWhen you collect a sample of data, you want to make sure that there's\\nas little bias as possible in the way you collect the sample.\\nProbability sampling is a family of sampling methods that assigns\\nprecise probabilities to the appearance of each sample to\\nreduce bias as much as possible in data design.\\nI want to help bring this to life and show you a few methods\\nof probability sampling.\\nSuppose you have a population of eight people.\\nEach person is given a distinct letter from A through H.\\n\\nOne method of probability sampling is called simple random sampling,\\nalso known as SRS.\\nA simple random sample is taken by sampling at random without\\nreplacement.\\nTo take a simple random sample of Size 2 from the population\\nof eight people, you can write each letter from A\\nthrough H on a separate index card,\\nplace all the cards into a hat, mix the cards as well,\\nand draw two cards from the hat without looking.\\nHere are all possible.\\nsimple random samples of Size 2 from the population\\nof 8 people.\\n\\nSo when selecting a sample, you could get any of these samples\\nwith equal chance.\\nNow another method of probability sampling is called\\ncluster sampling.\\nA cluster sample is taken by dividing the population into\\nclusters and then using SRS to select clusters at random. To take\\na cluster sample of Size 2 from the population of 8 people,\\nyou can pair up each person to form four clusters of 2 people\\nper cluster and then use SRS to select one cluster.\\n\\nThe selected cluster is a sample of Size 2.\\nSuppose you pair up the individuals like this,\\nthose are your clusters.\\nSo when selecting a cluster, you could get either AB,\\nCD, EF, or GH with equal chance.\\nNow, you might be wondering how useful is a sampling method?\\nSo I'll tell you some of the pros and cons of cluster sampling.\\nI'll start with the pros.\\nCluster sampling makes sample collection easier,\\nand many agencies use cluster sampling to conduct surveys.\\n\\nFor example, it's much easier to survey 100 people in each city\\nthan to survey thousands of people distributed across the entire US.\\nSo what are the cons?\\nCluster sampling tends to produce more variation in estimation,\\nso you have to take larger samples when using cluster sampling.\\nAnother method of probability sampling is called stratified\\nsampling.\\nstrata and then producing one simple random sample per stratum.\\n\\nTo take a stratified sample of Size 2 from the population\\nof 8 people, you would first divide the\\npopulation into 2 Strata. Strata 1 would contain A,\\nB, C, D, and E, and Strata 2 would contain F,\\nG, and H.\\nThen you would use SRS to select one individual from each strata.\\nThis results in a sample of Size 2.\\nHere are the possible samples you could get.\\nNow, you might have noticed that the strata in this example\\nare different sizes.\\n\\nIn stratified sampling, the strata do not have\\nto be the same size, and that can be an advantage.\\nFor example, you could stratify the US by occupation,\\nthen take the samples from each strata of size proportional to the\\ndistribution of occupations in the US.\\nThis would ensure that occupations that are not as common would still\\nshow up in a stratified sample.\\nA simple random sample might completely miss people\\nin such occupations.\\nSo stratified sampling helps you ensure that subgroups of the\\npopulation are well represented in the sample,\\nwhich can lessen variation in estimation.\\n\\nHowever, stratified sampling can sometimes be more difficult to\\nperform because sometimes you don't know how large\\neach strata is.\\nNow you know the importance of probability sampling and three\\nmajor sampling methods.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4485934\",\"duration\":152,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Using non-probability sampling\",\"fileName\":\"4457428_en_US_02_02_LA24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"You can also collect data with non-probability sampling techniques. After this lesson, you'll be able to recognize what these techniques are and the scenarios in which using them can be beneficial. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5847259,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Sometimes, data collection can be very expensive and time-consuming,\\nand you may not have access to all the members of a population.\\nIn that case, you would not be able to take a random sample.\\nInstead, you could use a different technique called non-probability\\nsampling, which is a subjective,\\nin other words, non-random method.\\nWith this method, there is no guarantee that every\\nindividual in the population has a chance of being included\\nin the sample.\\nSo this method has higher risks of sampling bias,\\nbut it's also easier and less expensive to implement.\\n\\nIt's often used in qualitative or exploratory research,\\nwhere the goal is to gain an initial understanding of\\na specific phenomenon.\\nIn this lesson, I will introduce key types of non-\\nprobability sampling with examples of each.\\nThe first is volunteer sampling.\\nWith this approach, volunteers make up the sample.\\nFor example, if a researcher wants to learn more about the experience\\nof having a particular disease, they could circulate a survey\\nwhere the eligibility requirement is that the participant\\nhas the disease.\\n\\nThose who meet that criteria and want to participate voluntarily\\nshare their responses to the survey questions.\\nAnother method is purposive sampling.\\nWith this approach, a researcher uses their best\\njudgment to select a sample that they think is a best fit.\\nFor example, if a researcher wants to learn more about the\\nexperiences of employees with disabilities,\\nthe sample could be intentionally selected to suit that goal.\\nAnother method is quota sampling, which is one of the most common\\nforms of non-probability sampling.\\n\\nWith this approach, sampling is done until a specific\\nnumber of units,\\nin other words, quotas, for various subpopulations\\nhave been selected.\\nThis helps in achieving sample size objectives and ensuring that\\nmembers of different subpopulations are included.\\nFor example, if a researcher wants to learn more about consumer\\npreferences of individuals across different socioeconomic groups,\\nthey could use quota sampling.\\nOne more method is snowball sampling.\\nIn snowball sampling, participants recruit other\\nparticipants to join the sample.\\n\\nThis is used when it's hard to directly reach members of a\\npopulation with the required characteristics.\\nFor example, if a researcher wants to learn more about the musical\\ntechniques of artists in niche genre,\\nthey may consider using snowball sampling.\\nIf you need to collect data with limited resources for a time\\nsensitive project and probability sampling is not an option,\\nyou can consider using one of these non-probability\\nsampling methods.\\n\"}],\"name\":\"2. Starting with Data Design\",\"size\":13542540,\"urn\":\"urn:li:learningContentChapter:4485935\"},{\"duration\":348,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4488794\",\"duration\":136,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Comparing Python and R\",\"fileName\":\"4457428_en_US_03_01_LA24\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"You'll want to set up your data science projects to be successful, and using Jupyter Notebook is a great way to do so. After this lesson, you'll be able to set up Jupyter on your computer and familiarize yourself with the Jupyter environment.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4134450,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"R and Python are among the most popular languages for\\ndata science,\\nI want to help you understand the differences and provide a basic\\ncomparison between these two languages and point out\\nthe strengths of each.\\nPython is generally used when data analysis tasks need to be\\nintegrated with web applications, or statistical code needs to be\\nincorporated into a production database.\\nMeanwhile, R is mainly used when the data analysis tasks require\\nstandalone computing or analysis on individual servers.\\n\\nPython emphasizes productivity and code readability.\\nIn contrast, R focuses on better user-friendly data analysis\\nstatistics and graphical models.\\nPython is used by programmers that want to delve into data analysis\\nor apply statistical techniques and by developers that\\nturn to data science.\\nOn the other hand, R has been used primarily in\\nacademics and research.\\nHowever, it's rapidly expanding into the enterprise market.\\nCoding and debugging is easier to do in Python due to Python's\\nnice syntax.\\n\\nThe indentation of the code affects its meaning.\\nA piece of functionality is always written the same in Python.\\nMeanwhile, statistical models can be written with only\\na few lines in R.\\nThere are style sheets in R, but not everyone uses them and the\\nsame piece of functionality can be written in several ways in R.\\nPython's focus on readability and simplicity makes its learning\\ncurve relatively low, and Python is considered a good\\nlanguage for new programmers.\\nHowever, R has a steep learning curve at the beginning.\\n\\nOnce you know the basics though, you can easily learn advanced\\ntechniques.\\nR is not hard for experienced programmers.\\nPyPi stands for Python Package Index and it's a repository of\\nPython software consisting of libraries.\\nUsers can contribute to PyPi, but it's a little bit complicated\\nin practice. And CRAN stands for the Comprehensive R\\nArchive Network.\\nIt's a huge repository of R packages that users can\\neasily contribute to.\\nPython and R both have strengths and weaknesses,\\nand depending on your needs, you might find yourself using\\none, the other, or both.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4489776\",\"duration\":212,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Setting up your Jupyter environment\",\"fileName\":\"4457428_en_US_03_02_MM24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6665021,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"In data science,\\nthe Python 3 programming language is a useful computational\\ntool, and you'll see me using Python 3 throughout\\nthis course.\\nTo write programs, you need an environment\\nspecifically built for coding.\\nNow there are various platforms out there,\\neach providing a unique coding environment and the more you\\ntalk to those who code, the more you'll hear strong\\nfeelings towards one platform or another.\\nWhat's important to understand here is that all platforms will\\nprovide an ability to get started and apply the skills you're\\nlearning in this course.\\n\\nAnd the platform I'm using is called Jupyter Notebook.\\nI've included a link in the resource file.\\nLet's set up your environment.\\nSo I'm on the Anaconda distribution website, and I'm going\\nto scroll down to see the latest version that's available\\nfor me to download.\\nAt the time of recording, it's 3.7. For you might be a\\ndifferent version and that's totally fine.\\nNow, you'll want to click on \\\"Download\\\" and it should begin\\ndownloading for you.\\nSo I've already downloaded this, so I'm going to go ahead and open\\nup my downloads folder to find the installer there.\\n\\nSo now, I'm going to double click\\nto open up the installer.\\nNow, you're going to click through some of these dialogs,\\nso press continue.\\nYou're going to click \\\"Agree,\\\"\\nthen click \\\"Install\\\" and enter your password.\\nGreat.\\nWe're all installed here.\\nSo let's go ahead and click \\\"Continue\\\" and let's hit \\\"Close.\\\"\\nYou can either keep it or move to trash.\\n\\nI'm going to choose to move to trash.\\nNow you want to open terminal.\\nAnd if you're on a Mac like I am, you can do command space\\nand type terminal into spotlight and hit \\\"Enter.\\\"\\nAnd now you want to type in \\\"jupyter notebook,\\\"\\nmake sure everything is lowercase and that there's a space\\nbetween the two words,\\nlike this and you want to hit \\\"Enter.\\\"\\nAll right. There on the home page of your Jupiter and you're\\nready to get going.\\n\\nThe first thing you want to do is click on \\\"New.\\\"\\nThis is on the upper right area of your screen.\\nAnd you want to click on \\\"Python 3.\\\"\\nThis is how we create a new notebook with Python 3.\\nAnd Python 3 is the latest version of Python at this point.\\nSo one of the first things you want to do is to name\\nyour notebook.\\nAnd you do this by clicking on \\\"Untitled\\\" and typing in\\na new notebook name.\\nI'm going to type in \\\"Practice.\\\"\\nOnce you type that in, you can click \\\"Rename.\\\"\\nAnd there you go,\\nyou've renamed your notebook.\\n\\nNow, there are a lot of buttons and menu options here,\\nbut all you need to worry about right now is this box right here.\\nThis box is called a cell, and you can type code into\\na cell and then run it.\\nSo I'm going to go ahead and type in a line of code and I'm\\ngoing to type print,\\n\\\"Hello, world.\\\"\\nAnd there are two ways to run a cell.\\nYou can either click \\\"Run\\\" at the top here or if you're on a Mac,\\nyou can hit \\\"Shift-Enter.\\\"\\nI'm going to hit \\\"Shift-Enter.\\\"\\nAnd there we go,\\nHello\\nworld is printed out, and if you're following\\nalong here,\\nyou just wrote your first piece of code.\\n\\nNow your Python 3 environment is all set and you're ready to\\nlearn how to use this computational tool\\nin data science.\\n\"}],\"name\":\"3. Utilizing Computational Tools\",\"size\":10799471,\"urn\":\"urn:li:learningContentChapter:4488796\"},{\"duration\":1201,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4488793\",\"duration\":161,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Defining tabular data\",\"fileName\":\"4457428_en_US_04_01_MM24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Once you have access to a dataset, you will need to interact with it and read the data most quickly and efficiently. After watching this video, you'll be able to read tabular data with Python.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4950882,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Data sets can be structured in different ways.\\nA data set structure refers to the arrangement of the data\\nin the data set.\\nThere are several ways to structure data,\\nbut a lot of data scientists prefer working with tabular data,\\nand the main reason is tabular structure is just more convenient\\nto work with.\\nTabular data is arranged in rows and columns.\\nData files are stored in specific formats.\\nOne of the most common file formats for storing tabular data\\nis Comma-Separated Values or CSV, where each record is stored as a\\nline in the file and each file is separated by a comma.\\n\\nIf your data is stored in a CSV file,\\nyou can use the read_CSV method from a library called\\nPandas to quickly read the file into memory.\\nPandas is a powerful library in Python that provides easy to\\nuse data analysis tools.\\nFor example, say you're working with data regarding the names of\\nbabies born in the United States and this data is stored in a CSV\\nfile called us_baby_names.csv.\\nTo access the data, you can read in the\\nfile like this.\\n\\nThe first thing I'm going to do is import the Pandas Library.\\nAnd I do this by writing the keyword import followed by pandas.\\nAnd I'm also going to add in as pd.\\nThis means that going forward in this notebook,\\nI need to use pd to refer to pandas.\\nAnd I'll go ahead and run the cell.\\nNow, I want to read in the CSV file called us_baby_names_csv and a\\nreminder that that CSV file is stored in the same directory as\\nthis notebook. To read in the CSV file,\\nI'll use the read CSV method located in the Pandas library.\\n\\nSo I'll type pd.read_csv ()\\nand now I'll type in the name of the CSV\\nfile as a string.\\nSo I'll type in 'us_baby_names.csv', and I'll go ahead\\nand run the cell. There,\\nthat's what the data looks like.\\nAnd this object is called a Pandas data frame.\\nNow, if I create a variable and store this data frame in that\\nvariable, whenever I want to access the data,\\nall I have to do is refer to that variable.\\n\\nSo I'll go ahead and create a variable.\\nI'll call it us_babies,\\nand I'll assign it to the data frame that I get when I\\nread in the CSV file.\\nI'll go ahead and run the cell.\\nNow, when I type in us_babies and run the cell,\\nI have access to the same data set.\\nNow you know what tabular data is, how it looks, and how to use the\\nPandas Library to read in CSV files.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4487771\",\"duration\":373,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Reading tabular data\",\"fileName\":\"4457428_en_US_04_02_MM24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Being able to read data effectively is only half the battle, you also want to be able to analyze the data for insights. After this lesson, you'll be able to use what you're reading within the tabular data to formulate preliminary interpretations of your data. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11939342,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Pandas is a powerful library in Python that provides\\neasy-to-use data analysis tools.\\nWhen you use pandas to read in data,\\nyou get a data frame.\\nA data frame is a tabular data structure where each column is\\nlabeled and each row is labeled.\\nFor example, say you're working with data regarding the names of\\nbabies born in the United States, and this data is stored in a CSV\\nfile called us_baby_names.csv.\\nThe first thing I'm going to do is import the Pandas library.\\n\\nAnd I do this by writing the keyword import followed by pandas.\\nAnd I'll also add in as pd.\\nNow, this means that going forward in this notebook,\\nI need to use pd to refer to pandas.\\nI'll go ahead and run the cell.\\nAnd now, I want to read in a CSV file called us_baby_names.csv\\nthat I have stored in the same directory that this notebook\\nis stored.\\nSo I'm going to use the read CSV method from the Pandas\\nlibrary to do that.\\nSo I'll type in pd.read_csv ()\\nand now I'm going to type in the name of the CSV\\nfile as a string 'us_baby_names_csv'.\\n\\nAnd I'll go ahead and run the cell.\\nAnd now you can see the data.\\nAnd this object here is called a pandas DataFrame.\\nNow, I can create a variable called us_babies and assign\\nit to this data frame,\\nso whenever I want to access this data,\\nall I have to do is refer to that variable.\\nSo I'll go ahead and run the cell.\\nSo now, if I want to see the data again,\\nall I have to do is type in us_babies into this cell\\nand run. There,\\nthat's my data set.\\nAs you can see, the columns are labeled ID, name,\\nyear, gender, and count, and the rows are labeled 0, 1, 2\\nall the way till 1,825,433.\\n\\nNote that gender in this data set refers to the gender assigned\\nto these babies at birth.\\nNow, the labels of a data frame are called the indices of\\nthe data frame,\\nand they make data manipulation easier.\\nNotice that each row represents a distinct pair of baby\\nname and birth year.\\nLet's use pandas in this data set to answer the following question.\\n\\\"What were the five most popular baby names in 2014 in the US?\\\"\\nFirst, I'll show you how to access the year column from the\\nus_babies data frame.\\n\\nAnd I do this by writing us_babies [year].\\nNote that the name of a column is always expressed as a string.\\nI'll go ahead and run the cell. There,\\nand this object is called a Pandas series.\\nNow, I want to slice out the rows of the us_babies data frame\\nwith the year 2014.\\nIn other words, I only want the rows of the US\\nbabies data frame that correspond to names that were given to babies\\nborn in the year 2014.\\nSo I first want to create a series that contains true for each row I\\nwant to keep and false for each row I want to drop.\\n\\nI do this by comparing each year in US babies with 2014.\\nSo I'll write us_babies [year] == 2014.\\nAnd I'll run the cell. There,\\nas you can see, each year from the year column was\\ncompared to 2014 and I got a series of true and false.\\nJust a note, these true and false values are known as booleans\\nin programming.\\nNow I want to use loc.\\nLoc is a method that allows you to access a specific group of rows\\nand columns from a pandas data frame.\\n\\nLoc can take in a series of Booleans such as the one I\\njust created as an input.\\nSo I'll pass in the series of Booleans as a first input to loc,\\nand then the second input will be a colon.\\nI'll type in us_babies.loc[us_ babies[Year] == 2014, :]\\nNow, this part means that I want to access only the rows where\\nthe year is 2014.\\nAnd the colon here denotes that I want to access all the columns for\\nthe rows were years 2014.\\n\\nNow, I'll go ahead and run the cell.\\nThere we go.\\nNow, I'll create a variable named us _babies_2014 and assign\\nit to this data frame,\\nand I'll run the cell.\\nSo now, I can use us_babies_2014 to access the data frame\\nI just created.\\nThe next step is to sort the rows in descending order by count.\\nTo do this, I'll use the sort values method.\\nI'll pass in count as a first input and ascending equals\\nfalse as a second input.\\n\\nAnd that second input is what allows me to sort in\\ndescending order.\\nSo I'll type in us_babies_2014.sort values (Count, ascending = False)\\nand I'll run the cell.\\nAnd I got a new data frame.\\nThat's because the method sort values returns a new data frame.\\nNow, it'll be convenient to store this new data frame in a variable\\nso that I can refer to the variable whenever I want to\\naccess the data frame.\\n\\nSo I'll go ahead and create a variable.\\nI'll call it \\\"sorted_us_2014\\\"\\nand I'll assign it to this data frame, and I'll run the cell.\\nSo now, when I type in, \\\"sorted_us_2014\\\" and run the cell,\\nI have access to the sorted data frame.\\nFinally, I want to slice out the first five rows of sorted_us_2014\\nI loc is a method that works similarly to loc but takes in\\nnumerical indices instead of the names of columns as inputs.\\nSo I'll go ahead and type in sorted_us_2014.i loc [0:5]\\nand I'll run the cell. There.\\n\\nSo as you can see, the notation 0:5\\nallows me to access the first five rows of the sorted_us_2014\\ndata frame.\\nAnd according to the data set I'm working with,\\nEmma, Olivia, Noah, Sophie, and Liam are the five most\\npopular baby names in 2014 in the United States.\\nNow you know how to access specific columns,\\nselect subsets, and sort the rows of a data set.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4493805\",\"duration\":149,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Interpreting tabular data\",\"fileName\":\"4457428_en_US_04_03_MM24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Tabular data manipulation and drawing conclusions from data is a crucial component of data science. After watching this video, you'll be able to start gathering insights from your dataset. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4851332,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Imagine I have a data set that has information on baby names for\\neach state in the US.\\nNotice that each row represents a distinct set of baby name,\\nbirth year, and birth state.\\nNow, let's use pandas and the states underscore babies data set\\nto answer the following question.\\nWhat were the five most popular baby names in 2014 in California?\\nIn this lesson, I'll show you how to do this\\nusing the Pandas library.\\nAs a reminder, this is what the state's babies data\\nframe looks like.\\n\\nNow, the first thing I want to do is slice out the rows\\nfor the year 2014.\\nSo I'll use the loc method.\\nThe first input indicates that I want only the rows of the states\\nbaby's data frame that correspond to names of babies born in various\\nstates in the year 2014.\\nThe second input indicates that I want all columns for the\\naforementioned rows. And since the loc method returns\\na new data frame, I'll go ahead and store it in\\na variable which I'll name,\\n\\\"states_babies_2014.\\\"\\nAnd I'll run the cell now.\\n\\nNow, I'll type \\\"states_babies_2014\\\" and run the cell.\\nThere you go.\\nThe next thing I want to do is slice out the rows of the states\\nbabies 2014 data frame that correspond to the state,\\nCalifornia.\\nTo do this, I'll use the loc method again.\\nThe next step is to sort the rows of the CA baby's 2014 data frame\\nin descending order by count.\\n\\nTo do this, I'll use the sort values method.\\nFinally, I want to access the first five rows of the sorted\\nCA 2014 data frame.\\nTo do this, I'll use the i loc method.\\nSo according to this data set, Sophia, Noah, Isabella,\\nJacob and Emma are the five most popular baby names in\\n2014 in California.\\n\\nYou can use these techniques to filter and sort data\\nframes on your own.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4489775\",\"duration\":353,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Gathering insights\",\"fileName\":\"4457428_en_US_04_04_MM24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"The goal of data science is to identify and answer specific questions. After watching this lesson, you'll be able to evaluate what questions you want to answer and what types of questions are ideal for your scenario.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11635360,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Let's use pandas and the states_babies data set to\\nanswer the following question. \\\"What were the most popular female and\\nmale baby names in California in each year?\\\"\\nNow, I'll show you how to do this using the Pandas library.\\nAs a reminder, the loc method allows you to access a specific\\ngroup of rows and columns from a Pandas data frame,\\nand the method receives two inputs.\\nThe first input describes which rows to take from the data frame,\\nand the second input describes which columns to take from the\\ndata frame. And loc returns\\na new data frame containing the rows and columns you specified\\nSo I'll type in ca_babies = states_babies.loc [state_babies['state'] = = CA , :]\\nAnd I'll go ahead and run the cell.\\n\\nThis specifies that I only want the rows of the states babies data\\nset where state is California and the colon specifies that I want\\nall the columns for those rows.\\nSo now I'll type in ca_babies and hit \\\"Run.\\\"\\nThere we go.\\nNow, I'll show you how to group the CA babies data frame by both\\nyear and gender.\\nTo do this, I'll use the group by method.\\nNow, the group-by-method allows you to group the data in a data\\nframe based on the criteria you specify.\\n\\nIn this case, the criteria, I'll specify\\nare a list of the names of the columns by which I want\\nto group my data.\\nI want to group my data by year and gender.\\nSo I'll pass in a list containing year and gender as input\\nto the group by method.\\nSo I'll type in ca_babies.group by(['Year' , 'Gender'])\\nAnd note that in programming, the items of a list are enclosed\\nby square brackets and items are separated from each\\nother by commas.\\n\\nNow, when you call the group by method on a data frame,\\nit does not return a new data frame.\\nRather, it returns an object called a data frame\\ngroup by object.\\nAnd this object contains information about the groups\\nthat were created.\\nSo I'll use another method that operates on those groups to create\\na new data frame that suits my needs.\\nAnd this method is called the AG method.\\nNow the AG method can receive an aggregation function as input and\\nuse it to aggregate the groups of data.\\nAG applies the aggregation function to every column\\nin each group,\\nand each column of a Pandas data frame is a Pandas series.\\n\\nIn my case, I've grouped my data on year and gender,\\nand I need an aggregation function that takes in a Pandas series as\\ninput and finds the most popular baby name in that series.\\nI'll define this function myself, so I'll create a cell.\\nOver here,\\nI'll start with the keyword def, followed by the name of the\\nfunction and I'll go with popular.\\nNext is parentheses and in the parentheses I'll type in s,\\nwhich will represent the input that this function receives.\\n\\nS will be a Pandas series containing baby names.\\nNext is a colon and I'll hit \\\"Enter\\\" to get to the next line.\\nNow, it would be easier if this function receives baby names in\\norder of highest count to lowest count.\\nSo what I'll do is I'll sort CA babies before I call the group\\nby method in the AG method.\\nI'll use the sort values method to do that.\\nSo I'll type in sort_values ()\\nI'll type in \\\"count\\\" since I want to sort the data based on count.\\n\\n, ascending = false because I want to sort\\nin descending order.\\nAnd then I'll have a period there.\\nNow, I'll go back to the aggregation function\\nI was defining.\\nwhich is a Pandas series\\ncontaining baby names in order of highest count to lowest count.\\n\\nAnd it returns the most popular name in S.\\nWhat I just wrote is called a multiline comment.\\nIt's not read by the computer.\\nIt's just for me and you.\\nNow, I'll use the i loc method.\\nI'll write return s.i loc[0].\\nThis means that I am returning the item in S that has index zero.\\nIn other words, I am returning the first item in S.\\nThis item is the most popular name in S because S is ordered by count\\nsuch that the first item in S corresponds to the highest count\\nand the last item in S corresponds to the lowest count.\\n\\nI'll go ahead and run this cell.\\nNow, I'll call the AG method,\\nand I'll pass in the aggregation function that I just defined,\\nwhich I named popular.\\nAlso, I'll create a variable named CA grouped and assign it to the\\ndata frame that I'll get from doing this.\\nI'll go ahead and run the cell now.\\nNow, I can access the group data using CA grouped,\\nso I'll type in \\\"CA grouped,\\\"\\nand I'll hit run. There,\\nthis data frame contains the most popular female and male baby names\\nfor each year in California.\\n\\nNow, I want to point something out regarding the order of my code.\\nI defined the function popular in this cell,\\nand then I grouped the CA babies data set in the next\\ncell using popular.\\nThis is because I need to establish what popular means and\\nwhat popular does before I use popular.\\nNow you know how to group a data set and aggregate the group data.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4490795\",\"duration\":165,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Answering specific questions\",\"fileName\":\"4457428_en_US_04_05_LA24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5308486,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Now, let's use the Pandas Library and the us_babies\\ndataset to answer the following question, \\\"How frequently does your\\nfirst name occur across the years in the US among baby names?\\\"\\nFor this question, you'd want to go back to working\\nwith the us_babies dataset,\\nsince this question does not address specific states.\\nAs a reminder, this is what the US babies data frame looks like.\\nFirst, I want to slice out the rows of the US babies data frame\\nthat contain my name.\\nTo do this, I'll use the loc method.\\n\\nAs a reminder, loc allows you to access a specific set of rows and\\ncolumns from your data set.\\nSo go ahead and type in us_babies.loc[us_babies['Name'] = = Lavinya , :]\\nNow, this part indicates that I only want the rows of US babies\\nwhere name is Lavinya and the colon indicates that I want all\\nthe columns for the aforementioned rows.\\n\\nNow, I'll go ahead and store the data frame that loc returns here\\nin a variable named us_lav.\\nAnd I'll run the cell.\\nNow, when I type in us_lav and run,\\nI have access to that data frame.\\nNow, I want to create a horizontal bar plot that displays the counts\\nof my first name over the years.\\nTo do this, I'll use the plot.barh method. plot.barh allows\\nyou to create a horizontal bar plot based on the data in\\nyour pandas dataframe.\\nA horizontal bar plot presents quantitative data with rectangular\\nbars with lengths proportional to the values that they represent.\\n\\nSo I'll go ahead and type in us_lav.plot.barh(x = 'Year' , y = 'Count')\\nNow, this part indicates that year will be displayed on the x-axis,\\nand this indicates that count will be displayed on the y-axis.\\nNow, we'll go ahead and run the cell.\\nThere we go.\\nThis plot shows the counts of the baby name Lavinya being compared\\nacross 1994-2014 in the US.\\n\\nBy observing this plot, I can tell how frequently my name\\noccurred across the years among baby names in the United States.\\nYou can read more about the plot.barh method by following the\\nlink in the resource file.\\nAnd that's it.\\nNow you know how to set the index of a data set according to your\\nneeds and construct a horizontal bar plot of your data.\\nNow that you know some of the key methods in the Pandas Library for\\ntabular data manipulation, go ahead and try it for yourself.\\n\"}],\"name\":\"4. Structuring Your Tabular Data\",\"size\":38685402,\"urn\":\"urn:li:learningContentChapter:4485936\"},{\"duration\":561,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4489774\",\"duration\":51,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Defining exploratory data analysis\",\"fileName\":\"4457428_en_US_05_01_LA24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Statistical data types, including numerical and categorical data, are at the core of most data science operations. After watching this video, you'll be able to recognize the differences between these data types and why each of them is significant. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1544505,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Exploratory data analysis, also known as EDA,\\nis a major stage of the data science lifecycle.\\nThe goal of EDA is to deeply understand the data you\\nhave in front of you.\\nIn EDA, you visualize and transform the data so that you\\ncan pick up on patterns, issues, and anything interesting\\nin the data.\\nIn this process, you'll find out what questions you\\nwant to answer using the data.\\nAnd during EDA, it's important to not make\\nassumptions about the data and to be open to the possibilities of\\nwhat you'll find. When conducting EDA.\\n\\nYou would examine the statistical data types present\\nin your data set,\\nas well as the key properties of your data.\\nThis process helps you understand the data and determine how\\nrelevant the data is to the question you're trying to answer\\nor the problem you're trying to solve.\\nAnd now you know what exploratory data analysis entails.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4492757\",\"duration\":202,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Recognizing statistical data types\",\"fileName\":\"4457428_en_US_05_02_LA24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"EDA involves determining the key properties of the data you have. After watching this video, you'll be able to hone in on what the key properties of data are and how you can identify these properties within your dataset.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5180537,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"At the beginning of exploratory data analysis,\\nit's important to understand what kind of data lies in your data set.\\nIn the context of tabular data,\\nthere are three major statistical data types to keep in mind.\\nThe first is nominal data, which means data that has\\nno inherent order.\\nExamples of this data include political party affiliation\\nsuch as Democrat,\\nRepublican, independent, et cetera, or computer operating system\\nsuch as Windows, macOS, Linux, et cetera,\\nas well as things like gender and languages spoken.\\n\\nNext, is ordinal data, and this means data that falls\\ninto ordered categories.\\nExamples of this include clothing size such as small,\\nmedium, large, extra large or highest level of education,\\nsuch as high school,\\nundergrad, master's, Ph.D, or even a Yelp rating on a\\nscale from 0-5 stars.\\nThe third main data type is numerical data,\\nwhich means data that consists of amounts or quantities.\\nExamples of this include things like height,\\nweight, price, distance, blood pressure.\\n\\nNow, identifying the statistical data types that are present in\\nyour data set helps you make informed choices when you conduct\\nfurther analysis on the data.\\nThe data types in your data set correspond to specific operations\\nyou can perform on the data in a meaningful way.\\nIn other words, the type of data you have\\ndetermines what you can do with that data.\\nFor example, say you have a data set of job titles,\\nsalaries, and highest education levels of employees in a company.\\nEach row corresponds to an individual and each individual is\\nassigned a unique ID number and say the highest level of education\\nis represented by a number using a scale from 1-5,\\nwhere one means high school,\\ntwo means undergrad, three means masters and\\nfour means Ph.D.\\n\\nThe ID numbers and job titles are both nominal data.\\nThe salaries are numerical data, and the highest levels of\\neducation are ordinal data.\\nComputing the mean of the values in the salary column\\nis meaningful.\\nYou'll find out the average salary of an employee at the company.\\nHowever, computing the mean of the values in the highest level of\\neducation column is not meaningful.\\nFor example, you could get a mean of 2.7, but 2.7 doesn't\\ntell you much.\\nHowever, within the highest education level column,\\ncomparing one value to another, value can provide useful\\ninformation.\\n\\nFor example, say one person has a one, meaning a high school\\nbackground,\\nand another person has a two, meaning an undergrad background.\\nWell, you could say that the second person has a higher\\neducation level than the first person.\\nNow, within the ID number column, computing\\nthe mean of the values is not meaningful.\\nThe mean of the ID numbers doesn't tell you much.\\nNow, let's say you compare the ID number located in one row to the\\nID number located in another row.\\nSay these ID numbers are 103 and 105,\\n105 being larger than 103\\ndoesn't tell you much about the employees represented\\nby these rows.\\n\\nHowever, the fact that 103 and 105 are distinct numbers tells you\\nthat these rows represent two distinct employees in the company.\\nSo when you take time to understand the statistical data\\ntypes that are present in your data set,\\nyou'll have a better idea of what type of analysis you can\\ndo with your data.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4485933\",\"duration\":308,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Distinguishing properties of data\",\"fileName\":\"4457428_en_US_05_03_LA24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11900190,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Exploratory data analysis, also known as EDA,\\ninvolves determining the key properties of the data you\\nhave in front of you.\\nNow, I'll go over the main properties you investigate\\nwhen conducting EDA.\\nAsk yourself these questions about each property.\\nThe first main property is known as granularity,\\nwhich is what each record in the data represents.\\nConsider asking how fine or coarse is the data.\\nThe next property is scope.\\nThe scope of the data set refers to the coverage of the data set in\\nrelation to what you're interested in analyzing.\\n\\nWhat does the data describe?\\nDoes the data cover the topic you're interested in?\\nAfter that, there's temporality.\\nThis refers to how the data is situated in time and specifically\\nto the date and time fields in the data set.\\nWhen was the data collected?\\nFinally, there's faithfulness.\\nHow accurately does a data describe the real world?\\nShould you trust this data?\\nFor example, say you have data regarding shows and movies that\\nwere on Netflix from 2015-2021 globally.\\n\\nNow, let's identify the key properties of this data.\\nI'll start with granularity.\\nFirst, I'll import the necessary packages,\\nload the data into a data frame, get the shape of the data frame,\\nand display the first few rows.\\nLet's call this data set A.\\nIn this data set, each record represents a single\\nshow or movie that was available to stream on Netflix.\\nNow, let's say I group the Netflix data by director and aggregate the\\ngroup data using the count method.\\n\\nThis counts up the show or movie titles for each director so that\\nin the resulting data frame, each row represents a\\ndistinct director.\\nLet's call this data set B. In this data set,\\neach record represents a single director.\\nNote that within the data for a director,\\nthere can be multiple titles.\\nData Set B has a coarser granularity than data set A.\\nThe granularity of your data is important because it determines\\nwhat kind of analysis you can perform on your data.\\n\\nUsually, finer granularity is safer than coarser granularity.\\nIn most cases, you can use grouping and pivoting to transform\\nthe granularity of your data from fine to coarse.\\nHowever, there aren't as many tools to transform data\\nfrom coarse to fine.\\nNext, I'll discuss the scope of the Netflix data.\\nThis data set contains shows and movies that were added to Netflix\\nbetween 2015 and 2021.\\nIf you're interested in shows, in movies that were added to a\\ndifferent streaming platform, however, this data set would not\\nhave the appropriate scope for that goal.\\n\\nIn general, a larger scope is more useful than a smaller scope,\\nsince you can transform a larger scope into a smaller scope through\\nfiltering some things out.\\nBut a lot of times, you can't go from a smaller scope\\nto a larger scope.\\nFor example, if you had a data set containing shows and movies from\\nonly the United States, it would not be possible to infer\\ndetails about shows and movies outside of the US.\\nHowever, with this data set of shows and movies from various\\ncountries around the world, you could filter it down and get a\\nsubset to examine shows from one specific country if you wanted.\\n\\nAnother property I can look at is temporality. In this data set, the\\ndate_added column represents when a title\\nwas added to Netflix.\\nWhile the release_year column represents when the title\\noriginally came out. The date_added column\\ncontains dates and day-month-year format while the release year\\ncolumn contains year only.\\nThere are various formats in use around the world for\\nexpressing dates, and it's important to keep in mind\\nthese differences when analyzing data.\\n\\nAlso to consider how the data is situated in time,\\nyou could examine the release_year column.\\nHere, I've sorted the release years in ascending order and it seems\\nthat they span from 1925-2021.\\nSo there are two different dimensions to how this data\\nis situated in time.\\nOne is through date_added and the other is\\nthrough release_year.\\nThe release years go back farther in time than the dates of when the\\nitems were added to Netflix.\\n\\nAnother property to consider is faithfulness.\\nA data set is considered faithful if you think it accurately\\ncaptures reality.\\nUsually, an unfaithful data set may contain unrealistic or incorrect\\nvalues, dates in the future that represent events in the past,\\nnon existent locations,\\nnegative values that represent amounts or quantities,\\nor extreme outliers.\\nIt might contain inconsistencies such as an age column and a\\nbirthday column that contradict each other.\\nIt could have hand-entered data with misspellings or columns not\\nbeing in the right spot due to being shifted over or even data\\nfalsification with email addresses that seem fake, repeated\\ninformation,\\nespecially repeated use of uncommon values.\\n\\nAfter you understand the properties of your data,\\nyou will make more informed choices when conducting further\\nanalysis on that data.\\n\"}],\"name\":\"5. Using Exploratory Data Analysis\",\"size\":18625232,\"urn\":\"urn:li:learningContentChapter:4489777\"},{\"duration\":329,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4491768\",\"duration\":82,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Explaining data cleaning\",\"fileName\":\"4457428_en_US_06_01_LA24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Before you dive in and start cleaning your data, you'll want to gain some baseline information to help you navigate this process. After this lesson, you'll be able to ask questions to help better understand your data and how it was generated so you can most effectively clean it. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2305532,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Data cleaning is a process of combing through raw data and\\ntransforming it so that it's conducive to analysis\\nthat follows.\\nData cleaning can be time-consuming,\\nbut it's a critical stage of the data science lifecycle.\\nData cleaning often addresses missing values,\\nthe formatting of values, the structure of the data overall,\\nextracting information from complex values,\\nunit conversion, interpretation of magnitudes,\\nand so on.\\nFor example, say you have a data set regarding the final exam grade\\nof a particular class from the spring 2019 semester.\\n\\nAnd let's say you're interested in finding out the median grade.\\nLet's say some of the students exams were lost after they were\\ncollected and thus were not graded,\\nand these missing grades were replaced by zeros in the data set.\\nNow, you would not be able to accurately determine the median\\ngrade without addressing the zeros that replace missing grades.\\nThis is an example of a situation where you'd need data cleaning to\\naddress the incorrect values.\\nOther examples of data that would need data cleaning are missing\\ndata, misspellings,\\nrows that are duplicated, dates and addresses expressed in\\ninconsistent formats, and potentially outliers\\nor extreme values.\\n\\nData cleaning is an important process that data scientists\\nperform in order to make the data suitable for further analysis,\\nas well as drawing conclusions from the data.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4490794\",\"duration\":247,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Questions to guide data cleaning\",\"fileName\":\"4457428_en_US_06_02_LA24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8849678,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"When you begin the process of data cleaning,\\nthere are a few important questions to ask about the data.\\nFirst, are there missing values in the data set?\\nSecond, are there duplicate entries in the data set?\\nThird, are data points represented by the appropriate data types?\\nFor example, say you have data regarding shows and movies that\\nwere on Netflix from 2015-2021 globally.\\nIn this demo,\\nI'll start with the data loaded into a Pandas data frame.\\nFirst, let's get the shape of the data frame.\\n\\nThis tells me that there are 7,787 rows and 11 columns.\\nNow, let's check if there are missing values in this data.\\nYou can use the isna method followed by the sum method to get the\\nnumber of missing values in each column of the data frame.\\nThe output shows that there are missing values in the director,\\ncast, country, date added, and release your columns.\\nYou can also get the total number of rows that contain\\nmissing values.\\n\\nSo there are 3,631 rows with missing values.\\nAnd this indicates that the missing values make up about\\n46% of the data.\\nSince the majority of the rows do not have missing values,\\nyou can proceed with dropping the rows that have missing values.\\nAfter dropping those rows, you can confirm the shape\\nof the data now.\\nThe number of columns is the same as before,\\nbut now there are 4,808 rows.\\n\\nThis is still a substantial amount of data to work with.\\nNext, you can investigate for duplicates.\\nTo do this, you can use the duplicated method from pandas.\\nThis method returns a boolean, either true or false for each row\\nindicating whether that row is a duplicate entry or not.\\nAdding the sum method to the end allows you to get the total number\\nof rows that are duplicates.\\nSo there are zero duplicates in this data set.\\n\\nWhen working with date and time fields in a data set,\\nit's important to check the data type of those fields and ensure\\nthat they are in a meaningful and useful format.\\nThe D type attribute can be used to get the data type.\\nAs the output shows here, the date added column contains\\nvalues of the object data type denoted by the O.\\nThe object data type in pandas is a generic data type for a series\\nand typically means the values in the series are strings.\\nTo confirm, you can use the type function to get the data type of\\nthe first entry in the date added column.\\n\\nThe output is str, which confirms that the data type\\nof the first entry in the date added column is string.\\nRepresenting the dates that shows or movies were added as strings\\nis not that helpful.\\nFor example, you may want to compare when one title was added\\nto when another title was added. Using the pd.2\\ndate time method can help you convert this data into date time\\nformat so that you can make such comparisons meaningfully.\\nFinally, identify the data type of the release year column.\\n\\nThis shows that the release years are represented as integers,\\nwhich is the appropriate data type.\\nSince they're integers, you can easily compare the release\\nyear of one title to the release year of another title.\\nNow, cleaning every aspect of a data set may take too long,\\nbut on the other hand, not cleaning a data set at all\\nwould lead to drawing inaccurate conclusions from the data.\\nSo it's important to try to find a balance when cleaning data.\\nAlso, keep in mind that the decisions you make during data\\ncleaning impact all the analysis you perform afterwards.\\n\\nSo if there's a column you choose not to clean in your data set,\\nhave caution when using that column in analysis.\\nAlso, it's helpful to explicitly keep track of what changes you\\nmade to your data set during data cleaning,\\nso you can refer back to your notes when doing analysis.\\nNow you know a few important approaches to data cleaning.\\n\"}],\"name\":\"6. Cleaning Your Data\",\"size\":11155210,\"urn\":\"urn:li:learningContentChapter:4485937\"},{\"duration\":867,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4490793\",\"duration\":62,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Demystifying data visualization\",\"fileName\":\"4457428_en_US_07_01_LA24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Different types of visualization correspond to different types of data. After watching this video, you'll be able to recognize how data visualization is best completed when you're working with qualitative datasets. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2224894,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Data visualization is an essential tool for data science.\\nVisualization brings data to life.\\nOften, a good data visualization can convey trends and anomalies in\\nthe data more efficiently than a written description.\\nAlso, data visualization can be a great way to communicate your\\npredictions and conclusions to other people,\\nand you'll need to use some computational tools to create\\ndata visualizations.\\nTwo useful visualization tools that I'll be introducing in this\\ncourse are Python's Matplotlib and Seaborn libraries.\\n\\nMatplotlib is a library in Python that allows you to create two\\ndimensional plots of your data.\\nYou can find documentation for Matplotlib in the resource file.\\nAnd Seaborn is a library in Python that's based on Matplotlib and\\nallows you to create multidimensional plots and more\\nadvanced visualizations of your data.\\nYou can check out the documentation for Seaborn\\nin the resource file.\\nNow you know what data visualization is and a couple of\\ntools that help you visualize your data in Python.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4491767\",\"duration\":317,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Visualizing your qualitative data\",\"fileName\":\"4457428_en_US_07_02_LA24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Different types of visualization correspond to different types of data. After watching this video, you'll be able to recognize how data visualization is best completed when you're working with quantitative datasets. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9698737,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Usually different types of charts are used to visualize different\\ntypes of data.\\nand its subtypes are nominal data and ordinal data.\\nA reminder that nominal data is data that has no inherent order,\\nwhile ordinal data is data that falls into ordered categories.\\nA bar chart is one of the most commonly used charts to visualize\\nqualitative data.\\nIn this lesson, I will show you how to create\\nbar charts in Python.\\nFor example, say that you have a data set on Airbnb listings\\nin New York City, New York for 2019,\\nlast updated on August 12th, 2019.\\n\\nFirst, I'll import the Python libraries that I'll need,\\nso I'll go ahead and start with import pandas as pd.\\nImport matplotlib.pyplot as plt.\\nImport seaborne as sn.\\nAnd I'll run the cell.\\nNote that going forward, when I code in this notebook,\\nI need to use pd to refer to pandas, plt to refer to\\nmatplotlib.pyplot and sn to refer to Seaborn.\\n\\nNext, using the read CSV method from the Pandas Library.\\nI'll read in the CSV file Airbnb NYC 2019.csv which is located\\nin the same directory as this notebook and I'll store the pandas\\ndata frame that gets returned in a variable named listings.\\nSo I'll go ahead and type out listings = pd.read_csv('Airbnb_NYC_2019.csv')\\nand I'll run the cell.\\n\\nNow I'll type out listings and I'll hit \\\"Run.\\\"\\nThere we go.\\nThis is my data set.\\nNow, let's say I want to create a bar chart that displays the count\\nof Airbnb listings in each neighborhood group of New York\\nCity from the listings data frame.\\nTo do this, I'll use the count plot method from the\\nSeaborn library\\nfollowed by the show method from Matplotlib.pyplot.\\nSo I'll type in sne.count plot (x = 'neighborhood_group', data = listings)\\nfollowed by plt.show().\\n\\nNow, the count plot method helps me create the bar chart.\\nSetting the data parameter to listings indicates that I want to\\ndisplay data that comes from the listings\\ndata frame. And setting X to neighborhood group indicates that\\nI want to display the data that comes from this particular column.\\nNow, I'll go ahead and run the cell.\\nThere we go.\\nThat's a bar chart.\\nAnd from this bar chart, it appears that Manhattan is a\\nneighborhood group with the highest count of Airbnb listings\\nin New York City in 2019.\\nNow, let's say I want to create a bar chart that displays the\\naverage price of Airbnb listings in each neighborhood group of New\\nYork City from the listings data frame.\\n\\nTo do this, I'll use the bar plot method from the Seaborn library,\\nfollowed by the show method from Matplotlib.pyplot.\\nI'll start with sn.barplot (x = 'neighborhood_group', y = price, data = listings) followed by plt.show()\\nThe bar plot method allows me to create a bar chart and the show\\nmethod allows me to show the bar chart that's created.\\n\\nI set the parameter data to listings to indicate that I want\\nto display data that comes from the listings data frame.\\nI set the x parameter to neighborhood group because\\nneighborhood group is going to be displayed on the x axis and I set\\nthe parameter y to price because price is going to be displayed on\\nthe y axis, and I'll go ahead and run the cell.\\nThere we go.\\nNow, the black lines that you see through the middle of each bar\\nmark confidence intervals that were generated by the\\nbar plot method.\\nNow, confidence intervals are an important concept,\\nbut it's not in the scope of this video,\\nso I will not go into detail about it at this particular moment.\\n\\nSo let's say I want to recreate the bar chart above without\\nthose black lines.\\nTo do this, I'll use the bar plot method again.\\nAnd this time, I'll also include a parameter named CI,\\nwhich I'll set to false.\\nSo I'll go ahead and type in sn.barplot (x = 'neighborhood_group', y = price, data = listings, ci = false) followed by plt.show()\\nand I'll run the cell.\\n\\nThere we go.\\nThe black lines are gone.\\nAnd from this bar chart, it appears that Manhattan is a\\nneighborhood group with the highest average price for Airbnb\\nlistings in 2019 in New York City.\\nNow you know how to create different types of bar charts to\\nvisualize qualitative data.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4487770\",\"duration\":488,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Visualizing your quantitative data\",\"fileName\":\"4457428_en_US_07_03_LA24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":14657549,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Two types of charts that are commonly used to visualize\\nquantitative data are histograms and scatter plots.\\nNote that quantitative data is another term for numerical data,\\nwhich means data that consists of amounts or quantities.\\nIn this lesson, I'll show you how to create\\nthese charts in Python.\\nFor example, say that you have a data set on Airbnb listings\\nin New York City for 2019, last updated on August\\n12th of that year.\\nFirst, I'll import the Python libraries that I'll need,\\nso I'll start with import pandas as pd,\\nimport matplotlib.pyplot\\nas plt,\\nimport numpy as np and I'll run the cell.\\n\\nNote that going forward, when I code in this notebook,\\nI need to use pd to refer to pandas, plt to refer to\\nmatplotlib.pyplot and np to refer to Numpy.\\nNow, Matplotlib.pyplot is a collection of functions that allow\\nyou to create figures and plots and make changes to\\nthem in Python.\\nNumpy is a useful library for scientific computing in Python and\\ncontains functions that allow you to create data efficiently.\\nNext, using the read CSV method from the Pandas library,\\nI'll read in the CSV file Airbnb NYC 2019.csv which is located\\nin the same directory as this notebook and I'll store the pandas\\ndata frame that guests return in a variable named listings.\\n\\nSo I'll go ahead and type in listings = pd.read_csv('Airbnb_NYC_2019.csv').\\nAnd I'll go ahead and run this cell.\\nNow, I'll type in listings and run this cell.\\nThere we go.\\nThis is my data set.\\nNow, I'll use the hist method for Matplotlib.pyplot to create a\\nhistogram that displays a distribution of the quantitative\\ndata in the price column of the listings data frame.\\n\\nSo I'll type in plt.hist(listings ['Price'])\\nand on this line, I'll use the x label method to label the x-axis\\nwith price in US dollars.\\nSo I'll type in plt.x label ('Price(in US dollars)').\\nAnd on this line, I'll use the show method to show the histogram\\nthat gets created.\\n\\nSo I'll type in plt.show() In the histogram that\\nI'll get from this cell, the prices will be grouped into\\ncontiguous intervals called bins.\\nNow, I'll go ahead and run this cell. There,\\nthat's a histogram.\\nHowever, in this histogram, it's difficult to really see where\\nthe data lies with respect to the bins.\\nSo I'll recreate the histogram using the hist method and this\\ntime, I'll include the optional bins parameter,\\nwhich I'll set to a specific range of numbers and I'll create the\\nrange of numbers using the arange method from the Numpy library.\\n\\nSo I'll type in plt.hist(listings ['price'], bins = np.arange (0, 1100, 40))\\nThe first number I passed into the arange method represents the\\nleft end of the first bin.\\nThe second number represents the right end of the last bin.\\nAnd the third number represents the step size or the\\nwidth of each bin.\\n\\nOn the next line, I'll type plt.x label ('price in US dollars').\\nAnd on the next line, I'll type in plt.show().\\nAnd I'll run the cell.\\nThere we go.\\nNow, it's easier to see where the data lies with respect\\nto the bins.\\nAnd it appears that in New York City in 2019,\\na lot of the prices of Airbnb listings lie between around\\n$50 to around $500.\\n\\nNow, let's talk about scatter plots.\\nScatter plots are usually used to compare two sets of\\nquantitative data.\\nLet's say I want to create a scatter plot to compare the prices\\nof Airbnb listings and the number of reviews for those listings.\\nTo do this, I'll use the scatter method from matplotlib.pyplot.\\nSo I'll type in plt.scatter(x = listings ['price'], y = listings ['number of reviews'])\\nOn the next line,\\nplt.xlabel ('price').\\n\\nplt.ylabel('number of reviews')\\nfollowed by plt.show.\\nWhen I called the scatter method, I set the x parameter to listing\\nsquare brackets price.\\nNow, this indicates that I want price to be displayed\\non the x-axis,\\nand this indicates that I want number of reviews to be displayed\\non the y-axis.\\nI use the x-label method to label the x-axis and I use the y-label\\nmethod to label the y-axis.\\n\\nNow I'll go ahead and run the cell.\\nThere,\\nthat's a scatter plot.\\nNow, let's say I want to restrict the x-axis so that the scatterplot\\nonly goes up to a price of 1,100.\\nTo do this, I'll recreate the scatter plot using the\\nscatter method.\\nAnd this time I'll also use the x lib method for matplotlib.pyplot.\\nSo I'll type in plt.scatter(x = listings ['price'], y = listings ['number of reviews'])\\nplt.xlabel('price')\\nplt.ylabel('number of reviews')\\nplt.xlim(0, 1100)\\nfollowed by plt.show()\\nand I'll go ahead and run this cell.\\n\\nThere we go.\\nNow, let's say I want to decrease the size of the points\\non the scatter plot.\\nTo do this, I can recreate the scatter plot using the\\nscatter method.\\nAnd this time I'll also include the size parameter\\nwhich is named s,\\nand I'll set it to 5.\\nSo I'll type in plt.scatter(x = listings ['price'], y = listings ['number of reviews'], s = 5)\\nAnd on the next line plt.xlabel('price') plt.ylabel('number of reviews')\\nplt.xlim(0, 1100) followed by\\nplt.show().\\n\\nAnd I'll run the cell. There,\\nthe points on this scatter plot are a bit smaller and this plot\\nis a little easier to look at.\\nAt first glance of this plot, I notice a trend.\\nIt appears that listings with lower prices have more reviews.\\nThis leads me to ask the following question, \\\"Is there an association\\nbetween the price and the number of reviews for listings?\\\"\\nThis is just one example of a type of question that can come up when\\nyou're visualizing your data, and you'll want to conduct further\\nanalysis to investigate this question.\\n\\nSo visualizing your data helps you observe trends,\\nwhich leads you to ask questions which then informs the kind of\\nfurther analysis you perform.\\nNow you know how to use histograms and scatter plots to visualize\\nyour quantitative data.\\n\"}],\"name\":\"7. Using Data Visualization\",\"size\":26581180,\"urn\":\"urn:li:learningContentChapter:4489778\"},{\"duration\":1480,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4491766\",\"duration\":43,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Defining inference\",\"fileName\":\"4457428_en_US_08_01_LA24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Hypothesis testing is a helpful method you can use to identify if the results you're seeing in the data are meaningful. After watching this video, you'll be able to define a hypothesis test, recognize how they're used, and the core aspects of setting up a hypothesis test.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1582438,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Data scientists use inference to quantify how certain they are\\nthe trends they see in their data will be found in new data,\\nand they use inference to draw conclusions about a population\\nusing their data set.\\nFor example, inference is a useful process in election forecasting,\\npredicting the test scores of students in future exams based on\\ntheir test scores in past exams and more.\\nA couple of methods that are essential to inference are\\nhypothesis tests and confidence intervals,\\nand these methods involve resampling which enables you to\\ngeneralize the conclusions you draw so they are applicable\\nnot just to your data, but also to data that you\\nhave not seen before.\\n\\nNow you know what inference is and why it's important\\nin data science.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4493804\",\"duration\":313,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Designing a hypothesis test\",\"fileName\":\"4457428_en_US_08_02_LA24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Hypothesis testing allows data scientists to make informed conclusions based on the data that they observe. After watching this video, you'll be able to create a permutation test for a hypothesis.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10076535,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"To help answer questions about the world,\\ndata scientists use hypothesis test to make informed conclusions\\nbased on the data that they observe.\\nNow, data collection is not always precise,\\nso when you notice some trends in your data,\\nyou might be wondering whether those trends occur due to random\\nfluctuations in data collection or due to some real phenomena.\\nAnd this is where hypothesis testing comes in.\\nIn this lesson, I'll show you how to design\\na hypothesis test.\\nLet's say I have a fictional data set that represents a sample\\nof avocado trees.\\n\\nI have a new fertilizer, and I want to test if the new\\nfertilizer has an effect on how long the avocado takes to grow.\\nI have data on a sample of avocado trees,\\nand for each tree, the data set contains the amount\\nof time it took for the avocado to grow and whether the new\\nfertilizer was used.\\nNow, I've opened up the exercise file for this lesson.\\nFeel free to open the exercise file on your end as well\\nto follow along.\\nIn the first code cell, I imported all the python\\nlibraries that I'll need.\\nNext, I loaded the avocado data set into a Pandas data frame.\\n\\nSave that in a variable called avocado info and display\\nthe first few rows.\\nThe names of the columns in avocado info are growth\\nduration and fertilizer.\\nNow, I want to determine whether there is an association between\\nthe duration of growth and whether the fertilizer was used.\\nSo I'll design a hypothesis test.\\nI will create two hypotheses.\\nThe first hypothesis is called a null hypothesis.\\nThe null hypothesis usually does not state that there are\\nassociations between variables and usually attributes trends observed\\nin the sample to random chance.\\n\\nSo my null hypothesis will be the following. In the population, the\\ndistribution of growth duration of avocado trees that receive\\nfertilizer is the same as that of avocado trees that did not\\nreceive fertilizer.\\nIf the two distributions are different in the sample,\\nit's due to random chance.\\nAnother way I can state this null hypothesis is the following\\nIn the population, on average, avocado trees that\\nreceive fertilizer took the same period of time to grow as those\\nthat did not receive fertilizer.\\nThe second hypothesis is called an alternative hypothesis.\\n\\nThe alternative hypothesis usually attributes trends observed in the\\ndata to associations between variables.\\nSo my alternative hypothesis will be the following.\\nIn the population, the distribution of growth\\nduration of avocado trees that receive fertilizer is different\\nfrom that of avocado trees that did not receive fertilizer due to\\nan association between growth duration and whether fertilizer\\nwas used.\\nAnd on average, avocado trees that received\\nfertilizer took a shorter period of time to grow than those that\\ndid not receive fertilizer.\\n\\nNow, the goal of a hypothesis test is to decide between the null\\nhypothesis and the alternative hypothesis.\\nIt would help to visualize the data.\\nYou can plot two histograms and overlay them.\\nTo do this, I use the hist plot method from the Seaborn library.\\nI called sns.histplot, passed in avocado info as the data, growth\\nduration as the variable that should be plotted on the x-axis,\\nand fertilizer as the variable that determines the hue.\\nThe hue determines the color of the bars for each histogram.\\n\\nThen I created a legend using the legend method from plt and passed\\nin the appropriate labels.\\nFinally, I used plt.show to display the overlaid histogram\\non the screen.\\nThe orange histogram corresponds to avocados that were fertilized.\\nAnd the blue histogram corresponds to avocados that were\\nnot fertilized.\\nFrom this plot, it appears that on average,\\nthe growth duration of avocados that receive fertilizer may be\\nshorter than the growth duration of those that did not.\\n\\nThis leads me to ask, \\\"Is this trend due to random chance?\\\"\\nIn other words, when the sample was collected\\nfrom the population, did it just so happen that the\\nsample contains data with such a trend?\\nOr is there an underlying association between growth\\nduration and whether fertilizer was used?\\nThe hypothesis test I am designing can be used to answer\\nthis question.\\nThe next step is to come up with a test statistic.\\nThe test statistic helps you decide between the two hypotheses.\\n\\nThe null hypothesis says that on average,\\nthe growing time is the same for avocado trees that receive\\nfertilizer and for those that did not.\\nAnd the alternative hypothesis says that on average,\\navocado trees that receive fertilizer took a shorter period\\nof time to grow than those that did not receive fertilizer.\\nSo my test statistic can be the following.\\nThe average growing time among avocado trees that receive\\nfertilizer minus the average growing time among avocado trees\\nthat did not receive fertilizer.\\n\\nSo how exactly does this test statistic indicate which\\nhypothesis is better supported by the data?\\nWell, smaller values of this test statistic would indicate that the\\nalternative hypothesis is better supported,\\nwhile larger values of this test statistic would indicate that the\\nnull hypothesis is better supported.\\nNow you know how to design a hypothesis test,\\nidentify a question you want to answer,\\ncreate null and alternative hypotheses, and come up with a\\ntest statistic.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4488792\",\"duration\":253,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Creating a permutation\",\"fileName\":\"4457428_en_US_08_03_LA24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"If you have two or more samples of data, you'll find that using a permutation test will be helpful for you to prove your hypothesis. After this lesson, you'll be able to identify the core elements of setting up and executing a permutation test. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8611148,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Hypothesis testing allows data scientists to make informed\\nconclusions based on the data that they observe.\\nI have a Pandas data frame that contains data on the time taken by\\na sample of avocado trees to grow avocado fruits and whether the\\ntrees receive fertilizer.\\nIf a tree received fertilizer, the corresponding value in the\\nfertilizer column would be true.\\nOtherwise, it would be false.\\nI want to determine whether there's an association\\nbetween growth\\nduration and fertilizer usage, and I've already designed\\na hypothesis test.\\n\\nMy null hypothesis states that on average,\\navocado trees that received fertilizer took the same period of\\ntime to grow than those that did not.\\nAnd my alternative hypothesis states that on average,\\navocado trees that receive fertilizer took a shorter period\\nof time to grow than those that did not.\\nSo I came up with the following test statistic The average growing\\ntime among avocado trees that receive fertilizer minus the\\naverage growing time among trees that did not receive fertilizer.\\nNow, before I conduct the test, I have to assume one of the\\nhypothesis is true.\\n\\nUsually, the null hypothesis is what you assume to be true before\\nyou conduct the test.\\nSo I'll assume that the trend I observed between growing duration\\nand fertilizer usage is due to random chance.\\nIt's time to conduct the hypothesis test.\\nI'll perform a specific type of hypothesis test that's known\\nas a permutation test.\\nIn a permutation test, you randomly permute the data.\\nIn other words, you randomly rearrange the data.\\nIn this lesson, I'll show you how to create\\na permutation.\\nI've opened up the corresponding exercise file.\\n\\nFeel free to open it on your side as well to follow along.\\nIn the first code cell, I imported all the Python libraries\\nthat I'll need.\\nAnd then I loaded the avocado data set into a Pandas data frame.\\nSave that in a variable called avocado_info\\nand display the first few rows.\\nThe next step is to compute the observed value of the\\ntest statistic.\\nThis can be directly computed from your data.\\nFirst, I created two subsets of the data.\\nThe first subset corresponds to avocado trees that receive\\nfertilizer, and I saved it in a variable\\nnamed fertilized.\\n\\nThe second subset corresponds to avocado trees that did not\\nreceive fertilizer, and I saved it in a variable named\\nnot_fertilized.\\nUsing these subsets of the data, I computed the observed value\\nof the test statistic, which I stored in a variable\\nnamed observed_test_stat.\\nUsing these subsets of the data, I computed the observed value of\\nthe test statistic which I stored in a variable named\\nobserved_test_stat.\\n\\nThe mean method allows me to calculate the mean or the average\\nof the numbers in a sequence.\\nThere, that's the observed value of the test statistic.\\nNext, I want to show you how to randomly permute the data in the\\ngrowth duration column of avocado_info.\\nThere is a helpful method in the Pandas library I can use\\nand it's called sample.\\nWhen used on the growth duration column,\\nthe sample method returns a random sample of items from that column.\\nI set the frac parameter to one to indicate that I want all the items\\nin the column to be in the sample that gets returned.\\n\\nThe frac parameter represents the fraction of items that will be in\\nthe sample that gets returned.\\nThere.\\nNow, the sequence of numbers on the right side are the randomly\\npermuted items from the growth duration column,\\nand the sequence of numbers on the left side are the indices.\\nThese indices are the indices from the growth duration column,\\nexcept they're not in order here due to permutation. To generate new\\nindices that are in order,\\nI use the reset index method from the Pandas library.\\n\\nThere.\\nNow, a new set of indices have been added on the left.\\nHowever, the old set of indices is still there next to the new set.\\nTo get rid of the old set of indices,\\nI can include the drop parameter and set it to true when calling\\nthe reset index method.\\nThere you go.\\nThis is a permutation of the data in the growth duration column.\\nNow you know how to create a permutation,\\nand this is an important building block to words conducting\\na permutation test.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4491765\",\"duration\":395,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Conducting a permutation test\",\"fileName\":\"4457428_en_US_08_04_LA24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"You can use a confidence interval to test your hypothesis or estimate. After this lesson, you'll be able to solve complex equations by bootstrapping your confidence interval.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":13823353,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"The process behind creating a permutation is an important\\nbuilding block for conducting a permutation test.\\nIn this lesson, I'll show you how to conduct\\na permutation test.\\nFeel free to open the corresponding exercise\\nfile to follow along.\\nNow, I'll need to permute the data more than once,\\nso it'd be helpful to have a function that I can call whenever\\nI want to permute the data.\\nSo I've defined a function that allows me to do this.\\nAnd I named the function \\\"Perm.\\\"\\nI started with the keyword def, followed by the name\\nof the function, which is perm parentheses,\\nand then data. And data will be a generic representation of the data\\nI can pass in as input to this function.\\n\\nNext was colon.\\nIn the body of the function,\\nI used the keyword return followed by a call to the sample method\\nsetting frac to one,\\nfollowed by a call to the reset index method setting drop to true.\\nI want to determine if there's an association between growth\\nduration and whether fertilizer was used.\\nIn order to do this using a permutation test,\\nI need to permute my data many times. During each permutation,\\nI need to simulate the test statistic under the null\\nhypothesis and I need to keep track of all the simulated values\\nof the test statistic.\\n\\nSo I started by creating a variable named\\nsim_test_stat and setting it to an empty\\narray using the array method from the Numpy library.\\nNote that an array is like a storage box that allows you to\\nstore an ordered sequence of items and sim_test_stat\\nwill be used to collect all the simulated values of the test\\nstatistic that will be generated during the permutation test.\\nNext, I created a variable named reps to represent the number of\\nrepetitions that will occur in the permutation test.\\nIn other words, rep stores the number of times\\nI will permute the data.\\n\\nI want to permute the data many times.\\nSo I gave reps the value of 10,000.\\nThen I created a for loop, a reminder that a for loop allows\\nyou to repeat a particular process a certain number of times.\\nThe process used to conduct a permutation can be repeated 10,000\\ntimes in order to conduct 10,000 permutations.\\nSo I called the range function and passed in reps.\\nThis makes sure that the for loop repeats that many times.\\nThe next step is to call the perm function that I defined earlier in\\norder to permute the data in the growth duration column of avocado\\ninfo and store the result in a variable named perm info.\\n\\nThen I created a new data frame with two columns.\\nThe first column will contain the data from perm info,\\nand the second column will contain the data from the fertilizer\\ncolumn of avocado info.\\nAnd I stored this new data frame in a variable named df. When\\ncalling pd.data frame, I had to specify the names of the\\ncolumns for this new data frame and the data that needs\\nto go in each column.\\nSo I passed in a dictionary that maps column name to column data.\\nPermuted duration is mapped to perm info and fertilizer is mapped\\nto the fertilizer column from avocado info.\\n\\nSo df has two columns.\\nThe first column is named Permuted Duration and the second column\\nis named Fertilizer.\\nThen I created two subsets of the data in df.\\nThe first subset corresponds to the permuted growth durations of\\navocado trees that receive fertilizer,\\nand the second subset corresponds to the permuted growth durations\\nof avocado trees that did not receive fertilizer.\\nI saved the first subset in a variable named fertilized,\\nand I saved the second subset in a variable named not_fertilized.\\nThe next step is to compute the value of the test statistic\\nfor this permutation, which can be stored in a\\nvariable named stat.\\n\\nTo do this, I again used the mean method from the Numpy library.\\nSo I called np.mean on fertilized and I called np.mean\\non not fertilized\\nand then I took the difference.\\nIn other words, I subtracted the two.\\nI need to keep track of all the simulated values of the\\ntest statistic.\\nSo I need to store stat in sim test stat. To do this,\\nI called the append method from the Numpy library and reassigned\\nsim_test_stat to update its value.\\nNow I'll run this cell.\\nIf you're following along, note that 10,000 permutations will\\nbe performed through the cell.\\n\\nSo it may take a while for the cell to finish execution.\\nSo be patient.\\nGreat.\\nIt just finished.\\nIn the next cell,\\nI want to check out what sim_test_stat contains.\\nLooks good.\\nMy goal is to draw a conclusion.\\nSo my next step is to use sim_test_stat to compute the P value.\\nIn general, the P value represents the approximate probability that\\nthe observed value of the test statistic or a more extreme value\\nshows up among the simulated values of the test statistic under\\nthe assumption that the null hypothesis is true.\\n\\nIn this test, the P value will be the proportion of simulated values\\nof the test statistic that were less than or equal to the observed\\nvalue of the test statistic.\\nTo compute this proportion, I'll divide the number of\\nsimulated values that satisfy this condition over the number\\nof simulated values.\\nTo count the number of simulated values that satisfy the condition,\\nI used the count non-zero method from the Numpy library and I\\npassed in sim_test.less than or equal to observed test stat.\\nA reminder that the observed test stat variable contains the\\nobserved test statistic.\\n\\nThe number of simulated values is the same as the number of times I\\npermuted which is stored in the variable reps.\\nSo to compute the P value, I divided the call to np.count\\nnon zero by reps and stored it in a variable named p_value.\\nI can check out what P value is in this next cell.\\nThere.\\nThe P value is 0.0.\\nIn other words, 0%.\\nFinally, I can draw a conclusion and I will use a P value threshold\\nof significance, also known as a P value\\ncutoff to do so.\\n\\nIf my P value is below my P value cutoff,\\nthen I'll reject the null hypothesis.\\nThe most commonly used P value cutoffs are 5% and 1%.\\nI'll use 5% as my P value cutoff.\\nSince my P value of 0% is lower than my P value cutoff of 5%,\\nI reject the null hypothesis.\\nI conclude that there is a statistically significant\\ndifference between the average growing time among avocado trees\\nthat received fertilizer and the average growing time among avocado\\ntrees that did not receive fertilizer.\\n\\nNow you know how to conduct a hypothesis test.\\nOnce you've designed your hypothesis test,\\nyou compute the observed value of the test statistic,\\nsimulate the test statistic under the null hypothesis\\nmany times, compute the P value,\\ncompute the P value to the P value cutoff of your choice,\\nand draw your conclusion on which hypothesis is true.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4490792\",\"duration\":476,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Bootstrapping a confidence interval\",\"fileName\":\"4457428_en_US_08_05_LA24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":19654317,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Oftentimes, data scientists need to estimate an unknown parameter\\nof a population, have only one random sample from\\nthe population and cannot take more samples due to time and cost.\\nIn such situations, data scientists use a process\\ncalled bootstrapping.\\nBootstrapping allows you to simulate new random samples from\\nthe population by resampling from your original sample.\\nResampling from your original sample consists of sampling at\\nrandom with replacement from your original sample many times.\\nEach time you simulate a new random sample,\\nyou compute an estimate of the unknown parameter of the\\npopulation based on the sample, and you collect all the estimates\\nyou compute along the way.\\n\\nThen, using your estimates, you can create something called\\na confidence interval, and you can say that the value of\\nthe unknown parameter lies in that interval with a certain\\nlevel of confidence.\\nIn this lesson, I'll show you how to bootstrap\\na confidence interval.\\nI have a Pandas data frame named avocado_info that\\ncontains data on a sample of avocado trees. For each\\navocado tree,\\nthe data set indicates the time the tree took to grow avocado\\nfruit and whether the tree was given fertilizer.\\nNow, let's say that I want to estimate the following population\\nparameter, the difference between the average growth duration of\\navocados that receive fertilizer and the average growth duration of\\navocados that did not receive fertilizer.\\n\\nI can use bootstrapping to create a 95% confidence interval and I'll\\nbe 95% confident that this interval will contain the value\\nof the population parameter.\\nFeel free to open the exercise file for this lesson\\nto follow along.\\nI've imported all the Python libraries that I'll need,\\nloaded the data into a data frame and displayed the first few\\nrows of the data frame.\\nNow, I'll show you how to take a random sample with replacement\\nfrom an existing sample.\\nI'll first create two subsets of the data in avocado info.\\n\\nThe first subset corresponds to the growth durations of avocado\\ntrees that receive fertilizer, and I save that in a variable\\nnamed fertilized.\\nThe second subset corresponds to the growth durations of avocado\\ntrees that did not receive fertilizer.\\nAnd I saved that in a variable named not_fertilized.\\nNow, I'll take a random sample with replacement from the sample of\\ngrowth durations of fertilized avocado trees.\\nThis can be accomplished by using the random.choice method\\nfrom the Numpy library.\\nI called np.random.choice and passed in fertilized,\\nwhich is the existing sample and I set the size parameter to the\\nlength of fertilized using the LEN function.\\n\\nThis indicates that I want the new sample to have the same length\\nas the existing sample.\\nThere,\\nthis is a new sample of growth durations of fertilized\\navocado trees.\\nNext, I'll take a random sample with replacement from the sample\\nof avocado trees that did not receive fertilizer.\\nTo achieve this, I again use the random.choice\\nmethod from the Numpy library.\\nSo I called np.random.choice, passed in not fertilized, and set\\nsize to the length of not fertilized using the\\nLEN function again.\\n\\nThere,\\nso this is a new sample of growth durations of avocado trees that\\ndid not receive fertilizer.\\nNow, I need to take a new sample many times so it would be helpful\\nto have a function that I can call whenever I want to take\\na new sample.\\nI can define the function myself and I'll name the function\\n\\\"resample.\\\"\\nI started with the keyword \\\"def,\\\" followed by the name\\nof the function, which is resample,\\nthen parentheses and I passed in a ridge_sample which will\\nbe a generic representation of the original sample that will be\\npassed in as input to this function and then a colon. In\\nthe body of the function,\\nI used the return keyword and called np.random.choice.\\n\\nI passed in a ridge sample and set size to the length of\\na ridge sample.\\nNow, I'll go ahead and run this cell.\\nNext, I defined a function that helps me perform bootstrapping and\\ncompute the mean for every sample I simulate along the way.\\nThis function will return a collection of all the means and I\\nnamed this function \\\"bootstrap.\\\"\\nI started with the keyword \\\"def,\\\" followed by the name of the\\nfunction which is bootstrap and then parentheses and passed in a\\nridge sample which will be a generic representation of the\\noriginal sample that will be passed in as input to this\\nfunction and then comma followed by reps.\\n\\nReps will be a generic representation of the number\\nof times to resample,\\nwhich will also be passed in as input to this function and then a\\ncolon. In the body of this function, I created a variable named \\\"means\\\"\\nand set it to an empty array using the array method from\\nthe Numpy library.\\nNote that an array is like a storage box that could store an\\nordered collection of items, so I use the variable means to\\nstore and keep track of the means that are computed from the new\\nsamples that are drawn during bootstrapping.\\nNext is a for loop, a reminder that a for loop allows\\nyou to repeat a particular process a certain number of times.\\n\\nThe process used to take a new sample can be repeated many times\\nin order to take many new samples.\\nSo I called the range function and passed in reps,\\nwhich makes sure that the for loop repeats that many times.\\nThen I called the resample method that I defined earlier to take a\\nnew sample from the original sample,\\nand I stored the result in a variable named \\\"new_sample.\\\"\\nNext, I used the mean method from the Numpy library to compute\\nthe mean of the new sample, and I stored the result in a\\nvariable named new_mean.\\n\\nI want to collect the means\\nI compute across all new samples so I need to store new mean in the\\nvariable means. I used the append method from the numpy library to\\nupdate the variable means.\\nSo I called np.append and passed in means, comma, new mean and\\nreassigned means to the result.\\nThis adds new mean to the end of the array that stored in\\nthe variable means, and that's the end of the for loop.\\nAt the end of the function, after the for loop, I use the return\\nkeyword followed by means.\\n\\nNow I'll go ahead and run the cell.\\nThe next step is to call the bootstrap function I just defined\\nin order to simulate new samples of growth\\ndurations of avocado trees that were fertilized,\\nsimulate new samples of those that did not, compute the mean of each\\nnew sample, and compute estimates of the population parameter.\\nSo I created a variable named fertilized means and I set it to a\\ncall to the bootstrap function where it passed in fertilized, 10,000\\nAnd then I created a variable named not_fertilized means,\\nand I set it to a call to the bootstrap function where I passed\\nin not_fertilized, 10,000.\\n\\nNext, I created a variable named estimates and I assigned it\\nto fertilized means minus not fertilized means.\\nNow, I'll go ahead and run this cell.\\nIn the next cell,\\nI'll check out what the variable estimates contains.\\nThere you go.\\nNow, to get an idea of the distribution of estimates,\\nI could create a histogram using the hist plot method from\\nthe Seaborn library.\\nSo I called sns.histplot and passed in estimates. And on the\\nnext line, I called plt.show so that the plot displays\\non the screen.\\n\\nThere,\\nthis is my histogram.\\nThe final step is to construct a 95% confidence interval.\\nTo do this, I'll take the two point fifth and 97 point fifth\\npercentiles of the estimates I computed during bootstrapping.\\nI'll use the percentile method from the Numpy library.\\nSo I called np.percentile passed in estimates, 2.5,\\nand then I called np.percentile again and this time I\\npassed in estimates, 97.5.\\n\\nThere you go.\\nThis confidence interval allows you to say with 95% confidence\\nthat the population's mean difference in growth duration\\nbetween avocado trees that were fertilized and those that were not\\nis between approximately -11.34 and -7.19.\\nNow you know how to bootstrap a confidence interval.\\n\"}],\"name\":\"8. Using Inference and Statistical Analysis\",\"size\":53747791,\"urn\":\"urn:li:learningContentChapter:4493807\"},{\"duration\":1556,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4485932\",\"duration\":106,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Defining prediction for data science\",\"fileName\":\"4457428_en_US_09_01_LA24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Classification is an important machine learning technique you can use when working with data. After watching this video, you'll be able to describe classification and explain how it is used.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3582338,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"An important aspect of data science is discovering what data\\ncan tell us about the future.\\nFor example, based on a person's social media profile,\\nwhich upcoming movies will likely interest them?\\nWhat does climate and environmental data say about\\ntemperatures a few decades from now?\\nHow can a database of past clinical trial reports be used to\\nestimate the risks of a new clinical trial?\\nAnswering questions like these involves making predictions.\\nIn this lesson, I'll identify two major types of\\nprediction tasks the data scientists work on.\\n\\nThe first is classification.\\nClassification is about predicting the value of a categorical\\nvariable.\\nThe variable you want to predict is categorical,\\nwith dog and cat being the possible categories,\\nin other words, classes.\\nNow, there are many techniques the data scientists have developed for\\napproaching classification.\\nOne method is K-nearest neighbors, which uses the distance between\\nthe data point that you want to classify and the data points that\\nare already classified.\\n\\nThe classes of the data points that are nearest to the new data\\npoint inform the predicted class of the new data point.\\nThe second is regression.\\nRegression is about predicting the value of a continuous variable.\\nFor example, predicting the retail price of a car based on the\\ncar's acceleration rate.\\nThe variable you want to predict is continuous.\\nPrice can be any number and isn't restricted to discrete intervals.\\nThere are many methods for regression as well.\\nOne method is linear regression, which models a linear relationship\\nbetween variables and the linear model can be used to predict\\nthe dependent variable.\\n\\nNow you have an overview of what prediction means in data science,\\nas well as some key methods that you'll encounter in this area.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4493803\",\"duration\":127,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Navigating classification\",\"fileName\":\"4457428_en_US_09_02_LA24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"k-NN or k-Nearest Neighbor is a common data science algorithm. After watching this video, you'll be able to define the k-Nearest Neighbor algorithm and how to use it to classify data.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4658565,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Classification is an important machine learning technique and\\nit's a type of prediction task.\\nClassification is a vast topic that consists of numerous\\nconcepts.\\nSo for the purposes of this course,\\nI'll provide a quick introduction to classification.\\nClassification is a process of making categorical predictions\\nusing data. In classification, you have some data that has\\nalready been placed in the correct categories,\\nand the goal is to learn from this data in order to make good\\npredictions for new data that you encounter in the future.\\nHere are a few examples where classification can be used\\nin the real world.\\n\\nClassification can be used to make weather forecasts.\\nWeather stations predict tomorrow's weather based on\\ntoday's weather and the weather from the previous days,\\nit can be used to classify emails as spam and not spam,\\nas well as to classify phone calls as spam and not spam.\\nClassification can also be used to predict if a patient has\\na particular disease.\\nIt can also be used to predict which candidate a person will\\nvote for in an election.\\nYou can use classification to predict the genre of a song,\\nthe genre of a movie or the genre of a TV show.\\n\\nAlso, classification can be used on dating apps and dating sites to\\npredict whether two users are compatible in order to provide\\nusers with recommendations on who to connect with.\\nNext, I'll introduce some key terms used in classification.\\nA situation where you want to make a prediction is called\\nan observation.\\nEach observation has certain aspects that describe\\nthe observation,\\nand these are called attributes.\\nThe attributes are known, and each observation belongs\\nto a specific category, which is called a class.\\n\\nThe class is not known. in classification,\\nthe goal is to correctly predict the classes of observations using\\nthe attributes of the observations.\\nIn order to make predictions, you need something called\\ntraining data.\\nbeen correctly classified, so you would analyze the training\\ndata and then build something called a classifier.\\nA classifier is an algorithm that helps you classify future\\nobservations whose classes you do not already know.\\nNow you know what classification is and why it's useful.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4487769\",\"duration\":193,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Recognizing the k-NN algorithm\",\"fileName\":\"4457428_en_US_09_03_LA24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"k-Nearest Neighbors is a great algorithm to use, but navigating it with an example can be helpful to fully grasp the concept. After this lesson, you'll be able to apply the k-Nearest Neighbors algorithm and use it to perform classification within a dataset. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6496295,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"There are a lot of different methods to approach\\nclassification,\\nbut for the purposes of this course,\\nI'll give you a quick introduction to one of the methods.\\nAnd there are a lot of resources out there for you to learn\\nabout other methods.\\nIn this lesson, I'll introduce the K-nearest\\nneighbor algorithm, which is a powerful method to\\napproach classification.\\nBut before I do, I want to go over some key terms\\nused in classification.\\nAn observation is a situation where you want to make\\na prediction.\\nEach observation has certain aspects that describe\\nthe observation,\\nand these are called attributes.\\n\\nThe attributes are known and each observation belongs to\\na specific category, which is called a class,\\nand the class is not known. In classification,\\nthe goal is to correctly predict the classes of observations using\\nthe observations attributes.\\nIn order to make predictions, you need training data.\\nTraining data consists of observations that have already\\nbeen correctly classified, so you would analyze the training\\ndata and then build something called a classifier.\\nA classifier is an algorithm that helps you classify future\\nobservations whose classes you do not already know.\\n\\nBinary classification is performed when the classification task at\\nhand involves observations that each belong to one of two classes.\\nMulticlass classification is performed when the classification\\ntask at hand involves observations that each belong to one of\\nmultiple classes and by multiple I mean more than two.\\nNow the K-nearest neighbor algorithm,\\nalso known as a K-NN algorithm, works as follows.\\nFirst, you pick a number k.\\nNote that it may be convenient to pick an odd number so that you\\ndon't have to deal with ties.\\n\\nNext, you pick a set of attributes from your training data that are\\nmost relevant to the classification task at hand.\\nWhen you encounter a new data point,\\nyou determine the new data points k-nearest neighbors.\\nIn other words, you determine the K training data\\npoints with the shortest distances to the new data point.\\nThen you find out the class that is most frequent among the K\\nnearest neighbors and use that class to classify the\\nnew data point.\\nFor example, let's say I want to build a binary classifier that\\nhelps me classify emails as spam or not spam and say that I have a\\ndata set containing training data.\\n\\nThe training data set specifies the attributes and the correct\\nclasses for a bunch of emails.\\nSome of the attributes given in the training data set are\\nthe body of the email, the subject of the email,\\nthe date time stamp, whether the message was a reply\\nand whether the message was a foreword.\\nFirst, I would observe the given attributes.\\nNext, I would try to see if I can come up with more attributes that\\nare relevant to the classification task at hand,\\nusing the given attributes.\\nFor example, the length of the subject as well as the length of\\nthe body may be relevant to determining whether an email\\nis spam or not spam.\\n\\nSo I can add these attributes to my training data set\\nafter computing the length of the bodies and the lengths of the\\nsubjects for the emails in my training data.\\nNext, I would analyze the training data and look for patterns or\\ntrends between the attributes of the emails and the classes\\nof the emails.\\nThen from the attributes I have, I would choose the attributes that\\nI think are most relevant to spam filtering.\\nNow you have insight on the K-nearest neighbor algorithm and how\\nit's used in classification.\\nSo if you want to classify some data,\\ntry using K-NN.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4487768\",\"duration\":449,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Implementing k-Nearest Neighbors\",\"fileName\":\"4457428_en_US_09_04_LA24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Regression is all about exploring relationships, which is often what evaluating data involves. After this lesson, you'll be able to define regression as a task of prediction in data science. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":16723185,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"In this lesson, I'll go over an example of\\nimplementing the K-Nearest Neighbors or K-NN algorithm.\\nLet's say you have a data set that was collected to help doctors\\ndiagnose chronic kidney disease or CKD.\\nEach row in the data set represents a patient who was\\ntreated in the past and whose diagnosis is known.\\nFor each patient, you have a set of measurements\\nfrom a blood test.\\nYour goal is to develop a way to classify future patients,\\nas has CKD or doesn't have CKD based on their blood test results.\\n\\nI've opened up the exercise file for this lesson.\\nFeel free to open the exercise file on your end as well\\nto follow along.\\nIn the first code cell, I started by importing all the\\npython libraries that I'll need.\\nThis includes imports from Pandas, Matplotlib, Seaborn and Sklearn.\\nSklearn is another powerful library for data science.\\nIt contains many useful methods for implementing machine learning\\nalgorithms in Python.\\nYou can learn more about it using the link in the resource file.\\nNext, I loaded the CKD data set into a Pandas data frame.\\n\\nThen I used the head function to get the first few rows\\nof the data frame.\\nAs a data-cleaning step,\\nI renamed the column named Blood Glucose Colon random to just\\nglucose for simplicity.\\nIt's easier to work with column names that are shorter,\\nand I used the head function again to make sure that the data\\nframe was updated.\\nTo get a better understanding of the data,\\nI accessed the shape attribute of the data frame.\\n\\nThis tells me that there are 158 rows and 25 columns.\\nI also used the info function to get some basic information\\nabout the columns.\\nThis shows that there are no missing values in the columns,\\nand there are a variety of data types in this data set.\\nWhen performing classification, it's important to check for class\\nbalance in the data set.\\nClass balance refers to how evenly distributed the values in the\\noutcome variable are across the different classes.\\n\\nClass balance is important because you don't want to build a\\nclassifier that is biased towards one class over another.\\nA perfect split is very rare. When there are two classes,\\na common standard is that anything more extreme than a 9010 split\\nis considered too imbalanced.\\nAnd in that case, there are techniques like\\nresampling that can be used to balance the data.\\nI can use the value counts method from the Pandas library to\\ncheck for class balance.\\nIn this data set, there's a 7327 split\\napproximately,\\nwhich is not too imbalanced.\\n\\nSo I can proceed with this data set as is.\\nNow, let's use visualizations to get more insights about the\\nrelationships between variables in the data.\\nLet's start with the scatterplot of glucose over hemoglobin and\\ncolor in the data points to distinguish between\\nthe two classes.\\nClass 1 represents has CKD and Class 0 represents\\ndoes not have CKD.\\nThis plot shows a clear pattern.\\nData points in the lower right tend to represent people who do\\nnot have CKD and the rest tend to be folks with CKD.\\n\\nYou could also use this plot to visually simulate how a nearest\\nneighbor algorithm would work here.\\nLet's say a new data point has been identified.\\nYou have the glucose and hemoglobin attributes of this new\\ndata point and you want to predict its class.\\nYou could find the point in the training set that is nearest\\nto the new point.\\nIf that nearest point is a CKD point, you would classify the\\nnew point as CKD.\\nIf the nearest point is a not CKD point,\\nyou would classify the new point as not CKD instead.\\nBut the separation between the two classes won't always be as clean\\nif you choose a different pair of attributes.\\n\\nFor instance, let's say you choose glucose and white blood\\ncell count.\\nLet's create a scatterplot for this.\\nAs the scatterplot shows, sometimes, folks with CKD have glucose\\nand white blood cell levels that look identical to those of\\nsomeone without CKD.\\nSo a classifier is inevitably going to make the wrong prediction\\nfor them if the prediction is based on the nearest point.\\nThe solution is generalizing the nearest neighbor algorithm,\\nmaking it a K-nearest neighbor algorithm.\\n\\nFor example, K could be three.\\nSo instead of using the nearest point,\\nyou could use the three nearest points to make a prediction.\\nAnd really k can be any number like 4 or 5 and so on,\\nbut it's usually convenient to pick an odd number so that you\\ndon't have to deal with ties.\\nLet's go with three for now.\\nNext, I isolated the y variable.\\nThis is also known as the outcome variable,\\nthe target variable, or the dependent variable.\\nEssentially this is the variable that you want to predict.\\n\\nThen I isolated the X variables.\\nThese are also known as the features or the independent\\nvariables.\\nto use to predict Y.\\nAnd from this, I selected the X variables that are numeric.\\nIn other words, having integer or float\\ndata types.\\nNext, I split X and Y into training and testing sets using the train\\ntest split function from sklearn.\\n\\nThis function randomly splits the data.\\nI set test size to 0.25, which means 75% of the data goes\\ninto training and 25% goes into testing.\\nI also specified random state so that this process can\\nbe reproduced.\\nIf I don't specify the random state parameter,\\nthen each time I run this train test split, I would get\\na different result.\\nAnd then I checked that the training and testing sets were populated.\\n\\nI also checked the shapes of the training and testing sets.\\nThe number of columns in x_train and x_test match, the number of\\nrows in x_train and y_train match, and the number of rows in\\nx_test and y_test match.\\nNext, I created a K-neighbor's classifier object and saved\\nit in a variable named K-NN.\\nAnd then I fit the K-neighbor's classifier to the training data.\\nNext, I used the fitted neighbors classifier to predict on the\\ntraining set and save those predictions in a variable named\\npreds_train.\\n\\nI then computed the accuracy of the predictions for the training\\nset using the score function from Sklearn.\\nThe output shows that the accuracy of the predictions on the training\\nset is about 86%.\\nFinally, I got the predictions on the testing set using the\\npredict function again, and I saved those predictions\\nin a variable named preds_test\\nAnd here are those predictions.\\nAnd to compare, here are the true values from the testing set.\\n\\nLastly, I computed the accuracy of the predictions for the testing\\nset using the score function again.\\nThe output here shows that the accuracy of the predictions\\non the testing set is 85%.\\nNow that you've gone through this example,\\nyou can go ahead and try implementing the K-NN algorithm to\\nperform classification on a data set of your choice.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4492756\",\"duration\":172,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Navigating regression\",\"fileName\":\"4457428_en_US_09_05_LA24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"You can use linear regression to help you predict the value of one variable using the value of another. After this lesson, you'll be able to recognize the value of linear regression and articulate how it functions. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6002454,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"In data science, regression can be used to predict the value of\\na continuous variable.\\nThere are different types of regression techniques,\\neach suited for a different scenario.\\nA couple of the major techniques include linear regression and\\npolynomial regression.\\nLinear regression can be used to model a linear relationship\\nbetween variables and use the linear model to predict the\\ndependent variable.\\nMeanwhile, polynomial regression can be used to model a non-linear\\nrelationship between variables and use the non linear model to\\npredict the dependent variable.\\n\\nWithin linear regression, there are two types.\\nThe first is simple linear regression and the second is\\nmultiple linear regression.\\nSimple linear regression is about using one independent variable,\\nalso known as feature to predict the value of the dependent\\nvariable\\nindependent variables, also known as features to predict\\nthe value of the dependent variable.\\nIn the rest of this lesson, I'll show you how to navigate\\nquestions that can be answered through regression with a couple\\nof example context to make it clear.\\n\\nImagine that a data professional is interested in making\\npredictions about user engagement for a mobile app.\\nHere's the question they might ask, \\\"How much does each in-app feature\\ninfluence user engagement?\\\"\\nThe in-app features might include a live chat with customer support\\nand FAQ section that updates weekly and a community space to\\nconnect with other users.\\nThe next step is to determine which variable in the data should\\nbe the outcome variable.\\nIn other words, the variable that will be\\npredicted. If they have access to data about user session lengths,\\nin other words, how long users spend in the app\\neach time they open it,\\nthe outcome variable can be session length.\\n\\nThen they should identify how the outcome variable is measured.\\nSession length can be measured by number of minutes,\\nwhich is continuous. Because the outcome variable is continuous and\\nthey're interested in how much each feature influences\\nthe outcome variable,\\nthey could proceed with linear regression.\\nIf there is only one feature of interest,\\nthey would build a simple linear regression model.\\nOr if there are multiple features of interest,\\nthey would build a multiple linear regression model.\\nNow, imagine a different context, making predictions about patient\\nresponses to medical treatments.\\n\\nA possible question could be, \\\"How much does each factor influence a\\npatient's response to a medical treatment?\\\"\\nFor example, if the goal of the treatment is to improve white\\nblood cell or WBC count and you have access to that data,\\nWBC count can be the outcome variable.\\nThis outcome variable is a continuous measure,\\nso you could use linear regression to address this task.\\nAs these examples demonstrate, regression can be used to answer\\na variety of questions.\\nAs a fun exercise, think of a question that involves\\npredicting a continuous variable that you're interested in,\\nand think about how regression can be used to achieve that goal.\\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4489773\",\"duration\":140,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Checking assumptions of regression\",\"fileName\":\"4457428_en_US_09_06_LA24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Linear regression uses a dependent and independent variable to help you test and form the relationships within your data. After this lesson, you'll be able to use linear regression to make predictions for your dataset. \",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3674974,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"When using linear regression to answer question or\\nmake predictions,\\nit's important to be aware of the assumptions that must be met.\\nIn this lesson, I'll introduce four key\\nassumptions of simple linear regression.\\nThe first is linearity.\\nTo detect if this assumption is met,\\nplot the independent and dependent variables on an x, y coordinate\\nplane and make sure that the points on the plot appear to\\nfall along a straight line.\\nIf the visualization looks like a random cloud or resembles a\\ncurve rather than a line, then the assumption is not met,\\nwhich means a linear model would not fit the data well and you\\nmight need a different or a more complicated model for\\nyour data set.\\n\\nIn contrast, a plot that shows the data points clustering around a\\nline indicates that linear regression would be an appropriate\\nmodel to represent the relationship between X and Y.\\nThe next is normality.\\nThis assumes that the residual values or errors are normally\\ndistributed.\\nResiduals are calculated after the model is built and they indicate\\nhow far off the predictions are from the true values.\\nSo you can't check this assumption until after you build the model.\\nBut once the model is built, you can create a specific\\nplot called a quantile-quantile or q-q plot\\nof the residuals.\\n\\nIf the points on the plot appear to form a straight diagonal line,\\nthen you can say that the normality assumption is met.\\nThen there's independent observation.\\nThis means each observation in the data set is independent.\\nIt's helpful to use the context around how the data was collected\\nand the variables used in order to determine if this assumption\\nis met.\\na scatterplot of the fitted values versus residuals should\\napproximately resemble a random cloud of data points.\\n\\nIf there are any patterns in that plot,\\nthen you might need to re-examine the data.\\nFinally, there's homoscedasticity.\\nThis means that the variance of the residuals is constant.\\nTo check whether this assumption is met,\\ncreate a scatterplot of fitted values,\\nalso known as predictions versus residuals,\\nThere should be constant variance along the values of the\\ndependent variable.\\nIn other words, there will be no clear pattern or\\nyou will notice a random cloud of data points in this plot.\\nHowever, if you observe a cone-shaped pattern,\\nfor example, then the assumption is not met.\\n\\nNow you know the main assumptions of linear regression.\\n\"},{\"urn\":\"urn:li:learningContentVideo:4485931\",\"duration\":369,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Implementing linear regression\",\"fileName\":\"4457428_en_US_09_07_LA24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":13547207,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Imagine that you're part of a team that provides insights about\\nmarketing and sales.\\nYou've been assigned to a project that focuses on the use of\\ninfluencer marketing, and you'd like to explore the\\nrelationship between radio promotion budget and sales.\\nYou're provided a data set that includes information about\\nmarketing campaigns across TV, radio, and social media,\\nas well as how much revenue and sales was generated from\\nthese campaigns.\\nThe goal is to build a linear regression model that can predict\\nsales based on radio promotion budget.\\n\\nIn this lesson, I'll demonstrate how to use linear\\nregression to solve this problem.\\nI'll be going through the exercise file for this lesson.\\nFeel free to open it up on your end as well to follow along.\\nPython libraries that are most commonly used for implementing\\nlinear regression include the Stats-models Library and\\nthe Escalar Library.\\nIn this demo, I'll be using the Stats-models library.\\nI've started by importing the Python libraries that I'll need.\\nThe next step is to load the marketing and sales data from the\\nprovided CSV file into a Pandas data frame and display the first\\nfew rows of the data frame.\\n\\nThe data includes TV promotion budget,\\nradio promotion\\nbudget, social media promotion budget, type of influencer that the\\npromotion is in collaboration with, and sales.\\nAnd note that the quantities in this data are expressed in\\nmillions of dollars.\\nAnd then I got the shape of the data frame.\\nThis indicates that there are 572 rows and five columns.\\nNext, it's important to check for missing values.\\nThis can be done using the isna method followed by the sum method.\\n\\nAs the zeros here indicate, there are no missing values\\nin any of the columns.\\nTo visualize the data, I'll create a plot of pairwise\\nrelationships between variables using the pair plot method\\nfrom the Seaborn library.\\nIn the scatterplot of sales over radio,\\nthe points appear to cluster around a line.\\nThis indicates that a linear model may be suitable for modeling\\nthe relationship between sales and radio,\\nand the linearity assumption of linear regression is likely met.\\n\\nNext, I'll split the data set into train and test. To get train,\\nI called the sample method from pandas.\\nI passed in frac a 0.75 and random state of zero.\\nThe 0.75 indicates that 75% of the data will go into train.\\nSpecifying the random state parameter ensures that this\\nprocess can be reproduced.\\nAnd then I assign test to be the remaining rows from the\\noriginal data frame, and then I'll confirm that the\\ntrain and test sets were populated.\\n\\nAfterwards, I'll select a subset of each with just the variables\\nneeded for the linear regression model.\\nSince the goal is to use radio to predict sales,\\neach subset needs to include only those two columns.\\nI can then confirm that these subsets were populated as well.\\nThe next step is to use the OLS function to create an OLS object.\\n\\nOLS stands for Ordinary Least Squares, which is a common approach\\nfor linear regression.\\nWhen calling the OLS function, I passed in the formula and\\ndata parameters,\\nthe formula is sales tilde radio, which specifies that sales will be\\nthe Y variable and radio will be the X variable and I specified\\ntrain subset as the data for OLS.\\nI saved the OLS object in a variable named ols_market.\\nThen I can create the linear regression model by fitting\\nthe OLS object.\\n\\nThis automatically fits the model to the training data.\\nTo get a summary of the model, I can call the summary method.\\nFrom the summary output,\\nI can identify the coefficients.\\nThe y intercept is 42.8594 and the slope is 8.4170.\\nOne way to interpret this is companies with $1 million more in\\ntheir radio promotion budget accrue $8.417 million more\\nin sales on average, according to this data.\\n\\nNow that the model is built, it's important to continue\\nchecking whether the assumptions of linear regression are met.\\nI can call the regplot method from Seaborn to visualize the data\\nalong with the line of best fit from the linear regression.\\nThis shows an approximately linear relationship between the X and Y\\nvariables which confirms the linearity assumption.\\nNext, I'll compute the residuals.\\nThe residuals, quantify how far off the model's predictions\\nare from the true values.\\nI can then create a histogram to visualize the distribution\\nof the residuals.\\n\\nThe histogram shows that the distribution of the residuals\\nis approximately normal, so the normality assumption of\\nlinear regression is likely met.\\nThen I created a quantile-quantile plot,\\nalso known as a q-q plot.\\nIn this plot,\\nthe points closely follow a straight diagonal line.\\nSo this confirms that the normality assumption is meant. To\\nget the predictions also known as fitted values on the\\ntraining data,\\nI called the predict method.\\n\\nThen I created a scatterplot of the training predictions over the\\nresiduals along with the horizontal line at Y = 0.\\nIn this plot, the points resemble a cloud like structure and don't\\nseem to follow an explicit pattern.\\nSo it looks like the independent observation assumption is not\\nviolated and the residuals appear to be randomly spaced.\\nSo the homoscedasticity assumption seems to be met as well.\\nFinally, I called the predict method again,\\nthis time to get the predictions on the test data.\\n\\nAnd that's it.\\nNow you know how to implement linear regression using methods\\nfrom the Stats-models library to make predictions.\\nThe approach shown in this lesson can be used for other\\ndata sets as well.\\nSo if you're interested in predicting a continuous variable\\nfrom another data set,\\ngo ahead and try implementing linear regression.\\n\"}],\"name\":\"9. Using Prediction in Data Science\",\"size\":54685018,\"urn\":\"urn:li:learningContentChapter:4487775\"},{\"duration\":65,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4493802\",\"duration\":65,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Next steps\",\"fileName\":\"4457428_en_US_10_01_LA24\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2486321,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\"Congratulations on completing this course.\\nThere's a lot to learn about data science,\\nbut the learning definitely does not stop here.\\nWhile watching someone walk through examples is important\\nto learning how things work, it's equally important to\\npractice on your own\\nafter watching. I also recommend that you check\\nout the following resources.\\nThe first is Kaggle, an online community of data\\nscientists and other developers who participate in contests,\\nshare their datasets, discuss their findings, and more.\\nThe data sets posted on Kaggle are free for the public to use.\\n\\nThe next resource is the book, Developing Analytic Talent:\\nBecoming a Data Scientist by Vincent Granville.\\nAnd another great resource is the website towards data science.\\nThis site is a platform for people to stay updated on cool\\nadvancements in the field of data science,\\nexchange ideas, and access step by step tutorials that address\\nvarious topics in data science.\\nSo that's it.\\nI hope you can see how data science is changing our world.\\nAnd when you take time to learn data science,\\nyou can be a part of making the world a better place.\\n\\nThank you for watching and good luck.\\n\"}],\"name\":\"Conclusion\",\"size\":2486321,\"urn\":\"urn:li:learningContentChapter:4487776\"}],\"size\":244465192,\"duration\":7255,\"zeroBased\":false},{\"course_title\":\"Statistics Foundations 1: The Basics\",\"course_admin_id\":2866076,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":2866076,\"Project ID\":null,\"Course Name\":\"Statistics Foundations 1: The Basics\",\"Course Name EN\":\"Statistics Foundations 1: The Basics\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"&lt;p&gt;Statistics is not just the realm of data scientists. All types of jobs use statistics. Statistics are important for making decisions, new discoveries, investments, and predictions. Whether the subject is political races, sports rankings, shopping trends, or healthcare advancements, statistics is an instrument for understanding your favorite topic at a deeper level. In this course, Professor Eddie Davila offers beginner-level lessons, so you too can master the terms, formulas, and techniques needed to perform the most common types of statistics.&lt;/p&gt;&lt;p&gt;Eddie covers several examples of data and charts. He explains how to find the middle of your data set, as well as the mean and median. He introduces range, then goes into standard deviation and what to do with outliers. These techniques help you understand your data, prove theories, and save time, money, and other valuable resources\u2014all by understanding the numbers.&lt;/p&gt;&lt;p&gt;This course is part of a &lt;a href=https://www.linkedin.com/learning/paths/anaconda-python-for-data-science-professional-certificate target=_blank&gt;Professional Certificate&lt;/a&gt; from Anaconda.&lt;/p&gt;&lt;p&gt;This course is part of a &lt;a href=https://www.linkedin.com/learning/paths/statistics-foundations-professional-certificate-by-wolfram-research target=_blank&gt;Professional Certificate&lt;/a&gt; from Wolfram Research.&lt;/p&gt;\",\"Course Short Description\":\"Learn to understand your data using basics of statistics, such as defining the middle, mean, and median of your data set; measuring the standard deviation; and finding outliers.\",\"Content Type\":\"TOOLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":\"3349645\",\"Instructor Name\":\"Eduardo Davila\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"Associate Chair for the ASU Supply Chain Management program\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2021-03-05\",\"Course Updated Date\":\"2021-07-14\",\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"Yes\",\"Has Challenge/Solution\":\"Yes\",\"LIL URL\":\"https://www.linkedin.com/learning/statistics-foundations-1-the-basics,https://www.linkedin.com/learning/statistics-foundations-the-basics\",\"Series\":\"Foundations\",\"Limited Series\":null,\"Manager Level\":\"General\",\"LI Level\":\"Beginner\",\"LI Level EN\":\"Beginner\",\"Sensitivity\":null,\"Internal Library\":\"Technology\",\"Internal Subject\":\"Data Science\",\"Primary Software\":\"Microsoft Excel\",\"Media Type\":\"Video\",\"Has CEU\":\"Yes\",\"Has Exercise Files\":\"Yes\",\"Visible Duration\":1983.0,\"Visible Video Count\":14.0,\"Learning Objectives\":\"Introduce the concepts of mean, median, and mode.,Explain how to calculate range., Explore the z-score concept.,Define standard deviation.,Introduce the empirical rule.,Explore how standard deviation and normal distributions are related.,Recognize the possible role of outliers.\",\"Contract Type\":\"PERPETUAL\",\"Certifications\":\"CPE:National Association of State Boards of Accountancy (NASBA)::Statistics\",\"Framework Topic\":null,\"Automatic Caption Translations\":\"Global Captions\",\"Automatic Metadata Translations\":\"Global Metadata\",\"Gen AI Feature Flag\":null,\"Hands-On Practice\":null,\"Hands-On Practice Library\":null,\"Unlocked for Viva Learning\":\"Global Captions\",\"Free Course\":null,\"Certification Library\":\"Certifications\",\"Github Codespace\":null,\"Skills Count\":1,\"Skills\":\"Statistics\",\"Skills EN\":\"Statistics\",\"Content Manager\":\"Steve Weiss\",\"Acquisition Manager\":\"Steve Weiss\",\"Framework Subject\":null},\"sections\":[{\"duration\":82,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2402703\",\"duration\":82,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"The beginning of your statistics journey\",\"fileName\":\"2866076_00_01_WL30_Intro\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":14643385,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Data-driven decision making, statistical analysis,  \\n it's all become an important part of life as we know it.  \\n As we navigate our world of business, science, politics,  \\n sports, and pandemics, statistics is the foundation  \\n for making good decisions built on data.  \\n So many people, devices, and events,  \\n the data piles up.  \\n Understanding how to describe the data  \\n by finding its middle, its edges, and then telling the story  \\n of data in pictures is vital for our personal understanding  \\n and also to help others understand.  \\n In this course,  \\n I'll show you how to deal with basic statistics.  \\n We're going to talk about some things you've heard of,  \\n like means, medians, and standard deviations.  \\n Plus, we'll talk about more in-depth topics,  \\n like normal distributions,  \\n the empirical rule, and outliers.  \\n Together, all of these tools  \\n will help you better understand your data set.  \\n This particular course isn't complex or nuanced,  \\n but it should get you thinking  \\n in the language of statistics,  \\n and then you'll be able to turn that knowledge  \\n into decision-making ability.  \\n Ready to dive into some stats? Good, let's get to it.  \\n \\n\\n\"}],\"name\":\"Introduction\",\"size\":14643385,\"urn\":\"urn:li:learningContentChapter:2403686\"},{\"duration\":184,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2398850\",\"duration\":81,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Introduction to data and charts\",\"fileName\":\"2866076_01_01_MM30_CHGRTA\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to understand data sets and their limitations. Knowing what to look for in a data set is an important skill.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5251708,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - We live in a world of data.  \\n It's everywhere, and new data are generated every second.  \\n Every time we buy a product, Google something,  \\n vote in an election, or watch a show on Netflix,  \\n we create data.  \\n All of that data is collected and stored,  \\n but what does it look like?  \\n For many people, data looks like an intimidating,  \\n if not meaningless jumble of numbers,  \\n but with the use of charts, graphs, and tables,  \\n the meaning of the data becomes more clear  \\n and the data begins to tell a story.  \\n Your favorite stories might be in novels,  \\n comic books, or movies.  \\n In the world of statistics,  \\n stories are illustrated with charts, graphs, and tables.  \\n They illustrate dominance. They reveal change.  \\n They help us organize.  \\n More importantly, they can educate and empower us.  \\n And the more we know, the more curious we become,  \\n and this is what drives us to look more deeply  \\n at the data we have, or it might motivate us  \\n to gather better data sets in the future.  \\n Whether you're trying to learn, decide, persuade,  \\n charts, graphs, and tables will be the tools used  \\n to write your statistics story.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2403683\",\"duration\":103,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Data and chart examples\",\"fileName\":\"2866076_01_02_XR30_Charts\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, explore data tables, frequency tables, histograms, pie charts, and dot plots.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3350886,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Let's look at some statistics tools  \\n we can use to illustrate our datasets.  \\n I'm in the exercise file 01_02.  \\n Suppose we have a collection of data  \\n related to a group of 50 college students.  \\n In the table, we can display all of the weights  \\n of these students in pounds from heaviest to lightest.  \\n That's sort of interesting.  \\n We could also create a table that reports  \\n the frequency of each weight.  \\n We had six at 170 pounds, and only one at 130 pounds.  \\n It's a bit easier to digest  \\n than the table with all the individual data points.  \\n If you want to see each individual data point,  \\n the data plot might be what you're looking for.  \\n Much more appealing than a list of numbers,  \\n I can see numbers in the dots.  \\n If the dot plot is still too overwhelming,  \\n put the data into 10-pound intervals.  \\n And then turn that into an appealing bar chart,  \\n which we call a histogram.  \\n The 50 data points, they're all in there.  \\n On this table, I've added a column  \\n that provides the frequency of each interval in percentages.  \\n And here's that data as a relative frequency histogram.  \\n Weight intervals to find each separate bar,  \\n the height of the bar indicates the relative frequency.  \\n Or, if you prefer, we can take the same data  \\n and throw it into a pie chart.  \\n Each slice gives us an indication of the percentage  \\n of students in each category.  \\n Next time you look at a chart or table,  \\n don't get intimidated, and don't look for the right answer.  \\n Read it like a story.  \\n Think about what it means to you  \\n and embrace your questions as an opportunity  \\n to open a discussion about the data  \\n and the decisions it might provoke.  \\n \\n\\n\"}],\"name\":\"1. Data and Charts\",\"size\":8602594,\"urn\":\"urn:li:learningContentChapter:2398852\"},{\"duration\":552,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2398851\",\"duration\":150,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"The middle of your data set\",\"fileName\":\"2866076_02_01_MM30_Middle\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Large data sets can be intimidating. Finding the center of a data set can provide a starting point to understand the data.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7181073,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Every new set of data is filled with mystery.  \\n You have no idea what it contains.  \\n Somewhere inside the data is a story.  \\n Every time I get a data set,  \\n I wonder what kind of story will this tell?  \\n Will it told me something odd,  \\n something interesting, or something that's common knowledge?  \\n So, how do you begin to unravel the story?  \\n Well, when we read a book, we start at the beginning,  \\n but with a dataset, we start in the middle, literally.  \\n It makes sense.  \\n Wouldn't it be nice to know the middle  \\n or center of that data,  \\n especially if our data set has thousands  \\n or even millions of data points?  \\n Knowing the center of the data would seem  \\n to give us some balance  \\n and a really nice starting point.  \\n Let's take these two data points points, 2 and 4.  \\n Where's the middle?  \\n Halfway between them seems about right.  \\n So it's 3.  \\n Our two data points are equally far away  \\n or equidistant from 3.  \\n But how about when you have three data points: 1, 2, and 6?  \\n Where's the middle?  \\n Is it the middle value, 2?  \\n Maybe the average of the three numbers?  \\n Well, that would be 3, huh?  \\n And what happens when we have thousands  \\n of data points in our data set?  \\n Where's the middle now?  \\n In world of statistics,  \\n we often use three tools to help us understand  \\n the center of our data.  \\n First, the mean,  \\n which is the average of all the numbers in the data set.  \\n That's simply the sum of all the numbers  \\n divided by the count of the numbers.  \\n Second, the median, the middle value in the data set.  \\n Half the data points are bigger than the median,  \\n the other half are smaller.  \\n To determine the median,  \\n you do need to arrange all the numbers in order  \\n from lowest to highest or vice versa.  \\n Third, we have the mode.  \\n That's the most common number in the data set.  \\n It's a nice to know number,  \\n but I wouldn't make too many predictions  \\n based on just the mode.  \\n By looking at some simple data sets,  \\n we can practice finding the center of our data set,  \\n and thus start to discover the story.  \\n Let's do that next.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2397815\",\"duration\":225,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Basic data sets\",\"fileName\":\"2866076_02_02_XR30_MeanMM\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to describe, calculate, and interpret the mean and median.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6927549,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] So how do you find  \\n the mean, median, and mode of a data set,  \\n and how do the three of them together  \\n help you better understand your data set?  \\n Let's begin with a small and simple data set.  \\n I'm in exercise file 02_02_Begin.  \\n It only has seven data points.  \\n First, let's find the median.  \\n The median is the middle value.  \\n To find the middle value,  \\n you can use this formula, the quantity n + 1 over 2,  \\n where n is the number of values in our data set.  \\n Our data set has only seven values, so n is equal to 7.  \\n And then we can solve,  \\n n + 1 divided by 2.  \\n So what we're looking for is our fourth value.  \\n What we then need to do is organize our values  \\n from smallest to largest or largest to smallest,  \\n so we'll put these in ascending order.  \\n And now we're looking for the fourth value.  \\n One, two, three, four, this is our fourth value.  \\n That is our median.  \\n If you want, you can use a formula.  \\n The median of these values is 40.  \\n Next, we can calculate the mean,  \\n which is often called the average.  \\n The average is the sum of all the data points divided by n,  \\n so if we know that n is equal to 7,  \\n so what we're going to do is  \\n we're going to sum up all of our data points,  \\n which is 490,  \\n so 490 divided by 7 gives us 70.  \\n You can also use a formula for this.  \\n So it's average of all of these values over here.  \\n And again, the average is 70.  \\n Finally, let's identify the mode.  \\n The mode is the most common number in our data set.  \\n In this dataset, the mode is 20.  \\n It shows up three times all the other values  \\n in this dataset only appear once.  \\n Again, you can use a formula.  \\n Using all three of these numbers together,  \\n we can now better understand our data set.  \\n Here's our complete data set:  \\n 20, 20, 20, 40, 50, 140, 200.  \\n The median is 40, the mean is 70, the mode is 20.  \\n Because this data set is so small,  \\n we can see that while the middle value or median is 40,  \\n it makes sense that the mean is larger  \\n since we have two data points much larger than 40.  \\n Five of the numbers are 50 or below,  \\n but the two largest values, 140 and 120,  \\n they greatly increase the average.  \\n Together, the median 40 and the mean 70 told me  \\n that while half the data points are under 40,  \\n the numbers above the median must have been really large  \\n if they pushed the average to 70.  \\n As for the mode in the data set with only seven data points,  \\n we have three data points of 20.  \\n It represents all of the data points below the median  \\n and it definitely pulled down the average.  \\n The mode is begging us to investigate  \\n why it's so common in such a small data set.  \\n One last thing, in this video, we used a tiny data set  \\n so it's easy to both find and then understand  \\n the mode, median, and mean,  \\n and now when you run up against a giant data set,  \\n you'll know that you can trust the mode, median, and mean  \\n to help you better understand your data.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2397816\",\"duration\":177,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Special circumstances\",\"fileName\":\"2866076_02_03_XR30_MMMSpecial\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to calculate and interpret the mean and median for different types of data sets.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5484565,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Mean, median, and mode,  \\n they're all helpful in understanding a data set,  \\n and they're all fairly easy to find or calculate.  \\n So, let's look at another data set  \\n to test our emerging statistics skills.  \\n Here's a bigger dataset.  \\n I'm an exercise file 02_03_Begin.  \\n A professor gave an exam to her class.  \\n These are the 20 exam scores.  \\n First, let's find the mode.  \\n If you look through the data set,  \\n you'll notice that no two students earned the same score,  \\n therefore, this data set does not have a mode.  \\n In case you were wondering what would happen  \\n if two students had a 90 and another two students had an 80,  \\n in that case, the data set would have two modes.  \\n This type of data set would be referred to as bimodal.  \\n So yes, a data set can have one mode, multiple modes,  \\n or as we saw in our data set, no mode at all.  \\n Next, let's find the median.  \\n Notice there are 20 values in our data set.  \\n So the middle value is the quantity n plus 1 divided by 2.  \\n N is the number of values in our data set, 20,  \\n and 20 plus 1 divided by 2 is 10.5.  \\n What does that mean?  \\n Well, because we have an even number of values.  \\n There's not a true middle value.  \\n So the 10.5 is telling us to find the 10th and 11th values.  \\n In this case, those are 75 and 76.  \\n We then take the average of the two values,  \\n the average of 75 and 76 is 75.5.  \\n So the median for this data set is 75.5.  \\n Half the students got below 75.5 on the exam,  \\n the other half got above 75.5 on the exam.  \\n Finally, let's find the mean for this data set.  \\n This would be the average of all 20 values.  \\n The sum of our 20 values is 1440,  \\n we have 20 values, our mean is 72,  \\n which is lower than the median of 75.5.  \\n Again, since our data set is relatively small,  \\n we can see why this is happening.  \\n Two students did significantly worse on the exam  \\n when compared to the other 18 students  \\n They got a 20 and a 27.  \\n Those two very low grades pulled down  \\n the average for the entire class.  \\n But if a student were to complain  \\n that the exam was too difficult,  \\n the professor might point to the median.  \\n While 72 may seem like a low average,  \\n over half the class got 75.5 on the exam.  \\n Additionally, the instructor may want to contact  \\n the two students to see why their scores were so much lower  \\n than the other 18 students.  \\n Means, medians, and modes.  \\n Find some data at work or on a sports site  \\n or on a business news site,  \\n and see if you can start to find  \\n the means, medians, and modes in your data set.  \\n \\n\\n\"}],\"name\":\"2. The Middle\",\"size\":19593187,\"urn\":\"urn:li:learningContentChapter:2404646\"},{\"duration\":1128,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2401664\",\"duration\":88,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Introduction to variability\",\"fileName\":\"2866076_03_01_MM30_Variability\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Data sets may have data points that are similar or that vary greatly. Statistics provides you with tools to measure variability.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3767153,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Mean, median, and mode,  \\n all helpful in understanding a data set.  \\n They're all simple concepts and all easy to calculate,  \\n but they have their limitations.  \\n For example, take these two dots or data points.  \\n Where is their midpoint? It's here.  \\n How about these two data points? Same middle.  \\n Both sets of dots have the same midpoint,  \\n but clearly the two sets of dots are very different.  \\n When we use real numbers, we find the same thing.  \\n All three of these tiny data sets have the same mean.  \\n The mean is 30,  \\n but each data set is obviously different.  \\n In data set one, the two data points are very close,  \\n but by the time we get to data set three,  \\n the two data points are very far apart.  \\n So how do we describe how close  \\n or how far away data points are from each other  \\n in a data set?  \\n In this chapter, we'll discuss range and standard deviation,  \\n two measures that help us understand  \\n how spread out the data points are in our data sets,  \\n which is something that statisticians like to refer to  \\n as variability,  \\n plus we'll discuss the very important empirical rule.  \\n And finally, we'll try  \\n and figure out what constitutes an outlier.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2403684\",\"duration\":145,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Range\",\"fileName\":\"2866076_03_02_MM30_Range\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to describe, calculate, and interpret the range and standard deviation. What's the relationship to the mean and median?\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6569742,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Look at these two small data sets.  \\n Both have the same average and median values.  \\n So, both have the same middle.  \\n Other than that, the data sets are quite different.  \\n These data sets are small,  \\n so we can quickly view all the data and see the differences,  \\n but what happens when the data sets are enormous?  \\n How could you measure variability?  \\n Well, if we think back to mean and median,  \\n we looked at the middle of the data set.  \\n So why not look at the edges of the data set?  \\n This is what the range does.  \\n The range is one of our measures of variability.  \\n To find the range,  \\n you simply subtract the smallest data point  \\n from the largest data point in the data set.  \\n So when we look at this data set, our range is 50,  \\n but in this data set, our range is 150.  \\n Easy enough, so let's put range to work.  \\n We can use this data set to explore  \\n how mean, median, and range can work together.  \\n 15 students took an exam.  \\n Here are the mean, median, and range:  \\n mean 60, median 58, range 70.  \\n Some may jump to the conclusion  \\n that the maximum value is 95 and the minimum value is 25.  \\n But here's the data.  \\n The minimum data point is 10.  \\n The maximum data point is 80.  \\n And if we use a histogram,  \\n we understand the data set even better.  \\n It's really because of one student the range is so large.  \\n Their lack of studying inflated the range.  \\n The range is a simple measure of variability.  \\n But as we just saw,  \\n it only takes one rogue data point  \\n to exaggerate the size of your data set's range,  \\n and that's why we'll want to look at standard deviation.  \\n The range only takes into account two data points.  \\n The standard deviation, on the other hand,  \\n measures variability by considering every data point.  \\n Let's look at that next.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2402704\",\"duration\":188,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Standard deviation\",\"fileName\":\"2866076_03_03_MM30_stdev\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Just how far is a data point from the mean? Standard deviations can help you figure this out.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8330724,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - A dataset is a collection of data points.  \\n We've seen that, together, these data points  \\n have a mean, median and mode.  \\n And we've also just seen that those data points  \\n have a standard deviation and a range.  \\n All of those tools helped us define the collective,  \\n tell a story.  \\n But how can we define each individual data point  \\n within the data set?  \\n For example, the dataset has a mean of 139 pounds,  \\n and a standard deviation of 41 pounds.  \\n The data set has a pretty big data point of 231 pounds.  \\n Other than saying it's a very big data point,  \\n or that it's 92 pounds above the mean,  \\n how else can we describe how big this data point is  \\n inside of this dataset?  \\n Well, we can describe individual data points  \\n by their distance from the mean  \\n by using the standard deviation.  \\n We refer to this as a data point's Z score.  \\n To find a Z score, we use this formula.  \\n As you can see, all you need is the dataset's mean  \\n and standard deviation.  \\n Then, all you do is plug in one of the values  \\n in the dataset.  \\n Let's try it.  \\n For this dataset, we have a mean of 139,  \\n and a standard deviation of 41.  \\n Let's plug in the largest value in the dataset, 231.  \\n 231 minus 139, and we divide by 41.  \\n So, this data point has a Z score of 2.24.  \\n That means 231 is 2.24 standard deviations  \\n from the mean in the positive direction.  \\n Let's find the Z score  \\n for another value in our dataset, 112.  \\n Same formula.  \\n Now, it's 112 minus our mean, 139.  \\n And we divide by the standard deviation, 41.  \\n Notice what happens here.  \\n Our Z score is negative.  \\n Negative 0.66, which makes sense since 112  \\n is smaller than our mean value, 139.  \\n Also, negative 0.66 indicates  \\n that this data point, 112,  \\n is relatively close to the mean, 139.  \\n So, we just discovered that one of the data points  \\n we chose had a Z score of 2.24.  \\n The other had a Z score of negative 0.66.  \\n And now you have a decent idea of how the Z score  \\n tells you a bit more about an individual data point  \\n and its relationship to the mean.  \\n Next, let's take a deeper look at standard deviation.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2896554\",\"duration\":161,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Calculating standard deviation\",\"fileName\":\"2866076_03_03a_XR30_calcstdev_2021Q3\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"While standard deviation can easily be calculated by an Excel spreadsheet, let's look at a simple example of how you can manually calculate standard deviation. That's why you'll want to use Excel to help you calculate the standard deviation for your data set.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5063705,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Narrator] While a spreadsheet can easily calculate  \\n the standard deviation of a given dataset,  \\n let's dig in and calculate the standard deviation ourselves.  \\n A reminder, standard deviation  \\n is sort of the average distance  \\n from the data set's mean  \\n to all the individual data points, but not quite.  \\n It's actually the average squared distance from the mean.  \\n Here's the formula for standard deviation.  \\n As you might imagine, the Sigma warns us  \\n that we'll be doing this calculation  \\n for every data point in our dataset.  \\n Yes, these calculations could get ugly quick.  \\n So to keep things simple,  \\n we'll be using a very small dataset.  \\n Let's use this data set with only four values,  \\n two, eight, 10, and 12.  \\n First, we need to find the mean  \\n of these four data points, which we'll call X-bar.  \\n The average of these four data points is eight.  \\n So X-bar is equal to eight.  \\n We also need N, the sample size.  \\n We have four data points, so N is equal to four.  \\n So now our formula looks like this,  \\n eight is our X-bar, four is our N.  \\n And remember, the Greek letter Sigma tells us  \\n we need to do the X minus eight calculation  \\n for each of our four data points.  \\n So for our first data point, we take two  \\n minus the mean of eight, which gives us negative six  \\n and negative six squared is 36.  \\n Our second data point is eight,  \\n eight minus eight means we square zero.  \\n Our third data point is 10 minus eight, which is two.  \\n So we square two, and our final data point is 12,  \\n 12 minus eight gives us four, so we square four.  \\n We then add up all the values in our numerator,  \\n 36, zero, four and 16, which gives us 56,  \\n which means we have 56 divided by three.  \\n This value, 18.7, we call this our variance,  \\n but the square root sign tells us we aren't done.  \\n And if we take the square root of 18.7,  \\n our variance, we get 4.32,  \\n which means the standard deviation of our dataset is 4.32.  \\n This was a small dataset.  \\n So calculating the standard deviation step-by-step  \\n was manageable, but as your data sets get really large,  \\n you may want to utilize a spreadsheet  \\n to help you find your standard deviation.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2400685\",\"duration\":104,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Big and small standard deviation\",\"fileName\":\"2866076_03_04_MM30_Bigsmall\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5417825,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Narrator] One dataset has a standard deviation of 20.  \\n Another, a standard deviation of 200.  \\n Which of these datasets has less variation?  \\n The answer is that it really depends.  \\n First, consider what you're actually measuring.  \\n A standard deviation of 20 degrees Celsius  \\n for daily high temperatures in Paris for one summer,  \\n it'd be huge.  \\n But a standard deviation of $200  \\n for the annual salaries of teachers across the country  \\n would not be as significant.  \\n In those examples, we were considering  \\n the dataset as a whole.  \\n But standard deviation is also used  \\n to investigate individual data points.  \\n For example, suppose a data scientist  \\n has an annual salary of $200,000.  \\n But the mean is $100,000,  \\n and the standard deviation is $50,000.  \\n We might say that they are  \\n two standard deviations above the mean.  \\n A data scientist that makes $50,000 per year  \\n is one standard deviation below the mean.  \\n As you can see, standard deviation  \\n can be a very helpful tool  \\n in understanding datasets and their individual data points,  \\n and most importantly, how those data points relate  \\n to the central tendency.  \\n Standard deviation will help us  \\n generate interesting questions  \\n about the data collection methods, the entire pool of data,  \\n and even the individual points of data.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2397817\",\"duration\":241,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Empirical rule\",\"fileName\":\"2866076_03_05_MM30_Empirical\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"One, two, or three standard deviations? The answer to this question tells you something about your data points or sets.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9723838,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - The empirical rule.  \\n I know, it sounds scary.  \\n But, actually the empirical rule is very useful  \\n for understanding the distribution  \\n of data points in our data sets.  \\n So what is it?  \\n First, it's important to note  \\n that this rule works for symmetrically,  \\n or normally distributed data.  \\n On this chart, the zero is in the middle of the x-axis.  \\n That's the mean of the data set.  \\n The data points in our data set are distributed  \\n in a bell shaped pattern that is centered at the mean.  \\n As you can see, our data are symmetrically distributed,  \\n or mirrored on each side of the y-axis.  \\n We call this a normal distribution.  \\n Once we understand this,  \\n we can now break down the empirical rule.  \\n The empirical rule tells us  \\n that most of the data points in our data set  \\n fall within three standard deviations of the mean.  \\n Notice, at the bottom along the x-axis  \\n the numbers one, two, three moving to the right  \\n and negative one, negative two,  \\n and negative three, moving to the left.  \\n The distance between each number represents  \\n one standard deviation.  \\n What's so interesting about the empirical rule is  \\n that it says when you have symmetrical distribution  \\n of the data, you can expect 68% of all your data points  \\n to be within one standard deviation.  \\n So, 68% of all the data points are  \\n within negative one and positive one on this graph.  \\n The empirical rule then goes on to say that 95%  \\n of all data points fall within two standard deviations  \\n of the mean.  \\n Again on our graph,  \\n 95% of all the data points  \\n are expected to be within negative two  \\n and positive two on this graph.  \\n And finally, the empirical rule tells us  \\n that when you have the bell shaped curve,  \\n often referred to as a normal distribution,  \\n 99.7% of the data points in the dataset  \\n will fall within three standard deviations.  \\n So, on our graph, 99.7% of all of our data points  \\n in the data set are under the curve  \\n between negative three and positive three.  \\n Only 0.3% of all our data  \\n is expected to fall outside of that region.  \\n A reminder though, this works when we have  \\n the well-centered, symmetrical bell shaped curve.  \\n Unfortunately, the empirical rule begins to lose value  \\n the farther our data set strays  \\n from the classical, normal distribution.  \\n To review, if a data point has a z-score of negative 0.8  \\n the data point is to the left of the mean  \\n near the negative 0.1.  \\n It's within one standard deviation of the mean,  \\n and it is part of the 68% of the data points  \\n that are closest to the mean.  \\n But, if a data point had a z-score above 3.2,  \\n we call that particular data point an outlier.  \\n Because, it's probably not among the 99.7%  \\n of all the data points closest to the mean.  \\n It would be very far to the right,  \\n a bit beyond three.  \\n As you can see, the empirical rule,  \\n the bell curve, and z-scores are great tools  \\n in understanding our data set as a whole,  \\n as well as, the individual data points in our data set.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2403685\",\"duration\":201,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Outliers\",\"fileName\":\"2866076_03_06_MM30_Outliers\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"When is a data point too far from the mean? Is this odd or interesting?\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11553388,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Nowadays, we hear the term outlier quite a bit.  \\n Often, it's used to describe some strange outcome.  \\n For example, a normal resting heart rate  \\n is between 60 and 100.  \\n One patient has a resting heart rate of 40,  \\n 20 beats lower than the expected range.  \\n Doctors might consider that an outlier.  \\n A 12-year-old child that graduates from college with honors,  \\n 10 years before most people.  \\n Most would say that that kid is an outlier.  \\n And consider this.  \\n Someone has a resting heart rate of 53.  \\n That's only seven beats below the expected range.  \\n Or if someone graduates college at 19,  \\n three years earlier than most.  \\n I guess what I'm asking is  \\n what exactly makes something an outlier?  \\n Most disciplines that count on statistics  \\n say that an outlier is a data point  \\n that is an abnormal distance from the other values  \\n in the dataset.  \\n But what's abnormal?  \\n Believe it or not, there is no singular definition  \\n of abnormal in the world of statistics.  \\n So the whole concept of outliers is inexact.  \\n In fact, these rogue or distant data points  \\n are topics of discussion.  \\n Take this data set.  \\n This data point is very different from the others.  \\n It really stands out.  \\n Should we just label it an outlier  \\n because it looks so different in a chart or on a graph?  \\n We could.  \\n Some people like to establish rules, though.  \\n For example, anything more than two standard deviations  \\n from the mean is an outlier.  \\n Still, in other cases, an outlier is just something new  \\n or unprecedented, like a 25% one-day drop  \\n in the stock market.  \\n Now that we have defined an outlier,  \\n what should we do with an outlier?  \\n Ignore it as an abnormal event?  \\n In general, I would say no.  \\n Unfortunately, some consider outliers as events  \\n that are not likely to be seen again.  \\n They prefer to ignore the outlier.  \\n To them, it's not worth investigating something so odd.  \\n But others, they see them as opportunities to learn.  \\n Maybe a strange and unexpected event  \\n is the beginning of a new trend.  \\n Will this odd event motivate a massive change in behavior?  \\n In the case of a great athletic feat,  \\n maybe this person knows something  \\n others haven't figured out yet.  \\n Perhaps strange weather aided their attempt.  \\n Did they trained differently?  \\n Did they use different equipment or technology?  \\n As you encounter potential outliers in your data  \\n at the office, or even in your hobbies,  \\n ask good questions.  \\n Is this really an outlier?  \\n How did this happen?  \\n What can we learn?  \\n What needs to change?  \\n A mass of closely distributed data points  \\n can be very instructive,  \\n but sometimes the lone outlier can provide us  \\n with a brand new perspective.  \\n \\n\\n\"}],\"name\":\"3. Variability\",\"size\":51221075,\"urn\":\"urn:li:learningContentChapter:2398853\"},{\"duration\":37,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2397818\",\"duration\":37,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Next steps\",\"fileName\":\"2866076_04_01_LA30_NextSteps\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7961705,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Thank you for spending some time with me  \\n and learning a little bit more about elementary statistics.  \\n I want to let you know that there's a part two  \\n to this course that covers probability in depth.  \\n Please check that out as well.  \\n Learning stats is definitely a long journey,  \\n and there's so much more complexity  \\n than what I've presented here today.  \\n However, this is a good starting point.  \\n I encourage you to continue moving forward  \\n with your statistics education,  \\n and perhaps you can become a stats savant,  \\n or perhaps you can become the outlier.  \\n \\n\\n\"}],\"name\":\"Conclusion\",\"size\":7961705,\"urn\":\"urn:li:learningContentChapter:2403687\"}],\"size\":102021946,\"duration\":1983,\"zeroBased\":false},{\"course_title\":\"Statistics Foundations 3: Using Data Sets\",\"course_admin_id\":2446433,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":2446433,\"Project ID\":null,\"Course Name\":\"Statistics Foundations 3: Using Data Sets\",\"Course Name EN\":\"Statistics Foundations 3: Using Data Sets\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"&lt;p&gt;Statistics are a core skill for many careers. Basic stats are critical for making decisions, discoveries, investments, and even predictions. But sometimes you need to move beyond the basics. This third course in the &lt;i&gt;Statistics Foundations&lt;/i&gt; series gives you practical, example-based lessons on the intermediate skills associated with statistics: Samples and sampling, standard errors, confidence intervals, and hypothesis testing.&lt;/p&gt;&lt;p&gt;Eddie Davila takes a look at topics like sampling, random samples, sample sizes, sampling error, trustworthiness, the central unit theorem, confidence intervals, and hypothesis testing. This course is a must for those working in data science, business, and business analytics\u2014or anyone who wants to go beyond means and medians and gain a deeper understanding of how statistics work in the real world.&lt;/p&gt;&lt;p&gt;This course is part of a &lt;a href=https://www.linkedin.com/learning/paths/anaconda-python-for-data-science-professional-certificate target=_blank&gt;Professional Certificate&lt;/a&gt; from Anaconda.&lt;/p&gt;&lt;p&gt;This course is part of a &lt;a href=https://www.linkedin.com/learning/paths/statistics-foundations-professional-certificate-by-wolfram-research target=_blank&gt;Professional Certificate&lt;/a&gt; from Wolfram Research.&lt;/p&gt;\",\"Course Short Description\":\"Go beyond the basics of statistics with practical, example-based lessons to learn how data sets and statistics are used in the real world.\",\"Content Type\":\"SKILLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":\"3349645\",\"Instructor Name\":\"Eduardo Davila\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"Associate Chair for the ASU Supply Chain Management program\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2022-07-15\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"Yes\",\"Has Challenge/Solution\":\"Yes\",\"LIL URL\":\"https://www.linkedin.com/learning/statistics-foundations-3-using-data-sets,https://www.linkedin.com/learning/statistics-foundations-using-data-sets,https://www.linkedin.com/learning/statistics-foundations-using-data-sets-2022-revision-of-statistics-foundations-2-high-visibility\",\"Series\":\"Foundations\",\"Limited Series\":null,\"Manager Level\":\"General\",\"LI Level\":\"Intermediate\",\"LI Level EN\":\"Intermediate\",\"Sensitivity\":null,\"Internal Library\":\"Technology\",\"Internal Subject\":\"Data Science\",\"Primary Software\":null,\"Media Type\":\"Video\",\"Has CEU\":\"Yes\",\"Has Exercise Files\":\"Yes\",\"Visible Duration\":6057.0,\"Visible Video Count\":21.0,\"Learning Objectives\":\"Describe how non-representative samples can lead to biased conclusions in the context of polling.,Recognize the characteristics and process of obtaining a convenience sample.,Explain how concepts such as the law of large numbers and the central limit theorem are relevant to understanding the impact of sample size.,Assess how confidence intervals contribute to the overall reliability and validity of election poll results.,Discuss the role of test statistics in hypothesis testing and how they are used to find the p-value.\",\"Contract Type\":\"PERPETUAL\",\"Certifications\":\"CPE:National Association of State Boards of Accountancy (NASBA)::Statistics\",\"Framework Topic\":null,\"Automatic Caption Translations\":\"Global Captions\",\"Automatic Metadata Translations\":\"Global Metadata\",\"Gen AI Feature Flag\":null,\"Hands-On Practice\":null,\"Hands-On Practice Library\":null,\"Unlocked for Viva Learning\":\"Global Captions\",\"Free Course\":null,\"Certification Library\":\"Certifications\",\"Github Codespace\":null,\"Skills Count\":2,\"Skills\":\"Statistical Data Analysis,Statistics\",\"Skills EN\":\"Statistical Data Analysis,Statistics\",\"Content Manager\":\"Steve Weiss\",\"Acquisition Manager\":\"Steve Weiss\",\"Framework Subject\":null},\"sections\":[{\"duration\":124,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3082812\",\"duration\":124,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Discover samples, confidence intervals, and hypothesis testing\",\"fileName\":\"2446433_en_US_00_01_WL30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"In this course, discover data, distributions, probability, and random variables. Learn how this all ties to samples and sampling.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2292908,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - As a person that loves statistics,  \\n perhaps as someone who just appreciates statistics,  \\n you're probably comfortable with the basics,  \\n means, medians, standard deviations,  \\n probabilities, and normal distributions.  \\n They're all part of your stats vocabulary.  \\n But perhaps for you, stats appreciation is not enough.  \\n You want to collect your own data,  \\n you want to make a reasonable decision based on data,  \\n and you'd like to test statistical assumptions.  \\n If that sounds like you, you've come to the right place  \\n because that is what this course is all about.  \\n This course, Statistics Foundations: Using Data Sets,  \\n is the third of a four-part series  \\n that I'm hoping will empower you to better understand  \\n the numbers you will encounter in your life.  \\n In this course, we'll discuss the collection of data  \\n and the importance of the simple random sample.  \\n We'll look at confidence intervals,  \\n and we'll discover the importance of hypothesis testing  \\n in the fields of science, business, and beyond.  \\n Hi, my name is Eddie Davila.  \\n I'm a university instructor  \\n with degrees in business and engineering.  \\n I write ebooks.  \\n And of course, I develop online educational content.  \\n I'm a huge sports, music, and movie fan,  \\n and I'm passionate about science and health.  \\n And I can tell you that in every important facet of my life,  \\n having a better understanding of statistics  \\n allows me to improve my performance  \\n and often to find a greater level of satisfaction  \\n whether I'm working or playing.  \\n And I'll tell you, I think you'll walk away  \\n with a new perspective after watching this course.  \\n You won't just understand the power of data and statistics.  \\n You'll understand some of the common mistakes  \\n and misconceptions about statistics.  \\n Welcome to Statistics Foundations: Using Data Sets.  \\n A better understanding of the incredible power  \\n of collecting data through samples  \\n is just around the corner.  \\n \\n\\n\"}],\"name\":\"Introduction\",\"size\":2292908,\"urn\":\"urn:li:learningContentChapter:3087927\"},{\"duration\":773,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3088170\",\"duration\":194,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Sample considerations\",\"fileName\":\"2446433_en_US_01_01_MM30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Samples allow you to understand large groups with small groups of data. In this video, learn about sample considerations you should make before you gather a sample: size, quality, and selection techniques.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2941951,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Imagine that you're a candidate  \\n trying to get elected as mayor of a city  \\n with one million people.  \\n Your campaign wants to calculate your chances of winning.  \\n The election is only one month away,  \\n and the campaign has a limited budget.  \\n So this means the team doesn't have the time  \\n or the money to ask every voter what they think.  \\n Believe it or not,  \\n this situation occurs more frequently than you think.  \\n You want to know everything,  \\n but measuring everything is impossible.  \\n You can't poll every voter,  \\n just like a manufacturer can't measure the quality level  \\n of every single cell phone.  \\n A farmer can't measure the average size of every tomato.  \\n And think about scientists, they can't track the health  \\n of every single person in the country.  \\n When you can't measure an entire population,  \\n you can instead use a sample.  \\n A sample is a section or subset of an entire population.  \\n And under the right circumstances,  \\n a sample can act as a good representative  \\n of the entire population.  \\n But gathering that good representative sample is tough.  \\n Let's look back at our election example.  \\n Remember, the city has a population  \\n of one million eligible voters  \\n but you discover a polling organization took a sample.  \\n They discovered that 60% of the people in the sample  \\n support your opponent.  \\n Only 40% of the sample support you.  \\n Before you panic,  \\n let's ask some simple questions about that sample.  \\n What was the size of the sample?  \\n How many of those one million eligible voters were polled?  \\n 100, 1,100, 100,000?  \\n Small samples often have large margins of error  \\n but even a large sample can be flawed.  \\n And the selection process is important.  \\n Let's say you polled 5,000 people.  \\n How are those 5,000 people selected?  \\n Were they called on the phone  \\n or approached outside of a grocery store?  \\n And how many people decline to be surveyed?  \\n Also, is it possible the polling organization was biased?  \\n Some unethical polling groups try to collect biased data,  \\n data that isn't truly representative of the population.  \\n And other groups are just sloppy.  \\n They want to collect good data  \\n but they don't understand basic sampling methodology.  \\n Also, how did they measure?  \\n Which questions were asked in the poll?  \\n It's possible that questions were too complex,  \\n confusing, or even misleading.  \\n Strangely enough, despite the endless list  \\n of sample considerations,  \\n the best samples are the ones that are chosen at random.  \\n - The simple random sample is the gold standard  \\n when it comes to collecting data,  \\n but in the world of statistics, nothing comes easy.  \\n So let's look at the complex nature  \\n of the simple, random sample.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3088171\",\"duration\":281,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Random samples\",\"fileName\":\"2446433_en_US_01_02_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn about random samples and the challenges of gathering a random sample.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4252563,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Typically, we can't gather the data  \\n for an entire population.  \\n It's either too expensive, too time consuming,  \\n or it's just not possible.  \\n So ideally, statisticians look to gather data  \\n from parts of the population, a sample of the population.  \\n And the most dependable data  \\n comes from what's called a simple random sample.  \\n In a simple, random sample,  \\n each individual in the population has the same probability  \\n of being chosen for inclusion in the sample  \\n as any other individual.  \\n Or each subset of K individuals  \\n has the same probability of being chosen for the sample  \\n as any other subset of K individuals.  \\n For example, in a town of 10,000 people,  \\n any 100 people in the town are just as likely  \\n to be chosen for inclusion in the sample  \\n as any other 100 people in the same town.  \\n But gathering a simple random sample is not that simple.  \\n Actually, it's quite difficult.  \\n Why, well, a simple random sample  \\n must exhibit two key characteristics.  \\n The sample must be unbiased,  \\n and the data points must be independent.  \\n So let's discuss bias and independence.  \\n And let's also see why each characteristic  \\n can be so elusive.  \\n A simple random sample is one  \\n where every member of the population  \\n has an equal chance of being chosen.  \\n Now, why is this so difficult to achieve?  \\n Well, let's consider phone surveys.  \\n We'll have our pollster randomly select numbers  \\n from a long list of phone numbers.  \\n How could this be biased?  \\n Well, some people have multiple phones,  \\n personal phones, work phones.  \\n They may be more likely to get calls.  \\n And some people never answer calls from unknown numbers.  \\n They'll never get polled.  \\n The time of the call  \\n might better target certain types of people.  \\n How about in-person polls and surveys?  \\n The location of the pollster may favor certain people.  \\n Also, our pollster may seek out certain types of people,  \\n attractive, non-threatening,  \\n or perhaps our pollster is intimidating.  \\n That could definitely influence participation.  \\n If the data was collected on a university campus,  \\n the majority of participants  \\n might have very similar demographics.  \\n How about online surveys?  \\n These are completely optional,  \\n so they often are easy to avoid.  \\n Then again, some people may take them multiple times.  \\n How about if our poll pays participants?  \\n This might mean we're gathering data  \\n from people that want or need money.  \\n This probably has you questioning  \\n almost every study or poll you've ever seen.  \\n Yes, some unethical organizations  \\n intentionally seek out biased samples.  \\n But as you can see,  \\n sometimes even the most reputable organizations  \\n can have difficulty gathering a truly random sample.  \\n Now that we've covered bias,  \\n let's move to the characteristic of independence.  \\n The data in the sample must exhibit independence.  \\n What does that mean?  \\n It means that the selection of one participant  \\n must not influence the selection of other participants.  \\n If a scientist is trying to measure the average size  \\n of a fish in a lake,  \\n are certain fish likely to be frightened away  \\n by the presence of the boat?  \\n And are others likely to swim away  \\n when they see that first fish get caught?  \\n Or consider a voluntary survey,  \\n where subjects are paid for participation.  \\n Is it possible that a person that volunteers  \\n tells their friends about this paid opportunity?  \\n Now we have numerous people from the same friend group.  \\n Alternately, if the participant  \\n felt the payment was too low,  \\n they might tell their friends to stay away.  \\n Sometimes you're given a complete data set.  \\n Other times, you need to collect the data.  \\n In either case, remember, the simple random sample  \\n is the key to statistically dependable data sets.  \\n Samples must be unbiased,  \\n and the data points must be independent.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3080914\",\"duration\":298,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Alternative to random samples\",\"fileName\":\"2446433_en_US_01_03_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn about the pros and cons of alternate samples: stratified, cluster, systematic, and opportunity.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4488286,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - The simple random sample.  \\n It's the foundation of dependable  \\n statistical analysis.  \\n But as we've seen,  \\n the simple random sample can be rather elusive.  \\n Eliminating bias,  \\n and maintaining data independence  \\n is challenging.  \\n That's why some people use  \\n alternative sampling methods.  \\n Now, before we explore  \\n these sampling alternatives,  \\n I want to be sure you understand  \\n that the simple random sample is still  \\n the only way to get  \\n dependable statistical outcomes.  \\n Yeah, I know.  \\n Some of you are probably  \\n screaming at the screen right now,  \\n \\\"Hey, if the simple random sample  \\n is the only way  \\n to ensure dependable results,  \\n why would anyone use these alternatives?  \\n Well, these alternative methods  \\n are simple.  \\n Simple to organize, easy to carry out,  \\n and often they seem both logical and sound.  \\n Let's quickly look  \\n at some of these alternative  \\n sampling methods,  \\n and the weaknesses associated  \\n with each one.  \\n For a systematic sample,  \\n simply choose one unit,  \\n and then every K unit thereafter.  \\n So if you are measuring  \\n customer satisfaction at a store  \\n perhaps you might ask the first person  \\n to come out of the store for their opinions,  \\n and then you might ask every fifth customer  \\n after them for their opinion.  \\n So what are the weaknesses  \\n of the systematic sample?  \\n The sampling time and sampling location  \\n might give you bias results.  \\n Collector might introduce  \\n or inhibit independence.  \\n For an opportunity sample,  \\n the sampler simply takes the first N number  \\n of units that come along.  \\n Suppose you wanted to do a study  \\n on being a parent in the modern age.  \\n Maybe you distribute 10,000 surveys  \\n to parents of children that attend  \\n some public elementary schools  \\n in the city of Chicago.  \\n 525 of the 10,000 surveys are returned.  \\n What do you think some of the weaknesses  \\n of this sample could be?  \\n Well, the location of the schools.  \\n The age of the children.  \\n The letter that accompanies the survey.  \\n The types of parents  \\n that respond and the motivations of the parents  \\n that fill out the survey will likely  \\n create both bias and independence challenges.  \\n A stratified sample  \\n is one where the total population  \\n is broken up into homogenous groups.  \\n Suppose we want to find  \\n children's favorite colors  \\n in a school district.  \\n The district has four schools,  \\n and 1,000 children total.  \\n But each school  \\n has a different number of children.  \\n Suppose we wanted to pull 100 children,  \\n 10% of the district.  \\n We would then pull 10% of the children  \\n at each school.  \\n The weaknesses of stratified sampling.  \\n Well, we don't know  \\n which sampling technique or techniques  \\n were used to pick the students  \\n from each school.  \\n Also, maybe the students at school D  \\n all pick the school's colors  \\n instead of their actual favorite color.  \\n As you can see,  \\n both bias and independence  \\n could be problems here.  \\n A cluster sample is similar  \\n to stratified samples  \\n in that we break things up in the groups.  \\n What's the difference?  \\n In stratified groups,  \\n all the members of a single group  \\n were the same.  \\n In clusters, the groups are likely  \\n to have a mix of characteristics.  \\n Suppose we're testing a new product.  \\n We would choose 20 US cities.  \\n In each city,  \\n we ask 300 people to rate the new product.  \\n While the people in a single sample  \\n might all be from the same city,  \\n each sample might contain men and women.  \\n People of different races, academic degrees,  \\n and socioeconomic backgrounds.  \\n So as you can see,  \\n these alternative sampling methods  \\n appear rather logical,  \\n and in some cases fairly simple.  \\n Actually, my guess is that  \\n if you yourself have done a simple study,  \\n you've probably used one of these methods  \\n to collect data  \\n for the very reasons I just stated.  \\n Is that a bad thing?  \\n No, not really.  \\n But again, it's important to understand  \\n the limitations of your study.  \\n The reported results,  \\n and very likely your analysis.  \\n At the same time,  \\n these simple but flawed sampling techniques  \\n may tell us some things  \\n we didn't know or hadn't considered.  \\n This may inspire us to ask bigger questions.  \\n They might help us to gain funding  \\n for a bigger study.  \\n And ultimately,  \\n these alternative sampling methods  \\n may spark more robust and rigorous studies.  \\n The simple random sample  \\n will always be the gold standard  \\n but these alternative sampling methods  \\n should not be completely dismissed.  \\n \\n\\n\"}],\"name\":\"1. Sampling\",\"size\":11682800,\"urn\":\"urn:li:learningContentChapter:3085848\"},{\"duration\":598,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3083791\",\"duration\":338,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"The importance of sample size\",\"fileName\":\"2446433_en_US_02_01_MM30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"The size of a sample dictates if your results are valuable. In this video, learn why a larger sample size is better.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5090597,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - A sample is a group of units drawn from a population,  \\n and the sample size is the number of units drawn  \\n and measured for that particular sample.  \\n Now, the total population itself  \\n may be very large or perhaps immeasurable,  \\n so a sample is just looking at a slice of the population  \\n in the hopes of providing us  \\n a representative picture of the entire population.  \\n As you might guess, the larger the sample size,  \\n the more accurate our measurement,  \\n or at least the more confidence we have  \\n that our sample is a good representative  \\n of the entire population.  \\n But, just how important is sample size?  \\n Well, let's first establish how an experiment might look.  \\n Let's say we own a machine that manufacturers forks,  \\n the forks manufactured by the machine  \\n are judged as either acceptable or defective.  \\n This is a magic fork manufacturing machine.  \\n Over its entire existence,  \\n it will manufacture exactly 90% good forks,  \\n and exactly 10% defective forks.  \\n The machine won't break down and it won't get tired,  \\n as I said, it's a magic fork machine.  \\n So, the value of p for this machine is 0.90.  \\n Remember, p is the proportion  \\n of good forks this machine produces,  \\n 90% of all the forks this machine  \\n will ever produce will be good forks.  \\n Look, we don't actually know that right now,  \\n the machine can't tell us that.  \\n We can't know the actual true p  \\n until the machine has produced a lifetime of forks.  \\n But if enough samples are collected over time,  \\n we would find that the average of the proportions  \\n for all the samples measured would approach  \\n the true p value of 0.90.  \\n In our Central Limit Theorem video,  \\n I'll show you how this happens, but for now,  \\n let's just accept that this is true.  \\n Anyway, if we had five forks in our sample,  \\n and four were good and one was bad, p^,  \\n which is the acceptable proportion  \\n for this particular sample,  \\n p^ would be four good forks  \\n divided by five total forks in our sample.  \\n p^ is equal to 0.80.  \\n That's just one sample,  \\n you'd collect a bunch of samples,  \\n average their p^, and hope that the samples  \\n were pointing you toward the true p.  \\n I know, I know, you're wondering,  \\n \\\"What does this have to do with a sample size?\\\"  \\n Well, without actually knowing the true p, 0.90,  \\n using only the average of all our previous p^,  \\n what we'd like to know is, for any given sample,  \\n how likely is it that I'm close to the real p 0.90?  \\n Well, let's assume our p^ are normally distributed,  \\n in other words,  \\n they take on the shape of the famous bell curve.  \\n If that's true, we can calculate  \\n our standard deviation for our p^  \\n and assume that 68% of our p^ would fall  \\n within one standard deviation of the true value of p.  \\n And this is where sample size becomes important, why?  \\n Well, let's take a look at the formula  \\n for standard deviation.  \\n In this formula, p would be 0.90,  \\n that would not change,  \\n but we want to see the impact of having a larger sample size.  \\n n represents the sample size.  \\n For this example, if n is equal to five,  \\n then one standard deviation would be 0.134.  \\n So it's 13.4% from 90% in either direction,  \\n which means that with a sample size of five,  \\n we would expect 68% of all of our samples  \\n to have between 76.6% and 100% good forks.  \\n 100% is the maximum since we can't have more  \\n than 100% good forks.  \\n 76.6% to 100% is a pretty large range.  \\n Let's try some larger sample sizes.  \\n If n is equal to 25, 1 standard deviation would be 6%.  \\n If n is equal to 100, 1 standard deviation would be 3%.  \\n And n equals 400 gives us a standard deviation of 1.5%.  \\n At n equals 400, we would expect 68%  \\n of all our samples collected to have  \\n between 88.5% and 91.5% good forks,  \\n much closer to our true p.  \\n The bigger the sample size,  \\n the smaller our standard deviation.  \\n The bigger the sample size, the more confident we are  \\n that our sample's p^ is close  \\n to the population's actual p.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3088172\",\"duration\":260,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"The central limit theorem\",\"fileName\":\"2446433_en_US_02_02_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"The central limit theorem helps you understand how data is likely to be distributed even with smaller samples.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3931812,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - The central limit theorem.  \\n Just saying those words can be a little intimidating.  \\n I mean, it sounds complicated,  \\n but it turns out it's a rather simple concept,  \\n a concept that's not only important  \\n to our world of statistics, but dare I say,  \\n it's also a concept that is rather interesting.  \\n Let's start simple, a distribution of discrete numbers.  \\n We start on the left, where we have five values of 5.  \\n We move right along our distribution,  \\n two units of 10, four units of 15, six units of 20.  \\n And on the right of our distribution,  \\n we have three values of 25.  \\n 20 different readings in our entire population.  \\n If we average out the values of our 20 different readings,  \\n we get an average of 15.0.  \\n Now, suppose we didn't want to tally up all 20 values,  \\n but we still wanted to find the average of the data set.  \\n Could we use samples to direct us to the population mean?  \\n Let's try it.  \\n I used a number randomizer  \\n to take three samples of four units each.  \\n Here's our first sample.  \\n Sample one: 20, 20, 20, 15.  \\n Our sample mean for this sample is 18.75.  \\n Sample two: 5, 20, 5, 20.  \\n Our sample mean for sample two is 12.5.  \\n Sample three: 5, 25, 15 20.  \\n Our sample mean here is 16.25.  \\n We have three samples,  \\n thus, we have three sample means 18.75, 12.5, and 16.25.  \\n If we average those, we get the mean of our means, 15.83,  \\n not too far off from our actual population mean of 15.0.  \\n Now I know what you're saying.  \\n \\\"These are three handpicked samples,  \\n each with only a sample size of four.  \\n Couldn't this all just be luck?\\\"  \\n Well, the central limit theorem tells us that it's not luck.  \\n The central limit theorem tells us the more samples we take,  \\n the closer the mean of our sample means  \\n will get to the population mean.  \\n Actually, it's even more interesting.  \\n Because as we start to take many more samples,  \\n dozens of samples, hundreds of samples,  \\n even thousands of samples,  \\n the sample means, if plotted as a histogram,  \\n would look like this.  \\n Yes, we start to see that the sampling distribution  \\n of our sample means is looking quite a bit  \\n like a normal distribution.  \\n But wait, it gets more interesting.  \\n In our very simple example, we had a sample size of four.  \\n Suppose we increase our sample size to six.  \\n If we, again, take thousands of samples,  \\n look what happens to our distribution.  \\n And if our sample size increases to 10,  \\n as you're probably noticing,  \\n as sample size increases,  \\n the curve looks more like the normal curve.  \\n Also, the curve is getting taller and more narrow,  \\n which means a larger sample size  \\n gives us a smaller standard deviation.  \\n As I said, the central limit theorem is sort of simple,  \\n really interesting, and obviously, incredibly important  \\n in the world of statistics.  \\n And while we use a tiny population of discrete values,  \\n the central limit theorem works with massive populations  \\n and also with continuous values.  \\n So, no matter if your interests lie in agriculture,  \\n academic test scores, political polls, or medical studies,  \\n a few simple random samples  \\n and the central limit theorem  \\n can help you better understand the overall population.  \\n \\n\\n\"}],\"name\":\"2. Sample Size\",\"size\":9022409,\"urn\":\"urn:li:learningContentChapter:3087928\"},{\"duration\":871,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3086782\",\"duration\":396,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Standard error for proportions\",\"fileName\":\"2446433_en_US_03_01_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn what a sampling error is, how it is calculated, and what role the sample size plays in the size of the sampling error.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5963925,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Before we dive into standard error,  \\n let's recap a few things we already know.  \\n In an experiment,  \\n we may collect numerous simple random samples.  \\n Each sample has a sampling proportion.  \\n For example, in a sample of 10 students,  \\n eight of 10 students passed the test.  \\n 80% is our sampling proportion.  \\n Remember, we have numerous simple random samples.  \\n When data is normally distributed,  \\n we expect 68% of simple random samples  \\n collected from the population  \\n to fall within one standard deviation  \\n of the population proportion.  \\n In other words, if the actual population proportion is 70%  \\n and one standard deviation is 10%,  \\n we would expect 68% of simple random samples to fall  \\n between the lower limit of 60% and an upper limit of 80%  \\n which brings us to the standard error.  \\n The standard error  \\n is the standard deviation of our proportion distribution.  \\n Let's use an example to calculate the standard error  \\n and then tie it back to everything we've learned so far.  \\n In the cell phone industry,  \\n companies struggle to keep their clients happy.  \\n Suppose a reputable national poll finds that 60% of adults  \\n are satisfied with their cell phone provider.  \\n Let's take that as our population proportion, 0.60.  \\n I want to know if my city reflects the national average.  \\n To do this, I take some simple random samples  \\n of 100 cell phone users in our city.  \\n 100 users isn't a very big sample size,  \\n especially for a big city.  \\n So I know there will be some level of error  \\n with each of my samples.  \\n This is the standard error.  \\n So how big is the standard error in this situation?  \\n As you might have guessed,  \\n the size of the standard error depends on sample size.  \\n Here is our formula for the standard error.  \\n p is the national population proportion, 0.60,  \\n and n is the sample size for my simple random samples, 100.  \\n So we find that for n equals 100,  \\n our standard error is approximately 0.05 or 5%.  \\n This is the size of one standard deviation.  \\n And if we assume national cell phone data  \\n is normally distributed,  \\n we would expect 68% of all my simple random samples  \\n with a sample size of 100  \\n to have sample proportions, or p-hats,  \\n that are within one standard deviation  \\n of the population proportion.  \\n With a population proportion of 60%,  \\n I would expect 68% of all p-hats  \\n to be between 55% and 65%.  \\n So if tomorrow, we gathered a simple random sample  \\n of 100 cell phone customers  \\n and 57% of those customers were satisfied,  \\n we could say that our city was likely on par  \\n with the national proportion of 60%  \\n because we were within the 5% standard error.  \\n Then, again, if we could afford  \\n to take simple random samples  \\n with sample sizes of 1,000 cell phone customers,  \\n notice what happens here.  \\n Since n is now 1,000,  \\n our standard deviation drops to about 0.015 or 1.5%.  \\n So if n is equal to 1,000,  \\n we would expect 68% of those larger samples  \\n to have p-hats between 58.5% and 61.5%.  \\n Again, that's what we would expect.  \\n But what happens when 68% of our samples are not falling  \\n within our calculated upper and lower limits?  \\n Well, it doesn't necessarily mean our data is bad.  \\n Perhaps, it signals that something in our city is different  \\n from the overall nation.  \\n Customers, cell phone companies, or a combination of the two  \\n might create a unique environment in our city.  \\n Perhaps, there is a flaw  \\n in the reported national average of 60%.  \\n Maybe their data-gathering techniques were flawed.  \\n Maybe the national market has changed  \\n since that number was first reported.  \\n Or perhaps, my sampling method was biased.  \\n As you can see, standard errors are helpful  \\n when trying to understand a large population  \\n with the help from some simple random samples.  \\n That said, samples that fall beyond the standard error  \\n shouldn't be deemed failures.  \\n They should be analyzed and discussed.  \\n You never know they may lead you  \\n to some interesting discoveries.  \\n So let's recap.  \\n The standard error  \\n in situations where we were looking at proportions  \\n is a standard deviation.  \\n This is the formula for the standard deviation  \\n of a sample proportion, p-hat.  \\n The bigger our sample size,  \\n the smaller our standard deviation.  \\n This standard deviation is our standard error.  \\n The standard error allows us to set up a range  \\n around the population proportion  \\n that extends the equivalent of one standard deviation  \\n in both the positive and negative direction.  \\n The formula for our upper limit  \\n is p plus the standard deviation.  \\n And for our lower limit,  \\n it's p minus the standard deviation.  \\n Once the range is established,  \\n if we assume the probability distribution is nearly normal,  \\n then we would expect that 68%  \\n of the simple random samples gathered in the upcoming weeks  \\n would fall within the standard error.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3080915\",\"duration\":222,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Sampling distribution of the mean\",\"fileName\":\"2446433_en_US_03_02_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to find the average weight of bags of dog food sold by a company and the miles per gallon of a vehicle.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3366852,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Through the use of the central limit theorem,  \\n we've seen just a few simple random samples guide us  \\n in the direction of the population proportion.  \\n We can do the same with the mean of a population.  \\n Suppose there's a league of college basketball players.  \\n 3,000-plus players are in the league.  \\n We'd like to know the average weight  \\n of basketball players in the league,  \\n the population mean.  \\n But we don't want to weigh all 3,000-plus players.  \\n What can we do?  \\n Well, we can take four simple random samples.  \\n Each sample includes the weight  \\n of five players in the league.  \\n Our sample size is five.  \\n As you can see, in Sample A,  \\n the five players had weights of 180, 160,  \\n 205, 195, and 145.  \\n The mean weight of this sample is 177.  \\n Here are the three other samples.  \\n Sample B has a mean of 174.  \\n Sample C has a mean of 181.  \\n And Sample D has a mean of 172.  \\n If we then average those four sample means,  \\n 177, 174,  \\n 181, and 172,  \\n we get the mean of our sample means, 176.  \\n Now truth be told, I had a huge data set,  \\n and I took my simple random samples from the data set.  \\n So I know that the true population mean  \\n of my entire data set is 180.  \\n Pretty incredible, right?  \\n With only four samples and a sample size of five,  \\n I was able to get a meaningful approximation  \\n of the true population mean.  \\n The mean of my sample means was 176.  \\n The true population mean is 180.  \\n And the central limit theorem tells us  \\n as we increase the number of samples  \\n and we increase the sample size,  \\n we should get closer to the true population mean.  \\n I couldn't resist trying.  \\n I picked six new simple random samples from my data set.  \\n This time I used a sample size of eight.  \\n The mean of our means for these six samples is 180.5.  \\n Incredibly close to the true population mean of 180.  \\n So now, when faced with a very large  \\n or even massive population,  \\n we can trust that the central limit theorem  \\n and some simple random samples can point us in the direction  \\n of the true population mean.  \\n Let's say instead of 3,000-plus  \\n male college basketball players,  \\n we wanted to know the average weight  \\n of 18 to 24-year-old men in the United States colleges.  \\n There are millions of young males in college,  \\n but that shouldn't be a concern.  \\n The central limit theorem and your diligent efforts  \\n to collect some simple random samples  \\n will give you a reasonable approximation  \\n of the average weight of the entire population  \\n of male college students.  \\n And as usual, more simple random samples  \\n and larger sample sizes help us approach  \\n the true population mean.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3084810\",\"duration\":253,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Standard error for means\",\"fileName\":\"2446433_en_US_03_03_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how, once you have the sampling distribution of means, you can calculate the standard error for means.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10255127,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Through the use of the central limit theorem,  \\n we've now seen how taking just a few simple random samples  \\n can guide us in the direction of the population mean.  \\n Of course, when we use only a few samples  \\n to try and figure out a population mean,  \\n we understand that the average of our sample means  \\n isn't perfect.  \\n It comes with a standard error.  \\n So how do you figure out the standard error  \\n for our simple random samples?  \\n Let's say we're trying to figure out how long it takes  \\n to get our coffee drinks at the local cafe  \\n between 7:00 am and 8:00 am on weekday mornings.  \\n We take samples on four different weekdays.  \\n Our sample size for each of these samples is five.  \\n Here's our data for those days, times are in minutes.  \\n So for sample A we can see that the time it took  \\n our five customers to get coffee ranged  \\n from 0.6 minutes to 2.4 minutes.  \\n The average or mean for sample A was 1.58 minutes.  \\n If we take the average of the sample means  \\n or the mean of our means, we find that the average time  \\n to get a coffee drink was about 1.52 minutes.  \\n Using those four sample means we can also  \\n calculate the standard deviation  \\n of our sample means, 0.25 minutes.  \\n The standard deviation of our sample means  \\n this is our estimated standard error  \\n and this formula shows the relationship  \\n between the standard deviation of sample means 0.25  \\n and the standard deviation of the entire population  \\n of drink order times.  \\n Take a look at this formula.  \\n Sigma X bar is equal to sigma over the square root  \\n of our sample size n.  \\n Sigma X bar is our standard error 0.25.  \\n So it is the standard deviation of our four sample means.  \\n On the other side of the equation, we have another sigma.  \\n This sigma is the standard deviation  \\n for the entire population.  \\n So by plugging in our calculated standard error  \\n from our cafe example, which was 0.25 minutes  \\n and then plugging in five for n our sample size  \\n we can then solve for sigma,  \\n our population's standard deviation.  \\n We can see that based on these four samples,  \\n with a sample size of five,  \\n we can estimate the population standard deviation  \\n is about 0.56 minutes.  \\n Again, we can see how sample size can have a huge impact  \\n on working with samples to find out information  \\n about the entire population.  \\n In essence, what the formula tells us  \\n is that if we use larger sample sizes  \\n our standard error gets smaller.  \\n This is also important as we collect samples in the future.  \\n Why?  \\n Well, when we collect another sample of drink  \\n order times tomorrow and the rest of the week  \\n we would expect that 68% of our samples  \\n will have sample means that fall within 0.25 minutes  \\n of 1.52 minutes which is the calculated mean of our means.  \\n The standard error formula is very simple  \\n but still very informative.  \\n By understanding the simple relationship  \\n between sample size, the standard deviation  \\n of our population and the standard deviation  \\n of our sample means, we can better understand  \\n our population as well as the samples  \\n we will be taking going forward.  \\n \\n\\n\"}],\"name\":\"3. Standard Error\",\"size\":19585904,\"urn\":\"urn:li:learningContentChapter:3084813\"},{\"duration\":1458,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3083792\",\"duration\":182,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Introduction to confidence intervals\",\"fileName\":\"2446433_en_US_04_01_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, instead of finding results, you are given results and then asked how sure you are about those results. Are you 75% sure, 85% sure?\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2771391,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - The central limit theorem,  \\n it tells us that with multiple simple random samples,  \\n we can get a great approximation  \\n of the population mean.  \\n And the larger  \\n the sample size of those random samples, the smaller  \\n the standard deviation of our distributions,  \\n and the more certain we can be  \\n about our population mean estimate.  \\n In other words, more samples  \\n and larger sample sizes are a good thing.  \\n But in this section,  \\n we're going to go in the opposite direction.  \\n We're going to look at the power  \\n of having only a single random sample.  \\n We're going to look at confidence intervals.  \\n In this section,  \\n you'll often see results that look like this.  \\n We are 95% confident that the average adult  \\n in the United States drinks  \\n between two and three liters of beverages per day.  \\n Here's the incredible part.  \\n With one simple random sample,  \\n this statistician created an interval,  \\n an interval that stretches  \\n from a lower limit to an upper limit.  \\n In this example, it stretched from two liters  \\n to three liters, and the statistician assigned a level  \\n of confidence to that interval.  \\n In this example,  \\n the statistician that created the interval is 95% certain  \\n that the actual population mean for US adults  \\n is between two and three liters of beverages.  \\n Think about how incredibly powerful this is.  \\n One single random sample allows us to be 95% confident  \\n that our interval actually contains  \\n the real population mean.  \\n That's an incredibly efficient use of resources,  \\n but before we move on,  \\n let's take a moment to discuss  \\n what a 95% confidence level means.  \\n Suppose that instead  \\n of taking just one single random sample, we took 20 samples,  \\n and then suppose for each of the 20 samples,  \\n we created a 95% confidence interval.  \\n So we'd now have 20 95% confidence intervals.  \\n We would expect 95% or 19 of those confidence intervals  \\n to contain the real population mean,  \\n and we'd expect 5% or one confidence interval  \\n to not contain the real population mean.  \\n So even with a single sample,  \\n you're feeling pretty good  \\n about the confidence interval you create.  \\n Confidence intervals.  \\n They can provide us incredible insight  \\n with only a single random sample.  \\n So let's dive into confidence intervals.  \\n Let's look at how they're created  \\n and what insight they can provide to statisticians.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3082813\",\"duration\":224,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Components of a confidence interval\",\"fileName\":\"2446433_en_US_04_02_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to find the key components of a confidence interval before developing a confidence interval.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3404485,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Before we create confidence intervals  \\n that will help us identify the true population proportion,  \\n let's take a look at the formula  \\n and the elements of the formula  \\n that we'll use to create the upper limit  \\n and the lower limit of our confidence intervals.  \\n The formula for the upper limit is p-hat  \\n plus a z-score times the standard deviation.  \\n The formula for the lower limit is p-hat minus a Z-score  \\n times the standard deviation.  \\n Let's look at each element individually.  \\n In this example, let's say we're trying to figure out  \\n the proportion of women in a city  \\n with a population of 250,000 people.  \\n First let's look at p-hat.  \\n Remember we're only taking one simple random sample  \\n to create our confidence interval.  \\n p-hat will be the proportion  \\n of women in our single random sample.  \\n If our single sample is 100 people  \\n and that sample contains 55% women,  \\n we would say our p-hat for this sample was 0.55.  \\n Next, let's look at the standard deviation.  \\n We don't know the standard deviation  \\n for our entire population, but we can use this formula,  \\n the formula for standard error.  \\n The standard error is a good approximation  \\n of the population standard deviation.  \\n And to be more exact, we would call this the sampling error  \\n since it is based on data from a single sample.  \\n We know that p-hat is 0.55,  \\n and we know our sample contained 100 people,  \\n so n is equal to 100.  \\n This gives us a standard error of about 0.05.  \\n Finally, we need our Z-score.  \\n To find this, we'll first want to remember the empirical rule.  \\n The empirical rule states that for a normal distribution,  \\n we would expect about 68% of samples  \\n to fall within one standard deviation  \\n of the true population proportion.  \\n We would expect about 95% of our samples  \\n to fall within two standard deviations  \\n of the population proportion,  \\n and we'd expect about 99.7% of our samples  \\n to fall within three standard deviations  \\n of the population proportion.  \\n Remember Z-score is a measure  \\n of the number of standard deviations.  \\n This is why for a 95% confidence interval,  \\n we should expect our Z-score to be very close to 2.0.  \\n To be more exact, it's closer to 1.96.  \\n But we'll discuss that in a later chapter.  \\n For now, let's just use 2.0.  \\n In this example, p-hat is 0.55,  \\n our Z-score is 2.0, and our standard error is 0.05.  \\n So our upper limit is 0.65 and our lower limit is 0.45.  \\n So for this example,  \\n we can say that based on only this one sample,  \\n we are 95% certain that the proportion of women  \\n in our city's population is between 0.45 and 0.65.  \\n Just one sample, pretty cool, right?  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3087926\",\"duration\":455,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Creating a 95% confidence interval for a population\",\"fileName\":\"2446433_en_US_04_03_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video learn how to provide a window of results that encompasses 95% of the likely outcomes.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6836500,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - So there's an upcoming election  \\n for mayor of a large city between two candidates.  \\n Let's simply call them candidate A and candidate B.  \\n You work for candidate A.  \\n Candidate A's campaign team  \\n wants to know where candidate A stands.  \\n So they ask you to conduct a poll.  \\n You gather a simple, random sample of 100 voters.  \\n You ask if they will vote for candidate A or candidate B.  \\n 55% Of 100 voters polled  \\n said they planned on voting for candidate A.  \\n Anything over 50% in the election is a win.  \\n So based on the poll,  \\n things look promising for candidate A.  \\n That said, it's a big city.  \\n And you have just one sample.  \\n And the sample size was only a hundred.  \\n Look, I know my pre-election poll isn't perfect,  \\n but even this small poll  \\n can provide us some helpful information.  \\n Let's use our poll results  \\n to create a 95% confidence interval.  \\n In other words,  \\n let's create an interval that very likely  \\n will include the actual proportion of votes  \\n that candidate A will get on election day.  \\n To do this,  \\n let's first look at our normal distribution curve.  \\n The curve is centered at the sample proportion.  \\n We want to capture 95% of the area under the curve.  \\n We aren't looking for the most extreme outcomes.  \\n So we will exclude 2.5%  \\n of the high-end of the curve at the right  \\n and the 2.5% on the low-end of the curve at the left.  \\n We want the area in the middle.  \\n First,  \\n let's find the upper limit point  \\n to the right of the center of the curve.  \\n To find the upper limit we'll need to use z-scores.  \\n We want to find the z-score for 0.975.  \\n Why 0.975?  \\n 0.975 Indicates that 97.5% of the data  \\n is to the left of this point  \\n and 2.5% of the data is to the right of the curve.  \\n We find 0.975 on our z-score table.  \\n By looking at the top of the column and left in the row,  \\n we discover that our z-score is 1.96.  \\n Remember a z-score of 1.96 means  \\n if you go 1.96 standard deviations  \\n to the right of center of the curve,  \\n you'll have 97.5% of the data to the left of that point  \\n and 2.5% of the data to the right of that point.  \\n The same thing happens 1.96 standard deviations  \\n from the center of the curve in the negative direction.  \\n 2.5% Of the data is below the lower limit,  \\n 2.5% of the data is above the upper limit,  \\n and 95% is in between the two limits.  \\n Our sample proportion is 0.55,  \\n the center of our interval.  \\n We now need to move  \\n 1.96 standard deviations higher than 0.55  \\n and 1.96 standard deviations lower than 0.55.  \\n Let's now calculate our standard deviation.  \\n We don't know the real population proportion  \\n nor do we know the total population standard deviation.  \\n So instead, we use the formula for standard error.  \\n It's basically the formula for standard deviation,  \\n but we use the sample proportion as our p-hat.  \\n Since we're using p-hat for the sample proportion,  \\n it's actually not the standard error.  \\n This is called the sampling error  \\n since it's based on a single sample,  \\n We plug in 0.55 as p-hat.  \\n Our sample size is 100.  \\n So N is equal to 100.  \\n This gives us a sampling error of 0.05.  \\n This will act as our standard deviation in our upper  \\n and lower limit calculations.  \\n Here are our formulas for the upper  \\n and lower limits of our 95% confidence interval.  \\n P-hat is 0.55.  \\n 1.96 Was the z-score.  \\n 0.05 Will be our standard deviation.  \\n As you can see,  \\n our lower limit is 0.452  \\n and the upper limit is 0.648.  \\n Uh-oh, our lower limit is below 50%.  \\n It's 0.452.  \\n The confidence interval is telling us that based  \\n on this single sample of 100 people,  \\n losing is still a possibility.  \\n That said, most of our interval is still over 50%.  \\n So the news is mostly good.  \\n Still nervous?  \\n How about if the campaign  \\n is willing to fund a poll of 1,000 voters?  \\n This new poll has only 54% of voters favoring candidate A,  \\n a little lower than our previous sample.  \\n We know our z-score for a 95% confidence interval is 1.96.  \\n We need to calculate a new sampling error.  \\n P-hat is 0.54, N is equal to 1,000.  \\n Our new sampling error is 0.016.  \\n So let's calculate our interval limits.  \\n Look at that.  \\n Our new interval stretches from 0.509 to 0.571.  \\n If the election were to have a result identical  \\n to anything within our 95% confidence interval,  \\n candidate A would win.  \\n Remember, according to this sample,  \\n there is now a 95% chance that on election day candidate A  \\n will receive between 50.9% and 57.1% of the vote.  \\n There's only a 5% chance that the election day results  \\n will fall outside of that interval.  \\n And don't forget,  \\n since this is only a 95% confidence interval,  \\n it's possible that those 5% might include results  \\n that are even better than 57.1% of the vote for candidate A.  \\n No matter how you slice it,  \\n that should make candidate A's team feel pretty good, right?  \\n Yeah, there's always that one person on the team that asks,  \\n \\\"Can we get a 96% interval or what about 98%?\\\"  \\n So for those people,  \\n next we'll create a confidence interval  \\n that's greater than 95%.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3086783\",\"duration\":323,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Alternative confidence intervals\",\"fileName\":\"2446433_en_US_04_04_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"With a single 95% confidence level example, you can learn how to develop your own. In this video, explore how to develop confidence levels that are higher\u2014or lower\u2014than 95%.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4871494,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - For some people 95% just isn't good enough.  \\n So what happens if someone demands  \\n a 98% confidence interval?  \\n Well, let's remember a 95% confidence interval stretches  \\n in equal distances in opposite directions  \\n from our distribution mean, or proportion, how far?  \\n Enough to include 95% of the probability distribution,  \\n which means that a 98% confidence interval  \\n would have to stretch a little bit farther  \\n so our interval would include 98%  \\n of the probability distribution.  \\n So, you see, my numbers aren't necessarily better,  \\n I simply increase the size of my interval.  \\n For example, let's say you lost your car keys.  \\n Perhaps you're 75% sure the keys are in the living room,  \\n but you're 99% sure the keys are somewhere in the house.  \\n By simply extending the possible location  \\n of where your keys could be you've increased  \\n the probability your keys are in the designated area.  \\n You increased the area of your confidence interval.  \\n With that in mind, let's go ahead and figure out  \\n how to calculate the limits of this expanded interval.  \\n Actually, it's very simple.  \\n Remember to find the limits of our 95% confidence interval  \\n with a proportion distribution, we used these formulas.  \\n Our sample proportion p hat plus, or minus  \\n our sampling error times 1.96, why 1.96?  \\n Because that was the appropriate z-score for 95%.  \\n So really the only thing we will change  \\n to adjust our interval is the z-score of 1.96.  \\n But how do we find the right z-score for, let's say, 98%.  \\n Don't get fooled, you don't want the z-score for 0.98.  \\n You actually need the z-score for 0.99, why?  \\n Well, let's look at our distribution.  \\n We want to set limits where 98% of the data  \\n is under the curve between the limits.  \\n So 2% of the distribution falls outside the limits.  \\n 1% of the distribution on this end of the curve,  \\n and 1% on this end of the curve.  \\n So we need to find the z-score for 0.99.  \\n Here's a z-score table, within the table  \\n we're looking for 0.9900,  \\n or the closest number that is greater than that.  \\n In this case, the appropriate z-score is 2.33.  \\n And since the interval will stretch  \\n in equal distances in opposite directions  \\n we will use 2.33 for both our upper and lower limit.  \\n So let's use some of the election polling numbers  \\n from the previous video, p hat was equal to 0.54.  \\n Our sampling error is 0.016 and n is equal to 1000.  \\n In the previous video, we found the upper  \\n and lower limits were 0.509 and 0.571.  \\n And with a lower limit of 0.509  \\n we were feeling fairly confident  \\n about a victory in the election.  \\n Now let's calculate our 98% interval limits.  \\n As you can see, our 98% upper limit is 0.577.  \\n And our 98% lower limit is 0.503.  \\n A victory with over 50% of the vote  \\n is still barely within our margin of error.  \\n Of course, there's always the person that wants more.  \\n So how about 99%, using the same logic as with 98%  \\n we realize we need to find the z-score  \\n for 0.995, which is 2.58.  \\n Let's calculate our 99% interval.  \\n Here are the calculations for the upper and lower limits.  \\n Here, we see that the chance for a very narrow election loss  \\n is within our margin of error.  \\n Nonetheless, it looks like based on our simple random sample  \\n that we can feel somewhat confident  \\n that an election win is likely.  \\n Still, even with this strong statistical evidence  \\n the candidate could lose.  \\n So if the candidate lost after we reported  \\n that a win seemed rather likely  \\n how might that loss be explained?  \\n Let's try and figure that out in our next video.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3086784\",\"duration\":274,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Confidence intervals with unexpected outcomes\",\"fileName\":\"2446433_en_US_04_05_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Suppose a 95% confidence interval is provided, but then the actual outcome lies outside of the given interval. In this video, learn how to find explanations for unexpected outcomes.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4133909,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Suppose before an election, a polling organization  \\n develops a 95% confidence interval.  \\n This 95% confidence interval reports that Candidate A  \\n will receive between 51% and 54% of the vote.  \\n Then election day comes around, and Candidate A loses.  \\n Candidate A would probably be furious.  \\n Before the election, they were very confident of a win,  \\n and now they realize that they actually lost.  \\n How could this have happened?  \\n Well, this is where it helps  \\n to be a well-rounded statistician.  \\n Beyond having a knowledge of the numbers and formulas,  \\n you need to understand the real-life environment  \\n that surrounds the poll.  \\n In this case, it would be helpful if we understood  \\n how political polls are taken  \\n and also the nature of the actual election.  \\n So what might go wrong during the actual poll?  \\n Some people that are polled want to throw off the poll,  \\n so they just may lie.  \\n Or perhaps they're too embarrassed to tell a pollster  \\n about their true opinion.  \\n So instead, they tell a lie which they believe  \\n will please the pollster.  \\n Then again, maybe they didn't lie.  \\n Perhaps the respondent changed their mind between  \\n the time of the poll and the actual date of the election.  \\n It's also possible some people were unsure  \\n of who they'd vote for on the day of the poll.  \\n Nonetheless, they choose a candidate for the poll  \\n just to please the pollster.  \\n Perhaps there were issues in gathering a random sample,  \\n the location of the poll,  \\n the people chosen, how they were chosen,  \\n the incentives used to entice more participants.  \\n It takes a very experienced organization  \\n to gather a truly random sample.  \\n Sometimes, in an effort to influence undecided voters,  \\n some politically biased polling organizations  \\n might seek biased polling results that they can then use  \\n in the media to show that their candidate  \\n is popular among likely voters.  \\n These organizations may have had poor sample selection,  \\n poorly worded questions,  \\n or other questionable, if not deceitful, practices.  \\n As you can see, the polling process itself  \\n is filled with challenges.  \\n So let's move on to election day.  \\n What might go wrong on election day?  \\n Bad weather, a health epidemic, unsafe travel conditions,  \\n car trouble, work or family commitments.  \\n This is just a short list of reasons people might not  \\n be able to get to the voting booth on election day.  \\n Perhaps between the time of the pre-election poll  \\n and election day, something changed voters' perceptions.  \\n Maybe there was a preventable health crisis  \\n or voters were upset about the way  \\n the city handled a snowstorm.  \\n Or maybe there was a political scandal.  \\n Sometimes, voters just choose to stay home.  \\n Why? They don't really care that much.  \\n Maybe they just forgot.  \\n Perhaps they heard that the lines were long.  \\n Maybe they had been watching the news,  \\n and analysts made it seem as though  \\n the outcomes were certain.  \\n Perhaps the voter thought this election is a done deal.  \\n My vote isn't going to make a difference at this point.  \\n Hopefully, you aren't growing distrustful of statistics.  \\n If you investigate confidence intervals  \\n that have been reported over the last few decades,  \\n you'll see that very often, they're very accurate.  \\n Nonetheless, when the confidence interval misses the mark,  \\n it's important to know where the poll might have gone wrong.  \\n Actually, it's best to know these things  \\n before the study is even performed.  \\n If you're looking to use confidence intervals  \\n to make important decisions,  \\n be sure you investigate how the study was done  \\n and which assumptions and simplifications were included  \\n in the development of the study.  \\n As I said, a good statistician  \\n has to know more than numbers and formulas.  \\n They need to really understand the environment  \\n that they're looking to measure.  \\n \\n\\n\"}],\"name\":\"4. Confidence Intervals\",\"size\":22017779,\"urn\":\"urn:li:learningContentChapter:3085849\"},{\"duration\":2158,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3084811\",\"duration\":243,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Hypothesis test introduction\",\"fileName\":\"2446433_en_US_05_01_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, discover whether outcomes actually happen by chance.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3679295,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Sometimes, we come across a data set  \\n or outcome that seems a bit odd.  \\n For example, in a city made up of 51% women,  \\n where jury pools are said to be chosen at random,  \\n a certain jury pool of 50 people contains only eight women.  \\n Or here's another one.  \\n A national coffee chain creates a contest  \\n where customers can win prizes.  \\n A customer gets one game piece  \\n with every beverage they purchase.  \\n Millions of people play the game.  \\n There are 10 prizes worth over $100,00.  \\n And two of those big prizes are won  \\n by relatives of coffee chain employees.  \\n Or this more ominous example.  \\n A chemical factory has 500 employees.  \\n In only a two year period,  \\n 2 of the 500 employees are diagnosed with brain cancer.  \\n Each of those scenarios makes us pause.  \\n We might say to ourselves, \\\"That doesn't seem right.\\\"  \\n We may even jump to conclusions.  \\n And still, in other cases,  \\n the data set may present a possible opportunity.  \\n For example, a pharmaceutical company has developed a drug  \\n to treat the common cold.  \\n It's reported that the average adult  \\n with a cold will normally experience cold symptoms  \\n for about 8.5 days.  \\n When testing this new medicine,  \\n on a random sample of 250 people with the common cold,  \\n it's found that this sample of patients  \\n on average experienced cold symptoms for only 7.3 days,  \\n about 1.2 days fewer than those  \\n that did not take this new drug.  \\n In all of these cases,  \\n with we're left with lots of questions.  \\n Is lack of women in the jury group a likely outcome?  \\n Was the coffee chain's contest fair?  \\n Should the chemical plant employees be concerned  \\n about their health?  \\n And in the case of the cold drug,  \\n does this mean this new drug should be approved for use?  \\n Should the drug be tested further?  \\n As you can see, these types of scenarios could impact  \\n our careers and our companies.  \\n Understanding how to interpret the data  \\n can help us make decisions.  \\n It can help us influence leadership.  \\n And perhaps, in some cases,  \\n it could impact the health of people.  \\n This is where hypothesis testing comes into play.  \\n Hypothesis testing is an extremely popular method  \\n for exploring outcomes.  \\n In general, in performing a hypothesis test,  \\n statisticians will make an assumption about a population.  \\n They establish a threshold  \\n for rejecting that assumption.  \\n They then collect a random sample from the population.  \\n They measure the sample, and finally,  \\n they see whether or not the sample measurement  \\n supports their assumption.  \\n When done properly, hypothesis testing  \\n can be an extremely powerful statistical tool,  \\n but it can be a bit complex.  \\n You see, hypothesis testing will require  \\n that you put to use almost every element  \\n of your statistics foundation.  \\n Means, proportions, and standard deviations,  \\n normal distributions, z-scores, the empirical rule,  \\n sampling and sample size, and confidence intervals.  \\n But once you have it at your disposal,  \\n you'll be able to provide valuable input  \\n in almost any career, whether it's science,  \\n medicine, business, education, public policy,  \\n and even sports and entertainment.  \\n No matter your field, make sure you understand  \\n the most basic elements of hypothesis testing.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3086785\",\"duration\":452,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Hypothesis test : Step-by-step\",\"fileName\":\"2446433_en_US_05_02_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to test your hypotheses with these four steps: developing hypotheses, identifying the test statistic, calculating p-value, and comparing significance level to p-value.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6792132,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Narrator] Suppose a town has 35,000 adult residents.  \\n 50% are male, 50% are female.  \\n Each week, 50 adults are chosen  \\n at random to participate in jury duty.  \\n Women have complained that they're getting called  \\n to jury duty more often than men.  \\n Jury administrators contend the system is random and fair.  \\n A committee is set up to investigate.  \\n They use the next jury pool as a sample.  \\n This next pool of 50 potential jurors  \\n has 14 men and 36 women.  \\n The jury administration says the process is fair.  \\n It happened by chance.  \\n A lobbying group disagrees.  \\n They feel something is making women  \\n much more likely to be chosen.  \\n What we have here is an excellent opportunity  \\n to utilize hypothesis testing.  \\n Hypothesis testing is really a process,  \\n in our case, a five-step process.  \\n In an effort to keep you focused on each step,  \\n we're going to keep the math simple.  \\n So let's begin.  \\n In our first step, we need to set up our hypotheses.  \\n There will typically be two hypotheses.  \\n H sub zero or H naught are null hypothesis.  \\n The null hypothesis is what is presently accepted as fact.  \\n In this situation, the null hypothesis  \\n is that women have at least a 50% chance  \\n of being chosen for the jury.  \\n So our null hypothesis is p  \\n is less than or equal to 0.50.  \\n Why?  \\n Because the jury administration believes  \\n women have an equal chance or better of being chosen.  \\n Let's now develop our alternative hypothesis, H sub a.  \\n This would be the opposite of the null hypothesis.  \\n So here, our alternative hypothesis  \\n is p is greater than 0.50.  \\n This one would say that women  \\n have a greater than 50% chance  \\n of being chosen for the jury pool.  \\n Our next step is to state a significance level,  \\n which we will call alpha.  \\n Essentially, this sets a threshold for our test.  \\n In other words, what would have to be the probability  \\n for you to believe that the system was not fair?  \\n What would it take for you to reject the null hypothesis?  \\n What if only 20% of the time,  \\n at least 36 of the 50 members  \\n of the pool were female?  \\n What if it was only 10% of the time?  \\n In many cases, statisticians like to utilize  \\n a significant level of 5%.  \\n If there is less than a 5% chance  \\n that 36 or more women can be picked  \\n for our jury of 50 people at random,  \\n less than one in 20 chance,  \\n we will reject the null hypothesis.  \\n In our third step, we look to find a statistic  \\n that will help assess the validity of our null hypothesis.  \\n How could we see if this outcome,  \\n 36 women and 14 men, or one even more extreme  \\n could happen at random under these circumstances?  \\n We'll need to go back to something discussed  \\n in the probabilities course, binomial probabilities.  \\n Remember, our p is equal to 0.50.  \\n The stated probability of a woman  \\n being chosen for the jury pool.  \\n And we will have 50 trials,  \\n since that's how many seats there are in the jury pool.  \\n We have our null hypothesis,  \\n our significance level, and our test statistic.  \\n Next, we find the p-value for that test statistic.  \\n The p-value is the probability  \\n that this outcome could occur by chance.  \\n So we're looking for the probability  \\n that the number of women chosen  \\n for the jury pool would be at minimum 36.  \\n So what is that probability?  \\n Well, via Google, I found an online binomial calculator.  \\n I plugged in the probability of success as 50%.  \\n I entered that there were 50 trials  \\n and I stated I wanted 36 successful outcomes.  \\n The binomial calculator stated  \\n that the cumulative chance of 36 successful outcomes  \\n in 50 trials was 0.0013 or 0.13%.  \\n Wow, that outcome is not very likely at all.  \\n So our final step, time to compare our p-value  \\n to our fixed significance level.  \\n What we found was that assuming that the odds  \\n that a man and a woman were equally likely  \\n to be chosen for a jury,  \\n there was only a 0.13% chance  \\n that at random 36 or more women  \\n would be chosen for a 50-person jury pool.  \\n Remember, the fixed significance level alpha was 0.05 or 5%.  \\n Clearly, the p-value fell short of our significance level.  \\n And thus, we must reject the null hypothesis.  \\n This means that we believe that something  \\n is making it much more likely for a woman  \\n to be chosen versus a man.  \\n Now it doesn't prove that the cause  \\n is evil and intentional,  \\n nor does it prove that the cause  \\n is unintentional and innocent.  \\n It simply means we reject the null hypothesis.  \\n There are only two possible outcomes in a hypothesis test.  \\n Reject the null hypothesis  \\n or do not reject the null hypothesis.  \\n Notice, do not reject doesn't mean  \\n that we accept the hypothesis.  \\n Reject simply means we contradicted the null hypothesis.  \\n On the other hand, do not reject means  \\n that we could not contradict the null hypothesis.  \\n It's sort of like saying a person  \\n on trial is guilty or not guilty.  \\n Guilty means the evidence is there to convict.  \\n Not guilty means there was a lack of evidence.  \\n Not guilty does not necessarily mean the jury  \\n believed the person was innocent.  \\n They just lacked the evidence to prove guilt.  \\n Hypothesis testing is an extremely important part  \\n of the world of statistics,  \\n and every field that leans on statistics for assistance.  \\n This was a very abbreviated version  \\n of the hypothesis testing process.  \\n It's probably not enough to make you an expert,  \\n but it will be helpful in understanding statistical studies  \\n you may encounter at work or in other mediums.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3082814\",\"duration\":345,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"One-tailed vs. two-tail tests\",\"fileName\":\"2446433_en_US_05_03_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn about the difference between one-tailed and two-tailed tests. One-tailed tests look for an area on one end of the normal curve, while two-tailed tests search for two areas on opposite ends of the normal curve.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5193303,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Let's consider three different statements.  \\n First, a recent national study has found  \\n that the average American between the ages  \\n of 18 and 24 checks their phone 74 times per day.  \\n A mobile service provider questions these results.  \\n Second, the average amount of time it takes an adult  \\n to recover from the common cold is 8.5 days.  \\n A new medicine was tested on a sample of adults  \\n suffering from the common cold.  \\n The average recovery time for the people  \\n in this group was 6.2 days.  \\n The pharmaceutical company manufacturing the medicine  \\n believes it should receive government approval.  \\n Third, the national average for a college entrance exam  \\n is 1,000 points.  \\n The Regent Test Prep Academy claims  \\n that their students consistently beat the national average.  \\n These are all situations where hypothesis testing  \\n would be useful, but each of these situations  \\n would require a different type of hypothesis test.  \\n Let's look at each situation individually.  \\n In our first situation, we had a claim  \\n that said people between the ages of 18 and 24  \\n checked their phones 74 times per day.  \\n Some folks doubted the claim though.  \\n Notice, this group did not say the number was too high,  \\n nor did they contend the number was too low.  \\n They just expressed doubt in the stated average  \\n of 74 times per day.  \\n In this case, our hypotheses look like this.  \\n H-nought would be mu is equal to 74.  \\n H sub a mu is not equal to 74.  \\n If we look at our normal distribution, what we have is this.  \\n 74 is the mean of our null hypothesis.  \\n Let's say that we thought that anything more  \\n than two standard deviations from the mean  \\n would indicate that we could reject our null hypothesis.  \\n On the other hand,  \\n anything less than two standard deviations  \\n from the null hypothesis would tell us  \\n that we could not reject the null hypothesis.  \\n As you can see, we have two rejection areas here.  \\n One rejection area in the positive direction,  \\n greater than the mean,  \\n the other in the negative direction, less than the mean.  \\n This is considered a two-tailed test  \\n because the null hypothesis is tested in both directions.  \\n On the other hand, in our example  \\n where the average person recovers from the cold in 8.5 days,  \\n our test group recovers in 6.2 days.  \\n This is a one-tailed test.  \\n Why? Well, in this case, our hypotheses look like this.  \\n H-nought is mu is equal to or greater than 8.5.  \\n H sub a is mu is less than 8.5 days.  \\n H-nought states that the medicine was not helpful.  \\n The null hypothesis states people took 8.5 days or longer  \\n to recover.  \\n The alternative hypothesis, H sub a,  \\n states that the medicine does in fact have an impact.  \\n Recovery takes fewer than 8.5 days.  \\n Our normal distribution graph is centered on 8.58,  \\n our null hypothesis mean.  \\n We then establish two areas.  \\n Each area begins two standard deviations from the mean.  \\n The difference here  \\n is that the drug can only be considered helpful  \\n if the patients actually get better faster,  \\n which means that this area to the left,  \\n this small single tail,  \\n this is the area that shows the people  \\n that are recovering more quickly.  \\n If our test ends up in this area,  \\n people in our sample are recovering more quickly.  \\n We could therefore reject the null hypothesis,  \\n which stated that people were not recovering more quickly.  \\n This college test example is very similar  \\n to the cold medicine example.  \\n The difference here is that we are looking  \\n for an increase in the test scores.  \\n Here, the hypotheses for this situation, H-nought,  \\n m is less than or equal to 1000.  \\n H sub a, m is greater than 1000 points.  \\n Our null hypothesis is saying students of the Regent school  \\n do not see increased test scores.  \\n Instead, they see average scores,  \\n or perhaps, even below average scores.  \\n The alternative hypothesis says that the Regent students  \\n do score over the national average.  \\n What do we see in our normal distribution?  \\n Again, we see one tail.  \\n If we land in this area to the right,  \\n we would reject the null hypothesis.  \\n If we land anywhere else in the large area to the left,  \\n we would not reject the null hypothesis.  \\n As you start to look for opportunities  \\n to utilize hypothesis testing, be sure you consider  \\n whether your hypothesis test is for one or two tails.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3085847\",\"duration\":386,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Significance test for proportions\",\"fileName\":\"2446433_en_US_05_04_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, explore the possibility that the true population probability is larger than some threshold value.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5822672,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Let's imagine we're working  \\n for a candidate's campaign team.  \\n We find that in a random sample of 500 eligible voters,  \\n 54% of those polled said  \\n they plan on voting for our candidate.  \\n Our candidate needs over 50% of the vote  \\n to win the election.  \\n So the poll looks pretty good,  \\n but in an effort to better understand the polling results,  \\n we decide to use hypothesis testing.  \\n Let's take a look.  \\n Step one, we need to develop the hypotheses.  \\n H0, our null hypothesis, indicates that the candidate  \\n has not won and will not win the election.  \\n So p is less than or equal to 0.50.  \\n In other words, the hypothesis states  \\n that the candidate would get 50% or less of the votes,  \\n not enough votes to win the election.  \\n H sub a, our alternative hypothesis,  \\n indicates the candidate wins.  \\n Thus, our alternative hypothesis is p is greater than 0.50.  \\n The candidate will get a majority of the vote and win.  \\n Step two, our significance level for this test will be 5%.  \\n If there is less than a 5% chance  \\n that the candidate gets 50% or less of the vote,  \\n then we will reject our null hypothesis.  \\n On a distribution chart centered at 0.50,  \\n we know our sample of 500 people has a p-hat of 0.54.  \\n If the actual population proportion is only 0.50,  \\n and we've got a sample of 0.54,  \\n how far to the right of the center are we?  \\n As you can see, this is a right-tailed test.  \\n If our sample of 0.54 is less than 5% likely  \\n in this distribution centered at 0.50,  \\n the candidate should feel rather confident.  \\n Step three, let's identify the test statistic.  \\n If the actual population proportion is 0.50 or less,  \\n then how far off is our sample with a p-hat of 0.54?  \\n In other words,  \\n how many standard deviations are we from 0.50?  \\n So in this situation, our test statistic is a z-score.  \\n We'll call it z sub p.  \\n In this formula, p-hat is the sample proportion, 0.54.  \\n p0 is the proportion from our null hypothesis, 0.50.  \\n And n is our sample size 500.  \\n The z-score will tell us how many standard deviations  \\n our sample proportion of 0.54 is  \\n from the null hypothesis proportion of 0.50.  \\n The numerator helps us calculate the distance  \\n from our sample proportion to p0.  \\n The denominator is a calculation  \\n for the standard deviation for a sample of 500.  \\n This tells us the z-score is 1.79.  \\n In other words, this sample of 500 people  \\n is 1.79 standard deviations  \\n from the required proportion for victory.  \\n Step four, our test statistic z sub p is 1.79.  \\n If we look this number up on our z-score chart,  \\n you'll find that 1.79 leads you to 0.9633.  \\n So our p-value is one minus 0.9633.  \\n This gives us a p-value of 0.0367, or 3.67%.  \\n In other words, if the real population proportion  \\n is in fact 0.50 or smaller,  \\n our sample of 0.54 would be in the top 3.67% of all samples.  \\n Step five, time to compare our p-value  \\n to our fixed significance level.  \\n Our fixed significance level, alpha, was 5% or 0.05.  \\n Our p-value of 3.67%, or 0.0367,  \\n is smaller than our 0.05 significance level.  \\n In other words, our sample of 0.54 is not very likely,  \\n if the actual population proportion is 0.50 or smaller.  \\n Thus, we can reject the null hypothesis.  \\n The politician can breathe easy.  \\n Going back to the distribution chart  \\n since we are on the right side of the chart,  \\n we translate our p-value to one minus alpha, one minus 0.05.  \\n So 0.95 is the dividing line between reject  \\n and do not reject regions.  \\n We are to the right of this line,  \\n so we are in the reject the null hypothesis region.  \\n But let's imagine what would've happened,  \\n if we had stated that our significance level was 2%,  \\n the dividing line moves to 0.98.  \\n Now we are in the do not reject region of the distribution.  \\n So if you want the chances to be less than one in 50,  \\n less than a 2% chance that the candidate may lose,  \\n the hypothesis test will not let you reject  \\n the null hypothesis that states the candidate will get  \\n less than 50% of the vote.  \\n As you can see, sometimes the result of your hypothesis test  \\n can hinge on the chosen significance level.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3088173\",\"duration\":430,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Significance test for means\",\"fileName\":\"2446433_en_US_05_05_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn about an important test often used by industry to see if a large sample of product should be accepted or rejected.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6466066,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - K-Nosh is a national gourmet dog food company.  \\n They sell thousands of bags of dog food each day.  \\n They sell 8, 20, and 40 pound bags,  \\n but the 20 pound bag is by far their most popular size.  \\n K-Nosh has high-end customers.  \\n They demand outstanding products and excellent service.  \\n Customers expect at least 20 pounds of dog food  \\n in every 20 pound bag,  \\n so while the bag is labeled as 20 pounds,  \\n K-Nosh sets the desired weight  \\n of each bag at 20.15 pounds.  \\n They hope that this will ensure each bag  \\n has at least 20 pounds of dog food.  \\n Out of the 5,000 bags they produce daily,  \\n K-Nosh pulls a random sample of 100 bags.  \\n Based on the 100 bag sample,  \\n they will either send out the entire shipment of 5,000 bags  \\n or they will reject the entire shipment of 5,000 bags.  \\n This sounds like a job for hypothesis testing.  \\n Today's sample had an average weight of 20.1 pounds.  \\n We will call this X bar or the sample mean.  \\n In addition, K-Nosh has stated that their population  \\n standard deviation is 0.26 pounds.  \\n Step one, let's develop the hypotheses, H naught.  \\n Our null hypothesis indicates that on average  \\n the bags of dog food weigh 20.15 pounds or more.  \\n So mu, our population mean,  \\n is greater than or equal to 20.15.  \\n In other words, the hypothesis states  \\n that based on the sample of 100 bags,  \\n the entire shipment of 5,000 bags  \\n has sufficient dog food,  \\n and they can all be shipped.  \\n H sub a are alternative hypothesis indicates  \\n that on average the bags of dog food  \\n weigh less than 20.15 pounds.  \\n Thus, our alternative hypothesis is mu is less than 20.15.  \\n In other words, the hypothesis states  \\n that based on the 100 bag sample,  \\n the entire shipment of 5,000 bags  \\n does not contain sufficient dog food.  \\n The 5,000 bags cannot be shipped.  \\n Step two, our significance level for this test will be 5%.  \\n If there is less than a 5% chance  \\n that the 5,000 bags have 20.15 pounds,  \\n then we will reject our null hypothesis.  \\n On a distribution chart centered at 20.15,  \\n we know our sample of 100 bags has an X bar of 20.10.  \\n If the actual mean of the 5,000 bags is 20.15,  \\n but our sample mean has only 20.10 pounds,  \\n how far to the left of the center are we?  \\n As you can see, this is a left-tail test.  \\n If a sample of 20.10 pounds is less  \\n than 5% likely in this distribution,  \\n which is centered at 20.15,  \\n we will need to reject the entire shipment.  \\n Step three, now we need the test statistic.  \\n If the actual mean weight of the 5,000 bags  \\n is 20.15 pounds or greater,  \\n then how far off is our sample  \\n with an X bar of 20.10 pounds?  \\n In other words, how many standard deviations  \\n are we from 20.15 pounds?  \\n So in this situation, our test statistic is a z-score.  \\n To find our z-score we'll use this formula.  \\n X bar is the sample mean, 20.10.  \\n Mu is the mean from our null hypothesis, 20.15.  \\n n is our sample size 100,  \\n and sigma is our population standard deviation 0.26.  \\n The z-score will tell us how many standard deviations  \\n from our sample mean of 20.10  \\n is from our null hypothesis mean of 20.15.  \\n The numerator helps us calculate the distance  \\n from our sample mean to mu.  \\n The denominator is a calculation  \\n of the standard deviation for a sample of 100.  \\n When we calculate this,  \\n we get a z-score of negative 1.92.  \\n In other words, this sample of 100 bags  \\n is 1.92 standard deviations  \\n from the required mean for 5,000 bags.  \\n Step four, our test statistics Z is negative 1.92.  \\n If we look this number up on a z-score chart,  \\n you will find that negative 1.92 leads you to 0.0274.  \\n So our p-value is 0.0274 or 2.74%.  \\n In other words, if the real population mean  \\n is 20.15 or greater, our sample of 20.10  \\n would fall in the bottom 2.74% of all possible samples.  \\n Step five, time to compare our p-value  \\n to our fixed significance level.  \\n Our fixed significance level alpha was 5% or 0.05.  \\n Our p-value of 2.47% or 0.0247  \\n is smaller than our 0.05 significance level.  \\n In other words, a sample mean  \\n of 20.10 is not very likely  \\n if the actual population mean is 20.15,  \\n thus we can reject the null hypothesis.  \\n The bags in the population are very likely too light.  \\n And believe it or not, we must reject the entire shipment.  \\n I'm guessing some of you may see this as harsh,  \\n but believe it or not, this quality control technique,  \\n which is called acceptance sampling,  \\n was very popular in the past  \\n and is still used in some industries today.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3084812\",\"duration\":302,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Type one and type two errors\",\"fileName\":\"2446433_en_US_05_06_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to use decision tables to summarize a situation where two different types of errors are possible.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4568730,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - In our hypothesis tests, we've always set up  \\n a null hypothesis and an alternative hypothesis.  \\n The null hypothesis typically assumes  \\n the status quo prevails.  \\n The null hypothesis might state that the system works  \\n or it might tell us that nothing has changed in our system.  \\n Our alternative hypothesis assumes the opposite.  \\n The alternative hypothesis might tell us  \\n that the system is broken.  \\n It might tell us that things have changed.  \\n Let's use a special type  \\n of cancer screening test as an example.  \\n This fictional screening would provide a reading  \\n based on your blood.  \\n The average reading is 100.  \\n People that get a reading over 125  \\n get a positive test result.  \\n This would indicate they have cancer.  \\n If we're going to equate this to a hypothesis test,  \\n we would say the cancer screening had two hypotheses.  \\n The null hypothesis would state that everything's okay.  \\n The person being tested does not have cancer.  \\n The alternative hypothesis would state  \\n that the person being tested does in fact have cancer.  \\n Let's establish an alpha of 0.02 or 2%,  \\n and let's say the incidence of cancer  \\n is normally distributed.  \\n So if we're going to look at this on a normal distribution,  \\n we might say that 100 is the mean.  \\n Anything to the right of 125  \\n would be considered a positive result for cancer.  \\n Our null hypothesis is no cancer, so left of 125,  \\n we do not reject the null hypothesis.  \\n The test indicates that the patient does not have cancer.  \\n But, to the right of 125,  \\n we would reject the null hypothesis.  \\n The test indicates the patient does have cancer.  \\n Nonetheless, these cancer tests are not perfect.  \\n Remember, our alpha is 2%.  \\n So if a patient gets 125 or higher on the test,  \\n a positive test, it's unlikely but not impossible  \\n that the patient may not have cancer.  \\n This is called a false positive result.  \\n This is one type of error.  \\n But there's a second type of error.  \\n It's possible someone scored less than 125, a negative test,  \\n but they might actually have cancer.  \\n This is called a false negative result.  \\n Often, statisticians use a grid like this  \\n to understand the possible outcomes.  \\n At the top, we see the actual truth.  \\n Some of the people tested do not have cancer.  \\n Some people do have cancer.  \\n In terms of our null hypotheses,  \\n no cancer agrees with our null hypothesis.  \\n Cancer does not agree with the null hypothesis.  \\n Along the left side,  \\n we have two possible outcomes of the test.  \\n Positive test indicates cancer.  \\n Negative test indicates no cancer.  \\n Now, let's look at the possible results.  \\n If the test comes back negative  \\n and the patient does not have cancer,  \\n the cancer screening test was correct,  \\n and thus, our hypothesis test worked.  \\n Also, if the test comes back positive  \\n and the patient does have cancer,  \\n again, the screening test worked.  \\n But how about these two other quadrants?  \\n If a person gets a positive result  \\n but they do not have cancer, this would be a false positive.  \\n In statistics, we also call this a type one error.  \\n The opposite is also possible.  \\n A person gets a negative result, but they do have cancer.  \\n This would be called a false negative.  \\n In statistics, we also call this a type two error.  \\n Type one errors are telling healthy people  \\n that they have cancer.  \\n So, in that case, maybe our test is too sensitive.  \\n Type two errors are telling sick people they're healthy.  \\n This could indicate our test is not sensitive enough.  \\n In both cases, we're concerned  \\n about the quality of the test and the testing kits,  \\n but the types of errors  \\n and the possible causes for the different types of errors  \\n may be very different.  \\n Hypothesis tests, even when they're done the right way,  \\n they can be flawed.  \\n So, it's important to understand  \\n a hypothesis test might make a mistake,  \\n and by knowing the different types of errors,  \\n type one and type two,  \\n it can help you in developing  \\n and interpreting your hypothesis tests  \\n and the subsequent results.  \\n \\n\\n\"}],\"name\":\"5. Hypothesis Tests\",\"size\":32522198,\"urn\":\"urn:li:learningContentChapter:3083793\"},{\"duration\":75,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3080916\",\"duration\":75,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Next steps and additional resources\",\"fileName\":\"2446433_en_US_06_01_MM30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1177606,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Congratulations, you made it.  \\n You survived sampling and sample size,  \\n you created confidence intervals  \\n and you performed some very basic hypothesis tests.  \\n If you weren't already surprised, interested  \\n or perhaps skeptical of the statistics  \\n that you encounter at work and in the media,  \\n you're probably now hypersensitive  \\n to any statistic that's put in front of you.  \\n You might even ask probing questions  \\n about sampling methods or get excited  \\n when you see poll results listed  \\n with their margins of error.  \\n I guarantee you'll now be keenly aware  \\n when people present data that is very likely unreliable.  \\n So what's next?  \\n Well, you can move on to even more advanced  \\n statistics courses that cover topics like regression,  \\n comparing two populations and analysis of variance  \\n or perhaps you want to learn more about business analytics.  \\n You can follow me here on LinkedIn  \\n for more statistics and business courses.  \\n In either case, your statistics foundations  \\n will be valuable tools that will help you understand  \\n the world around you and guide you to make sound decisions  \\n based on data.  \\n Once again, congratulations and thanks for watching.  \\n \\n\\n\"}],\"name\":\"6. Continuing Your Statistics Learning Journey\",\"size\":1177606,\"urn\":\"urn:li:learningContentChapter:3087929\"}],\"size\":98301604,\"duration\":6057,\"zeroBased\":false},{\"course_title\":\"Learning Python (2021)\",\"course_admin_id\":2896241,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":2896241,\"Project ID\":null,\"Course Name\":\"Learning Python (2021)\",\"Course Name EN\":\"Learning Python (2021)\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"&lt;p&gt;Python\u2014the popular and highly-readable object-oriented language\u2014is both powerful and relatively easy to learn. Whether you're new to programming or an experienced developer, this course can help you get started with Python. Joe Marini provides an overview of the installation process, basic Python syntax, and an example of how to construct and run a simple Python program. Learn to work with dates and times, read and write files, and retrieve and parse HTML, JSON, and XML data from the web.&lt;/p&gt;&lt;p&gt;This course includes Code Challenges powered by CoderPad. Code Challenges are interactive coding exercises with real-time feedback, so you can get hands-on coding practice alongside the course content to advance your programming skills.&lt;/p&gt;&lt;p&gt;This course is part of a &lt;a href=https://www.linkedin.com/learning/paths/anaconda-python-for-data-science-professional-certificate target=_blank&gt;Professional Certificate&lt;/a&gt; from Anaconda.&lt;/p&gt;\",\"Course Short Description\":\"Get started with Python, the popular and highly-readable object-oriented language.\",\"Content Type\":\"TOOLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":\"85\",\"Instructor Name\":\"Joe Marini\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"Technology Industry Veteran\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2021-11-19\",\"Course Updated Date\":\"2023-09-14\",\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"Yes\",\"Has Challenge/Solution\":\"Yes\",\"LIL URL\":\"https://www.linkedin.com/learning/learning-python-2021,https://www.linkedin.com/learning/learning-python-14393370,https://www.linkedin.com/learning/learning-python-revision-q4-2021\",\"Series\":\"Learning\",\"Limited Series\":null,\"Manager Level\":\"Individual Contributor\",\"LI Level\":\"Beginner\",\"LI Level EN\":\"Beginner\",\"Sensitivity\":null,\"Internal Library\":\"Technology\",\"Internal Subject\":\"Programming Languages\",\"Primary Software\":\"Python\",\"Media Type\":\"Interactive\",\"Has CEU\":\"No\",\"Has Exercise Files\":\"No\",\"Visible Duration\":11142.0,\"Visible Video Count\":31.0,\"Learning Objectives\":null,\"Contract Type\":\"PERPETUAL\",\"Certifications\":null,\"Framework Topic\":null,\"Automatic Caption Translations\":\"Global Captions\",\"Automatic Metadata Translations\":\"Global Metadata\",\"Gen AI Feature Flag\":null,\"Hands-On Practice\":\"Hands-On Practice with Code Challenges\",\"Hands-On Practice Library\":\"Coding Practice\",\"Unlocked for Viva Learning\":\"Global Captions\",\"Free Course\":null,\"Certification Library\":null,\"Github Codespace\":null,\"Skills Count\":1,\"Skills\":\"Python (Programming Language)\",\"Skills EN\":\"Python (Programming Language)\",\"Content Manager\":\"Jennifer Brady\",\"Acquisition Manager\":\"Natalie Pao\",\"Framework Subject\":null},\"sections\":[{\"duration\":194,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:4511430\",\"duration\":51,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Learning Python\",\"fileName\":\"2896241_en_US_00_01_2023Q3_WX30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3008111,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - The Python programming language has become one  \\n of the most popular languages in the world.  \\n Python has an easy to learn structure.  \\n It runs on multiple operating systems  \\n both on the client and the cloud, and has a vast ecosystem  \\n of tools and libraries that address a large number  \\n of programming scenarios.  \\n Hi, I'm Joe Marini  \\n and I've been building software professionally  \\n for some of the biggest companies  \\n in Silicon Valley for more than 30 years.  \\n In this course, you'll get a hands-on introduction  \\n to the Python programming language.  \\n Then we'll move on to working  \\n with some of Python's built in high level data types,  \\n such as dates, times and files.  \\n Finally, we'll wrap up by processing information  \\n such as HTML, XML, and JSON.  \\n If you're ready to start building the next generation  \\n of cross platform applications that run  \\n on the client as well as the cloud,  \\n let's get started learning Python.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3025081\",\"duration\":75,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"What you should know\",\"fileName\":\"2896241_en_US_00_02_XR30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1858061,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Before we get started,  \\n there are some concepts that you should already  \\n be familiar with in order to get  \\n the most value out of this course.  \\n This course is designed to quickly get you up and running  \\n with the Python programming language.  \\n It is not intended to be a general introduction  \\n to the fundamentals of programming itself.  \\n You should already be familiar  \\n with the basic principles of programming,  \\n such as variables, functions, statements, and so on.  \\n If you're not familiar with these concepts,  \\n I suggest you watch Foundations of Programming Fundamentals  \\n before taking this course.  \\n It does a great job of introducing  \\n the fundamentals of programming.  \\n If you have prior experience  \\n with other programming languages like JavaScript,  \\n that will also be very helpful.  \\n And it's okay if you don't,  \\n you will still be able to benefit from the course.  \\n But JavaScript has some language features  \\n that are kind of similar to the things we'll run into  \\n in Python, so having some knowledge of JavaScript will help,  \\n but again, not required.  \\n You should also know how to use  \\n some common programming tools,  \\n like your operating system's terminal program  \\n and a text editor or an integrated development environment.  \\n If you need to brush up on using an IDE or text editor,  \\n consider watching Learning Visual Studio Code,  \\n which is the editor I'll be using in this course.  \\n Once you feel comfortable with these concepts,  \\n you can go ahead and get started.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3023363\",\"duration\":68,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Exercise files\",\"fileName\":\"2896241_en_US_00_03_XR30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1968240,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] I've provided a set of exercise files  \\n to accompany this course, which you can download  \\n from the associated GitHub repository.  \\n You can see here that I've placed them on my desktop  \\n so that they're easy to access, but you can place them  \\n wherever is most convenient for you.  \\n So let's open the folder and take a look at how  \\n they're arranged.  \\n You can see that the exercise files are arranged according  \\n to the chapter that they correspond to in the course.  \\n So let's open up one of the chapters.  \\n Each exercise file has a name and ends with either  \\n _start or _finished.  \\n The _start version of the file is the starting point  \\n of that particular exercise that I will use to build  \\n towards the finished working version.  \\n The finished version right here is the corresponding code  \\n in it's finished state.  \\n Now, how you use these exercise files is entirely up to you.  \\n If you want to use the start version and then follow along  \\n with me as I build toward the finished version,  \\n well, that's great.  \\n If you want to jump ahead and just look at the finished  \\n version to see how everything works, well, that's great too.  \\n It's entirely up to you.  \\n So once you have the excess files folder downloaded,  \\n and you've got it where you want it on your system,  \\n then you're ready to go.  \\n \\n\\n\"}],\"name\":\"Introduction\",\"size\":7221726,\"urn\":\"urn:li:learningContentChapter:3019945\"},{\"duration\":857,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3017843\",\"duration\":98,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Installing Python on Windows\",\"fileName\":\"2896241_en_US_01_01_XR30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to install Python on a Windows machine.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3006002,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Let's begin by making sure that Python  \\n is properly installed and configured on your computer.  \\n So here on my machine,  \\n I'm going to open a terminal window,  \\n and then in the terminal window,  \\n I'm going to type py.  \\n I could also just type the word Python by itself,  \\n but I'm going to type py --version,  \\n and hit the enter key.  \\n And you can see that I'm using Python 3.9 on my computer.  \\n Now, if you're on Windows and you didn't get a result  \\n that looks like this,  \\n the word Python followed by a version number,  \\n then you probably got some kind of error message  \\n or the version number you have is less than 3.9.  \\n So in either case, that means you need to install  \\n the latest version of Python on your machine.  \\n So let's go over to the Python website.  \\n This is the Python website, located at python.org.  \\n And I'm going to go ahead and click  \\n on the Downloads area right here, right?  \\n And you can see that there's a link to download  \\n the latest version, which is the 3.X series.  \\n And for this course, you should use at least 3.9.  \\n And you can also see that the Downloads page defaults  \\n to the version for my operating system,  \\n which in this case is Windows,  \\n and there are download links provided  \\n for a variety of other OS's.  \\n Now I've already done this for my machine,  \\n so if you need to, go ahead and download  \\n and then run the installer by clicking  \\n on this button right here.  \\n It's a very simple process  \\n and it should take only a few minutes to complete.  \\n And then go back and try that terminal test again  \\n that we did earlier to make sure that everything worked.  \\n That's pretty much all you need to do.  \\n So once you've got Python installed,  \\n you are ready to continue.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3021791\",\"duration\":117,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Installing Python on Mac\",\"fileName\":\"2896241_en_US_01_02_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to install Python on a Mac machine.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3049927,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Installing Python on the Mac  \\n is pretty much the same as installing it on Windows.  \\n Now, the good news is  \\n if you're watching this on a Mac or Linux machine,  \\n chances are, you've already got Python installed  \\n on your system, but it might not be the most recent version.  \\n The Mac ships with Python as does many versions of Linux.  \\n So you might already be good to go,  \\n but you can make sure you have the right version  \\n by following along with me.  \\n So here on my machine, I've opened a terminal window  \\n and if you're on a Mac or Linux computer,  \\n then just use the terminal program  \\n that came with your system.  \\n So I'm going to type python3.  \\n And this is important,  \\n if you're on a Mac or Linux,  \\n instead of just python by itself,  \\n or pi because pi only works on Windows.  \\n So type python3.  \\n And the reason is because some systems come  \\n with both the older Python 2  \\n as well as the newer Python 3 installed.  \\n So I'm going to type python3 --version  \\n and you can see that I'm using Python 3.9 on my computer.  \\n Now if you didn't get a result that looks like this,  \\n the word Python followed by a version number,  \\n you probably got some kind of error message,  \\n or maybe you got a version number that's older than this.  \\n And that means that Python is not on your computer,  \\n or you need to go get the latest version.  \\n So let's go do that on the Python website.  \\n So this is the Python website located at python.org.  \\n And I'm going to go ahead and click on the Downloads button.  \\n And you can see here that there is a link  \\n to download the latest version right here.  \\n Now this page might look a little bit different  \\n when you get here, but it'll look pretty similar  \\n and how to download this will be pretty obvious.  \\n So you can see that there's a link  \\n to download the latest version.  \\n And there's also links that download to other versions  \\n for operating systems.  \\n So if you need to,  \\n go ahead and download the Python installer,  \\n that's appropriate for your computer in this case, the Mac,  \\n and then install it, run the installer,  \\n and then try the terminal test again that we just did.  \\n So once you've got Python installed,  \\n you're ready to continue.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3017844\",\"duration\":283,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Choosing an editor or IDE\",\"fileName\":\"2896241_en_US_01_03_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to select an editor or IDE to use with Python.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10546074,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] There are a lot of great tools out there  \\n for working with the Python programming language,  \\n and in this course, you can use any code editor  \\n that you want.  \\n I'm going to be using Visual Studio Code from Microsoft.  \\n It has great support for Python editing, and it's free,  \\n and it runs on Mac, Windows and Linux.  \\n It also has a wide variety of plugins available,  \\n which will help when working with Python.  \\n So if you want to use VS Code along with me in this course,  \\n then download it from code.visualstudio.com,  \\n just come to the site right here,  \\n click on this little Download button,  \\n and it'll download the proper version  \\n for your operating system and then go ahead and install it.  \\n Now again, just want to remind you that VS Code  \\n is not a requirement, you can use any editor that you want.  \\n In a separate video, we'll see how to run the example files  \\n directly from the terminal.  \\n So you can go that route if you want to,  \\n or if you're using a different editor,  \\n it will still be very easy to follow along  \\n with the rest of the course.  \\n So once you have Visual Studio Code installed, launch it,  \\n and then once it's launched, click on the extensions icon,  \\n which is this one right here, these little square boxes.  \\n Once you click on the square boxes up here  \\n in this little search box,  \\n we're going to type the word Python,  \\n because we're going to install the Python extension.  \\n And usually it's the first result, this one right here,  \\n you can see it's from Microsoft, it has a ton of downloads,  \\n there are other options for working with Python,  \\n but this is the one that you should be using.  \\n So go ahead and install that one,  \\n and if I go back to my list of installed extensions,  \\n you can see that I've already got Python installed  \\n and it should automatically install this Pylance  \\n language server for you.  \\n So just install the Python extension  \\n and you should be ready to go.  \\n So this extension add support for debugging  \\n and running Python apps,  \\n right from within Visual Studio Code,  \\n and when you install it, if VS Code asks you to restart  \\n then go ahead and do that.  \\n All right, so once we've done that,  \\n we're going to take a few moments,  \\n and we're going to set up some of the preferences  \\n and settings that are going to make VS Code easier to use.  \\n So first, make sure that VS Code is using the version  \\n of Python that you installed.  \\n Now usually this is set up for you, but let's make certain,  \\n so we're going to open the exercise files folder  \\n as a VS Code project.  \\n And you can either click on the Open Folder button here,  \\n or you can drag and drop the folder  \\n onto the application window,  \\n I'm going to go ahead and click on Open Folder,  \\n and then my ExerciseFiles are on my desktop,  \\n so I'll select that folder,  \\n all right so I've got my Python project now open  \\n and we'll give VS Code a moment to go ahead  \\n and activate it's extensions, all right,  \\n and then in chapter two,  \\n go ahead and open up the helloworld_start file,  \\n and you can see down here, VS Code says it's activating  \\n it's extensions, all right.  \\n And then you should see over here in the status bar,  \\n the version of Python that the IDE is using.  \\n So if you click on this little text,  \\n you'll see this pop-up appear,  \\n and this gives you the opportunity to choose  \\n the interpreter that you want to use,  \\n and you can see, I only have the one version  \\n of Python installed.  \\n So just go ahead and select that version number  \\n and you should be fine.  \\n Now, if you don't see this little text label down here  \\n in the corner, that's not common, but it might happen,  \\n what you can do is use a different way to select  \\n the right Python engine.  \\n So in the View menu, you can choose either  \\n the Command Palette option right here,  \\n or you can just type Control+Shift+P on the Windows machine  \\n it's Command+Shift+P on the Mac,  \\n and that will open up this little pop-up.  \\n Then type Python select,  \\n and you can see that there's an option  \\n for Python Select Interpreter.  \\n So go ahead and select that one,  \\n and you'll see the same pop-up appear,  \\n and then just choose the Python Interpreter  \\n that your machine has installed.  \\n And after you do that, you should be all set.  \\n So now let's open up the settings for VS Code  \\n in our Windows you can type Control+,  \\n or Command+, on the Mac,  \\n or you can find it in the menu bar.  \\n So let's go ahead and type Control comma,  \\n and here in the search box,  \\n I'm going to search for a preference named  \\n executeinfiledir, all right?  \\n And that's this preference right here,  \\n make sure that it's checked, and then save the preferences.  \\n So this preference tells VS Code,  \\n to look in the same directory as the program source file  \\n when it needs to work with other files,  \\n which we will see later in the course.  \\n All right, that's pretty much it.  \\n So once you've got VS Code installed  \\n and set up along with the preference changes,  \\n then you are ready to proceed.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3022805\",\"duration\":140,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"How to run the Python examples\",\"fileName\":\"2896241_en_US_01_04_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to run the Python example files.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5229545,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] During this course, we're going  \\n to be building and running some example programs.  \\n And, as I demonstrated earlier,  \\n I'll be using Visual Studio Code during this course.  \\n And we've seen how to get that set up in a previous video,  \\n but using VS Code isn't required.  \\n You can use any editor you want, and it's important  \\n to know how to run Python programs outside  \\n of the development environment that you're using.  \\n So, here's what we're going to do.  \\n First, open the terminal program for your computer.  \\n On the Mac and Linux this is usually called terminal.  \\n On Windows this is either PowerShell,  \\n or the regular command prompt.  \\n Now, it's beyond the scope of this course  \\n to explain how the terminal works.  \\n So if you're not familiar with it,  \\n you'll need to read up on it on your own.  \\n From here, let's go into the exercise files directory,  \\n which is wherever you put it.  \\n So here, on my system it's on the desktop.  \\n So, I'm going to go into the desktop  \\n and I'm going to go into the exercise files folder  \\n and let's list that, all right so I've got my chapters.  \\n So, let's go into chapter two.  \\n All right, and inside chapter two,  \\n we have a program called helloworld_finished.  \\n All right so, to execute a Python program,  \\n we use the Python command like this.  \\n I can either type py on Windows.  \\n Now, this doesn't work on the Mac,  \\n but on Windows you can type py,  \\n or you can type Python by itself.  \\n And that's the name of the Python program.  \\n And remember on the Mac, or on Linux, it'll be python3.  \\n And that's because Macs and Linux machines usually have  \\n a older version of Python, the 2.7 series,  \\n and usually Python is mapped to the older series.  \\n So you'll type python3 on the Mac or Linux.  \\n So here on Windows I'll type python,  \\n and then the name of the Python program file we want to run.  \\n So, I'm going to type helloworld,  \\n (typing)  \\n and I want to run the finished version.  \\n And when I hit the Enter key,  \\n you can see that the program runs  \\n and prints hello world and asks me  \\n for my name, so I'm going to type Joe.  \\n And it says, \\\"Nice to meet you, Joe.\\\"  \\n And we'll see how to build that program later.  \\n But all of the examples in this course can be run this way.  \\n So, if you choose to use a different development environment  \\n than Visual Studio Code, or even if you are using VS Code  \\n and just prefer running the examples  \\n this way, then you have this option.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:4515423\",\"duration\":219,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"CoderPad Challenges\",\"fileName\":\"2896241_en_US_01_05_C_2023Q3_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7332645,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] This course includes  \\n automated code challenges that appear when you click  \\n on the challenge links in the courses table of contents.  \\n Each challenge includes instructions  \\n and a couple of code editors you can use to create  \\n and test your own solution to the challenge.  \\n These challenges are hosted by CoderPad  \\n and they appear in the same area  \\n of the course page where you watch the course's videos.  \\n We recommend using a desktop browser  \\n for the best experience with the code challenges  \\n but you can use the LinkedIn Learning mobile app  \\n if you prefer.  \\n The Code Challenge has four areas.  \\n There's the instructions in the top left,  \\n a code editor for your answer in the top right,  \\n another code editor where you can see  \\n how your code is used here in the bottom right,  \\n and there's a console for output in the bottom left.  \\n You can use these drag handles  \\n to allocate space as you like,  \\n and you can see I can bring up the console  \\n a little bit here.  \\n And you can also collapse  \\n the course's table of contents on the left  \\n to get more space.  \\n Each challenge has instructions  \\n that include a description of the challenge  \\n and the challenge's parameters  \\n and the desired result.  \\n Depending on the challenge  \\n you might see some additional information  \\n in the instructions such as an explanation  \\n of the parameters that your code will be given,  \\n along with some examples  \\n of what the expected output might look like.  \\n So you're going to create your answer  \\n in the top right code editor  \\n and there are comments showing where to put your solution.  \\n When you click the test my code button  \\n you'll see a message indicating  \\n whether your code returned a correct result.  \\n So let's go ahead and put in the right result.  \\n So to find the largest number, I'm going to return max  \\n and I'm going to call numbers.  \\n And then I'll click test my code.  \\n And you can see down here in the console  \\n that I have a successful result  \\n and it shows what my code returned.  \\n So if your code isn't successful, let's go ahead  \\n and put this back, just returning zero,  \\n and I'll click test my code again,  \\n you can see that now I have the wrong answer  \\n and I can ask for help.  \\n So the show expected results  \\n and show hints variables up here  \\n determine whether you see the expected result  \\n and any hints, you can change them each to a value of true  \\n to control this output.  \\n So let me go ahead and change those,  \\n and I'll show you what I mean.  \\n And so now I'll click test my code again,  \\n and you can see that it says, \\\"It's incorrect.\\\"  \\n Here's what my code returned,  \\n and if I scroll down, you'll see that now  \\n it shows what the expected result is  \\n and it's giving me a hint.  \\n The code editor in the lower right  \\n shows how your code will be executed,  \\n and you can change this code  \\n to experiment with different test cases.  \\n So instead of the large number being 19, I'll make that 25,  \\n and let's go back and put the right answer in again,  \\n I'll click test my code,  \\n and sure enough, now you can see  \\n I'm getting the new correct answer.  \\n Regardless of whether your answer is successful,  \\n you'll see messages in the console output  \\n here in the lower left.  \\n And if any messages are too long to fit in that area  \\n you can scroll sideways to see all the text, or again,  \\n use the drag handles to resize the area to your preference.  \\n When you've finished each code challenge,  \\n return to the course's table of contents  \\n and click the next video to see my solution.  \\n \\n\\n\"}],\"name\":\"1. Getting Started\",\"size\":27838297,\"urn\":\"urn:li:learningContentChapter:3017847\"},{\"duration\":4265,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3025082\",\"duration\":545,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Building Hello World\",\"fileName\":\"2896241_en_US_02_01_XR30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"In this video, learn the basic structure of a Python program.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":16762002,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Now that we have Python installed  \\n and our tools set up,  \\n it's time to start writing some actual Python code.  \\n But before we fire up our text editor  \\n and just start diving in,  \\n we're first going to use Python's interpreted mode  \\n in the command line interface to see how easy it is  \\n to write and run Python.  \\n So here I've started up my terminal program,  \\n and you can do the same on your computer,  \\n doesn't matter if it's Windows or Mac,  \\n and I'm going to type Python by itself and hit return.  \\n And remember on the Mac,  \\n you're going to have to do Python three, okay?  \\n So I'm going to type Python, and when I do this,  \\n you can see that this places me  \\n into Python's interpreted mode, right?  \\n So right here is the version number for Python,  \\n and then there's some help text.  \\n All right, and then there's this little three angle  \\n bracket prompt right here.  \\n Now in this mode, I can just simply type some Python code  \\n and it will run immediately.  \\n So I'm going to go ahead and type 2+2,  \\n and you can see that the answer comes back as four.  \\n Now, Python is an interpreted language,  \\n like some other common ones in use today,  \\n for example like JavaScript in the browser.  \\n In other words, it's not like Java or C or C++,  \\n the application does not need to be compiled  \\n and then built into an executable before you can run it.  \\n The Python interpreter simply takes each line of code  \\n as it comes across it,  \\n and then interprets and executes the code.  \\n And in this case,  \\n it's simply taking the numerical expression, two plus two,  \\n evaluating it, and it gets four back.  \\n All right, let's try a different line of code.  \\n I'm going to write print and then a parentheses  \\n and a quotes and type in Hello world and then quotes,  \\n and then a closed parentheses, right?  \\n I'll hit enter.  \\n And now you can see that I've executed  \\n these simple Python statement print,  \\n which is a built-in Python function,  \\n and we'll learn more about functions,  \\n along with the string of characters, Hello world.  \\n Don't worry about understanding all of this right now,  \\n it will become clearer as we go through the course.  \\n All right, let's try one more thing.  \\n I'm going to write name equals input, and I'm going to type,  \\n what is your name, question mark,  \\n and then close quote and parentheses.  \\n And when I hit enter,  \\n you can see that now Python is running the input function,  \\n which gives me a chance to enter a value.  \\n So I'll type Joe and hit enter.  \\n So now I've created a variable  \\n and that variable is called name,  \\n which contains the value that this input function asked for.  \\n So if I just type name by itself,  \\n you can see the value that the name variable contains,  \\n which is Joe.  \\n Now all of this is not how you would normally write  \\n and run your real Python programs.  \\n I mean, obviously real programs  \\n are going to be a lot more complex than this,  \\n but you can use the Python interpreter in command line mode  \\n to try out some simple things.  \\n Okay, now let's type the word exit and with an open  \\n and closed parentheses,  \\n so we're actually calling the exit function  \\n and that will exit us out of the Python interpreter  \\n and then back into the terminal command line.  \\n Okay, so now we've seen how to write and execute  \\n some basic Python statements,  \\n let's start up our code editor  \\n and write our first Python program.  \\n And I'm using Visual Studio Code, but again,  \\n you can use whatever editor you like.  \\n So here we are in VS Code,  \\n and I'm going to open up chapter two  \\n and here in chapter two, I'm going to open up the file  \\n named helloworld_start.py.  \\n So let's start off by printing out a hello world message,  \\n right, so I'm going to type print,  \\n and you can see that as I'm writing my code, right,  \\n visuals here in VS Code,  \\n I'm getting statement completion right as I'm typing,  \\n and that's because of the Python extension  \\n that we installed earlier.  \\n So I'm going to write print  \\n and then I'm going to write Hello World,  \\n and that's pretty much it for that line.  \\n And then let's also have the user enter their name.  \\n So I'm going to write name equals input.  \\n And I'll write, what is your name?  \\n And then I'll print, nice to meet you.  \\n And then outside the closing quotes,  \\n I'm going to put a comma and then name.  \\n All right. So let's go ahead and save this.  \\n All right, and we can start up a terminal window  \\n and go into the directory for the example file  \\n and run it like we did before,  \\n or if you're using VS Code  \\n and you've got the Python extension installed,  \\n you can also click this little icon up here,  \\n which it says you can see when I hover it, it says,  \\n run Python file in terminal, or I can right click  \\n in the source code and choose run Python file in terminal.  \\n So I'm going to go ahead and do that.  \\n And you can see that when I do that,  \\n the program is running in VS Code's built in terminal here,  \\n right, and you can see that Hello World is being printed,  \\n and here's the input for what is your name?  \\n So I'll type in Joe and it says, nice to meet you, Joe  \\n and then the program exits.  \\n So, so far so good. Let's change a couple of things.  \\n So I'm going to click on this little trashcan  \\n and get rid of this interpreter right here  \\n and what I'm going to do is define a function.  \\n We'll learn more about functions later in the chapter.  \\n So just bear with me for the moment.  \\n I'm going to write def, which defines a function,  \\n and I'm going to call the function main.  \\n And then I give it an open and closed parentheses  \\n and then a colon, right?  \\n Now, when I do that,  \\n you can see that this little red squiggle appears here.  \\n That means I'm getting an error.  \\n You can see it says expected indented block.  \\n So what I'm going to do is indent each of these lines  \\n under the function, main.  \\n So I'm going to hit the tab each time, okay?  \\n And it's important that all of these lines be indented  \\n using the same number of spaces.  \\n And you can see that I've got one, two, three,  \\n four spaces of intending.  \\n It doesn't matter if it's two or three or four,  \\n it doesn't matter.  \\n They all have to be the same.  \\n Now, again, I don't expect you to understand all of this  \\n right away, we're going to be going to this more deeply  \\n as the course goes on,  \\n but what I'm doing here is defining a function  \\n and that function contains our print and input statements.  \\n So I'm grouping all of these statements into one function  \\n that I can call elsewhere in my program.  \\n The Python syntax is a little bit different  \\n than other languages you might be used to.  \\n So Python actually uses the indentation level  \\n of the lines of code to indicate where that code belongs.  \\n So, because under the definition for the main function,  \\n I've got each of these lines indented by four spaces  \\n that indicates to the Python interpreter  \\n that these lines of code belong to the function name.  \\n Alright, so now I need to add some code  \\n to actually execute the main function.  \\n So what I'm going to do is I'm going to write if__name  \\n and then double underscore again,  \\n is equal to, and then inside quotes, double underscore main,  \\n and then double underscore and then a colon.  \\n And then once again, I have to indent.  \\n I'm going to call main.  \\n So why do we need to do this, and what does it do?  \\n So unlike in C Sharp or Java or other programming languages,  \\n Python does not automatically look for a specific function  \\n when the program starts.  \\n So what's happening here is this line of code right here,  \\n line 11, is checking to see that this module,  \\n this file of Python code is loaded  \\n and the interpreter has assigned  \\n the double underscore name variable, the value of main.  \\n That means that this Python program was executed  \\n as a main program.  \\n It was started from the command line  \\n or invoked from the Python executable somehow  \\n and therefore this function right here,  \\n the main function should be called.  \\n Now, the reason I need to do this is because Python code  \\n can be used multiple ways.  \\n My code in this file can be run as its own program,  \\n but I could also build a reusable module  \\n that can be included inside of other Python programs.  \\n So if I were using this code in another program,  \\n I wouldn't want all this code to just start running  \\n when it was imported into the other program,  \\n because that would cause problems.  \\n So lines 11 and 12 helped distinguish  \\n between when a Python file is being included  \\n in another program, or when that Python code  \\n is being executed as its own program.  \\n So in this case, the file is being executed as a program  \\n and this, if condition right here, will evaluate to true,  \\n and then the main function will be called.  \\n All right, so once again, let's save  \\n and I'm going to go ahead and right click  \\n and choose run Python file in the terminal.  \\n And you can see that we are getting the output  \\n just as we would expect.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3018969\",\"duration\":704,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Variables and expressions\",\"fileName\":\"2896241_en_US_02_02_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn about variables and how to use expressions.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":27753210,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] All right now,  \\n let's take a look at how the Python language works  \\n with variables and data types.  \\n So in my editor,  \\n I'm going to open up the variables_start file.  \\n And there are five major data types in Python.  \\n There are numbers such as integers  \\n and floating point values.  \\n Strings, which are a collection of characters.  \\n Boolean values,  \\n which can be either true or false.  \\n Sequence types, such as lists  \\n and a data type called tuples which are immutable.  \\n I mean, the can't be changed.  \\n And dictionaries, which map unique keys to specific values.  \\n And so you can see here,  \\n I have defined a set of variables that represent  \\n each of these data types.  \\n And I have a set of print statements  \\n that print each of these values.  \\n So before we do anything else,  \\n let's just go ahead and run what we already have.  \\n So I'll right click and choose run Python file in terminal.  \\n And remember if you're not using VS code,  \\n you can just run this in your terminal program.  \\n Like we saw earlier in the course,  \\n and you can see that the output  \\n contains the values of each of the variables  \\n that we've defined so far.  \\n All right, so far so good.  \\n Let's go back to the code.  \\n All right, let's try adding a couple of lines.  \\n I'm going to to write myint = abc.  \\n Okay, and then I'll print(myint).  \\n So now I've got myint = abc.  \\n So basically I'm redeclaring  \\n the variable that was declared up here  \\n previously as a number.  \\n So now I'm declaring it as a string.  \\n So let's go ahead and run this  \\n and you can see that it works.  \\n It started out as an integer, but now it's a string.  \\n So even if a variable has already been declared,  \\n you can redeclare it with a different type  \\n and that works just fine in Python.  \\n All right, let's keep on going.  \\n Okay, let's take a moment to look at sequence types.  \\n So for sequence types like lists and tuples  \\n we can access individual values  \\n using a square bracket notation with the index of the item  \\n that we want starting from zero.  \\n So to take an example,  \\n if I wanted to access the third item of my list,  \\n I would write something like this.  \\n I would write print(mylist)  \\n and then remember it's a zero-based index.  \\n So I would use index two.  \\n And the second item of my tuple, for example,  \\n would be index one.  \\n And you can also use what's called the slice notation  \\n to access a subset of a sequence.  \\n So for example,  \\n if I wanted to get the first index here  \\n all the way to the end of my list,  \\n I would write something like this.  \\n So I'll print(mylist)  \\n and then we're going to write one and then colon,  \\n and then the number five.  \\n So basically the two indexes that I want to get a subset  \\n from and slices also take a third optional parameter,  \\n which is what's called the step value.  \\n In other words, it's how many items to skip over.  \\n So for example,  \\n to get the second through the fifth items in my list,  \\n while skipping every second one,  \\n I could write something like this.  \\n Let me just copy this and paste it.  \\n So basically this is the start index,  \\n the end index and the step value.  \\n Okay, So let's go ahead and save  \\n and let's go ahead and comment out the previous prints  \\n to avoid muddying the output.  \\n All right, and we've already seen this one too,  \\n so we can comment that out as well.  \\n All right, so let's go ahead and save and let's run.  \\n And now you can see that we're getting,  \\n let's go ahead and scroll that up.  \\n All right, so we have the third item in my list.  \\n The second item, which is the next one of my tuple.  \\n Here we have items one through the end, right?  \\n So this is the second, third, fourth,  \\n and fifth item in my list.  \\n And this is the second and fourth item  \\n because we're skipping every second one in my list  \\n using the step value.  \\n All right, let's keep on going.  \\n So what's interesting is you can use the slice notation  \\n to actually reverse a sequence.  \\n So there's a neat little trick you can do.  \\n I'm going to print my list  \\n and then inside the square brackets,  \\n I'm just going to put two colons and then a minus one.  \\n So I'm not specifying a start value.  \\n I'm not specifying an end value.  \\n So it's going to be the default start and the default end,  \\n which is the entire sequence.  \\n And then the step value is going to be minus one.  \\n So this is actually going go reverse the sequence.  \\n So if we save and we run,  \\n you can see that now here's the original sequence.  \\n And here is in reverse order  \\n just by using the trick right here to do the minus step.  \\n Okay, so far so good.  \\n Let's go back to the code.  \\n Let me comment out the previous calls here.  \\n All right, dictionaries are a little bit different.  \\n Dictionaries don't work with indexes.  \\n What happens is you give them the key  \\n of the item that you want,  \\n and they return the value associated with that key.  \\n So if we scroll back up and we look at the dictionary here,  \\n we can see that these string one maps to the value one here  \\n and the string two maps to the value two.  \\n Now in dictionaries,  \\n the keys have to be unique values,  \\n but the values don't have to be unique.  \\n So if I want it to retrieve the value  \\n associated with this key of one right here,  \\n what I would do is write something like this,  \\n I'm going to print out mydict  \\n and it's going to be inside quotes the key of one, right?  \\n So let's go ahead and run that.  \\n And you can see that the key of one maps to the number one.  \\n Okay, all right, let's go back to the code.  \\n So let's make another change.  \\n And let me go ahead and comment that line out.  \\n All right.  \\n Let's see what happens when I try to combine  \\n two different data types,  \\n I'm going to print a string type, right?  \\n So this is a string.  \\n And then we're going to use the plus operator  \\n with the number 123.  \\n All right, so I'm going to save that and I'll try to run it  \\n and you can see that I'm getting an error.  \\n And right here,  \\n you can see specifically, I'm getting a type error.  \\n And this is happening because Python  \\n is what's called a strongly typed language.  \\n Even though you don't have to declare the type of a variable  \\n before you use it.  \\n So what happens is when Python goes to execute this code,  \\n right here, it infers a specific type for a value  \\n or a variable.  \\n So you can't go back and change the type  \\n or combine it with other types.  \\n So I've got a string and I've got a number  \\n which are two different types.  \\n I'm trying to combine them.  \\n And in Python, this doesn't work.  \\n You have to have all of the arguments,  \\n be the same type when concatenating a string like this.  \\n So let's make an adjustment.  \\n I'm going to use the str function  \\n to convert the number into a string.  \\n So what I'm doing here is using this built in function  \\n in Python called str.  \\n And that's going to convert this integer into a string.  \\n So that way I'll have a string plus another string.  \\n And that works just fine.  \\n So let's go ahead and save.  \\n I'm going to close that terminal and run this again.  \\n And now you can see that that works just fine.  \\n It's printing out string type 123,  \\n just as we would expect.  \\n All right, couple more things to look at.  \\n Let's take a look at global versus local variables.  \\n I'm going to go ahead and comment that out.  \\n So I'm going to define a function and add some code to it.  \\n Now, I don't expect you to understand this right away.  \\n We'll get into functions later in the course, but for now,  \\n just bear with me.  \\n So I'll declare a function called somefunction  \\n and I'll have a variable called mystr  \\n and I'll assign it the value of def  \\n and then I'll print(mystr).  \\n All right, so inside the function,  \\n you can see that I've got these two lines indented  \\n by some spaces indicating that they belong  \\n to this function here.  \\n So in Python, indentation and white space matters.  \\n So I've got mystr = def and then I'm printing mystr.  \\n Now, remember if we scroll back up,  \\n I've already declared mystr up here.  \\n And so I've got a mystr variable here.  \\n That's global, which is set to this is a string.  \\n And then I've got my local variable here,  \\n which is set to def.  \\n So let's add two more lines.  \\n I'm going to call the function  \\n and then I'm going to print(mystr).  \\n So let's go ahead and run and watch what happens.  \\n So you can see that when I run this,  \\n the value gets printed def, which is inside the function.  \\n But even though I've reassigned the value of mystr to def,  \\n once we get outside the function, it's back to being,  \\n this is a string again.  \\n Now that's because when you're inside a function definition,  \\n the function gets its own local copy of whatever variables  \\n you declare inside the function.  \\n So this variable mystr right here that's is different than  \\n the global one, that's defined up at the top.  \\n Now, if I actually want to affect the value  \\n of the global variable,  \\n I have to tell the function that there is a global variable  \\n named mystr, and that's the value it should make changes to.  \\n So what I'm going to do  \\n is I'm going to write the word global,  \\n and then I'm going to use the variable name of mystr.  \\n So the global statement with the name of the variable  \\n indicates to Python that this variable exists  \\n in the global namespace and is declared somewhere else.  \\n So now, if I save this and let's close that terminal  \\n and run it again.  \\n So now you can see the def is being printed twice.  \\n And the reason is because now I'm affecting the global value  \\n outside the function, because I've told Python,  \\n hey, that's a global variable.  \\n When I changed the value,  \\n it's going to affect the variable globally.  \\n So let's make one more change below this code.  \\n I'm going to write del mystr,  \\n and then I'll try to print it again.  \\n The dels statement deletes the definition of a variable  \\n that was previously declared.  \\n So when I get to this line here, print mystr  \\n there should be a problem.  \\n It should give me an error  \\n because that variable is gone now.  \\n So just for clarity sake,  \\n let's make sure that all the other functions  \\n are commented out and yes, they are.  \\n All right, so I'll save and I'll run and you can see,  \\n sure enough, here's the previous code.  \\n We're printing out the def twice.  \\n And then you can see name error,  \\n name mystr is not defined.  \\n And that's because right here on line 54,  \\n I've deleted the variable,  \\n which essentially means you can undefined variables  \\n in real time by using the del statement.  \\n All right, so that's a quick look at using variables  \\n and data types in Python,  \\n and we're going to take what we've learned in this video,  \\n and we'll use it throughout the rest of the course.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3025083\",\"duration\":712,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Python functions\",\"fileName\":\"2896241_en_US_02_03_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to write and execute Python functions.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":29923893,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Most applications,  \\n regardless of the programming language  \\n that they are written in,  \\n are broken up into smaller blocks known as functions.  \\n And Python's no different.  \\n Functions give us a way of organizing our programs  \\n so that they are more understandable and modular.  \\n In this example, we're going to take a look  \\n at how functions work in Python.  \\n So in my editor, I'm going to open up  \\n the functions_start file.  \\n And we're going to start off by defining a function.  \\n So functions are defined with the def keyword,  \\n along with a name.  \\n So I'll name my function func1.  \\n And then I'll use open and close parentheses.  \\n Now this function doesn't take any arguments,  \\n but we'll get to that in a little bit.  \\n And next comes a colon character.  \\n The colon indicates that you're starting the scope  \\n or body of a function.  \\n In other languages like Java and C, for example,  \\n use curly braces for this, but Python uses the colon  \\n and then white space indentation.  \\n So I'm going to add a print statement here.  \\n This is print.  \\n \\\"I am a function.\\\"  \\n So you can see that the print statement  \\n is indented by four spaces.  \\n And it's up to you how many spaces  \\n you want to indent your code.  \\n It can be four or three or two or eight.  \\n It doesn't really matter.  \\n The important point is that it has to be indented  \\n to indicate that the statements belong to the function.  \\n All right?  \\n So down here at the bottom,  \\n let's add a few more lines of code.  \\n So we'll call the function by using its name  \\n and some parentheses.  \\n And then we'll print func1, again,  \\n using the parentheses.  \\n And then we'll print func1 just by itself with no parens.  \\n All right, so now let's go ahead and save and run,  \\n and let's watch what happens.  \\n Okay, so in the result,  \\n you can see that \\\"I am a function\\\" got printed,  \\n followed by the same strings as \\\"I am a function\\\" again,  \\n followed by the value of none.  \\n So what's happening is this.  \\n In the first case, the function is being called directly,  \\n which executes the contents of the function,  \\n causing the print statement to print the string.  \\n After all, that's what the function does.  \\n So that's simple enough.  \\n In the second case, the function  \\n is also being called inside the print statement.  \\n So the output is the same as the first case.  \\n But then the outer print statement executes.  \\n And since our function doesn't return a result,  \\n Python evaluates the return value to be the constant  \\n of none and prints that.  \\n So these two lines right here are both the result  \\n of this statement right here.  \\n So when func1 gets called, it prints out this string,  \\n but then the print function prints out the return value  \\n of the function.  \\n And since there is no return value,  \\n the value is none.  \\n All right?  \\n In the last case, the function itself  \\n is not actually being executed,  \\n since we're not including the parentheses.  \\n We're just printing the value  \\n of the function definition itself,  \\n which evaluates to this string right here.  \\n That represents the function object that we've defined.  \\n So this demonstrates that functions themselves  \\n are objects that can be passed around to other pieces  \\n of Python code.  \\n Now we're not going to do that right now,  \\n but it's interesting to know that functions,  \\n just like any other object in Python, are values.  \\n You can just pass these around.  \\n Okay, so let's go ahead  \\n and try a couple of different examples.  \\n So let's define a function that takes some arguments.  \\n So once again, we'll use the def keyword.  \\n I'll call this one func2.  \\n And inside the parentheses, I'll have arg1 and arg2.  \\n Once again, we'll have my colon.  \\n And inside the function, I'll simply print arg1,  \\n separated by a space, and then arg2.  \\n And then I'm going to define a function  \\n that actually returns a value.  \\n So I'll define a function named cube.  \\n And that takes one argument named x.  \\n And I'm going to use the return keyword to return a value.  \\n And I'm going to return x times x times x.  \\n Okay, so now, let's go back down to our code down here,  \\n and let's add a few more lines to evaluate  \\n these new functions.  \\n So I'll call func2 with the values of 10 and 20.  \\n And then I'll print func2.  \\n And once again, I'll call it with 10 and 20.  \\n And then, one more parentheses there.  \\n There we go.  \\n And then I'll call print cube of 3.  \\n So first, I'm defining function two.  \\n Takes two arguments.  \\n And all it's going to do is print out the two arguments  \\n with a space between them.  \\n And then I have my function called cube,  \\n which takes a number and then returns that number multiplied  \\n by itself three times.  \\n So basically, it calculates the cube value of the number  \\n and returns it.  \\n All right, so let's go ahead and comment out  \\n these previous statements.  \\n And let's save and let's run this.  \\n All right, and you can see that on the first line,  \\n we've got 10 separated by space, and then 20.  \\n And then on the second line, similar to the first example,  \\n we've got 10, a space, and then 20.  \\n But again, there's no return value.  \\n So it's simply returns the value of none.  \\n And then for the cube function,  \\n we print the cube of 3, and get the value 27.  \\n Because three times three is nine, nine times three is 27.  \\n So in this case, the function does return a value  \\n and that's what gets printed.  \\n All right, so far so good.  \\n Let's go ahead and add another example.  \\n I'm going to define a function that takes arguments  \\n and supplies a default value for one of the arguments.  \\n So I'll define a function called power.  \\n And that's going to take an argument called num,  \\n and another argument called x.  \\n And I'm going to write x equals one.  \\n I'm supplying a default value in case  \\n it gets called without an argument for x.  \\n So inside, I'll have a local variable named result,  \\n and set that to one.  \\n And then I'm going to have a for loop.  \\n Now, again, we haven't covered loops yet,  \\n so just kind of bear with me for a second here.  \\n I'm going to have a loop that goes from i  \\n to the range specified by x.  \\n And we're going to have result equals result times the number.  \\n And then once that loop is over,  \\n we'll return the result.  \\n So in a nutshell,  \\n I have defined a function called power, takes two arguments.  \\n One of them is called num. One's called x.  \\n It takes a number and raises it to the given power.  \\n Now you notice here that I've got x equals one  \\n in the function definition.  \\n This assigns a default value for that argument.  \\n Now, again, don't worry about loops too much,  \\n but the idea here is that we're going to loop over  \\n the number of times that this value is passed to us  \\n and multiply the number by itself that many times.  \\n So now, let's add a couple of lines  \\n to execute this and try it out.  \\n So I'm going to print power of two, just by itself.  \\n And then I'll print power of two,  \\n and I'll pass in the value of three for the second argument.  \\n So in the first example, I'm calling the function power,  \\n but not giving it a value for x.  \\n So x is going to default to one.  \\n And then the next call calls the function  \\n with num equals two, and X equals to three.  \\n So that's going to return two to the power of three.  \\n Let's go ahead and comment out these previous ones,  \\n and let's run again.  \\n All right, and you can see that two raised  \\n to the first power is two.  \\n And then two raised to the third power is eight.  \\n Okay. So let's add one more test.  \\n What I'm going to do now is write print, power.  \\n And in this case, I'm going to reverse the arguments.  \\n I'm going to say x equals three,  \\n and then num equals two.  \\n So in this case, I'm reversing the order  \\n in which the arguments are called.  \\n So Python lets you call functions  \\n with their parameters being named along with the value.  \\n So when you do this, the Python interpreter figures  \\n out which to supply the values to.  \\n So you don't have to call the function with the arguments  \\n in a particular order,  \\n as long as you supply the names along with the values.  \\n So let's try this again.  \\n So you can see that in this example,  \\n we get two raised to the third power in both cases.  \\n So the answer is eight in both cases.  \\n So we've got one more example to look at.  \\n I'm going to define a function  \\n that takes a variable number of arguments.  \\n So I'm going to define a function,  \\n and it's going to be called multi_add.  \\n And the arguments are going to start with a star.  \\n And then I'm going to call the arguments args.  \\n Then I'll have my colon,  \\n and I'll have a local variable named result.  \\n I'll initialize that to zero.  \\n Once again, I'll have a loop.  \\n So for x in the args,  \\n I'm going to write result  \\n equals result plus x.  \\n And then I'll return the result.  \\n So what I've done here  \\n is I've defined a function called multi_add.  \\n And the star character means  \\n I can pass in a variable number of arguments.  \\n So the function is going to loop over each one  \\n of the arguments, and add them all to a running total.  \\n And then that's going to be returned as the result.  \\n So let's scroll down.  \\n Let's go ahead and comment these previous ones out.  \\n And then I'll print multi_add,  \\n and I'll pass in some numbers.  \\n See 4, 5, 10.  \\n How about four again?  \\n All right. So let's go ahead and save, and let's run this.  \\n And you can see that the result is 23.  \\n So I'll change the function call  \\n to include another parameter.  \\n Let's add another 10 on there.  \\n Let's save.  \\n And let's run again.  \\n And now the result is 33.  \\n So you can combine a variable argument list  \\n with a set of formal arguments,  \\n but just keep in mind that the variable argument list  \\n always has to be the last parameter.  \\n So I could do something like this.  \\n I could say like, arg1, right?  \\n But that has to be first.  \\n Okay. Oh, wait, actually not there.  \\n Sorry, let's scroll back up.  \\n Here in the definition,  \\n I can have an argument that comes  \\n before the variable arguments,  \\n but all of my named parameters have to come before  \\n the variable argument list.  \\n This guy always has to be last.  \\n So that, that way the interpreter knows  \\n which of the parameters to assign to the variable list.  \\n All right, so that's a quick introduction  \\n to defining functions in Python.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3018970\",\"duration\":497,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Conditional structures\",\"fileName\":\"2896241_en_US_02_04_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to make logical decisions within Python code.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":20917457,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] One of the most common operations  \\n of almost any program is making decisions.  \\n Your program will often need to compare different values  \\n and execute code based upon some logical outcome.  \\n And that's where conditional logic comes into play.  \\n So in the code editor,  \\n I'm going to open up \\\"conditionals_start\\\"  \\n and in Python,  \\n conditionals are handled using the \\\"if\\\" statement.  \\n And so you can see here in the main function,  \\n I've got two variables, X and Y,  \\n and they are 10 and 100 to start with.  \\n So let's go ahead and add our first conditional statement.  \\n I'm going to write \\\"if X is less than Y\\\"  \\n and then I'm going to assign the \\\"result\\\" variable  \\n to the string \\\"X is less than Y.\\\"  \\n And then I'll just print out the result.  \\n All right.  \\n So the code compares X to Y and if X is less than Y,  \\n then you can see we set the value of this result variable  \\n and then we print it.  \\n So let's run it.  \\n And I'm going to run this in my terminal  \\n and you can see sure enough X is less than Y.  \\n Alright, so it seems to work just fine.  \\n Now let's go ahead and close this terminal  \\n and let's see what happens if I change the value of X  \\n to be something like 1000.  \\n So I'll run this again.  \\n And now I'm getting an error.  \\n It says  \\n \\\"local variable results referenced before assignment.\\\"  \\n And the reason I get that error  \\n is because since X is no longer less than Y,  \\n this code is no longer executed.  \\n So my print is trying to print the value  \\n of a variable that was never declared.  \\n So we have to figure out a way  \\n to add in the case where the test condition is false.  \\n So let's close the terminal and make that change.  \\n So I'll write \\\"else result is equal to X is greater than Y.\\\"  \\n All right, so now I've got both conditions handled.  \\n So I have the \\\"if\\\" condition which will test this condition,  \\n and an \\\"else.\\\"  \\n \\\"Else\\\" will run in all the cases  \\n where this evaluates to false.  \\n All right, so let's run this one more time  \\n and sure enough, now we're getting \\\"X is greater than Y.\\\"  \\n Okay.  \\n So now let's try one more thing.  \\n Let's make them the same value.  \\n So I'll save and I'll run.  \\n And well, I'm getting \\\"X is greater than Y\\\"  \\n but that's not really true, right?  \\n They're the same value.  \\n And the problem is that  \\n this condition here evaluates to false.  \\n So we're kind of just assuming that X is greater than Y  \\n because it's not less than Y.  \\n So that's not really correct.  \\n We have to check to make sure  \\n that X actually is greater than Y.  \\n So we'll make one more change  \\n to fix this particular problem.  \\n I'm going to write  \\n \\\"elif X and then two equals and then Y.\\\"  \\n Set the string to be \\\"X is the same as Y.\\\"  \\n All right.  \\n So now we have, \\\"if\\\" we have \\\"elif\\\" and we have \\\"else\\\",  \\n so this gives us a way  \\n of chaining more than one condition together.  \\n And you can have as many \\\"elif\\\" statements as you want.  \\n So now we're checking for the special case  \\n where X and Y are the same.  \\n So if we run this  \\n and sure enough we get the right result,  \\n \\\"X is the same as Y.\\\"  \\n All right, there's another way  \\n of writing conditional statements.  \\n Sometimes you'll run into situations  \\n where you have just an \\\"if\\\" and just an \\\"else\\\"  \\n and so you'll have like four,  \\n or whatever lines of code,  \\n intended to do just a simple comparison.  \\n Python has a construct called a \\\"conditional\\\" statement.  \\n And the \\\"conditional\\\" statement lets you write a common  \\n \\\"if-else\\\" construct all in one line.  \\n It's a more concise way of writing the comparison logic.  \\n So let me just write the statement  \\n and you'll see what I mean.  \\n So right here I'm going to write  \\n \\\"result equals X is less than Y\\\"  \\n and then I'll write  \\n \\\"if X is less than Y.\\\"  \\n So I'll put the condition test right here  \\n and then I'll write  \\n \\\"else X is greater or equal to Y\\\".  \\n So this code does the work of an \\\"if- else\\\" construct,  \\n but just using one line.  \\n And then we'll print the result again.  \\n All right.  \\n using \\\"control slash.\\\"  \\n \\\"Command slash\\\" if you're on the Mac.  \\n All right, so we'll \\\"save.\\\"  \\n Okay, and let's go ahead and run this  \\n and we can see that X is greater or equal to Y  \\n because they're the same.  \\n And if I go ahead and change this back to 10  \\n and let me close that terminal and run it again.  \\n And now we're seeing, yes, X is less than Y.  \\n So it's a nice, concise way of writing  \\n a conditional statement instead of having  \\n this more verbose \\\"if-else\\\" block.  \\n So there's one more conditional structure  \\n that we should look at before we move on.  \\n And it's one of the features of Python that's newest.  \\n It was added back in the 3.10 release,  \\n which should be available by the time you watch this course.  \\n So if you want to try the code out  \\n that I'm about to show you,  \\n you got to have Python 3.10 installed.  \\n And you can see down here  \\n I've got 3.10 installed on my machine.  \\n So I'm going to write the code  \\n that uses the new \\\"match case\\\" statement.  \\n So when you have a lot of different values to test against,  \\n it can get pretty tedious  \\n to have to write all these multiple \\\"else-if\\\" statement.  \\n You have an \\\"if\\\" and an \\\"elif\\\" and an \\\"elif\\\" and an \\\"elif\\\"  \\n and then all these different conditions and so on.  \\n Python 3.10 adds the new \\\"match case\\\" statement,  \\n which is a feature that's been available  \\n in other languages for quite some time.  \\n So down here, I have a value variable  \\n and it's sent to the string of one.  \\n Now, if I wanted to compare this variable  \\n to multiple different values,  \\n I can use the \\\"match\\\" statement.  \\n So I'm going to write \\\"match\\\" and then \\\"value.\\\"  \\n And then what I'm going to do is list each possible case  \\n that the variable might match against.  \\n So I'll write \\\"case\\\" and then one.  \\n And in that case, I'll set the result to one,  \\n and then I'll write \\\"case two\\\"  \\n and set the result equal to two.  \\n I can also write a case statement  \\n that handles multiple possible values.  \\n So for example,  \\n I can write \\\"case three\\\" and then a vertical bar,  \\n which means the \\\"or\\\" operator,  \\n and then the string \\\"four.\\\"  \\n So now I've got a case that handles three and four,  \\n in which case I'll set  \\n the \\\"result equal to a tubal of three and four\\\" together.  \\n And I can add a case to handle any condition  \\n that I haven't explicitly specified.  \\n So you can think of this as a default case handler.  \\n So I'll write \\\"case underscore and then colon.\\\"  \\n And this case I'll write \\\"result is equal to minus one.\\\"  \\n So this case will be handled  \\n in case any of the other ones do not get executed.  \\n So you can see that this is a lot more pleasant  \\n to read than a large number  \\n of \\\"if\\\", \\\"elif\\\", \\\"else\\\" statements.  \\n So let me go ahead and comment out the previous example  \\n and let's make sure that we print results down here  \\n so we can see what's happening.  \\n All right. So let's save and then let's run this.  \\n All right. And you can see that the result is one.  \\n All right.  \\n So let's go ahead and change this to something else.  \\n Let's change it to the value of three.  \\n Alright. And then let's run this again.  \\n And I see we're getting the tubal.  \\n Okay. Now let's change it to something else,  \\n let's change it to 42.  \\n And we'll run it.  \\n And sure enough, we're getting the minus one result  \\n because the default case handler is being executed.  \\n So again,  \\n this \\\"match case\\\" feature requires  \\n at least Python 3.10.  \\n So if you want to try this out,  \\n make sure you have that version installed  \\n and give it a try on your own machine.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3019940\",\"duration\":568,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Loops\",\"fileName\":\"2896241_en_US_02_05_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to create repeating blocks of code in Python.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":22611114,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Running a block of code over and over again,  \\n via a construct known as a loop  \\n is also a very common scenario in programming  \\n and Python provides a couple of ways of doing that,  \\n which we're going to take a look at now.  \\n So in the editor,  \\n and you can see here,  \\n I've got a function called main and a variable named X,  \\n which I'm initializing to zero.  \\n So let's start by taking a look at the while loop.  \\n So I'm going to write the while statement  \\n and then inside parentheses,  \\n I'm going to write X is less than five,  \\n and then I'll have a colon  \\n which defines the scope block of my while statement.  \\n I'm going to print X  \\n and then I'm going to have  \\n X become equal to X plus one, all right?  \\n So once again, you can see that the code in the while loop  \\n is indented to indicate that it belongs  \\n to the scope of the loop.  \\n A while loop executes a block of code  \\n while a particular condition evaluates to true.  \\n So in this case,  \\n while X is less than five,  \\n we're going to print the value of X  \\n and then we're going to increment X by one.  \\n Now some other languages like C for example,  \\n provide a whole bunch of ways of writing loops.  \\n Python likes to keep things simple.  \\n It's only got two ways of doing loops,  \\n there's the while loop and there's the for loop.  \\n So we'll get to the for loop in a moment but for now,  \\n let's just take a look at the while loop.  \\n So we'll save this and let's run it  \\n and you can see that X starts out as zero,  \\n so it print 0 1, 2, 3, and four,  \\n and then it increments to five  \\n and then when the value of X becomes five,  \\n X is no longer or less than five, so the loop terminates.  \\n So now let's try our for loop.  \\n To write a for loop,  \\n I'm going to use the keyword for,  \\n and then I'm going to define a variable named X  \\n in the range between five and 10,  \\n and then I'm going to print X.  \\n All right, and let's go ahead  \\n and comment out these previous lines.  \\n For loops in Python, work a little bit differently  \\n than you might be used to seeing in other languages.  \\n So some languages like JavaScript and C and Java,  \\n they have this concept of an index variable  \\n that counts the number of iterations in the for-loop.  \\n So for example, in JavaScript,  \\n you might see something that looks like this.  \\n You'll have like, you know for and then I equals zero  \\n and then I is less than five  \\n and then I plus plus, okay,  \\n so you've got the four, right?  \\n And then I is zero, so this is the initialization part  \\n and then this is the conditional part  \\n and then this is the incremental part.  \\n Python works a little bit differently than this.  \\n Rather than having an index variable, right?  \\n We have, what's called an iterator.  \\n In this case, I have X loop over a range of numbers  \\n and to get that range of numbers,  \\n I'm using the built in range function.  \\n So I have a range going from five to 10  \\n and I'm going to print X each time.  \\n So it's probably easier to understand this  \\n once you've seen it in action,  \\n so let's go ahead and save this and run it  \\n and you can see in the output, right?  \\n It prints out 5, 6, 7, 8, and nine.  \\n And then when it gets to 10, it stops.  \\n Okay, so you've got X within the range,  \\n which is not inclusive of the 10 right here.  \\n So it excludes the outside number,  \\n so it only prints five through nine.  \\n But for loops operate over sets of things, not just numbers,  \\n so let's try something else.  \\n You can see here that I've got a variable named days  \\n and I'm initializing it  \\n to a list of abbreviated day names, right?  \\n So I've got a opening, closing brackets  \\n and inside the brackets, I've got strings of my day names.  \\n So this example has nothing to do with numbers.  \\n In this case, my for loop is going to iterate  \\n over each element in the days list.  \\n So to do that, what I'll do  \\n is I'll write for d in,  \\n the name of the collection in this case it's days  \\n and then once again I'll have my colon  \\n and inside the loop I'll print d  \\n and let me comment out this previous example.  \\n All right, so let's go ahead and save this and run it.  \\n And when I run it, you can see it's printing out,  \\n Monday, Tuesday, Wednesday, so on up through Sunday,  \\n so it's looping over the contents of the list right here.  \\n Again, no index counter involved,  \\n it's just iterating over the members of a list.  \\n All right, let's keep on going.  \\n So let's take a look at using  \\n the break and continue statements.  \\n So what I'm going to do is copy  \\n the for-loop that I had previously and paste it here  \\n and I'm going to uncomment this  \\n and I'll comment, the previous example.  \\n So this is the same for loop that we had earlier,  \\n where we have X in the range of five to 10,  \\n but we're going to do two different things.  \\n So first, let's look at the break statement.  \\n The break statement is used to break the execution of a loop  \\n if a condition is met or for some other reason.  \\n So I'm going to put a statement in here that says,  \\n if X is equal to seven, then break, right?  \\n So in this case, when X gets to be the value of seven,  \\n then the break statement will execute  \\n and it will cause the for loop to terminate,  \\n so let's go ahead and save and run this.  \\n And you can see that that's what's happening, right?  \\n So this time, instead of going all the way to nine,  \\n it prints out five and six, and then it gets to the seven  \\n and then when it gets to the seven,  \\n this break statement kicks in and terminates the loop  \\n so it never gets to print seven, eight or nine.  \\n Okay, so let's go back.  \\n Now, let's take a look at the continue statement.  \\n I'm going to add a continuous statement,  \\n I'm going to write if X  \\n percent two is equal to zero, then continue.  \\n And I'll just comment out the break statement, all right.  \\n So in this case,  \\n my code says if X modular two is equal to zero,  \\n in other words, take X divided by two  \\n and if the value left over is equal to zero, then continue.  \\n And continue means skip the rest of the code  \\n inside the loop and then just go back up to the top  \\n and do the next iteration.  \\n Now, the rest of the loop  \\n in this case is just this print statement,  \\n it's only one statement,  \\n but if there were more statements here,  \\n they would all be skipped, okay?  \\n So let's go ahead and save this and let's run it  \\n right, and now you can see that only five, seven and nine  \\n are being printed because what's happening is  \\n if it says, if X is percent two is equal to zero,  \\n so if I have an even number, right,  \\n it's not going to print six or eight  \\n because the continuous statement is going to execute  \\n and then go back up to the top and do the next iteration  \\n while skipping that particular print statement.  \\n Okay, let's take one more example of using loops.  \\n So let's go back up  \\n and revisit the loop that we had up here,  \\n where we're looping over these days.  \\n So I'm going to copy this line,  \\n paste it down here and uncomment it,  \\n and I'll comment out the previous example, right.  \\n Now, remember earlier I said that normally  \\n the for-loop in Python  \\n does not use an index variable, right?  \\n There's no loop counter normally.  \\n Well, you can get one if you really need it,  \\n so here's what you do.  \\n I'm going to write for I comma d, so a two polar values, right?  \\n So there's two values here in,  \\n and then I'm going to use the enumerate function  \\n and I'm going to enumerate the days list.  \\n I'm going to print both I and D, okay.  \\n So the enumerate function will iterate over this collection,  \\n just like the for loop normally would  \\n but in addition to returning the value  \\n of the item that's being looped at,  \\n it also returns a value  \\n that is the index of the item in question.  \\n So the enumerate function is going to return two values,  \\n it's going to return the index  \\n and the member of the collection that we're looking at  \\n and here I'm printing out both of these,  \\n the index and the item, right?  \\n So let's save and let's run it  \\n and you can see that I'm getting  \\n zero Monday, one Tuesday, two Wednesday and so on.  \\n So I'm getting the value of the day  \\n that's in the collection,  \\n as well as its numerical index using the enumerate function.  \\n So even though you only have  \\n the while loop and the for loop in Python,  \\n you can see that they're pretty versatile  \\n and they take the place of lots of other more  \\n fancy loop constructs in other languages.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3018971\",\"duration\":630,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Classes\",\"fileName\":\"2896241_en_US_02_06_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to define basic Python classes.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":26249404,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Python is an object-oriented programming language.  \\n And this means that you can create and use your own classes.  \\n And classes are a really great way  \\n of encapsulating functionality that can be kept together  \\n and reused as complete modules in other projects.  \\n And this can be really helpful in keeping larger programs  \\n both maintainable and easier to understand.  \\n So let's open up the classes_start file.  \\n And let's imagine that we're building an application  \\n that manages vehicles, right,  \\n the cars and motorcycles and so on.  \\n So I'm going to start by defining a class  \\n that will hold some information about vehicles.  \\n So classes are defined using the class keyword,  \\n and then they're given a name.  \\n So I'll name my class vehicle.  \\n And then I'm going to use two empty parentheses,  \\n which are empty for now,  \\n but we'll see what those are used for in a moment  \\n and then a colon to begin the class scope.  \\n Now I need to add the method that gets called  \\n when the class gets constructed and initialized,  \\n and it's the double underscore init methods.  \\n So I'm going to write def and then two underscores init  \\n and then two underscores.  \\n Now, the init method is the function that Python calls  \\n when the object has been created  \\n and it's time to initialize the object's data.  \\n So I'm going to create some parentheses  \\n and inside the init functions parentheses,  \\n the parameter list, I'm going to put the word \\\"self\\\" okay.  \\n There are several different functions  \\n that have these double underscores in them.  \\n You don't call these directly usually.  \\n Python does it for you  \\n as it manages the object that you create and use.  \\n So what I'm going to do is use this method  \\n to have a property named body style  \\n that will hold the body style of the vehicle.  \\n In the init method  \\n I'm going to have the first parameter of be named self  \\n and then I'm going to have a parameter named body style.  \\n Now, by convention all of the methods in a class  \\n take the reference to the object as the first parameter.  \\n You can name it whatever you want.  \\n I just happened to name it self.  \\n You can name this X if you want to,  \\n you can name it \\\"the thing.\\\" It doesn't really matter.  \\n But you'll see in most Python code,  \\n the word \\\"self\\\" is the convention that most people use.  \\n So what I'm going to do is inside the init function,  \\n I'm going to write self.bodystyle  \\n is equal to the body style parameter.  \\n So now I've defined a property on the class  \\n and it's going to hold the value that was passed in  \\n to the class when it's created.  \\n So now that I've created this base class called vehicle,  \\n I can create other classes that derive from this class.  \\n After all, there's many different kinds of vehicles,  \\n different kinds of engines and other features.  \\n We wouldn't want to cram all that data into one class.  \\n So let's create a class called car,  \\n and this is going to be used for regular passenger cars.  \\n And since this class derives from the vehicle class,  \\n I'm going to specify vehicle  \\n inside the parentheses for the class definition  \\n and then I'm going to create the init function  \\n like I normally would.  \\n And in this case,  \\n I'm going to have a parameter named engine type.  \\n Now in the init function,  \\n I need to have a way of specifying,  \\n not just what the engine that the car uses,  \\n I also have to initialize the superclass, the vehicle class  \\n by first using what's called the super function.  \\n So I'm going to call super,  \\n and then I'm going to call the superclasses init method.  \\n And I'm going to call it with the body style, right?  \\n 'Cause remember,  \\n this is the parameter that goes to the vehicle class.  \\n So here I'm creating a car.  \\n So this is how I initialize the body style property  \\n in the superclass, the class that I derive from.  \\n Sometimes it's called the parent class of my car class here.  \\n Then I can set other properties specific to this class.  \\n So for example, I can say that wheels equals four  \\n because cars have four wheels.  \\n I can initialize the doors property,  \\n let's say that cars have four doors  \\n and then I'll have the self.enginetype  \\n and I'll initialize that to the engine type parameter  \\n that's passed into the init function.  \\n All right, let's do this one more time.  \\n So now that we have car and vehicle,  \\n let's make a class for motorcycles.  \\n So I'll define a class called motorcycle  \\n and a motorcycle also descends from vehicle.  \\n And then I'll create my init method.  \\n And in this case, we're going to have a motorcycle.  \\n It's going to take an engine type as a parameter,  \\n and also whether or not it has a sidecar.  \\n So once again, I'm going to call it the superclass.  \\n I'm going to call it the init function on the superclass.  \\n And in this case, I'm creating a motorcycle.  \\n And notice by the way, that when I do this,  \\n I don't have to pass in the self parameter  \\n to the init function. It's sort of implied.  \\n Python handles passing the object reference around.  \\n So you don't have to pass that first parameter  \\n as the object reference.  \\n All right. So I initialize the motorcycle  \\n and then I'll write some code that says  \\n if this motorcycle has a sidecar,  \\n then I'm going to have the wheels property equal to two.  \\n No, actually it's three if it has a sidecar,  \\n if it does not, oh, I've got to put the colon there.  \\n If it does not have a sidecar,  \\n then the wheels property will be two.  \\n And of course, motorcycles don't have doors.  \\n So I'll set the doors property equal to zero  \\n and of course we have the engine type,  \\n which is going to be the engine type that was passed in.  \\n Okay. So now we have our classes defined  \\n and once we've defined our classes,  \\n we can create specific objects of those types.  \\n So let's create a couple of cars and a motorcycle.  \\n To do that, we use the name of the class  \\n along with the parameters for the init function.  \\n So I'll have a variable in car one,  \\n and that's going to be a car type  \\n and I'll have that be a gas type car.  \\n And I'll create two. Car two is going to be an electric car.  \\n And then motorcycle one is going to be a motorcycle  \\n and that's going to have a gas engine  \\n and it will have a sidecar.  \\n So now that we've defined these classes  \\n and we've initialized them,  \\n we can access the properties of each class  \\n using dot notation.  \\n So for example,  \\n I can print how many wheels the motorcycle has  \\n by printing mc1.wheels  \\n and I can do something similar with the car.  \\n So I can print car one's engine type  \\n and I can also print car two's doors count.  \\n All right. So let's recap.  \\n We have our base class called vehicle,  \\n which is a body style property,  \\n has a body style property here.  \\n Then we have two subclasses, car and motorcycle,  \\n both of which inherit from the vehicle  \\n and define their own properties.  \\n We use these super function to initialize this superclass.  \\n And in each case we initialize  \\n the body style of the superclass  \\n and then we have our own properties  \\n specific to each one of those classes. All right.  \\n So let's go ahead and run what we have.  \\n And when I do,  \\n so you can see that the motorcycle has three wheels,  \\n 'cause it has a sidecar.  \\n Car one has a gas engine and car two has four doors.  \\n But classes don't just hold data.  \\n They can also define their own functions.  \\n So let's add the ability for each of these vehicles  \\n to drive.  \\n So back in my base class,  \\n I'm going to add a function named drive.  \\n And that's going to take a speed as a parameter.  \\n So inside this method,  \\n I'm going to define a property named mode.  \\n So now the mode is going to be driving  \\n when we call the drive function and the speed property  \\n is going to be whatever the speed parameter that was passed in.  \\n And then I can have each vehicle  \\n specify some driving behavior  \\n by overriding the base class method.  \\n So for the car, let's go ahead and add a drive method.  \\n And of course we're going to initialize the superclass.  \\n So we'll call it a super.drive  \\n with the speed that we were given.  \\n And then we're going to print \\\"driving my\\\"  \\n and then self.enginetype.  \\n And then I'll say car at, and then self.speed. All right.  \\n And then let's go ahead  \\n and add the same thing for the motorcycle.  \\n So I'll just go ahead and copy and paste these lines  \\n and put them down here in the motorcycle.  \\n And of course I am now driving a motorcycle,  \\n not a car anymore. All right. Okay.  \\n And then let's call those functions on our objects.  \\n So I'm going to write car.1 and I'll drive that car at 30  \\n and then car two will drive at 40  \\n and then the motorcycle is going to drive at 50.  \\n All right. So let's go ahead and run the code again.  \\n And now we can see that I'm driving my gas car at 30,  \\n my electric car at 40 and my gas motorcycle at 50.  \\n So this is just a simple example  \\n of how to define classes in Python.  \\n You can learn a lot more about this  \\n in the Python Object-Oriented Programming course.  \\n But in the meantime,  \\n think about how you might extend this example.  \\n So how would you add the ability  \\n to have different kinds of cars for example?  \\n How would you add additional functions like park or reverse?  \\n Take some time to experiment with the code here  \\n and try out some of these ideas.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3017845\",\"duration\":142,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Importing and using modules\",\"fileName\":\"2896241_en_US_02_07_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to import modules from the Python library and use them within a program.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5892531,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] One of the most powerful features  \\n of the Python ecosystem is the large number  \\n of library modules of pre-built code  \\n that you can use in your programs.  \\n The standard Python installation contains  \\n quite a few of these modules,  \\n and some of which we're going to learn more about  \\n later in the course, but, before we get there,  \\n let's take a look at a simple example  \\n that shows how to take advantage of all this code  \\n that you don't have to write yourself.  \\n So let's open up the modules_start file,  \\n and what I'm going to do is tell Python  \\n that my program wants to use the math module,  \\n which contains a whole bunch of functions  \\n for performing all kinds of mathematical calculations.  \\n To do that, all I need to do is use the import statement  \\n along with the name of the module that I want to use.  \\n So I'm going to write import math.  \\n Now, let's suppose I wanted to calculate  \\n the square root of a number.  \\n To do that, I can take advantage of the function  \\n that's in the math module named SQRT.  \\n So let's make a statement that does that.  \\n I'm going to print out \\\"The square root of 16 is\\\",  \\n and then I'm going to call math.sqrt,  \\n and I'm going to pass the parameter 16, all right.  \\n And you can see that when I type the dot  \\n after the math keyword, right here,  \\n there's quite a few math functions in this module, okay,  \\n but, for now, let's just use the square root one.  \\n So let's go ahead and save, and let's run this,  \\n and, sure enough, you can see  \\n that the square root of 16 is four.  \\n The math module also contains  \\n some useful math constant values.  \\n Let's close this terminal.  \\n So, for example, we can print the value of Pi,  \\n and I'll print \\\"Pi is\\\", math.pi.  \\n All right, so, once again, let's run this,  \\n and, sure enough, there's Pi, right there,  \\n 3.14159 and so on and so forth.  \\n So for the rest of this course,  \\n we're going to use some other great modules  \\n to perform useful work,  \\n such as manipulating dates and times, working with files,  \\n and even processing internet-based data like XML and JSON.  \\n But before moving on, though, I suggest taking a few moments  \\n and trying out some of the other math functions  \\n to get the feel for what it's like to work with modules.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3020814\",\"duration\":310,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Using exceptions\",\"fileName\":\"2896241_en_US_02_08_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to handle Python program errors by using exceptions.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":14681156,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Programs run into problems and errors  \\n all the time so it's a good practice  \\n to have a plan for handling them when they happen.  \\n And in Python, one way to do this  \\n is through exception handling.  \\n So here in my editor, I'm going to open up  \\n the exceptions_start file,  \\n and I'll start off by writing some code  \\n that I know is going to generate an error.  \\n So I'll write X equals 10 divided by zero.  \\n Now obviously divided by zero is a math error,  \\n so when I save and run this,  \\n we can see that the program crashes and exits  \\n with this division by zero error message.  \\n Now, this is a pretty bad experience for users  \\n and we can do a much better job of handling errors like this  \\n in our code by using exception handling.  \\n So let's close the terminal.  \\n So let's rewrite this by using exceptions.  \\n So I'm going to comment that out.  \\n I'm going to write try,  \\n and then I'm going to do my formula again.  \\n Okay.  \\n And then I'm going to write except,  \\n and I'm going to print  \\n well that didn't work.  \\n Okay. And we'll save.  \\n All right.  \\n that might cause some errors.  \\n Python will execute the code as usual.  \\n And if anything goes wrong,  \\n then the flow of the program transfers immediately  \\n to this closest except section here  \\n where I can handle the error.  \\n So in this case, the divide by zero error  \\n will cause the program to jump to the print statement.  \\n So now let's save and let's run this again.  \\n And you can see that instead of crashing  \\n my program prints out the custom error message  \\n well that didn't work.  \\n Now that's a better experience, but we can improve on this.  \\n We can write except sections that handle  \\n specific kinds of errors.  \\n So let's suppose I have some code in my try section  \\n that can cause different kinds of problems.  \\n So let me go back and comment out this previous example.  \\n So I'm going to write some code in my try section  \\n and I'll have an answer variable that's going to take  \\n the result of user input, and it's going to say,  \\n what should I divide 10 by?  \\n All right?  \\n And then the number is going to be  \\n the result of casting the answer into an integer.  \\n And then I'm going to print 10 divided by  \\n whatever number the user gives me.  \\n Now, in this case, the user might enter a zero,  \\n which would cause a divide by zero exception,  \\n or they might enter some input that isn't a number  \\n which will cause this int function here to fail  \\n with a value error exception.  \\n So to handle both of these separately,  \\n I can write multiple except sections.  \\n So the first one will handle the divide by zero error.  \\n So I'll write except zero division error.  \\n In this case, I'll get a local variable named E,  \\n which is the exception.  \\n And I'll print out you can't divide by zero.  \\n In this case, I won't use the local value E  \\n but in this case, I will.  \\n I'll write except value error as E  \\n and I'll print out you didn't give me a valid number.  \\n And I'll print out the exception here just to show  \\n that it can be done.  \\n And there's also one more section that we can add  \\n called a finally section.  \\n This section contains code that will always execute  \\n regardless of whether an error occurred.  \\n And you can use it to clean up any resources  \\n that you've allocated such as open files  \\n or other system resources that you're using.  \\n So I'm going to write finally,  \\n print this code always runs.  \\n All right.  \\n All right.  \\n Okay, so let's go ahead and enter a real number, like two.  \\n Okay, we can see that that works, right?  \\n So the answer is five and we can see  \\n that the finally section always runs.  \\n Okay, let's run it again.  \\n And this time let's enter something that's not a number  \\n so that the int conversion will fail.  \\n So I'll just enter blah, and you can see it says,  \\n you didn't give me a valid number.  \\n And then you can see that it's printing out  \\n the actual exception code right there.  \\n And then again, the finally section always runs  \\n and let's run it one more time.  \\n And then let's enter zero and you can see  \\n that the zero division error section is being triggered.  \\n So exceptions make error handling a bit easier to read  \\n by centralizing the code for dealing with those errors  \\n in one place and separating it from the code  \\n that does the program's actual work.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentAssessment:64ee20a6498e4e5b8410e010\",\"duration\":480,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"</> Code Challenge: Palindromes\",\"externalAsset\":{\"coderPadCampaign\":\"urn:li:coderPadCampaign:845019\"},\"coderPadCampaign\":null},{\"urn\":\"urn:li:learningContentVideo:2707381\",\"duration\":157,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Palindromes\",\"fileName\":\"2896241_en_US_02_10_C_2023Q3_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4901366,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] All right, let's take a look at my code  \\n for this challenge.  \\n And remember, it's okay if my code is different from yours.  \\n There's usually multiple ways to solve programming problems.  \\n In order to determine whether a string is a palindrome  \\n we have to ignore capitalization  \\n and we have to get rid of spaces and punctuation.  \\n So my code starts  \\n by converting the incoming string to lowercase  \\n so that way we don't have to worry  \\n about comparing different letter casing.  \\n Next, I strip off the spaces  \\n and the punctuation from the test string.  \\n So I create a new string and then I have a  \\n for loop that checks each character in the test string.  \\n And I'm using the isalnum function  \\n which is a built-in function for Python string objects.  \\n This function checks to see  \\n if a character is alphanumeric, and if it is  \\n then I add it to my new string, otherwise I skip over it.  \\n So when this loop completes  \\n I now have a string that is all lowercase  \\n and only has letters in it  \\n doesn't have spaces, doesn't have punctuation.  \\n Now I have to build the reverse version  \\n of the string in order to compare against the original  \\n because a palindrome means that the reverse  \\n of the string and the original are the same.  \\n So the way that I've solved it here is not  \\n necessarily the most efficient way of doing it.  \\n But since this is a learning course, I wanted to focus more  \\n on understanding the algorithm than just, you know  \\n being as clever as possible.  \\n So I have another variable called reverse stir  \\n and I have a loop that starts at the end  \\n of the test string and then works its way backward.  \\n So each time through the loop, I add the next character  \\n to the reverse stir until I reach the beginning.  \\n So by the time this loop completes, I have two strings.  \\n One is the original  \\n with all the capitalization and punctuation stripped out.  \\n And then I have the reverse stir, which is that  \\n that same stir but now reversed.  \\n And then I just have to compare those two strings.  \\n And if they're the same  \\n then we know it's a palindrome, otherwise we return false.  \\n So if I click on test my code  \\n you can see that in the array of strings that's being passed  \\n to my test, obviously we expect Hello World to  \\n not be a Palindrome and \\\"Mama?\\\" also will not be  \\n but \\\"radar\\\", \\\"Madam, I'm Adam\\\" and \\\"race car\\\" all should be.  \\n And sure enough, we have the correct results of three.  \\n \\n\\n\"}],\"name\":\"2. Python Basics\",\"size\":164551700,\"urn\":\"urn:li:learningContentChapter:3022809\"},{\"duration\":1694,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3020816\",\"duration\":383,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Reading and writing files\",\"fileName\":\"2896241_en_US_03_01_XR30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to read and write the contents of a file using Python.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":15012617,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] So now that we've taken a look  \\n at the basics of the Python language,  \\n we're going to turn our attention  \\n to using the rich library of predefined code  \\n that comes with Python  \\n in order to build functionality into Python applications.  \\n Python provides built-in methods  \\n for working with files and directories.  \\n You can open files, write data into them,  \\n read the data back in and so on  \\n and that's what we're going to take a look at  \\n in this chapter.  \\n So let's start by opening up the  \\n files underscore start code in our editor  \\n and what we're going to do is  \\n work with some basic file operations.  \\n Now, I don't need to import any classes to work with files  \\n because the functions for working with files  \\n are built into the base Python language,  \\n so for our first example,  \\n let's just write some information to a text file.  \\n Now to do this, I'll use the open function.  \\n So I'll create a variable named in my file  \\n and I'll call it open  \\n and then open takes a couple of arguments.  \\n I'm going to supply the name of the file I want to work with,  \\n so that's going to be text file dot txt,  \\n and then I need to specify what's called the open mode.  \\n So this is the access that I want to the file.  \\n So I'm going to in a string, supply the letter W  \\n because I want write access to the file,  \\n and then I'll also add the plus sign,  \\n which means that Python should create the file  \\n if it doesn't already exist.  \\n So when the open function returns,  \\n the result is a reference to a file object  \\n that I'm storing in a variable named my file.  \\n Now the file is open at this point,  \\n so we can write some data.  \\n And I'll do that here in this comment  \\n and I'll just create a for-loop,  \\n so I'll write for I in range 10  \\n and what I'm going to do  \\n is call the my file dot write function,  \\n to write this is some texts with a carriage return.  \\n So the write function just writes data to the file,  \\n which in this case  \\n is just going to be a series of 10 lines of texts  \\n and then when we're done,  \\n we need to close the file,  \\n so I'll write my file dot close.  \\n All right, so to recap,  \\n what we're doing is opening the file for writing,  \\n writing some data, and then closing the file, okay?  \\n So let's go ahead and save this and let's run it  \\n and let's see.  \\n All right, there's no errors, that's good  \\n and you can see over here in the file browser of vs code  \\n that this text file dot txt has shown up,  \\n and sure enough, there are the 10 lines of text  \\n that we written out.  \\n All right, so for the next example,  \\n let's try adding some content to an existing file.  \\n So what I'm going to do is comment out this line  \\n that creates the file,  \\n and I'll just copy that and paste it here  \\n and in this case,  \\n I don't want to use the W  \\n because that just creates a new file,  \\n it'll overwrite the existing one.  \\n What I want to do is specify A,  \\n to indicate that I'm going to append data to the file  \\n instead of overriding all the existing content.  \\n And the rest of the code is the same,  \\n which means that 10 new lines  \\n will be written to the existing file,  \\n so let's just distinguish those by putting in this word new  \\n so now we write out this as some new text.  \\n Okay, so let's go ahead and save this and let's run it.  \\n All right and then let's open the file one more time  \\n and now you can see that the 10 new lines  \\n have been added to the end of the existing file.  \\n Okay, so for the last example,  \\n let's read the contents of the file that we've created,  \\n and there's a couple of ways to do this.  \\n So first, I need to open the file for read access.  \\n So what I'm going to do is comment out  \\n the previous code that I've written,  \\n and I'm going to use the open function again,  \\n so I'll paste that in.  \\n So in this case,  \\n instead of opening for writing or for appending,  \\n what I'm going to do is open the file for read access  \\n by specifying the mode of R  \\n and then to make sure that the file was opened correctly,  \\n I'm going to check the files mode,  \\n so I'll write if my file dot mode is equal to R  \\n that means that the file has been correctly opened  \\n and now I can start reading the content.  \\n Now for this example, I'll use the read function,  \\n so I'm going to write contents equals my file dot read,  \\n and the read function  \\n will just read the entire contents at once,  \\n and then I'll just print them out.  \\n All right, so let's go ahead and try that.  \\n So we'll save and run, and there's no need to close the file  \\n if you're just reading it, right?  \\n If you're writing data, you have to close the file,  \\n but for read, you don't have to worry about it.  \\n So I'll just go ahead and run this,  \\n and sure enough you can see that the text is being read in  \\n and printed out to the terminals so that's good.  \\n You can also read the contents of a file line by line.  \\n So if you have a really large file,  \\n sometimes it doesn't make sense  \\n to read the whole thing at once,  \\n especially if all you want is a small piece of the content.  \\n So the read lines function is useful for this.  \\n So let me comment out the previous read and print code  \\n and what I'm going to do is write some new code below this.  \\n I'm going to use the read lines function,  \\n so I'll write fl for file line  \\n is equal to my file dot read lines  \\n and then for X in fl,  \\n I'll print out each individual line, all right?  \\n So in this case,  \\n I'm reading the content as a list or an array  \\n of individual lines, and then printing them.  \\n Now, the net effect should be the same  \\n as you just saw in the previous example,  \\n I'm just doing it in a different way.  \\n So it's save and let's run,  \\n and you can see once again,  \\n that the text is being printed out to the terminal.  \\n In this case, cause I'm on windows  \\n and I had a manual new line character  \\n in each one of these text lines,  \\n you can see that there's an extra blank line being added.  \\n Don't worry about that for now.  \\n What's happening is the print function here  \\n is adding its own return to the end of the line.  \\n So just like almost everything else,  \\n you can see that Python  \\n makes working with file content really easy.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3019942\",\"duration\":623,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Working with OS path utilities\",\"fileName\":\"2896241_en_US_03_02_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to use basic operating system path functions.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":27834911,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Sometimes you need to perform  \\n just some operations with files  \\n that go beyond reading and writing data.  \\n So for example,  \\n you might need to find out information about a file,  \\n whether it exists, what the path of the file is,  \\n whether a given file is a directory or whatever.  \\n So Python provides path related utilities  \\n to help you do this and we're going to examine that now.  \\n So here in the editor,  \\n let's go ahead and open up the ospathutils.start.  \\n and you can see I've already imported  \\n some modules we're going to need to work on this example.  \\n And some of them you might already recognize  \\n from previous examples,  \\n and we've got a new one here named OS.  \\n So this module gives us the ability to work with  \\n operating system related features.  \\n And you can also see that I've imported the path module  \\n from the OS module,  \\n and we're also going to be working with  \\n some dates and times.  \\n And we'll learn about those a little bit.  \\n Just bear with me for now as we go through this example.  \\n So let's start with something really simple.  \\n Let's just print the name of the operating system.  \\n So I'm going to go ahead and print os.name.  \\n All right.  \\n So let's go ahead and save  \\n and run that before we do anything else.  \\n And when I run that,  \\n you can see that nt is being printed out  \\n because believe it or not,  \\n the official name of Windows is actually nt, internally.  \\n So that's the string that comes back  \\n when we print the OS name.  \\n So let's go ahead and do another example.  \\n Oh and by the way, this is going to be different  \\n based on your operating system.  \\n If you're running this on Linux or a Mac,  \\n you're going to see something different here.  \\n So I'm running on Windows.  \\n So this is the result that I see.  \\n Okay, so let's take a look at some path related features.  \\n So, let's go ahead and see if a particular item exists.  \\n Now I ran the previous example,  \\n which created this text file here.  \\n So if you haven't done the previous example,  \\n you might want to do that one before you do this one.  \\n So what I'm going to do is print  \\n item exists,  \\n and then I'm going to create a string  \\n from the result of path.exists.  \\n And I'm going to check to see if  \\n textfile.txt exists, okay?  \\n And the path class right here,  \\n you can see I'm importing that  \\n separately from the OS module.  \\n So now I have access to all these path functions  \\n and textfile.txt clearly does exist.  \\n And I'm also going to check to see  \\n whether it is a file versus being a directory.  \\n So I'll write, item is a file  \\n and path.isfile.  \\n And once again, I'll pass in,  \\n textfile.txt,  \\n and then we'll do the same thing  \\n to check whether it is a directory, which it clearly is not.  \\n So instead of calling isfile, I'll call isdir.  \\n So in each of these cases,  \\n I'm operating on the textfile.txt item.  \\n So again, if you didn't do the previous example,  \\n go do that so that you have this code.  \\n So let's save and let's go ahead and run this.  \\n All right.  \\n So the item clearly exists.  \\n The item is a file.  \\n Oh, I made a little mistake there.  \\n This should say is a directory.  \\n All right.  \\n So let's run this again.  \\n All right, so it exists.  \\n It's a file and it's not a directory, all right.  \\n So let's try a few more operations.  \\n Let's try getting the file's full path.  \\n So I'll print item's path,  \\n and that is going to be path dot,  \\n I'm going to call the real path function  \\n for the textfile.txt item.  \\n And I'm also going to call the split function  \\n to separate the file name from the path.  \\n So I'll write  \\n item's path and name  \\n and I'll call path.split.  \\n And then I'll just pass in the result of real path,  \\n which is right here.  \\n So I'll just copy that  \\n and paste it into the split function call.  \\n All right.  \\n So let's go ahead and run that.  \\n All right.  \\n So here we can see that the item's path  \\n is in my desktop exercise files folder,  \\n and the item's path and name,  \\n we can see that that's a tuple, right?  \\n So the first is the path without the file name  \\n and then the file name by itself.  \\n So it's really easy to split those from each other.  \\n Okay, let's go back to our code  \\n and let's comment out some of these previous examples out  \\n to make it easier to read.  \\n All right, what we're going to do now  \\n is get information about the file's modification time.  \\n So what I'm going to do is use the path module  \\n to get the modification time of the file  \\n and then I'm going to use the time class's  \\n c time function to convert that into a readable time.  \\n Now we haven't covered dates and times yet,  \\n but you can see that I've imported  \\n the classes to work with them.  \\n And we'll learn about those in a little while,  \\n but for now, just bear with me as I do this.  \\n So I'm going to write T equals  \\n and I'm going to call the time classes, c time function.  \\n And I'm going to call the path classes, getmtime,  \\n which means get the modification time of textfile.txt  \\n and then I'll just simply print the result.  \\n And I'm also going to use the get modification time function  \\n to construct a date, time object  \\n using the from timestamp function  \\n that's built into the time class.  \\n So let's go ahead and do that.  \\n So I'm going to print out,  \\n and for this, I'm going to use the datetimes module.  \\n Okay, and the datetime module actually has a  \\n datetime class in it.  \\n All right, so I've got datetime.datetime.  \\n I know it's a little confusing, but bear with me  \\n and then I'm going to call from timestamp.  \\n And then the argument that I'm going to give  \\n the from timestamp function is this right here,  \\n path.getmtime of the file.  \\n So I'll copy that and I'll paste that into here.  \\n All right.  \\n So now I'm getting the modification time  \\n and I'm going to print out a nice readable time, right?  \\n It's just a couple of different ways  \\n of accomplishing more or less the same thing.  \\n So let's go ahead and run this.  \\n And we can see that the modification timestamp  \\n being printed out using two different formats, right?  \\n So you can see that the file was modified  \\n and here's a nice readable version.  \\n And then here is the result that comes from the timestamp.  \\n Okay, so one more example,  \\n and this time it's going to involve some date math.  \\n And again, we haven't really done  \\n the chapter on manipulating dates yet.  \\n So just bear with me on this.  \\n What I'm going to do is calculate how long ago  \\n the file was modified.  \\n So I'm going to create a variable named td,  \\n and I'm going to assign that to datetime.datetime,  \\n and I'm going to call the now function.  \\n And that will give me the current time, okay?  \\n So that's going to give me  \\n the current time that I have right now,  \\n and I'm going to subtract off datetime.datetimes class.  \\n And I'm going to call the from timestamp method again.  \\n So let's go ahead and copy this from timestamp call  \\n with the get path function.  \\n All right, and I got to make sure I get the right number of  \\n parentheses in there.  \\n So I'm going to copy that  \\n and I'm going to paste that in here.  \\n So I'm taking the current time  \\n and subtracting off the modification time.  \\n So I'm performing math with the dates.  \\n And then what I'm going to do is print  \\n It has been,  \\n and then, td,  \\n and then, since the file was modified.  \\n And then I'm going to do one other thing.  \\n I'm going to print,  \\n let's get rid of that space,  \\n I'm going to print  \\n or td dot,  \\n and I'm going to call the total seconds function  \\n and I'm going to print out seconds, okay?  \\n So let's go ahead and run this.  \\n And what this is going to do is create,  \\n and we'll learn about this in a little bit,  \\n this is going to create a time delta,  \\n which is an amount of time.  \\n It's a span of time, and we'll learn about that later,  \\n but I can use this to figure out  \\n a amount of time by subtracting two dates from each other.  \\n So let's save this and let's run it.  \\n All right.  \\n And you can see right here in the result  \\n that it has been more or less,  \\n almost 17 minutes since the file was last modified  \\n or 1,013 seconds since the file was last modified.  \\n So just to recap, right,  \\n we started off by seeing how easy it is  \\n to get information about the operating system.  \\n And then we use the path functions  \\n to learn some basic information about a file  \\n in our operating system's storage.  \\n And then we worked with some file paths to get the real path  \\n and split off the path from the file name.  \\n And then we worked with some times.  \\n We got the modification time of the file  \\n and then figured out a way to calculate  \\n how long ago the item was modified  \\n using the date times class now function.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3021792\",\"duration\":553,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Using filesystem shell methods\",\"fileName\":\"2896241_en_US_03_03_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to manipulate files and directories.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":23665317,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] So far in this chapter,  \\n we've seen how to create files  \\n and how to get information about files,  \\n and Python provides a set of utilities  \\n for manipulating files using the operating system's  \\n shell utilities, and that's what we're going to look at  \\n in this example.  \\n So let's start by opening up the Shell_start code.  \\n To use the shell utilities,  \\n I first need to import the SH Util module into my app,  \\n so let's do that first.  \\n So I'll import SH Util,  \\n and you can see that I've already imported  \\n the OS and the OS path modules into my app as well.  \\n So, we'll start off doing something pretty simple.  \\n Let's just make a duplicate or a copy of an existing file.  \\n Now, this example depends on the Textfile.txt file existing,  \\n and you can see I've got it over here in my file browser.  \\n If it's not there for you,  \\n it's probably because you didn't do  \\n one of the previous exercises in the chapter,  \\n and you just need to do one of the previous exercises,  \\n preferably the first one,  \\n just to make sure that this file exists.  \\n So first, you can see that the code uses  \\n the Path Class's Exists function  \\n to make sure that Textfile.txt exists.  \\n And so, if it does, what I'm going to do is  \\n retrieve the path information for the file.  \\n So I'll create a source variable,  \\n and I'll set that to be Path.realpath,  \\n and I will get the real path for Textfile.txt.  \\n So that gives me the path to the file.  \\n Now, to make a copy, I'm going to use this original path,  \\n and I'm going to just put a .bak extension on the file.  \\n So what I'm going to do is make a destination variable,  \\n and that's going to be Source plus .bak  \\n inside quotes, because it's a string.  \\n All right.  \\n Now, I'm going to make a copy  \\n using the Copy function of the SH Util module.  \\n So I'll call SHUtil.copy,  \\n and that's going to take the source  \\n and copy it to the destination.  \\n All right, so let's save.  \\n And if this works, then we should see both Textfile.txt  \\n and Textfile.txt.bak  \\n for backup.  \\n So let's go ahead and run this.  \\n And sure enough, you can see that Textfile.txt.bak  \\n shows up over here in the list.  \\n All right, so let's try something else.  \\n Let's go ahead and close my terminal.  \\n Let's try renaming the original file.  \\n And what we're going to do is use the Rename function.  \\n So this is located in the OS module,  \\n and I'm going to call the Rename function,  \\n and Rename takes two arguments,  \\n the original file that I want to rename  \\n and the file I want to rename it to.  \\n So I'm going to rename Textfile.txt to Newfile.txt.  \\n And as you might imagine, this just renames the file  \\n specified in the first argument  \\n to have the name in the second argument.  \\n All right, so let's go ahead and try this.  \\n And I'm going to comment out the previous example.  \\n So let's run.  \\n All right.  \\n And let's see, yep, sure enough,  \\n you can see now that there's Newfile.txt  \\n and Textfile.txt is renamed, so it's not there anymore.  \\n So, using the shell is more than  \\n just about manipulating files,  \\n so let's try something a little bit more interesting.  \\n Let's put some content into a zip archive.  \\n So we're going to use the Shell Utilities  \\n Make Archive function in order to create an archive file  \\n that contains the contents of this entire directory,  \\n all of this Python code, every file that's in here.  \\n So to do that, I first need to import  \\n the Make Archive class.  \\n So from Shell Util, I'm going to import Make Archive.  \\n And let's scroll back down, okay.  \\n So first, I need to get the directory path  \\n from the full path of one of these files,  \\n and that will give me the path to  \\n this file's directory right here.  \\n So what I'm going to do is call the Path.split function.  \\n And Path.split, remember, we saw this earlier.  \\n I'm going to pass in the source variable here.  \\n This gives me the real path up to this text file.  \\n And I'm going to assign the results.  \\n Remember that split returns two values.  \\n So I'm going to assign the root_dir and tail,  \\n which isn't going to be used,  \\n to the results of Path.split.  \\n So that will give me the directory name  \\n right here in this variable, this is what I'm going to use.  \\n And then, what I need to do is  \\n call the Make Archive function.  \\n So I'll call SHUtil.makearchive,  \\n and I need to give it the name that I want to create.  \\n So I'll just call that Archive,  \\n and then I need to give it the format,  \\n and I want it to create a zip file.  \\n And then, the directory that I want to place  \\n into the zip file, and that's going to be root_dir.  \\n All right.  \\n So, I've got my  \\n files renamed.  \\n So, we've got Newfile.txt,  \\n Textfile.txt.bak.  \\n There's one more change I need to make.  \\n Remember up here on line 13,  \\n this code only runs  \\n if Textfile.txt is present,  \\n and it's not there anymore  \\n because we changed the name of the file.  \\n So I'll just change this to say,  \\n \\\"hey, if Textfile.txt.bak is present, which it is,  \\n \\\"then go ahead and run this code.\\\"  \\n So now, we can save and we can run this.  \\n So we'll run this on the terminal, and it runs.  \\n And sure enough, you can see that Archive.zip  \\n is right there.  \\n Now, if you were to look inside this zip file,  \\n you would see all the files in here, all the Python code,  \\n these text files that we've created and so on,  \\n but we can actually get finer-grain control over  \\n adding specific items to the archive,  \\n so let's try that next.  \\n So what I'm going to do is close this terminal.  \\n So what I need to do is import the zip file module  \\n that gives me control over zip files.  \\n So, I'm going to import  \\n from the zip file module.  \\n I want to import the zip file class.  \\n And then next, I need to add code  \\n for creating the custom zip file.  \\n And what I'm going to do is use the With keyword.  \\n So, the With keyword lets me create a local scope  \\n that simplifies working with objects.  \\n So I'm going to write With Zip File.  \\n And zip file takes a couple of arguments,  \\n similar to other file-based functions in Python,  \\n so I'm going to give it the name that I want to create,  \\n and that's going to be Testzip.zip.  \\n And then, I need to give it the file access,  \\n so I want to be able to write to the archive.  \\n And then I'm going to use the As keyword,  \\n I'm going to say As New Zip.  \\n So I'm creating this variable  \\n with the result of this class's construction,  \\n and this makes it simpler for me to manage the context of  \\n opening and closing files.  \\n So, since this is a context manager, I indent my code.  \\n And what I'm going to do is  \\n manually add things to the zip file.  \\n So I'm going to write New Zip  \\n and I'm going to call the Write function,  \\n and I'll add Newfile.txt, I have to put that in quotes.  \\n And I'll also write Newzip.write  \\n and I'll add the Textfile.txt.bak files.  \\n All right, so I'm only going to add this file and this file  \\n to this archive, and everything else just gets left alone.  \\n And if this works, we should see a new file called  \\n Testzip.zip get created.  \\n So let's go ahead and save this,  \\n and let's comment out the previous example  \\n so we don't run it again.  \\n All right, so let's right-click and choose  \\n Run Python File In Terminal.  \\n And sure enough, you can see that there's Testzip.zip  \\n right there, and I encourage you to go ahead  \\n and explore it on your computer.  \\n If you open up the Archive.zip, you'll see all these files,  \\n and if you open up the Test Zip archive,  \\n you'll only see these two files that are in there.  \\n So, you can see that by using  \\n the Shell Utilities module of Python,  \\n it gives you really great control over  \\n manipulating file objects in the operating system.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentAssessment:64ee20a6498e4e5b8410e012\",\"duration\":480,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"</> Code Challenge: Files\",\"externalAsset\":{\"coderPadCampaign\":\"urn:li:coderPadCampaign:845023\"},\"coderPadCampaign\":null},{\"urn\":\"urn:li:learningContentVideo:4514427\",\"duration\":135,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Files\",\"fileName\":\"2896241_en_US_03_05_C_2023Q3_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4350902,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] All right, so for this challenge,  \\n we needed to add up all of the byte sizes of the text files  \\n in the Deps Directory  \\n and we had to ignore any files that were not text files.  \\n So in my code, I have to import the OS module  \\n and I gave this as a bit of a hint in the instructions  \\n was to look at the OS and OS Path modules.  \\n So I import OS because I'm going to make use of the code  \\n in that module.  \\n And then in my code, I have a variable  \\n that keeps track of the total byte count so far  \\n and that is initialized to zero.  \\n Then I have a variable that contains the name  \\n of the Deps Directory,  \\n and I made it a variable  \\n because I'm going to use it several times.  \\n So to get a list of the contents of the directory,  \\n I can use the listdr function,  \\n which is contained within the OS module,  \\n which is part of the Python Standard Library.  \\n That will give me a list of file names,  \\n but those file names don't have the directory path in them.  \\n Next, I have a loop  \\n that iterates over each one of the file names in the list.  \\n I need to make sure that each one is in fact a file  \\n and that it ends with the .txt suffix  \\n because we only want to count text files.  \\n So to do that, I use the OS Path module's isfile function  \\n and I need to give it the path of the file to check,  \\n which is the folder name Deps,  \\n along with a forward slash and the file name from the list.  \\n And then I also use the endswidth function,  \\n which is built into string objects,  \\n to make sure that the file name ends with a .txt suffix.  \\n So if this particular item is in fact a file,  \\n and more specifically is a text file,  \\n then I need to add its size and bytes to my running total.  \\n So the OS Path module has a function named getsize,  \\n which will give me the size of the file in bytes  \\n which I add to my total.  \\n And after this loop completes,  \\n it returns the total number of bytes.  \\n So let's go ahead and test this.  \\n And sure enough, you can see  \\n that we are expecting the result of 4,232  \\n and that's what we're getting.  \\n All right, so how did your solution compare to mine?  \\n \\n\\n\"}],\"name\":\"3. Working with Files\",\"size\":69017567,\"urn\":\"urn:li:learningContentChapter:3019946\"},{\"duration\":2169,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3022806\",\"duration\":404,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"The date, time, and datetime classes\",\"fileName\":\"2896241_en_US_04_01_XR30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"In this video, learn the basics of time-based Python functions.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":17760545,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this chapter,  \\n we're going to focus on  \\n manipulating dates and times.  \\n And we're going to start off by learning  \\n about some of the basic classes and types  \\n that are available for this purpose.  \\n So here in my project,  \\n I'm going to go to the chapter for dates and times  \\n and open up dates_start.py.  \\n And let me go ahead  \\n and shrink that down.  \\n All right.  \\n So, in order to get this rich functionality  \\n that Python provides your application,  \\n you have to tell the Python interpreter  \\n to go get it from somewhere.  \\n And the way that you do that  \\n and we've seen this  \\n a little earlier in the course,  \\n is by using something called an import statement.  \\n So let's go ahead  \\n and add that to our example.  \\n And what I'm going to do is rather than import  \\n everything from date times module,  \\n I'm going to write from datetime import date.  \\n And I'll do the same thing  \\n from datetime import time  \\n and then from datetime import  \\n and this may be a little bit confusing  \\n but there's actually a datetime class  \\n inside the datetime module.  \\n So I'm going to go ahead  \\n and import that as well.  \\n So what I'm doing here  \\n is telling the Python interpreter,  \\n that from the datetime standard module,  \\n I want to import the time, date  \\n and datetime classes.  \\n And these are predefined pieces of functionality  \\n in the Python library  \\n that let me manipulate dates and times.  \\n So I don't have to write this code,  \\n it's already written for me  \\n and I just need to import it  \\n in order to use it.  \\n So let's now go ahead  \\n and exercise some of the features  \\n of these classes.  \\n So for the first example,  \\n let's just print out today's date.  \\n So we are going to write  \\n today equals date.today.  \\n And then I'll print  \\n a string that indicates today's date  \\n and the today variable, right?  \\n So this code calls the today method  \\n on the date class  \\n which returns information  \\n about the current date.  \\n So let's go ahead and run that  \\n and see what happens.  \\n And I'll just choose run Python file  \\n in terminal from visual studio code.  \\n Of course I can also do that up here,  \\n so I'll choose that.  \\n And you can see that today's date is  \\n 2021, October 4.  \\n All right,  \\n so far so good,  \\n let's close this terminal.  \\n So for the next example  \\n let's print out  \\n some of the individual components  \\n of a particular date object.  \\n So using the today variable,  \\n I'm going to print out  \\n (indistinct) string says date components  \\n and then I'm going to print today.day,  \\n today.month  \\n and today.year.  \\n So the object that comes back  \\n from the today function  \\n has several properties associated with it.  \\n I can get the individual day,  \\n the individual month,  \\n the individual year among other things.  \\n So now let's go ahead and save this  \\n and run it again.  \\n And you can see in the output  \\n that the day components  \\n here is the day,  \\n here's the month  \\n and here is the year.  \\n All right.  \\n So the date object also provides  \\n some other useful properties  \\n that I can use  \\n in other more advanced features  \\n of an application.  \\n So for example,  \\n And that starts off at zero for Monday  \\n and goes up to six for Sunday.  \\n So let's go ahead  \\n and try that out.  \\n I'll print that today's weekday number  \\n and I'll access today.weekday.  \\n So let's imagine I had some list variable  \\n and I want it to provide an index  \\n into that list  \\n that depended on the weekday.  \\n So I can have something like days  \\n and then days could be a series  \\n or a list of strings  \\n like Monday, Tuesday, right, Wednesday,  \\n Thursday, Friday  \\n and then we'll just do the weekend as well.  \\n So what I can then do is something like this.  \\n I can print which oops, which,  \\n inside quotes,  \\n which is a,  \\n and then I'll print out,  \\n I put a space there as well,  \\n I'll print out the day's list  \\n and I'll index into the day's  \\n list using today.weekday.  \\n All right,  \\n so let's go ahead and run that.  \\n And you can say  \\n that today's weekday number is zero  \\n because it's a Monday  \\n and sure enough when I index into that list  \\n it says which is a  \\n and then the abbreviated Monday.  \\n All right,  \\n so that's a pretty good introduction  \\n to working with date objects.  \\n Let's try working with some datetime objects.  \\n So just like working with dates,  \\n I can get times as well.  \\n So using the datetime class  \\n instead of the date class,  \\n I can call the now function.  \\n And that will give me the current date  \\n as well as the current time.  \\n So let me comment out these previous examples  \\n and I'll use control slash for that  \\n or command slash on the Mac.  \\n And let's run what we have.  \\n And you can see that it says  \\n the current date and time is,  \\n and we got 2021-10-04  \\n and then I've got the time,  \\n and even some milliseconds.  \\n Right, let's close this terminal.  \\n So to get the current time,  \\n we need to get the time portion  \\n of the datetime object.  \\n So I'm going to have a variable named t  \\n and I'm going to call datetime.time.  \\n And then I'll pass  \\n the datetime.now's result into that.  \\n And then I'll print the current time is  \\n and then the t variable, all right?  \\n And the datetime class  \\n remember we imported that up here  \\n in the import list.  \\n So that's the item in the top in the import  \\n and that's this object  \\n I'm going to be using right here.  \\n So I can now create a class,  \\n a timeclass object  \\n and give it the value of datetime.now.  \\n And that will give me just the time.  \\n So let's go ahead and run this  \\n so we can compare it side by side.  \\n And when I run this,  \\n you can see in the output,  \\n it says the current date and time,  \\n that's what we got before.  \\n And now it says the current time  \\n and it shows me just the time now.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3021793\",\"duration\":442,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Formatting time output\",\"fileName\":\"2896241_en_US_04_02_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to format strings containing dates and times.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":19883790,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Now that we've seen  \\n how to retrieve basic date and time information in Python,  \\n let's take a look at how to format that information  \\n using a set of predefined string formatting codes.  \\n So in my editor,  \\n Now, in this example,  \\n I have already set up the import statement  \\n to import the date time class, so you don't need to do that.  \\n And Python provides  \\n a standard set of string formatting codes  \\n that you can use in a variety of scenarios.  \\n Now, if you've ever done any programming in C or C++,  \\n and used the standard C library,  \\n some of these codes might look familiar to you.  \\n If not, they're pretty easy to understand  \\n once you've seen them in action.  \\n So let's start with a familiar piece of code  \\n to get the current date and time.  \\n So, I'm going to create a variable called now,  \\n and I'm going to call it datetime.now.  \\n So now I've got the current date and time.  \\n Let's have a look at some of the options  \\n I have available to me to format the output.  \\n So to format data information,  \\n you use what's called the strftime function,  \\n which is available as a method on the datetime object  \\n that as returned by the now function.  \\n So let's go ahead and just try that out, all right?  \\n I'm going to print,  \\n oops,  \\n now.strftime.  \\n This function takes a string argument  \\n that contains one or more of these formatting codes,  \\n and we'll get into that in a second,  \\n which function as placeholders for date and time data.  \\n So for example, to format a string  \\n with the full year number, I could use something like this.  \\n I would write the current year is,  \\n and then %Y.  \\n All right.  \\n And in the output, you can see at the current year is 2021.  \\n Now, I can also mix these codes with regular texts,  \\n so let's get a little bit more fancy.  \\n I'm going to close this right here.  \\n And what I'm going to do is use several of the codes  \\n in the same string at once.  \\n So let's go ahead and copy this and paste it,  \\n and I'm going to use %a.  \\n And %a, you can see here in the comment  \\n means the weekday.  \\n So I'll do %a,  \\n then %d.  \\n And you can see %d is the day of the month,  \\n and then I'll do a space with %B,  \\n and the capital is important there, all right?  \\n And the B means the month, but I'm going to capitalize it.  \\n And then after %B I'll put another comma  \\n and put %y,  \\n okay?  \\n And you can see that y and Y are the year,  \\n and we'll see what the lowercase and uppercase does  \\n in just a moment, all right?  \\n So, this formatting string will print  \\n the abbreviated day name, followed by the day of the month,  \\n then the full month name, which is what the capital means,  \\n and then the two digit abbreviated year.  \\n So let's go ahead and try that.  \\n And sure enough,  \\n you can see that that's exactly what happens  \\n right here on this line.  \\n Python also gives you a way of printing out  \\n locale specific information.  \\n So rather than having to manually figure out  \\n these specific locale your application is being run in  \\n and how to print out information  \\n using the current localized versions of date and times,  \\n there's a set of codes to do that for you.  \\n So I'll enter some code to try that out.  \\n So let's try printing  \\n now.strftime,  \\n and I'm going to write locale date and time,  \\n and that's going to be %c,  \\n and let me copy and paste that.  \\n And then just doing the locale date by itself,  \\n that's going to be %x  \\n and I'll copy and paste this one more time  \\n and I'll do locale time and that's going to be X.  \\n All right, let's go ahead and give that a try.  \\n All right, and sure enough,  \\n is printed using my local computer settings.  \\n You can see that because I'm in the US I've got month,  \\n day and year separated by slashes,  \\n and the local time is 22 hours 48 minutes and 29 seconds.  \\n Now, if I was running this on a computer in say, Europe,  \\n then the information you see printed here  \\n would probably look a little bit different  \\n based upon what the locale settings are.  \\n So I got the month first, the day second and so on,  \\n but other countries put the day and then the month, right?  \\n So the control codes c and x and X allow you to use  \\n whatever the current locale supporting format is  \\n for dates and times.  \\n All right, so let's close this example.  \\n Let's finish up with a look at time formatting.  \\n So just the same way that you can print  \\n formatted data information,  \\n you can print formatted time information as well.  \\n So, I'm going to add a couple of lines here  \\n to exercise these options.  \\n So, I'll print now.strftime  \\n and this time I'll write out the current time  \\n and I'll use %I, and that's for the hour  \\n and then a colon,  \\n and then %M, M for the minute,  \\n and then another colon,  \\n and then %S, S for the second,  \\n and then I'll put a space and a %p  \\n and that's going to be the a.m. or the p.m.  \\n And then I'll do one more,  \\n and this time I'll do 24 hour time.  \\n And in this case, instead of the I, I'll do %H  \\n and just the M  \\n and I'll take off the S and the P, all right?  \\n So let's go ahead and save, and let's run this.  \\n And now, you can see that I'm controlling  \\n how the time is formatted.  \\n So for the current time, I've got 10:50:30 p.m.  \\n and then for the 24 hour time I've got 22:50.  \\n Now, if this were the morning,  \\n this would print out a 24 hour based value,  \\n so this value would be less than 12.  \\n So for example, it would be nine  \\n for nine o'clock in the morning.  \\n So if you find yourself needing to print format a date  \\n and time data, Python provides some pretty rich controls  \\n for accomplishing these scenarios.  \\n And of course,  \\n you don't need to keep all of these codes in your head.  \\n There's some great documentation on the supported (mumbles)  \\n and how they work.  \\n So let's switch over to the browser really quickly.  \\n And if you go to this link here in the Python documentation,  \\n you can see all these different codes that are listed,  \\n that you can use for formatting  \\n date and time related information.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3020817\",\"duration\":538,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Using timedelta objects\",\"fileName\":\"2896241_en_US_04_03_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to calculate time differences in Python.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":25638945,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] A common scenario involving dates and times  \\n involves performing mathematical operations  \\n on date and time values themselves.  \\n So for example, given a particular date,  \\n you might want to calculate a date in the future or the past  \\n relative to that date.  \\n And we can use the timedelta class in Python  \\n to help us with this.  \\n So that's what we're going to look at in this example  \\n here in my editor I'm going to open up timedeltas_start,  \\n and you can see I've already imported  \\n some of the modules and classes I'm going to need.  \\n So in order to use timedeltas,  \\n we first need to import the correct class  \\n from the daytime package.  \\n So let's do that first.  \\n So from datetime, I'm going to import the timedelta class,  \\n and a timedelta is basically a span of time.  \\n It's not a particular date, it's not a particular time,  \\n it's an amount of time,  \\n and you can use this class to perform time-based math.  \\n So let's take a look at some examples.  \\n First to construct a timedelta,  \\n all you need to do is create the timedelta class  \\n and then passing the amount of time  \\n that you want the Delta to represent.  \\n So I'll do something really simple,  \\n I'll create a timedelta,  \\n and I'm going to pass in some parameters.  \\n There's different properties you can pass in.  \\n I'm going to specify that the number of days should be 365  \\n and then it's going to be five hours  \\n and minutes is going to be equal to one, okay?  \\n So I'm creating a timedelta the represents  \\n 365 days, five hours, and one minute,  \\n and I'm going to print that out.  \\n So let's go ahead and run this, right?  \\n And you can see that sure enough  \\n there's my timedelta right there,  \\n it's 365 days, five hours, and one minute.  \\n So, let's use today's date as a reference  \\n for the next few operations.  \\n So I'll create a variable called now,  \\n and I'll set that to the result of daytime.now,  \\n and then I'll print out today is, and that's going to be now.  \\n So we've got today's date and time.  \\n Let's use a timedelta to figure out  \\n what today's date will be one year from now.  \\n So we'll print out, one year from now it will be,  \\n and then I'm going to print out,  \\n I'm going to use the str function  \\n to convert the result into a string.  \\n So I'm going to add now plus a timedelta  \\n and the timedelta is going to be days equals 365.  \\n So I'm going to create a timedelta of one year.  \\n Let me close down the taps, so we have some more room.  \\n So let's go ahead and try that.  \\n All right, and so sure enough we have today is,  \\n here's this date, and we can see that one year from now,  \\n it's going to be in 2022 on the same date, okay?  \\n So let's keep on going and see what else we can do.  \\n I'm going to lose that terminal.  \\n So I'm going to create a timedelta with more than one argument.  \\n I'm going to print, in two weeks and three days it will be.  \\n And then once again, I'm going to use the str function  \\n to convert this to a result.  \\n And I'll right now, plus timedelta.  \\n And I'm going to say weeks equals two  \\n and days equals three, okay?  \\n So in this case, I'm constructing a timedelta  \\n of two weeks and three days,  \\n adding that to the current date.  \\n So let's go ahead and try that out, so I'll run this again.  \\n All right, so let's see.  \\n Well, two weeks is 14 days, right?  \\n So if you add 14 to four that's 18 plus three more days  \\n that's the 21st.  \\n Yeah, so sure enough, two weeks from today,  \\n two weeks and three days, it's going to be October 21st.  \\n All right, let's keep on going.  \\n So I'll close this terminal.  \\n Next, let's try a date calculation  \\n that uses a date in the past,  \\n and let's also use what we've already learned  \\n from a previous video to use string formatting codes.  \\n So I'll create a variable name T and I'll get datetime.now.  \\n And I'm going to subtract off a timedelta  \\n where weeks is equal to one.  \\n So I'll subtract off a week  \\n and then I'll have an S variable.  \\n That's going to call the strftime function  \\n and strftime, I'm going to pass in my formatting string.  \\n So percent A and then percent B  \\n and then percent D for the day number.  \\n And then the full digit year is going to be a percent Y  \\n and then I'll print one week ago it was S, okay?  \\n All right, let's go ahead and run that.  \\n And oh, oops, error in my code right there.  \\n So what I need to do is use this equal sign.  \\n It's a minus sign, okay, there we go.  \\n So let's run this.  \\n Okay, so it says one week ago it was Monday,  \\n September 27th okay, great.  \\n So now I've used timedeltas  \\n to work on times both in the future and in the past.  \\n So let's take a look at one more interesting example.  \\n What I'm going to do is comment out  \\n all these previous examples I've done so far, right?  \\n Control + Slash.  \\n So let's do this.  \\n Let's write a script that's going to count,  \\n how many days it is until the next April Fool's Day.  \\n So I'll start by getting today's date.  \\n And then next I'll construct a date  \\n that represents April Fool's Day.  \\n So afd for April Fool's Day is going to be equal to,  \\n and I'm going to call the date constructor.  \\n I'm going to pass in today's year and then four,  \\n that's the month of April and then one for the first day.  \\n So now I have to use date comparison  \\n to see if April Fool's Day has already gone by,  \\n because if it has, I need to get the next April Fool's Day.  \\n So if April Fool's Day is less than today,  \\n then I'm going to print out, April Fool's Day already went by  \\n and let's print out the number of days it went by.  \\n So I'll subtract off today minus afd, right, .days okay?  \\n And I'm going to put all of that in parentheses, all right?  \\n And then I need to replace the current year  \\n with next year's.  \\n So I need to get next year's April Fool's Day.  \\n So I'm going to set afd equal to afd.replace,  \\n and I'm going to replace the year with today's year plus one.  \\n So now I just need to subtract the April Fool's Day date  \\n from today to create a timedelta result.  \\n So time to afd is equal to my April Fools date  \\n that I just calculated minus today.  \\n And then I'll print.  \\n It is time to afd.days.  \\n And I'll say days until the next April Fool's Day, alright?  \\n So let's go ahead and run this.  \\n And you can see that in this case,  \\n April Fool's Day already went by 186 days ago,  \\n which means it is now 179 days  \\n until the next April Fool's Day.  \\n So you can see that by using timedeltas,  \\n you can do some pretty advanced  \\n and complex date calculations  \\n using just the built-in standard classes  \\n that Python gives you.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3023364\",\"duration\":612,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Working with calendars\",\"fileName\":\"2896241_en_US_04_04_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to work with Python calendar functions.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":27336116,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] All right, let's wrap up this chapter  \\n by taking a look at a few examples  \\n of how to work with calendars in Python.  \\n So Python's library provides a couple  \\n of useful utilities for working  \\n with calendars in both text and HTML formats,  \\n as well as some other date and calendar utilities.  \\n So let's take a look at the module  \\n for how to work with this.  \\n So let's open up our calendars_start.py file  \\n and in order to use the calendar module in a Python app,  \\n you first need to import the module.  \\n So let's go ahead and do that.  \\n So I'll import the calendar.  \\n And that statement will import all the various classes  \\n from the calendar module into my app.  \\n So let's start off by just creating a plain text calendar.  \\n So to do that, I'm going to use the TextCalendar class.  \\n So I'm going to write calendar.TextCalendar  \\n and I'm going to specify that the week  \\n should begin on Sundays.  \\n And then I'll format this into a string.  \\n So I'll call the calendar's formatmonth method  \\n and I'm going to choose the year and the month  \\n for January and a couple of other options  \\n to format the month  \\n and then I'll print out the string.  \\n So the formatmonth method lets me format a particular month  \\n into a text string,  \\n and then I just print the results.  \\n So let's save and let's run this.  \\n Right?  \\n And you can see in the output  \\n that it's formatted January 2022 for me.  \\n The weeks begin on Sundays,  \\n and we've got another week here  \\n that starts on Saturday.  \\n Let's go back and change that parameter though.  \\n Let's change this to a Monday.  \\n And then let's save and run it again.  \\n And now we can see that the weeks begin on Mondays  \\n and the formatting of the weeks has been updated to match.  \\n Now let's see how to do the same thing with HTML.  \\n And for that, I'm going to use surprise,  \\n the HTMLCalendar class.  \\n So I'll create a variable hc  \\n and I'll call HTMLCalendar  \\n and once again, I want the calendar  \\n to start on Sundays.  \\n And then I'll do the same thing with the string.  \\n I'll just simply call formatmonth.  \\n And I'll do January  \\n and then I'll print the str.  \\n All right, let's go ahead and comment this out.  \\n And let's save and let's run.  \\n All right, so you can see  \\n that here I'm getting this HTML output.  \\n There's a table that contains all of my calendar information  \\n in table rows and table columns and so on.  \\n Now, I'm not going to walk through all the HTML code  \\n but you can see that it works.  \\n And if you want to go ahead and paste this into a browser  \\n to see the result, feel free to do so.  \\n Let's go see another example.  \\n So I'll go ahead and comment this out.  \\n You can also use the calendar class  \\n to perform some common operations on dates.  \\n So for example, I might have a need  \\n to iterate over the days of a given month.  \\n And I can use the itermonthdays method to do this.  \\n So what I can do is I'll write a for loop  \\n and I'll write for i in c.itermonthdays.  \\n And oh, I should uncomment one of these statements  \\n to create the calendar.  \\n So I'll call itermonthdays  \\n and I'll iterate over August of 2022.  \\n And I'll just print the day number.  \\n So this function is going to return numbers  \\n that represent each day in the month.  \\n So if I run this,  \\n you'll see, so each one of these numbers represents a day  \\n in the month.  \\n So in August, there's 31 days.  \\n So here's day number one.  \\n And that's obviously a Sunday  \\n because that's the first day of the week.  \\n And if we scroll all the way down,  \\n you'll notice that there's some trialing zeros.  \\n And what that means is that indicates  \\n that those days are in that week  \\n that belong to another month.  \\n So the 31st is the last day of August  \\n and then since the weeks end on a Saturday,  \\n so this is going to be a Saturday,  \\n this is going to be a Friday, a Thursday and a Wednesday,  \\n but those belong to the next month.  \\n So that's that example.  \\n Let's keep on going.  \\n The calendar class also provides some useful utilities  \\n for the current locale.  \\n So I can loop over the names in the month_names  \\n and day_name properties on the calendar class.  \\n So let me comment out this example  \\n and we'll try this out.  \\n So what this means is I don't have to have code  \\n in my application that knows what the names  \\n of the months are around the world.  \\n The system's locale will just give them to me  \\n based upon where my app happens to be running.  \\n So I'll write for name in calendar.month_name.  \\n And I'll print the name  \\n and then I'll do the same thing with days.  \\n So for day in calendar.day_name,  \\n I'll print the day.  \\n All right, so let's go ahead and save this.  \\n And run it.  \\n You can see that because I'm here in the United States,  \\n I'm getting the months in English names.  \\n So there's January, February, March and so on.  \\n Now, if I was in another part of the world  \\n or my local system here  \\n was set to be some place in Europe, for example,  \\n I would get the locale-based names,  \\n and you can see in the second example, same thing.  \\n I'm getting Monday, Tuesday, Wednesday.  \\n So I can get the names of both the months  \\n and the days as they would appear  \\n in the current locale for where the computer is  \\n or I guess where the system happens to be set to.  \\n Let's try one more example.  \\n So I'll comment this out.  \\n Let's do something fun.  \\n Let's suppose I had a team of people  \\n and the team meets on the first Friday of every month.  \\n And what I want to do is write a small script  \\n that just prints out what those dates are  \\n for the upcoming year.  \\n So that way I could give that list of days  \\n to my team members and they would know  \\n what the meeting dates are for the upcoming year.  \\n So what I need to do is calculate  \\n when the first Friday happens in each month  \\n and then calculate the date  \\n that represents that day.  \\n So let's go ahead and start our script.  \\n I'll print out team meetings will be on.  \\n And then I'm going to have a for loop.  \\n So I'm going to loop over all the months  \\n in the range from 1 to 13.  \\n And remember that 13 is not inclusive in the range.  \\n So this will give me months 1 through 12.  \\n Now, what I'm going to do is get an array  \\n of weeks that represents each one of these months.  \\n So I'm going to do that  \\n by calling the calendar's monthcalendar function  \\n for the given year.  \\n That's next year.  \\n And then each one of the months.  \\n So each time through this loop,  \\n m will be a month number  \\n and then I'm using the calendar class's  \\n monthcalendar function.  \\n That's going to give me back a list  \\n of lists of weeks  \\n that represent the days in the given month.  \\n So what I'm going to do then is have two variables.  \\n Weekone and that's going to be the first week  \\n that gets returned.  \\n And then weektwo,  \\n which will be the second entry in that list.  \\n So the first Friday of that month  \\n has to be somewhere within the first two weeks.  \\n So I've got two local variables here,  \\n weekone, weektwo, which I get from my array  \\n and then I just need to see which  \\n of those two weeks has the first Friday.  \\n So to do that, I'm going to use  \\n the calendar's Friday constant  \\n to index into each of these arrays.  \\n So I'll say if weekone  \\n and the calendar.FRIDAY index of weekone  \\n is not equal to zero,  \\n then I know that the meeting day  \\n is in weekone  \\n on calendar.FRIDAY.  \\n Otherwise, the meeting day  \\n has to be in weektwo  \\n on the same index.  \\n Calendar.FRIDAY.  \\n So remember, we saw this earlier,  \\n if the day number of a particular day in the week is zero,  \\n then that means that that day is part  \\n of a different month.  \\n So if the Friday value of the first week  \\n is equal to zero, then that Friday  \\n was in the previous month,  \\n and then this particular month starts  \\n on a Saturday so the first Friday  \\n has to be in the second week.  \\n So now at this point,  \\n I have my meetday variable set  \\n to whichever the first Friday's worked out to be,  \\n whichever week they were in.  \\n And then I just need to print out the month_name  \\n and the day.  \\n So I'm going to print out  \\n calendar.month_name for the current month.  \\n And then the meetday.  \\n All right, and that's pretty much it.  \\n That's all I have to do.  \\n So let's go ahead and save  \\n and let's run this.  \\n And you can see in the output,  \\n we've looped through all the months starting in January,  \\n going down to December.  \\n And now we have a list of the dates  \\n for the first Fridays of each month.  \\n So now I can give this list of dates to my team  \\n and they'll know what the actual dates are  \\n for the first Friday in each one  \\n of the months we're going to have our team meeting.  \\n Such is the power of Python.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentAssessment:64ee2105498e960bb80bb2cb\",\"duration\":600,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"</> Code Challenge: Dates and times\",\"externalAsset\":{\"coderPadCampaign\":\"urn:li:coderPadCampaign:845025\"},\"coderPadCampaign\":null},{\"urn\":\"urn:li:learningContentVideo:4511431\",\"duration\":173,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Dates and times\",\"fileName\":\"2896241_en_US_04_06_C_2023Q3_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":null,\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5444879,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Host] All right, so how'd you do on this one?  \\n The key to solving this challenge was to use  \\n the month calendar class that is in the calendar module,  \\n which is what I listed  \\n in the hint section of the challenge instructions.  \\n So let's go over my code.  \\n Remember that our function is given a year and a month  \\n along with a weekday value from zero to six  \\n which represents a day of the week,  \\n with zero being Monday and six being a Sunday.  \\n And our task was to return the number  \\n of those days that appear in the given month.  \\n So the number of Mondays, the number of Tuesdays, so on.  \\n So my code imports the calendar module  \\n and sets the day count to zero.  \\n And then I use the month calendar method to get the month  \\n for the given year.  \\n Now this function returns an array  \\n of lists for the specified month, and each list  \\n in the array represents a week that's in that month.  \\n Each one of those week lists contains seven integers  \\n and each index into that list corresponds  \\n to the integer that represents the day  \\n that we are interested in.  \\n So if the value at that index is zero  \\n then the week doesn't contain that day.  \\n And this typically happens  \\n at the beginning or the end of a month.  \\n So for example, if the first week  \\n in a month might start on a Wednesday, and that means  \\n that the indexes for Monday and Tuesday would be zero.  \\n So my code looks at the day for that index, and  \\n if the value is zero, then we don't increment the day count.  \\n We only increment the day count if the the value  \\n at that index is non-zero.  \\n So we do that for each one of the weeks in the week list  \\n and then we return the day count.  \\n So let's go ahead and test my code,  \\n so we've got 2025, so this is December, 2025  \\n and we're looking for Mondays.  \\n And when I click test my code, yep, sure enough  \\n we have five Mondays in December of 2025.  \\n Let's try 2023 and let's try July.  \\n And let's do Tuesdays.  \\n No, that's Wednesday.  \\n So let's go ahead and click test my code.  \\n And sure enough, there are four Wednesdays in July, 2023.  \\n And remember, you can check to see  \\n if your answer is correct by showing the expected result.  \\n So let me go ahead and return with the wrong answer.  \\n I'll just return zero here and we'll test my code  \\n and you can see that it isn't working.  \\n So my code returns zero  \\n and it says the expected result was four.  \\n So that's, you can see what the right answer  \\n is supposed to be.  \\n So go ahead and compare my answer  \\n with yours and then try playing around  \\n with different values and seeing what happens.  \\n \\n\\n\"}],\"name\":\"4. Using Dates and Times\",\"size\":92913309,\"urn\":\"urn:li:learningContentChapter:3025084\"},{\"duration\":1869,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3021795\",\"duration\":203,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Fetching Internet data\",\"fileName\":\"2896241_en_US_05_01_XR30\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to retrieve data from the internet using Python.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8508310,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] One of the areas where Python really shines  \\n is in retrieving and working with data from the internet,  \\n such as JSON, XML and HTML.  \\n In this chapter we'll see how to work  \\n with all three of these data types.  \\n Let's start by opening up the inetdata_start.py file.  \\n And in this first example,  \\n we're going to just retrieve data from a web server  \\n and print the results.  \\n So in order to make a request to a web server,  \\n I need to import the urllib.request module.  \\n So let's start by doing that.  \\n So I'm going to import urllib.request.  \\n And this module provides the classes and code  \\n I need to make HTTP requests.  \\n So next, I'm going to get rid  \\n of this placeholder pass statement in my main  \\n and I'm going to create a variable called weburl  \\n and weburl, I'm going to assign  \\n the result of urllib.request,  \\n and then I'm going to call the urlopen function.  \\n And the urlopen function just simply takes a string  \\n of the URL that I want to request.  \\n So I'm going to just give it a URL, a simple one.  \\n So I'll just go ahead and get some data from google.com.  \\n This will give me back a web response object.  \\n So the URL I'm opening up for here is just  \\n the address for Google's homepage.  \\n And for the moment what I'm going to do  \\n is just print out the result code.  \\n Now the result code is retrieved  \\n by calling the getcode function on the response  \\n that I've created.  \\n So I'm going to print out the result code,  \\n and that is going to be weburl.getcode.  \\n So this will just be a regular old HTTP result code.  \\n So for example, the result code will be 200  \\n if everything's okay, or 404, if not found for example.  \\n So let's go ahead and save this,  \\n and let's run what we have so far.  \\n So I'm going to choose run Python file in terminal.  \\n And sure enough, you can see that the result code is 200.  \\n So everything worked just fine.  \\n I'm able to connect to the website without any problems.  \\n And now that we've got the URL open,  \\n we can read some data and print it out.  \\n To do that, I need to call the read function  \\n on the weburl request that I've created.  \\n So what I'm going to do is make a new variable called data,  \\n and then I'll assign that to weburl.read.  \\n And this is very similar to reading files,  \\n which we saw how to do earlier in the course.  \\n So I'm going to go ahead and print out that data.  \\n So I'm just reading the entire contents of this URL  \\n into a variable called data,  \\n and I'm going to print that data out.  \\n So if all goes, well,  \\n this should be the HTML code for Google's home page.  \\n So let's go ahead and save this.  \\n And I'll close that terminal and start it up again.  \\n So I'll choose run Python in terminal.  \\n And sure enough, you can see,  \\n if we scroll back up through all this code,  \\n right here, near the top.  \\n All right. So here's the result code.  \\n The result code is 200 and then you can see  \\n that I get the HTML back for Google's homepage.  \\n So just in a few lines of code,  \\n we were able to open a connection to a URL  \\n and then read the contents of that URL  \\n and then print out the results.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3019944\",\"duration\":710,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Working with JSON data\",\"fileName\":\"2896241_en_US_05_02_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to load and parse JSON data into Python structures.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":31915555,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this example,  \\n we're going to take what we learned in the previous video  \\n to see how to use Python,  \\n to connect to a Real-time JSON data feed  \\n and process the information.  \\n JSON stands for the JavaScript Object Notation,  \\n and you'll run into this a lot when you're working with data  \\n from various different sources on the internet.  \\n The data feed that we're going to be using  \\n is the US Geological Surveys Earthquakes Data Feed,  \\n and I have their homepage open here.  \\n You can see here that the earthquake data feed  \\n is provided by the USGS,  \\n and they provide the feed in a variety of formats.  \\n So they have ATOM, and they've got Google Earth KML,  \\n they provide JSON.  \\n And if you click on this link right here,  \\n that GeoJSON Summary Feed, then you'll get this page.  \\n And this describes the format of the JavaScript object  \\n that comes back from the data feed.  \\n So if you scroll down a little bit,  \\n you can see that there's information  \\n such as longitude, latitudes.  \\n There's generated times, there's some URLs,  \\n and then there's this big long features array  \\n that describes each earthquake.  \\n So here's the magnitude, the place, the time,  \\n there's a longitude and latitude in here somewhere.  \\n So we're going to be using this feed  \\n to get information about current earthquakes  \\n all around the world.  \\n Now it's beyond the focus of this course  \\n to teach the concepts of JSON.  \\n So if you need to learn the basics of JSON,  \\n then you should consider watching  \\n the JSON Essential Training course first, right?  \\n Let's go over to our editor.  \\n In the editor, we're going to open up jsondata_start.  \\n To be able to use Python to process JSON,  \\n I first have to import the correct module,  \\n which is the JSON module,  \\n and that is part of the Python Standard Library.  \\n So I'm going to go ahead and import JSON.  \\n So I've already defined the main function.  \\n So if we scroll down a little bit,  \\n you'll see that here is the main function.  \\n And I've got a variable here called URL data,  \\n which is pointing to a URL that the USGS uses  \\n to deliver JSON data for all the earthquakes  \\n that have happened within the last day  \\n that were larger than a magnitude of 2.5.  \\n And just like in the previous example,  \\n I also have a web URL variable,  \\n and I'm calling the URL open function  \\n on the URL to get the data.  \\n So first I'm going to print out the result code  \\n to make sure that we're getting a result code of 200.  \\n If the result code comes back as 200,  \\n we're going to read the data from the URL and process it.  \\n This will retrieve the JSON data from the website,  \\n and we're going to write a function called print results,  \\n which if we scroll back up you'll see is right here,  \\n and print results will print out our customized results  \\n from the JSON data feed.  \\n So let's go ahead and write the code  \\n to check to make sure everything's okay.  \\n So I'll write, if webUrl.getcode  \\n is equal to 200,  \\n then I'll get the data,  \\n and I'll define a variable name data,  \\n and I'll call webUrl.read,  \\n and then we'll print out our customized results  \\n using the data.  \\n Otherwise we're going to print out an error,  \\n and the error will say,  \\n received an error from the server,  \\n cannot print results,  \\n and we'll print out the webUrl.getcode.  \\n Okay, so now let's fill out the print results function.  \\n So print results is going to take the JSON data object.  \\n All right?  \\n And you can see I've already written a line of code  \\n that you see here that's called the Load S function  \\n on the JSON module,  \\n and that assigns the result to a variable named the JSON.  \\n So the Load S function takes a string of JSON  \\n and parses it into a native Python object,  \\n in this case, a dictionary.  \\n So once we've done that, we can access that object  \\n like we would any other Python object.  \\n So for example, according to the GeoJSON spec,  \\n there's a property named Title in the metadata section,  \\n so let's go ahead and print that out.  \\n So I'll check to see if there is a title key in the JSON,  \\n and I'm going to check the metadata section.  \\n And if there is,  \\n I'm going to print the JSON,  \\n and in the metadata section, I'm going to print title.  \\n So let's save, and let's quickly go back to the browser.  \\n And back here in the browser,  \\n you can see in the metadata section,  \\n I'm getting this title right here.  \\n So this is the key that's going to be in the dictionary,  \\n and then that itself is a dictionary.  \\n So I'm going to get the title key  \\n from the metadata dictionary and print it out.  \\n Also within the metadata section,  \\n it looks like there's a count property,  \\n which tells us how many earthquakes  \\n there are in the dataset.  \\n So let's go ahead and print that out as well.  \\n So I'll get the JSON.  \\n And once again, I'll look inside metadata,  \\n and I'm looking for count,  \\n and I'll print out, count events recorded.  \\n All right. So let's go ahead and run what we have so far.  \\n So I'll save, and I'll right click  \\n and choose run Python in my terminal.  \\n And sure enough, we can see that the result code is 200.  \\n So that's working.  \\n This is the title right here,  \\n USGS magnitude 2.5+ earthquakes in the past day.  \\n And we can see that there are 33 events recorded.  \\n All right. So we're making some good progress.  \\n Now let's print out some of the details  \\n from the earthquake data structure.  \\n So let's close the terminal, and let's go back to the spec.  \\n And if we look in here, all right,  \\n we can see that there's a property named features, right?  \\n So this is an array where each entry  \\n has an object named properties  \\n that represents the details for each individual earthquake.  \\n So we're going to write some code that prints out the place  \\n where each one of the earthquakes occurred,  \\n and you can see that there's a place string right here.  \\n So let's go back to our code.  \\n So what I'm going to do is write a loop.  \\n I'm going to write, for I in the JSON,  \\n and I'm going to look in the features array,  \\n 'cause remember features is a list.  \\n We're going to loop over all of the feature entries,  \\n and I'm going to print in the properties object.  \\n I want to print out the place,  \\n and then after that loop completes,  \\n I'm just going to print out a little spacer  \\n so that we can keep all of our data separate.  \\n So now let's run that.  \\n So I save and let's go back, run this in the terminal,  \\n and let's see, all right, so we've got a list here.  \\n Okay. So here's our list of events, right?  \\n So we've got 33 events recorded,  \\n and we've got off the coast of Aisen, Chile.  \\n We've got 50 kilometers south of Whites City, New Mexico.  \\n We've got one in India, there's one in Hawaii.  \\n So you can see that we're getting  \\n all of the recorded earthquake events  \\n that were larger than 2.5 magnitude,  \\n and there's 33 of them.  \\n All right. So make it even more progress.  \\n Let's print out a list of all quakes  \\n that have a magnitude of four or greater,  \\n and we're going to examine the mag property  \\n of each quake to do this. All right?  \\n So once again,  \\n we'll have a loop for I in the JSON,  \\n and we're going to be looping over features.  \\n So I'm going to check to see if that element,  \\n and we're going to look at the properties,  \\n and I'm going to look at the magnitude key.  \\n So if that is greater than or equal to 4.0,  \\n then I'm going to print out properties,  \\n and the place.  \\n And then once again, I'll have my separator.  \\n So once again, let's save and let's run.  \\n All right, so let's go back up and scroll.  \\n Let's find the first separator.  \\n Okay. Here's the first separator.  \\n So these are going to be all the places  \\n where the magnitude was greater than 4.0,  \\n and you can see that there's a subset  \\n of all the earth quakes we've seen so far.  \\n So let's do one more example, right?  \\n For the last example,  \\n let's print a list of quakes  \\n where at least one person reported feeling something.  \\n So let's look back in the spec,  \\n and back here in the spec we'll see,  \\n if we look down in the spec here somewhere,  \\n where is it? There it is.  \\n There's a felt property right here.  \\n And this is the number of people who have felt the event  \\n and called it in and reported it.  \\n So let's go update our code.  \\n So let's go ahead and print out,  \\n \\\"events that were felt\\\", okay?  \\n And then once again, I'll have my for-loop,  \\n so I'll just copy and paste this.  \\n So we get the number of felt reports  \\n assign that to a variable,  \\n and that's going to be in each item, there's the properties,  \\n and there's going to be the felt property.  \\n And I'll say, if felt reports is not equal to none,  \\n so the property exists.  \\n I'll then say, if felt reports is greater than 0,  \\n we're going to print the properties and the place.  \\n So once again, I'll just copy this right here  \\n and paste it in.  \\n All right. And we'll also print the felt reports, times.  \\n Okay. So let's go ahead and save,  \\n and let's run this one last time.  \\n And we can see that our last list,  \\n these are all the events that were felt.  \\n So we've got one in Columbia that was felt twice.  \\n Here's one in Japan that was felt 18 times.  \\n Now, keep in mind that the data  \\n that you're going to be seeing  \\n is different than the data that I'm seeing here,  \\n and obviously that's because,  \\n you know, I'm looking at this data  \\n as of the date of this recording.  \\n And when you look at this data,  \\n this is going to be live real data.  \\n So your data is going to look different than mine.  \\n But I think you can see here though,  \\n that using Python to retrieve JSON data from the internet  \\n and manipulate it and process it is really pretty easy.  \\n And to learn more about the JSON  \\n handling features of Python,  \\n you should check out the documentation  \\n for the JSON Library here on the Python website.  \\n And while you're at it,  \\n I would suggest taking some time to experiment further  \\n with this example,  \\n and maybe try some of the other properties  \\n that we haven't touched on.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3023365\",\"duration\":554,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Parsing and processing HTML\",\"fileName\":\"2896241_en_US_05_03_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to work with HTML content in a Python program.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":23746702,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Python provides a built-in way  \\n for parsing structured data, such as HTML,  \\n as well as other kinds of data like we just saw previously  \\n with Jason.  \\n In this example, we're going to see how to create  \\n our own HTML parser  \\n based on the HTML parser class that Python provides.  \\n So let's go ahead and open HTML parsing underscore start,  \\n and you can see that what I've done here  \\n is I've already created my main function  \\n and I've got a variable called parser  \\n and I'm instantiating a my HTML parser class  \\n and I've created the starting point for that class up here  \\n which we will fill out with our logic.  \\n I've also imported the HTML parser class that we need  \\n from the HTML parser module  \\n and I'm creating a subclass of the existing  \\n HTML parser class that we've imported.  \\n And we'll come back to this in a moment.  \\n So in the main function,  \\n I already have the code needed to open an HTML file  \\n and parse it.  \\n Now I could have just used URL lib to open a URL  \\n and read the HTML data straight from the web.  \\n In this case, I'm going to just simply open up a sample file  \\n that we have right here called sample HTML.  \\n And we've already seen how to do this in the files chapter  \\n earlier in the course.  \\n And if we look at this file for a moment,  \\n we can see it's a pretty basic HTML file.  \\n There's a head and a body.  \\n In the head we've got a title tag  \\n and we've got some paragraph tags and the comment.  \\n So it's just a skeleton HTML file that we're going to use  \\n to test out the parser.  \\n So once the file has been read into memory,  \\n we're going to pass the contents of the file  \\n to our parser class.  \\n And our parser class has this function called feed  \\n and we're going to pass in the string  \\n that represents the entire HTML  \\n and the parser is going to work on it.  \\n So when you pass the HTML content to this feed function,  \\n it's going to take the HTML and run through it line by line.  \\n And each time it encounters a specific kind of data  \\n inside the HTML,  \\n my comments or tags or whatever  \\n the parser is going to call functions that you override  \\n in your subclass.  \\n That's these functions here.  \\n So you don't call these functions directly.  \\n The parser is going to call them for you  \\n as it is processing the HTML  \\n and then your code just responds to the type of data  \\n that's being processed.  \\n So in this case, for example,  \\n when the parser comes across a comment,  \\n it's going to call my handle comment method  \\n and it's going to pass the text data  \\n that's inside the comment.  \\n So let's go ahead and fill out this function.  \\n What we're going to do is write out that we  \\n encountered a comment and we'll print the data  \\n inside the comment  \\n and then I'm going to have a variable called pos,  \\n and I'm going to call the get pos function on the parser  \\n and this function will come back with two values.  \\n The line number and the character position  \\n that the parser was at when it came across this data.  \\n So then we'll also print that out as well.  \\n We'll simply print at line  \\n and it's going to be pos zero for the line  \\n and the character position which is going to be  \\n pos of one.  \\n So let's go ahead and save what we have right now  \\n and let's run it.  \\n So if we look back in the HTML file,  \\n we can see that there's only one comment and it says,  \\n this is a comment inside.  \\n So that's what we should see in the output.  \\n So let's go ahead and right click and run this.  \\n And sure enough, there's our output.  \\n It says, encountered a comment.  \\n There's the text data at line seven position four.  \\n Is that right? Yeah.  \\n Line seven. Yep.  \\n And indented by four spaces.  \\n Okay. So far so good.  \\n All right, let's go ahead and close that terminal  \\n and let's go ahead and fill out the rest of our functions.  \\n So let's go ahead and fill out handle data  \\n because it's basically the same as the one for comments.  \\n So I'll just simply copy this code right here  \\n and paste it down in handle data  \\n and I'll just simply encountered text data  \\n instead of comment.  \\n So the only difference here is that  \\n we only want to print actual text content  \\n and skip over white space lines.  \\n And I'll use Python to make sure that the string  \\n doesn't just consist of entirely white space  \\n by using the is space function.  \\n So what I'll do is I'll write if data dot is space,  \\n then I'll just simply return.  \\n So we won't print out just white space.  \\n All right. So that just leaves the handle start tag function  \\n and this function gets called when the closing angle bracket  \\n of an opening tag is reached.  \\n So for example, if we look inside the HTML,  \\n when the parser gets to say  \\n this closing angle bracket, right  \\n on this whole tag,  \\n that's when the start tag function will be called  \\n because it's the starting tag.  \\n Down here we have the closing HTML tag  \\n and up here we have the starting one.  \\n So right when it reaches this angle bracket,  \\n it's going to call that.  \\n Then start tags can have attributes on them,  \\n which we can see right here.  \\n This one has a language attribute.  \\n This anchor tag has an H ref attribute  \\n and they get passed into the attrs argument  \\n here on the function.  \\n So let's go ahead and fill in the code for this function.  \\n And it starts out just the same as the others.  \\n So I'll go ahead and print those lines.  \\n So I'll copy and paste those lines here  \\n and I'll just change comment  \\n to encounter the start tag instead  \\n and instead of data we have tag.  \\n Okay. And the position will remain the same  \\n but there's two things I want to do in addition.  \\n So for example, let's suppose I wanted to count  \\n the total number of paragraph tags in the file.  \\n So I'm going to make a global variable  \\n and again, there's plenty of ways to do this.  \\n I'll just demonstrate it this way.  \\n So I'll make a global variable called paragraphs  \\n and I'll initialize that to zero.  \\n And then in my code to handle the start tag,  \\n what I'm going to do is I'm going to write  \\n that there's a global variable named paragraphs.  \\n And then I'm going to check to see if the tag argument  \\n is equal to the letter P.  \\n Because again, looking at HTML,  \\n there's paragraph tags right here.  \\n So I want to count those.  \\n So if the tag name is P,  \\n then I'm going to increment paragraphs by one.  \\n And then I just need to print the results down here  \\n in the main function  \\n so I'll write out print and I'll say paragraph tags  \\n and I'll print out paragraphs.  \\n Okay. The other thing I wanted to do is print out  \\n any attributes that a tag has on it.  \\n And remember in HTML only start tags can have attributes.  \\n So the attributes are passed in this attrs array here.  \\n So I just need to check to see if there are any attributes  \\n by checking the length of that collection  \\n and then printing them out if there are any.  \\n So if the length of attrs  \\n is greater than zero, then I'm going to print out  \\n attributes and then I'm going to loop over each one.  \\n So for A in the attrs list,  \\n I'm going to print and I'll indent by a tab  \\n and I'm going to print out the attribute name  \\n which is going to be the zero position of that element,  \\n separated by an equal sign  \\n and then the second member of that array  \\n and that's going to be the value.  \\n So in this case,  \\n we're going to see lang equals E N and then we'll see  \\n H ref equals slash contact.  \\n Assuming our code works, of course.  \\n So let's save all of this and then let's run the app  \\n one more time.  \\n And so here in the output, let's take a look.  \\n So we can see starting at the top, right.  \\n So the HTML tag comes first  \\n and that's at line two position zero.  \\n And we can see that there are attributes and sure enough  \\n there's the lang equals E N  \\n and then there's the head and the title.  \\n And then inside the title, we have the text data, right?  \\n And there's our comment from before.  \\n And so we skip on down and we can see that  \\n all the way at the end we counted two paragraph tags.  \\n Well, is that right?  \\n Yes. There's two paragraph tags.  \\n Okay. So it looks like everything worked properly.  \\n So this is a basic example of using Python  \\n to process HTML by building your own HTML parser subclass  \\n based on the HTML parser class provided by  \\n the Python standard library.  \\n Maybe take a few minutes here and play around with this.  \\n Try out some different things on your own,  \\n experiment and learn more about how the parser class works.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3021796\",\"duration\":402,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Manipulating XML\",\"fileName\":\"2896241_en_US_05_04_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, learn how to load and parse XML data into Python structures.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":17174300,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Sometimes when you're processing markup like XML or HTML,  \\n you don't want to build a parser that just runs  \\n through the document one line at a time.  \\n What you'll need to do is have the entire document  \\n in memory so you can manipulate it.  \\n In other words, you'll operate  \\n on the Documents Object Model or DOM.  \\n In this example,  \\n we'll see how to use the XML Mini DOM class  \\n that Python provides to load an XML file  \\n and then operate on the document while it's in memory.  \\n So let's open up the XML parsing start file.  \\n And the first thing I'm going to do is import the module  \\n that let's me operate on an XML DOM.  \\n So I'm going to import xml.dom.minidom,  \\n and the XML file I'm going to be parsing  \\n is this one right here.  \\n This is sample XML  \\n and if you open it up and look at it,  \\n you can see it's a pretty standard XML file.  \\n It's just got some basic information about a person in it.  \\n So here's my name, where I live, some skills that I have,  \\n again, just simple XML file for demonstrating parsing.  \\n So let's go back to the code.  \\n So in my main function,  \\n I'm going to use the parse function  \\n on the XML mini DOM to load and parse the file.  \\n So I'll make a variable called, doc  \\n and I'll call xml.dom.minidom.parse,  \\n and to the parts function  \\n I'm going to parse that file  \\n samplexml.xml  \\n So this will parse the XML file  \\n and create an in-memory DOM object that I can manipulate.  \\n And because the name of the file that I want to parse  \\n happens to be in the same directory as my code,  \\n I don't have to do any fancy path manipulation.  \\n So once we've parsed the document,  \\n let's print out the name of the root of the document.  \\n So that's going to be Node name on the document element  \\n along with the tag name of the first child of the document.  \\n So there'll be doc.firstchild.tagname.  \\n Now, if these property names don't look familiar to you,  \\n there are standard names that are used  \\n in the Document Object Model,  \\n things like no name and first child and tag name,  \\n these are all standard properties of DOM elements.  \\n So let's just save and run what we have.  \\n And you can see that the node name of the doc  \\n is #document,  \\n which is just like the W3C specs as it should be.  \\n And the first child tag in the document,  \\n the tag name of that is person.  \\n And if you look sure enough,  \\n that's the first tag that's in the document.  \\n So, so far we're off to a good start.  \\n So let's go ahead and close this terminal.  \\n So now we're going to get a list of XML tags  \\n from the document and print each one.  \\n So I'm going to use the DOM standard function  \\n called get elements by tag name.  \\n So I'll name this variable skills  \\n and I'll call doc.getelementsbytagname.  \\n And I'm going to get all the skill tags.  \\n And again, if you look at the XML,  \\n that's going to be these tags right here.  \\n So I'll get all of those skill tags  \\n and then I'm going to print out.  \\n Let's see I'll print out skills.length  \\n skills are listed.  \\n All right, and then I'll print out  \\n each one of the skills.  \\n So, all right, for skill in skills,  \\n let's print out,  \\n skill.getattribute and I'm going to get the name attribute.  \\n So again, if we go back to the XML,  \\n you can see that each one of these skill tags  \\n has a name attribute and it has a value.  \\n So I'm going to loop over each one of the skills tags,  \\n get the attribute called name and print out its value.  \\n All right.  \\n So let's go ahead and save this  \\n and then let's run it.  \\n All right. So there's four skills listed.  \\n So that seems to be working  \\n and there they are JavaScript, Python, C-sharp  \\n and HTML, okay.  \\n So it looks like, again, everything seems to be working.  \\n Let's close this terminal.  \\n So let's do one more thing,  \\n let's create a new XML tag and add it into the document.  \\n So I'll create a new tag  \\n and I'll have a variable called new skill.  \\n And I'm going to call the create element  \\n function on the document.  \\n And I'm going to create a new skill element.  \\n And on that new skill,  \\n I'm going to call set attribute,  \\n and I'm going to set the name attribute  \\n to another skill that I have, let's do jQuery.  \\n And then I'm going to to tell the document  \\n to tell it's first child element,  \\n that's the person tag to append a new child  \\n inside of itself,  \\n and that's going to be my new skill tag.  \\n So create element is a standard W3C function,  \\n which creates a new tag.  \\n And then I'm creating that new tag.  \\n And then I'm sending the, the name attribute to be jQuery.  \\n And then I'm going to append this new skill tag  \\n into the first child of the document,  \\n which remember is this person tag.  \\n So the new skill tag is going to appear  \\n in the document below this one.  \\n And then we'll print out a listing of the skills  \\n before the new one is added.  \\n And then we'll print out the list  \\n after it's added to make sure everything worked.  \\n So let's do this again.  \\n So I'm going to copy this, paste this down here.  \\n So let's go ahead and save and let's run.  \\n All right.  \\n so we can see that there's four skills listed, right?  \\n So JavaScript, Python, C-sharp, HTML.  \\n And then I add the new tag and you know I made a mistake.  \\n I have to actually get the elements by tag name again.  \\n So let's also copy those two lines and paste them there.  \\n All right. So now let's go ahead and run this again.  \\n All right.  \\n Okay. So now we see that this time it worked.  \\n So we linked a little bit bigger.  \\n We see that there's four skills listed  \\n and then there's five skills listed  \\n because jQuery has now been added at the bottom.  \\n So that should give you an idea  \\n of how you can use the DOM and Python  \\n to manipulate structured markup, like XML in memory.  \\n \\n\\n\"}],\"name\":\"5. Internet Data Formats\",\"size\":78142521,\"urn\":\"urn:li:learningContentChapter:3018972\"},{\"duration\":94,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3022808\",\"duration\":94,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Where to go next\",\"fileName\":\"2896241_en_US_06_01_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2534654,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - All right.  \\n Well, that brings us to the conclusion of Learning Python.  \\n If you like what you've seen in this course,  \\n and you think that Python might be a good fit  \\n for projects that you're working on,  \\n there are a few places you can go next from here.  \\n So one of the best features of Python  \\n is the rich standard library of built in modules  \\n that provide a wide range of features and capabilities  \\n that you can use in your programs.  \\n To learn more about these modules,  \\n check out the Python Standard Library  \\n Essential Training Course.  \\n During this course, we saw how to use Python  \\n to access information over the internet  \\n and process data formats like JSON and XML.  \\n To go even deeper into this subject,  \\n check out the course, Python, XML, JSON, and the web.  \\n In addition to the built-in libraries  \\n that you can use in your apps,  \\n there are some really great  \\n third-party libraries available as well.  \\n The course Python Essential Libraries  \\n takes a look at some of the best  \\n and most commonly used third party modules  \\n that are out there today.  \\n Python is a very capable  \\n object oriented programming language,  \\n and we looked at some of the object oriented features  \\n in this course.  \\n If you want to learn even more  \\n about how to build great object oriented programs,  \\n then consider watching  \\n the Python Object-Oriented Programming course.  \\n And finally,  \\n if you want to take your Python skills to the next level,  \\n consider watching the Advanced Python course.  \\n Also, be sure to stay up to date with Python  \\n and learn more about the features provided by the language  \\n here at python.org.  \\n Here you'll find comprehensive documentation  \\n on all the features I showed in this course,  \\n along with some of the ones I didn't get to.  \\n Thanks again for watching, and, as always, happy coding.  \\n \\n\\n\"}],\"name\":\"Conclusion\",\"size\":3011767,\"urn\":\"urn:li:learningContentChapter:3019947\"},{\"duration\":0,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:3023362\",\"duration\":51,\"visible\":false,\"requiredForCertificateOfCompletion\":null,\"name\":\"Learning Python\",\"fileName\":\"2896241_en_US_00_01_WX30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3015640,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] The Python programming language  \\n has become one of the most popular languages in the world,  \\n and it's not hard to see why this has happened.  \\n Python has an easy-to-learn structure.  \\n It runs on multiple operating systems,  \\n both on the client and the cloud,  \\n and it has a vast ecosystem of tools and libraries  \\n that address a large number of programming scenarios.  \\n Hi, I'm Joe Marini and I've been building software  \\n professionally for some of the biggest and best known  \\n companies in Silicon valley  \\n for more than 30 years.  \\n In this course,  \\n you will get a hands-on introduction  \\n to the Python programming language.  \\n We'll start off by learning how to determine  \\n if Python is installed on your system  \\n and how to install it  \\n if it isn't already there.  \\n Next, we'll see how to build our first Python program  \\n in just a few lines of code.  \\n Then we'll examine the basics of the language, data types,  \\n variables, loops, functions, classes, and more.  \\n We'll move on to working  \\n with some of Python's built in high-level data types,  \\n such as dates, times,  \\n and files and directories.  \\n And finally, we'll wrap up  \\n by taking advantage of Python's extensive library  \\n of pre-built modules to build advanced features  \\n like retrieving data from the internet  \\n and processing information such as HTML, XML, and JSON.  \\n If you're ready to start building the next generation  \\n of cross-platform applications  \\n that run on the client as well as the cloud,  \\n then let's get started learning Python.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3020815\",\"duration\":152,\"visible\":false,\"requiredForCertificateOfCompletion\":null,\"name\":\"Challenge: Palindromes\",\"fileName\":\"2896241_en_US_02_09_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5731938,\"solution\":false,\"welcomeContent\":null,\"challenge\":true,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (electronic music)  \\n - [Instructor] Okay,,  \\n It's time to take what we've learned in the chapter  \\n and do a programming challenge.  \\n For this challenge,  \\n we're going to create a program  \\n that detects whether a string of characters is a palindrome.  \\n And a palindrome is a string that reads the same way,  \\n both forward and backward,  \\n minus any white space or punctuation.  \\n So I'm going to run the finished program  \\n right here in the terminal.  \\n And when I run it,  \\n it's going to become clear what you need to build  \\n for this challenge.  \\n So the program starts by asking for  \\n these strings to test for a palindrome,  \\n or the word exit to stop the program.  \\n And I'm going to enter the word radar,  \\n with a capital R,  \\n and you can see that the palindrome test  \\n is true and notice that the program ignores  \\n upper and lowercase letters.  \\n And radar is a palindrome  \\n because the word reads the same,  \\n both backward and forward,  \\n and I'm prompted for the next string.  \\n And I'll just keep doing this until I enter the word exit.  \\n So I can enter a string that has multiple words in it  \\n with spaces and punctuation.  \\n So I'll type Madam comma  \\n and then I'm Adam period,  \\n and then I'll hit return.  \\n And once again,  \\n you can see that this is a palindrome  \\n because once you strip off all the punctuation  \\n and the spaces,  \\n it reads the same forward and backwards.  \\n This also works with numbers.  \\n So if I type it in  \\n 1, 2, 3, 3, 2, 1,  \\n you can see that's also a palindrome.  \\n And just to make sure that this works correctly,  \\n I'll type in something that we know is not a palindrome.  \\n So I'll type in hello world  \\n and sure enough,  \\n the palindrome test returns false.  \\n Okay, so here's your challenge.  \\n You're going to build a program  \\n that accepts a string from the user  \\n and quits when the user types the word exit.  \\n Otherwise the program is going to take the input string  \\n and determine if it is the same  \\n both forward and backward.  \\n The program should ignore spaces and punctuation characters  \\n and print the result indicating whether the string  \\n is a palindrome.  \\n Okay, so that should be enough to get you started,  \\n but if you want to stick around for a moment,  \\n I'll give you a hint, okay?  \\n If you don't want the hint,  \\n then go ahead and stop the video now  \\n and get started on the challenge, okay?  \\n Okay, you ready for the hint?  \\n All right, it's your last chance.  \\n Okay, here's the hint:  \\n in order to determine if a specific character  \\n is a letter or a number,  \\n you can use this built-in function  \\n isalnumb and it works on strings.  \\n So this function will return true  \\n if all of the characters in the string are alphanumeric,  \\n okay?  \\n So I hope that helps.  \\n And I'll be back in the next video to review my solution.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3019941\",\"duration\":157,\"visible\":false,\"requiredForCertificateOfCompletion\":null,\"name\":\"Solution: Palindromes\",\"fileName\":\"2896241_en_US_02_10_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4929599,\"solution\":true,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (upbeat music)  \\n - [Instructor] Okay, so how did you do with this challenge?  \\n This was a bit of a tricky one.  \\n So let's walk through my solution  \\n and you can compare it to yours.  \\n And don't worry if your solution isn't the same as mine.  \\n All right, so let's open a code.  \\n So in my solution, I defined a function named is_palindrome,  \\n and we'll actually come back to that in just a moment.  \\n So my program's code uses a while loop  \\n to keep the program running  \\n as long as this run variable is true.  \\n So first the user is prompted to enter the string to test.  \\n And if the user enters the word exit,  \\n then the program exits by setting run to false  \\n and then breaking out of the loop.  \\n Next, I convert the string that the user entered  \\n to all lowercase so that I don't have to worry about  \\n comparing upper and lowercase letters.  \\n Then I need to strip out all of the white space  \\n and non-alphanumeric characters from the string.  \\n So I declare a new string variable,  \\n and then I loop over all the characters  \\n in the user supplied string.  \\n And then I use the isalnumb function  \\n to see if the character is alphanumeric.  \\n And if it is, then I add it to the new string.  \\n So at this point I have a string that is all lowercase  \\n and only contains letters and numbers.  \\n And then this is the string  \\n that I pass to the is_palindrome function.  \\n All right, so now I need to see if the string is the same,  \\n both forward and backward,  \\n and there are a number of ways you could do this.  \\n So one way would be to have two index variables  \\n that start at the beginning and end of the string.  \\n And then you work your way towards the middle  \\n comparing each character.  \\n The technique that I'm using here  \\n is called the slicing trick.  \\n So you use this special slice notation  \\n to reverse the string in place.  \\n So I compare the original string to the string  \\n after it's been reversed and if they are the same,  \\n then we know it's a palindrome.  \\n But like I said, there's multiple ways to do this.  \\n So how does my solution compare with yours?  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3019943\",\"duration\":167,\"visible\":false,\"requiredForCertificateOfCompletion\":null,\"name\":\"Challenge: Files\",\"fileName\":\"2896241_en_US_03_04_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6694362,\"solution\":false,\"welcomeContent\":null,\"challenge\":true,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (upbeat instrumental music)  \\n - [Instructor] Let's take what we've learned  \\n about working with files,  \\n and try out another programming challenge.  \\n In this challenge,  \\n you're going to create a program  \\n that creates a new directory,  \\n creates a text file within that directory,  \\n and writes into that file the listing  \\n of all the files in the current directory,  \\n along with the total byte count  \\n of all those files.  \\n So I'm going to run my finished code here  \\n so we can see what the results look like.  \\n So I'll go ahead and run my solution.  \\n And you can see that when I run the program  \\n over here in the File Explorer sidebar,  \\n there's a folder now called results.  \\n And inside that directory,  \\n there is a file called results.txt  \\n And if I open that file,  \\n you can see that at the top of the file  \\n is the total byte count  \\n of all the files in the directory,  \\n along with a listing of the files  \\n inside that directory.  \\n So here's all the Python code  \\n for the chapter that we've done,  \\n and the text file,  \\n that txt file that we worked on earlier.  \\n And by the way,  \\n your code should only count files.  \\n So let me go ahead and delete this folder.  \\n (button clicking)  \\n And what I'm going to do  \\n is make a temporary folder in here.  \\n I'll choose new folder and just name it, blah.  \\n So now I'm going to run my code again.  \\n (button clicking)  \\n All right.  \\n let's open the file,  \\n and you can see that there's no entry  \\n in this file for the blah directory, right?  \\n It's just skipped over.  \\n So your code should skip over any directories,  \\n and only process files.  \\n Okay.  \\n So that's the challenge.  \\n Your coach should list the files  \\n in the directory,  \\n count their bite size,  \\n and then make a total of all the bytes.  \\n Create a results folder  \\n with a results.txt file in it  \\n that lists the total byte count of all the files,  \\n and lists each file name.  \\n Now, if you don't want an extra hint,  \\n then you can stop the video now,  \\n and get started on the challenge,  \\n and I'll review my solution in the next video.  \\n If you want a hint,  \\n then stay with me for a few moments.  \\n Okay.  \\n Are you sure you want the hint?  \\n Really?  \\n Last chance.  \\n All right.  \\n The hint is that you're going to need  \\n to use the mkdir function in the OS module  \\n to create a directory.  \\n And you'll also need to use  \\n if I scroll up a little bit,  \\n the listdir function  \\n to list the contents of a given directory.  \\n Okay.  \\n So I hope that hint helps out a little bit.  \\n Go ahead,  \\n try the challenge,  \\n and then I'll review my solution next.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3017846\",\"duration\":135,\"visible\":false,\"requiredForCertificateOfCompletion\":null,\"name\":\"Solution: Files\",\"fileName\":\"2896241_en_US_03_05_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4378216,\"solution\":true,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (upbeat music)  \\n - [Instructor] Alright.  \\n Let's review the solution that I came up with  \\n for this particular challenge.  \\n So opened my code, and this is the solution code right here.  \\n So in order to work with directories in this challenge,  \\n I need the code that's available in the OS module.  \\n So I import that first here at the top of the file,  \\n then I create a variable named total bytes  \\n and initialize it to zero.  \\n And this is the variable that will hold  \\n the total byte counts  \\n of all the files in the directory.  \\n I then use the listdir function available in the OS module  \\n to get a list of all the files  \\n that are in the current directory  \\n and to just use the current directory,  \\n I don't need to pass any arguments.  \\n So just call this dir by itself.  \\n Alright?  \\n So then I have a loop and the loop processes each entry  \\n in the directory list.  \\n So I use the IS file function in the OS path class  \\n to make sure that I'm working with a file  \\n and not a directory.  \\n So if it is indeed a file,  \\n I call the get size function again in the OS path class  \\n and add the file size to the total byte count.  \\n Then I use the mikdir function to create the directory  \\n named results.  \\n Then I use the built-in open function  \\n to create the results.txt file  \\n inside the results directory.  \\n I then check to make sure the file mode is a W+  \\n to make sure that the file was opened for writing correctly.  \\n So then I write out the total byte count  \\n that I've collected so far,  \\n followed by a header for the files list.  \\n Then I once again,  \\n loop over each entry in the directory list.  \\n And again, I check to make sure that it's a file.  \\n And if it's actually a file,  \\n I write the name of the file out to the results file.  \\n And then when all that's finished,  \\n I call the close function on the results file.  \\n All right.  \\n So how does my solution compare to yours?  \\n Do you see any opportunities  \\n to maybe make it more efficient?  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3022807\",\"duration\":185,\"visible\":false,\"requiredForCertificateOfCompletion\":null,\"name\":\"Challenge: Dates and times\",\"fileName\":\"2896241_en_US_04_05_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5655209,\"solution\":false,\"welcomeContent\":null,\"challenge\":true,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (upbeat music)  \\n - [Narrator] All right, let's take what we've learned  \\n about dates and times and try out a programming challenge.  \\n So in this challenge, we're going to create a program  \\n that counts the number of a specific weekday  \\n during a given month and year.  \\n So in other words, the program will be able  \\n to count the number of Sundays,  \\n for example, in a specific year and month.  \\n So let's take a look at the finished program  \\n to see how it's going to work.  \\n So here in VS Code,  \\n I'm going to right-click on the challenge_solution file  \\n and choose run Python file in terminal.  \\n And remember, if you're not using VS Code,  \\n then you can just run this finished program  \\n like we saw how to do earlier in the course.  \\n So when I run the program,  \\n we're presented with a list of options  \\n for which day to count,  \\n or I can type exit to quit the program.  \\n So for example, let's go ahead and choose six for Sunday,  \\n and then I'll enter the year and I'll choose 2030  \\n and then the month, and I'll use 12 for December,  \\n and you can see,  \\n let me scroll up a little bit there.  \\n All right, when I enter the month and the year,  \\n then I get the result back and you can see  \\n that there are five Sundays in December of 2030.  \\n All right, and then the program repeats again.  \\n So let's go ahead and try this again with Thursdays.  \\n So Thursdays are three, so I'll type in three,  \\n and once again, I'll do 2030 and 12.  \\n And let me just make this a little bit bigger  \\n so we can see it.  \\n You can see that in 2030, in December 2030,  \\n and I entered three for Thursday,  \\n there are four Thursdays in the month and year specified.  \\n Okay, so your challenge is to write a program  \\n that counts the number of a certain weekday  \\n in the month and year that the user enters,  \\n and I'll give you a hint.  \\n And actually before I do the hint,  \\n let me also show you a couple of other things.  \\n If I enter something that's not valid input,  \\n like let's say it asked me the day of the week  \\n and I type in something like a,  \\n you can see that I'm getting an error here, right?  \\n And it says, \\\"Oh, sorry, that's not valid input,\\\"  \\n and then it asks me to do this again.  \\n So then I'll type in, say Tuesday,  \\n which is the number one,  \\n and then if I type in something that's not a valid year,  \\n you can see that, once again,  \\n I'm getting this error and then it goes back  \\n to the menu again.  \\n So you're going to have to find a way  \\n to handle those errors, and we saw how to do that  \\n earlier in the course.  \\n I'm going to give you a hint, okay?  \\n Now if you want the hint,  \\n then stay with me for a few seconds,  \\n and if you don't want the hint,  \\n then go ahead and stop the video here  \\n and get started on the challenge, okay?  \\n All right, do you want the hint?  \\n Okay, are you sure you want the hint?  \\n All right, the hint is that you'll need to take a look  \\n at the documentation for the month calendar class  \\n that we saw earlier in the chapter.  \\n So that's your hint.  \\n Go ahead and give that a try and I'll be back  \\n in the next video to discuss my solution.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:3021794\",\"duration\":173,\"visible\":false,\"requiredForCertificateOfCompletion\":null,\"name\":\"Solution:  Dates and times\",\"fileName\":\"2896241_en_US_04_06_XR30\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5459251,\"solution\":true,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (upbeat music playing)  \\n - Okay. Let's review the solution  \\n that I built for this challenge.  \\n And remember what's important here,  \\n is not that you get the same answer or code as I do.  \\n There's usually multiple ways  \\n of solving any given programming challenge.  \\n So the point of this,  \\n is for you to compare my solution to yours,  \\n and see how they're same and how they're different.  \\n All right.  \\n Okay. And let's go ahead  \\n and skip over this count days function for just a moment.  \\n So the main part of my program  \\n is this while loop right here,  \\n which is set to execute,  \\n as long as this run variable is true.  \\n So what I'm doing is,  \\n I'm using exception handling  \\n to deal with any errors that might happen.  \\n So my code is inside this try section.  \\n And remember we learned about exceptions  \\n back earlier in the course, in the basics chapter.  \\n So first the program prints the menu of options,  \\n listing the days to be counted or the exit option,  \\n and then the user enters their choice  \\n with this input statement.  \\n So if the user enters the word exit,  \\n the program stops by setting the run variable to false,  \\n and then breaking out of the while loop.  \\n Otherwise, I try to convert the user's choice,  \\n from a string to an integer number.  \\n Now, that might cause a value error.  \\n And if it does,  \\n then that's what the exception handlers right here,  \\n You can see I print out,  \\n \\\"sorry that's not valid input\\\".  \\n And then the whole process repeats again.  \\n Now, if that doesn't cause an error,  \\n then I ask for the year,  \\n and ask for the month.  \\n And if the user types in again, valid integers,  \\n then the count days function is called.  \\n And that is called with the year,  \\n month and day that the user entered.  \\n Otherwise, there must have been an error,  \\n and then the program will print this message,  \\n and start the loop all over again.  \\n So now let's go back  \\n and take a look at the count days function,  \\n because that's the real need  \\n of this solution right here.  \\n So the count days function uses the month calendar,  \\n to retrieve a list of weeks for the given year and month.  \\n So then for each one of the weeks in that list,  \\n the code checks to see if the value  \\n for the given day index that we are counting is not zero.  \\n And so remember the which day parameter  \\n is the integer index of the day that we're counting right.  \\n Zero for Monday, one for Tuesday and so on.  \\n So when the function returns,  \\n we print out the number of days within the month.  \\n Because this function is going to count,  \\n each one of those days for each one of those weeks.  \\n And then the return right here,  \\n is going to give us our result back,  \\n and then we print out the result.  \\n All right. So how does this compare to your solution?  \\n Did you remember to use exception handling  \\n to make sure the user entered valid data?  \\n Take some time to compare your code with mine,  \\n and try out some different ways of approaching the problem.  \\n \\n\\n\"}],\"name\":\"DEPRECATED\",\"size\":0,\"urn\":\"urn:li:learningContentChapter:4517059\"}],\"size\":442696887,\"duration\":11142,\"zeroBased\":false},{\"course_title\":\"Python Data Analysis (2020)\",\"course_admin_id\":2825705,\"metadata\":{\"Locale\":\"en_US\",\"Course ID\":2825705,\"Project ID\":null,\"Course Name\":\"Python Data Analysis (2020)\",\"Course Name EN\":\"Python Data Analysis (2020)\",\"Activation Status\":\"ACTIVE\",\"Display to Public\":\"Yes\",\"Display to QA\":\"No\",\"Course Description\":\"&lt;p&gt;Data science is transforming the way that government and industry leaders look at both specific problems and the world at large. Curious about how data analysis actually works in practice? In this course, instructor Michele Vallisneri shows you how, explaining what it takes to get started with data science using Python.&lt;/p&gt;&lt;p&gt;Michele demonstrates how to set up your analysis environment and provides a refresher on the basics of working with data structures in Python. Then, he jumps into the big stuff: the power of arrays, indexing, and tables in NumPy and pandas\u2014two popular third-party packages designed specifically for data analysis. He also walks through two sample big-data projects: using NumPy to identify and visualize weather patterns and using pandas to analyze the popularity of baby names over the last century. Challenges issued along the way help you practice what you've learned.&lt;/p&gt;&lt;p&gt;Note: This version of the course was updated to reflect recent changes in Python 3, NumPy, and pandas.&lt;/p&gt;&lt;p&gt;This course is part of a &lt;a href=https://www.linkedin.com/learning/paths/anaconda-python-for-data-science-professional-certificate target=_blank&gt;Professional Certificate&lt;/a&gt; from Anaconda.&lt;/p&gt;\",\"Course Short Description\":\"Interested in using Python for data analysis? Learn how to use Python, NumPy, and pandas together to analyze data sets large and small.\",\"Content Type\":\"TOOLS\",\"Localization Type\":\"ORIGINAL\",\"Original Course Locale\":null,\"Original Course ID\":null,\"Equivalent English Course\":null,\"Instructor ID\":\"4666188\",\"Instructor Name\":\"Michele Vallisneri\",\"Instructor Transliterated Name\":null,\"Instructor Short Bio\":\"Professor of Gravitational Physics at the Swiss Federal Institute of Technology\",\"Author Payment Category\":\"NON-LICENSED\",\"Delivery Mode\":\"ALL_AT_ONCE\",\"Series End Date\":null,\"Course Release Date\":\"2020-03-11\",\"Course Updated Date\":null,\"Course Archive Date\":null,\"Course Retire Date\":null,\"Replacement Course\":null,\"Has Assessment\":\"Yes\",\"Has Challenge/Solution\":\"Yes\",\"LIL URL\":\"https://www.linkedin.com/learning/python-data-analysis-2020,https://www.linkedin.com/learning/python-data-analysis-2,https://www.linkedin.com/learning/python-data-analysis-2020-revision\",\"Series\":\"Deep Dive (X:Y)\",\"Limited Series\":null,\"Manager Level\":\"General\",\"LI Level\":\"Intermediate\",\"LI Level EN\":\"Intermediate\",\"Sensitivity\":null,\"Internal Library\":\"Technology\",\"Internal Subject\":\"Data Science\",\"Primary Software\":\"Python\",\"Media Type\":\"Video\",\"Has CEU\":\"Yes\",\"Has Exercise Files\":\"Yes\",\"Visible Duration\":9035.0,\"Visible Video Count\":41.0,\"Learning Objectives\":\"Describe how to install and start Python, and load necessary libraries.,Explain examples of uses for lists and ranges in Python.,Explain string processing methods in Python.,Describe the characteristics and specifications of NumPy arrays.,Explain examples of uses for NumPy methods in generating and analyzing data.,Use matplotlib to create xy plots.,Describe the characteristics and specifications of DataFrames in pandas.\",\"Contract Type\":\"PERPETUAL\",\"Certifications\":\"CPE:National Association of State Boards of Accountancy (NASBA)::Information Technology\",\"Framework Topic\":null,\"Automatic Caption Translations\":\"Global Captions\",\"Automatic Metadata Translations\":\"Global Metadata\",\"Gen AI Feature Flag\":null,\"Hands-On Practice\":null,\"Hands-On Practice Library\":null,\"Unlocked for Viva Learning\":\"Global Captions\",\"Free Course\":null,\"Certification Library\":\"Certifications\",\"Github Codespace\":null,\"Skills Count\":2,\"Skills\":\"Data Analysis,Python (Programming Language)\",\"Skills EN\":\"Data Analysis,Python (Programming Language)\",\"Content Manager\":\"Steve Weiss\",\"Acquisition Manager\":\"Steve Weiss\",\"Framework Subject\":null},\"sections\":[{\"duration\":185,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2293496\",\"duration\":120,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Get started in data analysis with Python\",\"fileName\":\"2825705_00_01_WL30_Welcome\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Using Python, you can analyze data rapidly, using powerful tools adopted by a large and helpful community.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":23028870,\"solution\":false,\"welcomeContent\":true,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Data science, it powers so much of modern life,  \\n the internet, social media, artificial intelligence.  \\n But also on a personal level, the statistics  \\n from your Fitbit or the next song recommended by Pandora.  \\n And, truly, data science is driving a personal  \\n and social evolution.  \\n We're constantly learning and getting better  \\n and accomplishing monumental goals.  \\n However, do you feel like you're missing the boat?  \\n Maybe you're watching all these advances,  \\n but you don't really know how to get in the game.  \\n And you wonder, \\\"What goes on under the hood?  \\n \\\"How does someone one do data science?\\\"  \\n You don't know where to start.  \\n Do not worry, this is where I can help.  \\n My name is Michele Vallisneri,  \\n and I'm a research scientist at NASA.  \\n I use data science concepts and tools every day  \\n to analyze astronomy datasets,  \\n and my tool of choice is Python.  \\n It's an expressive and pragmatic computer language  \\n that has its own spirit and style.  \\n And it's supported by a diverse and helpful user community.  \\n My goal with this course is to get you started  \\n with data science, and more specifically, data analysis  \\n with Python, in a friendly and approachable way.  \\n It's not all encompassing.  \\n I don't recommend applying for a PhD program  \\n right after this course, but it will get you started,  \\n and I really hope inspired.  \\n That's what matters, and that's what you need,  \\n a jumping off point.  \\n I will take you through the foundations  \\n of doing data analysis with Python.  \\n We will look at the most important programming constructs,  \\n data structures, and third party packages.  \\n With this, you will be able to complete  \\n simple data analysis tasks, and you will be ready  \\n to move on to more advanced topics.  \\n I like to teach by example rather than in the abstract,  \\n so throughout this course, we will write  \\n and execute practical code and analyze real-world data.  \\n So let's enter the friendly but exciting world  \\n of Python data analysis.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2295355\",\"duration\":38,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"What you need to know\",\"fileName\":\"2825705_00_02_LA30_What\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"To learn the most from this course you need an elementary knowledge of the Python language, which you can obtain from other LinkedIn Learning courses. However, in this video, you can review Python's data structures, which are crucial to data analysis.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8474848,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Before getting started with this course,  \\n you want to have a basic working knowledge  \\n of programming in Python.  \\n Although we will review the aspects of the language  \\n that are essential to any data analysis task,  \\n I will not teach you about every feature of Python  \\n that we will meet.  \\n It will also be helpful to have an understanding  \\n of basic mathematical and statistical concepts,  \\n for example logical operations, functions,  \\n averages, minima and maxima.  \\n If you are familiar with these topics I recommend you start  \\n with beginner level Python and statistics courses  \\n in the library or with a textbook  \\n that suits your learning style.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2294373\",\"duration\":27,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"What's new in this update\",\"fileName\":\"2825705_00_03_LA30_New\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Like the original version, this course covers the foundations of data analysis with Python\u2014data structures, NumPy, pandas, matplotlib\u2014using practical real-world examples. The course is updated to reflect recent changes in the interfaces of those modules, to explore new features in recent versions of Python 3, to emphasize insightful visualization, and to introduce pandas with a modern pedagogical approach.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6090412,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - This is a new version of this course  \\n in which I have incorporated user feedback  \\n from many learners like you.  \\n Like the original version  \\n this course covers the foundations  \\n of data analysis with Python,  \\n data structures and the num pi, pandas,  \\n and map log packages  \\n using practical, real world examples.  \\n I have also updated the course  \\n to reflect changes in those modules  \\n and new useful features in recent versions of Python 3.  \\n \\n\\n\"}],\"name\":\"Introduction\",\"size\":37594130,\"urn\":\"urn:li:learningContentChapter:2294386\"},{\"duration\":840,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2295356\",\"duration\":155,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Install Anaconda Python on OS X\",\"fileName\":\"2825705_01_01_XR30_installosx\",\"demo\":true,\"videoCreationMetadata\":null,\"description\":\"Anaconda is a popular Python distribution that includes many useful packages. In this video, learn how to download and install Anaconda on your Mac.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5237373,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] For this course,  \\n we need an up to date installation of Python 3,  \\n and a few third party packages including Jupyter, NumPy,  \\n Pandas, and Matplotlib.  \\n In this video I show you how to install everything you need  \\n on MacOS 10.  \\n If you are a Windows user,  \\n feel free to jump to the next video.  \\n Later I will also show you how to use Python in the cloud  \\n using only your web browser.  \\n If you already use Python on your machine  \\n and you know how to install extra packages, please do so.  \\n Otherwise I suggest you follow me  \\n and install the free Anaconda Python Distribution,  \\n which includes everything that we will need.  \\n To install we go to anaconda.com.  \\n We find the download link at the top.  \\n Scroll down to our platform  \\n and select the Anaconda graphical installer  \\n which is currently at version 3.7.  \\n Any later version will also work fine.  \\n As of January 2020, Python 2 is no longer supported,  \\n so you should definitely be using version three  \\n which is mature, efficient,  \\n and introduces many exciting new features  \\n compared to version two.  \\n Once the download has completed,  \\n we click on the installer  \\n and proceed through a standard installation  \\n which will require several clicks.  \\n We are asked also  \\n whether we wish to install the PyCharm IDE,  \\n which is very complete and powerful.  \\n We will not be using it for this course,  \\n but you can give it a try.  \\n We can trash the installer,  \\n and we can now try out our new python installation,  \\n by opening up a terminal and typing Python.  \\n This gets us into the standard Python shell  \\n where we can write an execute code interactively.  \\n The prompt informs us  \\n that this is indeed the Anaconda version of Python 3.7.  \\n It's traditional to just say hello.  \\n We can also verify that all the packages we need  \\n are already installed by attempting to import them.  \\n NumPy, Pandas, and Matplotlib.  \\n No news is good news.  \\n All done.  \\n We are now ready to start experimenting with Python.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2295357\",\"duration\":172,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Install Anaconda Python on Windows\",\"fileName\":\"2825705_01_02_XR30_installwindows\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Anaconda is a popular Python distribution that includes many useful packages. In this video, learn how to download and install Anaconda on your Windows PC.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4789286,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Narrator] For this course,  \\n we need an up to date installation of python three.  \\n And a few third party packages.  \\n Including jupyter notebook, numpy, pandas,  \\n and matplotlib.  \\n In this video, I show you how to install everything  \\n you need on Windows.  \\n However, you can also experiment with Python in the cloud  \\n from your web browser.  \\n I explain how to do so at the end of this chapter.  \\n If you are already using Python on your machine  \\n and you know how to install extra packages,  \\n you are free to do so.  \\n Otherwise, I suggest you follow me  \\n and install the free Anaconda Python distribution.  \\n Which includes everything that we need.  \\n To install, we go to the anaconda.com website,  \\n we find a download link on the top.  \\n Verify that we have the right platform.  \\n And then download the 64 bit graphical installer.  \\n This is currently at version 3.7,  \\n but any later version will also work fine.  \\n Once the download has completed,  \\n we click on installer and proceed through an installation.  \\n This requires a few clicks.  \\n (mouse clicks)  \\n As of January 2020, Python two is no longer supported.  \\n So you should definitely be using version three.  \\n Which is mature, efficient, and introduces  \\n many exciting new features compared to version two.  \\n The final phase of the installation takes a few minutes.  \\n It looks like the setup is finished,  \\n and we now can get started with Python.  \\n We can now try out our new Python  \\n by opening up the Anaconda prompt,  \\n and typing python.  \\n This gets us into the standard python shell,  \\n where we can write and execute code interactively.  \\n The prompt, informs us that this is indeed  \\n the Anaconda version of Python 3.7  \\n It's traditional to say hello.  \\n We can also verify that all the packages that we need  \\n are already installed by attempt to import them.  \\n Numpy, pandas, and matplotlib.  \\n No news is good news.  \\n All done.  \\n We are now ready to start experimenting with python.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2295358\",\"duration\":251,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Working with Jupyter Notebooks\",\"fileName\":\"2825705_01_03_XR30_jupyter\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Jupyter Notebooks is a very powerful environment for exploratory data analysis. In this video, learn how to open, create, edit, and run Jupyter Notebooks.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6607421,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Narrator] Jupyter notebooks,  \\n offer a very convenient way to write code,  \\n run it, and collect the results including plots,  \\n in a single document.  \\n You can even write formatted text and equations.  \\n This is my favorite way of using Python,  \\n because it lets me experiment with data and code,  \\n document my work, and go back to it later.  \\n You start Jupiter notebook from the Anaconda navigator,  \\n by clicking on launch.  \\n If you don't have an Anaconda,  \\n you can go to a terminal, and type Jupyter notebook.  \\n A web browser opens, and I can choose  \\n if I wish to load an existing notebook from the file system,  \\n or to start a new one,  \\n which I do at the top right of the screen.  \\n New, Python three notebook.  \\n Here's the notebook. See the green box at the top?.  \\n It's a cell. It's ready for me to write some Python,  \\n for instance,  \\n (keyboard typing)  \\n The customary equating.  \\n I execute the code, by pressing Shift + Enter,  \\n or Shift + return depending on your keyboard.  \\n The output is printed immediately below it.  \\n I can click inside the cell,  \\n modify it,  \\n and execute it again, with shift enter.  \\n If a cell has a blue border,  \\n I need to press ENTER before I can edit it.  \\n Or I can click inside a different cell, to edit that one.  \\n In addition to a simple command,  \\n I can write a function over multiple lines.  \\n The editor, will color the Python source keywords,  \\n appropriately.  \\n Again, I execute with Shift + Enter  \\n cells, can also contain text rather than code.  \\n For that, I can use the drop down menu cell,  \\n to change the cell type to markdown.  \\n Then I click in the cell and start writing.  \\n Markdown is a simple but powerful text format  \\n that can do basic formatting, bold, italic,  \\n bullet points, hyperlinks, and even mathematical formulas.  \\n For instance, bold, (keyboard typing), with two asterisks.  \\n (keyboard typing)  \\n URLs, which are recognized,  \\n (keyboard typing)  \\n a bullet point,  \\n and a formula in the LaTeX language, between dollar signs.  \\n When I execute the cell, with shift Enter,  \\n everything is formatted in prettified.  \\n To copy a cell, I can click inside it,  \\n or use the arrow keys to select it, and then press  \\n escape C, to copy and then escape V, to paste.  \\n To cut a cell, I can do escape X  \\n To delete a cell ctrl M, and then D, and again D,  \\n Jupyter wants to be sure  \\n you really want to delete that cell.  \\n Or you can use the menus, of course,  \\n I gave you only the most useful keyboard shortcuts,  \\n but there are many more, look under the Help menu.  \\n The notebook is saved periodically for us,  \\n but I can also do that at any time with command S,  \\n ah, and I can give this notebook a name,  \\n such as learning Jupyter,  \\n by clicking at the top of the window.  \\n Go find the Jupyter notebook documentation,  \\n at Jupiter.org.  \\n You will also learn about Jupyter lab,  \\n and even more powerful,  \\n and complete interface than notebooks.  \\n For this course however, we will stay with Jupyter notebook.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2295359\",\"duration\":92,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Using the exercise files\",\"fileName\":\"2825705_01_04_XR30_exercisefiles\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2371318,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] For most of the videos in this course,  \\n we will be working through one of the Jupyter Notebooks  \\n that I prepare for you.  \\n For each notebook, we will go through the path  \\n and code that it contains.  \\n We will discuss what the code does  \\n and why I wrote it that way.  \\n We will execute it and examine the resulting output.  \\n At any time, you're welcome to pause the video,  \\n inspect the code, make changes  \\n and run your own experiments.  \\n All the notebooks are collected in your exercise files,  \\n organized by course chapter.  \\n They are the files with .ipynb file ending.  \\n You will also see some of the data files  \\n that we will be analyzing.  \\n In Chapter Five, I have included a subfolder  \\n named Downloaded.  \\n These are files that we will download  \\n from the web using Python,  \\n but I am including them here  \\n in case something goes wrong with the download.  \\n We open a notebook by finding it  \\n within the Jupyter Notebook file browser  \\n and clicking on it.  \\n The notebook cell that we're discussing and running  \\n will always be the one enclosed by a blue or green box.  \\n Once we're done with the notebook,  \\n you can close the browser tab  \\n and shut down the notebook in the Jupyter file browser  \\n by clicking on the box and then clicking Shutdown.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2293497\",\"duration\":170,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Using Python in the cloud\",\"fileName\":\"2825705_01_05_XR30_cloudpython\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"You do not need to install Python on your computer to use it for data analysis. In this video, learn how to use the Microsoft notebook server to run Python code in the cloud.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5073696,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] An exciting, recent development  \\n in the Python ecosystem is that it has become possible  \\n to run notebooks in the cloud using services  \\n such as Google Colaboratory and Microsoft Azure Notebooks.  \\n With both, you get a rather functional environment for free.  \\n If you'd like to follow along with this course  \\n using Python in the cloud,  \\n I suggest you use Azure Notebooks.  \\n Let me show you how to.  \\n We start at notebooks.azure.com.  \\n We sign in, which you can do using  \\n an existing Microsoft account or creating one.  \\n You may also be asked to create a user name  \\n for your profile.  \\n In Azure Notebooks, notebooks are organized in projects,  \\n so we create a new one.  \\n I will call it Python data analysis.  \\n The easiest way to get the exercise files  \\n into Microsoft Azure is to upload the zip file  \\n that contains all of them.  \\n The Upload button is here on the top right.  \\n So I go find a file and upload it.  \\n To unzip the archive, I open the Azure terminal.  \\n I type cd library to move into the project directory  \\n and then unzip exercise\\\\ files.zip.  \\n This will take a moment.  \\n Once it's done, we can type exit,  \\n and close this tab.  \\n If I refresh the window,  \\n I see that the exercise files have appeared.  \\n We are now ready for our course.  \\n For instance, I can look inside the exercise files  \\n for chapter two and select the first notebook.  \\n Azure Notebooks can be somewhat slow when loading  \\n and writing files, but don't worry.  \\n You'll get there.  \\n Also, as we speak, the default Python on Azure is 3.5,  \\n which is too old for this course.  \\n Hopefully that will change soon.  \\n In the meantime, please remember to switch the kernel  \\n to Python 3.6 after you open each notebook.  \\n You do that from the Kernel menu, go into Change kernel,  \\n and select Python 3.6  \\n There are many options out there to use Python in the cloud.  \\n Please feel free to use the one that works out best for you.  \\n \\n\\n\"}],\"name\":\"1. Installation and Setup\",\"size\":24079094,\"urn\":\"urn:li:learningContentChapter:2294387\"},{\"duration\":1819,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2295360\",\"duration\":425,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Warmup with Python loops\",\"fileName\":\"2825705_02_01_XR30_loops\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"There are many use cases in data analysis where you need to operate on data in a sequential fashion. In Python, you do so with looping constructs. In this video, learn how to refresh the Python loop syntax by solving a simple problem\u2014finding all the ways in which you can break a dollar into a set of coins.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11735820,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] We will begin every video  \\n by importing a standard set of Python modules that we need.  \\n This is a typical list.  \\n It's expedient to load often used modules  \\n by giving them a shorter alias.  \\n NP is the community standard for NumPy, PD for pandas.  \\n We also load this simple commander entity interface  \\n to matplotlib, pyplots,  \\n and finally, we ask the Jupyter notebook  \\n to keep the plots that we make in the notebook itself  \\n instead of opening a different window.  \\n So I shall now execute this cell  \\n by pressing Shift + Return.  \\n If you've worked in programming before,  \\n you must be familiar with loops.  \\n They allow us to automate repetitive operations.  \\n And loops are a good topic  \\n to start a quick review of the Python core language,  \\n which will focus on the features that are most important  \\n to work with data.  \\n So, how exactly do loops work in Python?  \\n We see them in a concrete example.  \\n Consider the combinatorial problem of breaking a U.S. dollar  \\n into all possible combinations of coins.  \\n For instance, $1 coin,  \\n two half-dollar coins,  \\n one half-dollar coins and two quarters, and so on.  \\n You can already see how we're going to need  \\n several nested loops for this.  \\n The basic structure of a loop in Python  \\n is for variable in iterable  \\n followed by a block that is executing multiple times  \\n with the variable that can own the values provided  \\n by the iterable.  \\n But what is an iterable?  \\n We can think of it as a black box  \\n that keeps providing new values until it runs out.  \\n A simple example is a Python container  \\n such as a list or a dict.  \\n Perhaps the most important iterable is range,  \\n which provides integer value from a start to a stop,  \\n exclusive of the stop.  \\n That means that range zero 10 counts from zero to nine.  \\n There are many reasons for this convention  \\n about the end value.  \\n For instance, by looking at the end value,  \\n we see immediately that the total number of elements  \\n in the range is 10.  \\n In the end, however, we just have to accept this  \\n as one of the building assumptions of Python.  \\n Range has a couple more interesting features.  \\n We can omit the stat value,  \\n and then it's assumed to be zero.  \\n We can provide a step argument to move through the range  \\n in increments larger than one.  \\n And if I give the step,  \\n I must also give the initial value to avoid confusion.  \\n Notice that the step is the third argument  \\n that I give in line four.  \\n Let's go back to the dollar.  \\n To generate all possible ways to break it up,  \\n we will use a very simple minder strategy.  \\n We will consider all possible candidate combinations,  \\n including the zero to one $1 coins,  \\n zero to two half-dollar coins,  \\n zero to four quarters, and so on.  \\n And at the end for each,  \\n we will check whether it adds up to a dollar.  \\n Therefore we need six nested loops.  \\n A loop within a loop within a loop.  \\n Luckily, it's Python that will keep track of them.  \\n This means that the first loop will be over range two.  \\n So, looping over zero and one.  \\n To keep the maximum number of each coin inside,  \\n we'll write it as range(1+1).  \\n We then proceed with the other coins, one loop for each.  \\n Each nested loop is indented with respect to its parent.  \\n Inside the innermost loop,  \\n we will check whether the total amount is $1.  \\n If so, we will add this combination to a list  \\n called combinations, which will start that.  \\n Let's try this out.  \\n And let's look at the results.  \\n The first few combinations seem to check out fine.  \\n It turns out there are 293 ways to get a dollar in change.  \\n That's a solution to the problem we posed.  \\n However, in data analysis,  \\n it often happens that the solution raises a new question.  \\n For instance, how many ways  \\n to make $2 out of change or three?  \\n Does the number of combinations increase linearly  \\n or quadratically with the amount we're breaking up?  \\n What we need to do, then, is to take the code we wrote  \\n and generalize it to answer those questions.  \\n Creating a function,  \\n we'll call it, say, find combinations,  \\n that will take a dollar amount in cents  \\n and return all possible ways to do it.  \\n Before we do so,  \\n we make a couple of changes to our code  \\n to make it faster and to make it easier to generalize.  \\n This is an example of refactoring.  \\n The first change is that we will not loop by count,  \\n but by value, using the step argument of the range.  \\n For instance, instead of looping over quarters  \\n with count 25 between zero and four,  \\n we will loop over the amount  \\n from zero to 100 in steps of 25.  \\n So, I have rewritten all the loops in these terms.  \\n As you see, the end of the range is always a dollar,  \\n 100 cents plus one.  \\n So the dollar is included.  \\n And the step is 100 for $1, 50 for half dollar,  \\n 25 for the quarter, and so on.  \\n The second change we're making  \\n is that we don't actually need  \\n the innermost loop over the pennies.  \\n As long as the total up to that point  \\n is less or equal than a dollar,  \\n we can always make up the difference.  \\n Therefore, we compute the dollar  \\n and write a different test.  \\n The result is again the same.  \\n Now we can take our code  \\n and turn it into the function find combinations  \\n by replacing the value 100 with a variable argument.  \\n We'll call it total.  \\n We do need to indent our code  \\n to make up the body of the function.  \\n So, here we go, $2.  \\n Or $3.  \\n You may be curious to know how fast this number grows.  \\n A plot will give us an idea.  \\n So let's plot 100 through 500,  \\n and we use a comprehension, which we will explain later,  \\n to find a corresponding number of combinations.  \\n Matplotlib will give us a quick plot.  \\n In fact, the number grows approximately  \\n as the fifth power of the total.  \\n You will find the loops are everywhere in data analysis,  \\n so it's good to get familiar with them.  \\n In Python, you can do a lot with the for construct  \\n and with range.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2294374\",\"duration\":319,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Sequences: Lists, tuples, and the slicing syntax\",\"fileName\":\"2825705_02_02_XR30_sequences\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"The built-in sequence types\u2014tuples, lists, ranges, strings, and buffers\u2014in which data elements are associated with indices, set the basic framework for accessing sequential data in Python. In this video, refresh the creation and indexing of sequences, review the important distinction between mutable and immutable types, and highlight the slicing interface.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8870275,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this movie, we are going to review lists.  \\n They are the quintessential Python container.  \\n They provide a way to store an arbitrary number  \\n of Python objects such as strings, floating-point numbers,  \\n other lists, or any other object  \\n and to access them using a numerical index.  \\n In Python lists are denoted by brackets and their elements  \\n are separated by commas.  \\n The length of a list is obtained with len.  \\n Indexing, individual list elements can be accessed by index.  \\n Starting with zero for the first element  \\n and ending at the length of the list minus one.  \\n This convention of starting from zero comes from C,  \\n the language that inspired Python  \\n and that was used to write the standard Python interpreter  \\n known as CPython.  \\n For instance, the first nephew is Huey.  \\n We can also look for the last nephew  \\n and we can even look for a nephew beyond the end of the list  \\n which in this case will yield an error.  \\n We can also index from the end.  \\n Starting at minus one and going down.  \\n That gets us Louie and Dewey.  \\n The bracket indexing notation,  \\n can also be used to reassign elements.  \\n Let's do that for all the nephews with a simple loop.  \\n Here we're just adding their last name.  \\n It's important to remember that lists do not need  \\n to have homogeneous content such as all strings  \\n or all numbers.  \\n We can mix it up.  \\n To add a single element at the end of the list,  \\n we use append.  \\n You see that here we are using Python  \\n in an object-oriented way.  \\n By accessing the method, specifically append,  \\n of the list object.  \\n It's so easy that we barely notice it.  \\n To add multiple elements in one go, we can use extend.  \\n To concatenate two lists, we use a plus.  \\n That's an example of operator overloading in Python  \\n where plus does different things for numbers and for lists.  \\n Last, we can insert elements at any position in a list  \\n using the insert method.  \\n How about removing elements?  \\n We can delete them based on their index with del  \\n or based on the value with remove.  \\n If we want a list sorted we can do this in place.  \\n So we modify an existing list with sort.  \\n Or we can make a new sorted list out of an existing one  \\n with sorted.  \\n Which demonstrates also how to sort backwards.  \\n All of this should be very basic to you  \\n if you work with Python in the past.  \\n Moving on to slices.  \\n Beyond working with individual list elements,  \\n we can manipulate them in groups.  \\n The convention is the same as for Python loops.  \\n The first index is included, the last is not.  \\n It's useful sometimes, to think of the indices  \\n as being placed at the edges of the cells in a list.  \\n We make an example based on the first few squares  \\n of the natural numbers.  \\n If we want the first two squares,  \\n we'd write a slice that goes from zero to two.  \\n There are a few more tricks that we can use in slicing.  \\n For instance we can omit the starting index  \\n to start at the beginning,  \\n omit the ending index to include elements to the end.  \\n Omit both, to get a copy of the list.  \\n Move through the indices in steps.  \\n And even use negative indices to count from the end.  \\n Slices can also be used to reassign a subset of items  \\n or to delete them.  \\n When we introduce NumPy arrays in chapter four,  \\n we will see that this basic slicing syntax carries over.  \\n So it's good to understand it fully on lists first.  \\n The empty list is written with an empty set of brackets  \\n and obviously it has length zero.  \\n Now for tuples, which look like lists  \\n but with parentheses instead of brackets.  \\n They are sometimes described as immutable versions of lists.  \\n We can do the same indexing and slicing tricks,  \\n but we cannot modify the elements or add new ones.  \\n One context in which one sees tuples often  \\n is tuple unpacking, where Python statements  \\n or expressions are automatically evaluated in parallel  \\n over a tuple.  \\n For instance, to assign multiple variables at once.  \\n The parentheses can even be omitted when there is no  \\n room for ambiguity.  \\n Tuples appear also when we iterate  \\n over multiple variables at once.  \\n For example using the enumerate iterator on a list.  \\n Which lets us loop over list index  \\n and list element together.  \\n We can also unpack a tuple to pass it to a function  \\n that requires multiple arguments such as three args.  \\n It takes a tuple if we prefix it with an asterisk.  \\n This ends our review of lists.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2296097\",\"duration\":317,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Dictionaries and sets\",\"fileName\":\"2825705_02_03_XR30_dicts\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Python dicts associate unique keys with values, while sets express collections of data items without duplication. These data types complement sequences in many common data-analysis tasks. In this video, review the creation, updating, and indexing of Python dicts and sets, and explore the changes to dict in Python 3.6 and later.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8565831,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] While lists give us a way  \\n to retrieve values by their index.  \\n Python dictionary or dicts  \\n associate keys with values.  \\n After my imports,  \\n let me write a simple dictionary.  \\n Dicts are written with curly braces,  \\n separating items with commas  \\n and prefixing them by their key in a column.  \\n For instance, the capitals of a few countries.  \\n Just as we do with lists,  \\n values are accessed with a bracket notation.  \\n But instead of a number, we're going to use a key.  \\n For instance,  \\n we may wish to look at the capital of Italy.  \\n The same notation can be used to add items to a dictionary.  \\n Accessing a nonexistent item results in a key error.  \\n We can also check  \\n whether an item exists or not  \\n with the in operator.  \\n So we have Italy, but not Germany.  \\n Combining two dictionaries requires  \\n a little more thought than combining two lists.  \\n Unlike lists, we cannot just use the plus to add them.  \\n That's because we need to specify what happens  \\n if both dictionaries define the same key.  \\n What we then do is to update a dict using another,  \\n which will replace existing items as appropriate.  \\n This happens in place and modifies the dict.  \\n Similarly to lists, we can delete items by key.  \\n In fact, keys do not need to be strings.  \\n Any Python object that is hashable may be used as a name.  \\n Hashable means that Python can convert it to a number.  \\n That's true for many types of objects.  \\n For instance, tuples  \\n which may be used to encode a birthday.  \\n We can see the internal representation  \\n of the keys with hash.  \\n Just very large numbers.  \\n The empty dictionary is written with an empty set of braces  \\n and has length zero.  \\n Looping over a dictionary  \\n is very similar to looping over a list.  \\n However, there are three different kind of loops  \\n you may want to write.  \\n The most straightforward syntax loops over the keys,  \\n for key in dictionary.  \\n Here, I'm using bold to denote language keywords.  \\n Whereas Roman words are the names of the variables  \\n that you will be using.  \\n You can loop also explicitly over the keys,  \\n you can loop over the values,  \\n and you can loop over the keys and values together.  \\n Let's see an example of each of these  \\n For country in capitals,  \\n we loop over keys.  \\n So will for country in capitals keys.  \\n Note that capitals dot keys is not a list,  \\n but a special iterator object.  \\n We can make it into a list though  \\n by feeding it to the list constructor list.  \\n The other two dict loops are over values, dot values,  \\n and over keys and values together using tuple unpacking.  \\n Beginning in Python 3.6 for the C Python interpreter,  \\n and in python 3.7, for the very language definition,  \\n the order of insertion is preserved for dicts.  \\n This means then when we loop over the keys or the items,  \\n we get them in the order  \\n in which we originally added them to the dict.  \\n That was not the case in previous versions of Python  \\n and in fact, the standard library defined a special object  \\n called order dict to preserve that order.  \\n That is not necessary now.  \\n Last, I want to mention sets.  \\n You can think of them as bags of item,  \\n which can be of mixed types  \\n and which do not have duplications.  \\n For instance, the continents.  \\n Sets are written with braces, but without columns.  \\n You can see that Africa only appears once,  \\n even if we had it twice when we define the set.  \\n We can check if an item exists in a set.  \\n We can add items  \\n or remove them  \\n or loop over the set.  \\n but there's no way to do indexing.  \\n Sets and especially dicts are very important in Python,  \\n since they underlie many aspects of the language itself.  \\n For instance, the methods and attributes of classes  \\n are stored internally in dicts,  \\n and a dict key based interface is also used  \\n in many third party packages, including pandas.  \\n So it's very good to become familiar with them.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2295361\",\"duration\":284,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Comprehensions\",\"fileName\":\"2825705_02_04_XR30_comprehensions\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Python comprehensions provide a legible and expedient way to create, transform, and filter sequences, dicts, and sets; you use these extensively in chapter 3. In Python 3, comprehensions largely replace functional calls such as map and filter. In this video, review the comprehension syntax, including multilevel comprehensions, and draw analogies to Python loops.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7527162,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In Python, especially when  \\n you're dealing with data, there are many cases  \\n where you want to iterate over a list  \\n or a dict performing operation on every element  \\n and then collect all the results in a new list, or dict.  \\n You can certainly do that with a loop.  \\n For instance, picking up the example  \\n from the last video,  \\n let's compute the first 10 squares,  \\n starting with an empty list and adding  \\n elements in the body of the loop with append.  \\n This works, but we can do better.  \\n We can be more pythonic, that is,  \\n we can respect Python's specific style and spirit.  \\n Python offers a great feature, comprehensions,  \\n that let us write shorter,  \\n more easily readable code,  \\n that achieves the same effect as the loop.  \\n In fact, the comprehension  \\n is a compressed version of the loop.  \\n Let's go through the steps to write one.  \\n It's a list we want, so we have brackets.  \\n Next, we have the loop.  \\n And then we backtrack to the beginning of the expression  \\n and we write code for the computation  \\n that we want to collect.  \\n In this case, taking the square.  \\n The result is the same,  \\n but we managed to write it  \\n in a very readable and efficient way.  \\n We can also filter the list of elements that we are creating  \\n by adding an if clause.  \\n For instance, we may want to collect only the squares  \\n that are divisible by four,  \\n which in fact, I need to do with the modulus operator.  \\n Again, quick and readable.  \\n In Python three, comprehension largely replace  \\n the map and filter built-in functions,  \\n which are important and so called functional languages,  \\n but did not really belong in Python.  \\n The syntax for dictionary comprehensions  \\n is also rather intuitive.  \\n For instance, let's create a dictionary  \\n that will get us the square  \\n of an integer from the integer itself.  \\n It's a dictionary, so we need braces.  \\n The loop part is the same  \\n for variable and iterable.  \\n But now, instead of the list items,  \\n we need to write key colon value pairs.  \\n We can also add an if clause if we want.  \\n I don't need one here.  \\n Here is the result in dict.  \\n Dict comprehensions are sometimes used  \\n to transpose an existing dict.  \\n Going back to our capitals,  \\n which we wrote as a dictionary index by country,  \\n we can get the countries index by capital.  \\n In the comprehension, we loop over the dict items,  \\n so we get tuples of country and capital,  \\n and we invert them by writing capital colon country.  \\n Sometimes, you see what look like naked  \\n comprehensions without the brackets.  \\n Those are in fact generator expressions,  \\n which are useful when you want to generate a sequence  \\n and consume the elements one by one  \\n without ever storing them in a list or a dict.  \\n For instance, to take the sum of the first 10 squares,  \\n we may write the interior part of our comprehension  \\n without the brackets and feed it directly to sum.  \\n Doing this, saves memory and time  \\n which is important if you deal with large amounts of data.  \\n In fact, the built-in range which we used earlier  \\n to demonstrate loops does something very similar.  \\n It never builds a list, but it keeps  \\n adding new values to the loop.  \\n If you don't currently use comprehension,  \\n I'm sure that if you try them  \\n you'll become addicted quickly.  \\n And you'll start doing all sorts  \\n of acrobatics, such as nested looping comprehensions.  \\n For instance, look at this nested loop,  \\n which creates a list of one,  \\n one two, one two three,  \\n one two three four, and so on.  \\n We can do the same with a nested comprehension  \\n just by writing the two loops  \\n in the same order in sequence.  \\n Comprehensions are incredibly useful  \\n to manipulate lists, dicts, and data.  \\n You should be familiar with both,  \\n understanding and writing them.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2293498\",\"duration\":474,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Advanced Python containers\",\"fileName\":\"2825705_02_05_XR30_advanced\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"The Python standard library offers powerful extensions of the built-in container types, which can help you write shorter and cleaner code. In this video, explore namedtuple, defaultdict, and the powerful data classes introduced in Python 3.7.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12995764,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] As I mentioned in the video about sequences,  \\n tuples are similar to lists,  \\n but we cannot change the arguments after creating the tuple.  \\n The formal way of saying that is that tuples are immutable.  \\n Tuples are very useful to store data records  \\n when we think that we are not going to modify the values.  \\n For instance, a list of people with their first names,  \\n last names, and birthdays.  \\n For each element in this list, for each person,  \\n we access the data fields by index.  \\n Zero for the name, one for the family name.  \\n This lets us write useful list comprehensions.  \\n For instance, to find all the people  \\n with a given birthday.  \\n We loop over every person in People,  \\n and for each we check if the third element  \\n of the tuple, index two, is July 15.  \\n I share a birthday with a very famous astronomer,  \\n Jocelyn Bell Burnell.  \\n Field access by index means that  \\n we have to remember which is which,  \\n creating the potential for bugs,  \\n and certainly reducing the expressiveness of our code.  \\n To help us out, the module Collections  \\n in the standard Python library offers  \\n a name tuple that lets you create a specialized object,  \\n a specialized tuple, that has a name and that  \\n associates labels with fields.  \\n For instance, a person type would be called Person  \\n and have fields first name, last name, and birthday.  \\n We can then create instances of the Name tuple  \\n by using the type and giving the field values sequentially.  \\n Or we can even use the field names,  \\n which lets us shuffle the fields if we need to.  \\n Name tuples have the advantage that they print nicely.  \\n Now let's look at accessing the fields.  \\n Indices still work.  \\n So we get a zero, one and two gives me  \\n first name, last name, and birthday.  \\n But field names using the object-oriented DOS syntax  \\n are now what we're going to use,  \\n because they make our intentions clear in the code we write.  \\n Let's convert our little database to name tuples.  \\n We can't use a standard tuple directly  \\n and feed it person type, because person type  \\n needs three arguments.  \\n Here, Python is complaining that two are missing.  \\n So this is a case where tuple unpacking comes useful.  \\n I use a star to unpack tuple zero into its three elements.  \\n To do all of them, we will, of course,  \\n use a list comprehension.  \\n Now our birthday search reads better.  \\n It shows me explicitly that I'm looking at  \\n the birthday field of each tuple.  \\n Python 3.7 introduced an alternative  \\n to tuples index for storing data records, data classes.  \\n To use them, we need to import data class  \\n from the data classes module.  \\n If you are for some reason in Python 3.6,  \\n you can still use data classes,  \\n but you need to install them explicitly as a package.  \\n For instance, with PIP Install.  \\n So I do my import, and this is how we would  \\n set up a personal record with first name, a string,  \\n last name, a string, and a birthday,  \\n and say again a string,  \\n with the default value for the birthday.  \\n If you're not familiar with Python classes,  \\n class decorators, the At data class that appears at the top,  \\n and if you're not familiar with that annotation  \\n the syntax will look somewhat alien.  \\n But basically, we're instructing Python  \\n to create the type of records that will have fields  \\n called first name, last name, and birthday,  \\n all of which will be strings.  \\n We'll create an instance of this class, a person,  \\n making the fields sequentially or by keywords.  \\n You see here that the field of that known birthday  \\n is applied, since I didn't provide a birthday  \\n to the definition.  \\n We can access the field by name but not by index.  \\n And again, the data class prints nicely.  \\n In contrast to name tuple,  \\n data classes are full Python classes,  \\n so we can define methods that operate on the fields,  \\n such as a method that returns a person's full name.  \\n If you're not familiar with object-oriented  \\n programming in Python, do not worry.  \\n We will not need this feature in what follows.  \\n Nevertheless, for person class two,  \\n calling full name as a method runs the code that we wrote  \\n and returns my full name.  \\n Data classes have many other useful features,  \\n such as freezing, disallowing modifications,  \\n ordering, allowing the comparison of class instances,  \\n defining data classes by inheritance, and a lot more.  \\n So I encourage you to learn more about them  \\n if you are somewhat familiar with  \\n object-oriented programming  \\n and specifically classes in Python.  \\n Now we move on to our last topic  \\n about data extractions in Python.  \\n In a video about dict, I discussed how  \\n a special variant of dictionary,  \\n collections order dict, is now much less useful  \\n because the standard dict preserves the order  \\n in which elements were inserted.  \\n There's another variant of dict that remains useful,  \\n collections default dict.  \\n The point here is to define a default for values  \\n that will be returned if we ask for a key  \\n for which there was no entry.  \\n More precisely, we have to provide a function  \\n that returns that default.  \\n Let me write out the function that we will use.  \\n We'll call it mydefault, and it will return a simple string.  \\n So here's my default dict.  \\n If I go in and ask for a key that doesn't exist yet,  \\n I will just get the default back.  \\n Not only, that key will be now part of the dictionary.  \\n This makes default dict useful  \\n when we want to build a dictionary  \\n where each key can correspond to a list of items.  \\n Let's make an example based on birthdays.  \\n With standard dict, we need to write code  \\n that behaves differently if the birthday  \\n has been seen already, and then we can append  \\n to the list of people with the same birthday  \\n or if the birthday has not been seen,  \\n in which case we need to create a list with one element.  \\n That is quite inconvenient.  \\n The repetition of code is annoying and prone to bugs.  \\n We'll use the full dict instead,  \\n and we will take advantage of the fact  \\n that list called as a function returns the empty list.  \\n So we can use it to provide a default.  \\n Thus, we can write birthdays  \\n as collection_defaultdict  \\n with list as the default maker,  \\n and then simply look over person in our name tuple  \\n and constraint to get in that key the birthday  \\n and appending to the resulting list.  \\n There are more useful container types  \\n in the standard library module collections.  \\n I encourage you to look them up  \\n and to use them in your work instead of  \\n reinventing those wheels.  \\n \\n\\n\"}],\"name\":\"2. Data Structures in Pure Python\",\"size\":49694852,\"urn\":\"urn:li:learningContentChapter:2294388\"},{\"duration\":824,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2294375\",\"duration\":67,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Anagrams overview\",\"fileName\":\"2825705_03_01_XR30_overview\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this chapter, practice Python data structures with a simple example of textual data: listing and analyzing anagrams in the English dictionary. In this video, explore the basic technique\u2014signature\u2014that you use to find anagrams, and outline your general strategy to map the technique to data structures.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1734395,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In chapter two,  \\n we have reviewed Python loops,  \\n data containers, and comprehensions.  \\n Now we will set them to work  \\n in a simple, practical project,  \\n finding anagrams in the English dictionary.  \\n As you know, two words are anagrams of each other  \\n when their letters can be rearranged  \\n to turn one word into the other.  \\n For instance, elvis and lives.  \\n We will use this simple strategy to find anagrams.  \\n We defined a signature of a word  \\n as the sorted list of its letters, including duplicates.  \\n So the signature of post would be opst.  \\n And then we find that spot, stop, tops, pots, and opts  \\n have the same signature as post  \\n and therefore they're all anagrams of each other.  \\n We're going to make a Python dict  \\n of all the words in the dictionary indexed by signature.  \\n And then to find out if a word has an anagram,  \\n we will just compute the signature  \\n and look it up in the dict.  \\n Let's begin.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2294376\",\"duration\":250,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Loading a dictionary\",\"fileName\":\"2825705_03_02_XR30_loading\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In many cases, parsing a text file manually is the fastest way to complete a simple data-analysis task. In this video, load a list of words from a file, and briefly explore Unicode strings in Python 3, which allow you to handle international character sets transparently.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6615853,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] We begin.  \\n By loading a list of words from a file.  \\n Your exercise files.  \\n Already contain a list that we can use as an example.  \\n The file is words.txt  \\n and it sits in the same folder as this Jupyter notebook.  \\n That file is, in fact, the nineteen thirty four dictionary.  \\n That is distributed with many UNIX systems.  \\n If you wish, you can find a better one and use that instead.  \\n Now in Python.  \\n We talk of idioms  \\n to refer to code constructs.  \\n That have become the preferred way  \\n to achieve a certain goal.  \\n A classical example is looping through  \\n all the lines of a text files.  \\n To do so.  \\n We open the file for reading.  \\n Let's open  \\n with a mode of \\\"R\\\"  \\n and then, we can use the file as an iterable.  \\n In a fold loop.  \\n Which has the result  \\n or giving us the lines one by one.  \\n For the moment.  \\n All that we will do with each line,  \\n is just collect it in a list.  \\n What did we get?  \\n More than two hundred thousand words.  \\n Let's look at the first few using slicing.  \\n As we learned in chapter two.  \\n That's good.  \\n I see two problems though.  \\n Every word ends in the new line character.  \\n Denoted in \\\"C\\\" and in Python  \\n as backslash \\\"n\\\".  \\n Also some of the words are capitalized.  \\n Which will interfere  \\n with our scheme of computing signatures.  \\n We can fix both issues using Python string methods.  \\n To strip leading and trailing whitespace.  \\n Including new lines.  \\n We can apply strip.  \\n let's take our own for example.  \\n The new line is stripped away.  \\n Now to switch the entire string to lowercase.  \\n Who use the method lower.  \\n So now.  \\n There's something more interesting to do  \\n in the body of a loop.  \\n Will append to the empty list  \\n is stripped and lowercase version of each line.  \\n Now I see a duplicate.  \\n Which comes from \\\"a\\\"  \\n appearing both in uppercase and lowercase.  \\n One way to get rid of duplicates  \\n is to build not a list but a set.  \\n so I will do my loop once more.  \\n Replace the empty initial list with the empty set  \\n and replace a pen with ADD  \\n and given that the body of the loop is just one line.  \\n There is an even more  \\n idiomatic way of writing it.  \\n You probably guessed it already as a comprehension.  \\n The comprehension will have  \\n the expression I want to collect  \\n and then the loop over lines in the file.  \\n Here it is.  \\n If we wish to restore the alphabetical order.  \\n We can just wrap the set  \\n in the Python built-in sorted.  \\n Which produces a list.  \\n A list however without duplications.  \\n We are now ready to make Anna Graham's.  \\n By the way.  \\n If you want to try in a different language  \\n such as French.  \\n You can follow along what we did  \\n with the appropriate file.  \\n The good thing is that in Python three  \\n all strings are natively unicode.  \\n Meaning that they can handle  \\n international character sets transparently.  \\n The characters are encoded internally  \\n using multiple bytes as needed.  \\n They only care that we need to take  \\n is to tell Python which encoding to use for  \\n the files we read and write.  \\n There are multiple mappings  \\n between character sets and bytes.  \\n So we need to know which one was used.  \\n Your exercise files include a French dictionary.  \\n Written using  \\n the iso-eighty eight five nine encoding  \\n also known as latin one.  \\n Let's read all of its lines.  \\n In this case instead of a loop.  \\n We use the built-in method with lines.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2293499\",\"duration\":329,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Finding anagrams\",\"fileName\":\"2825705_03_03_XR30_finding\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this video, use Python comprehensions to create Python dicts that let you list anagrams and sort them in various ways. These examples show the flexibility and legibility of Python comprehensions.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9579381,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] We pick up our exercise  \\n where we left it in the last video.  \\n We have made a sorted list of lowercase words.  \\n lets load it up.  \\n Now, remember our strategy of comparing signatures.  \\n Those are the sorted lists  \\n of the component letters of each word.  \\n We need a function to make them.  \\n Taking the string N again as an example,  \\n let's see what happens if we sort it.  \\n Which we do with the built-in sorted.  \\n Indeed, we get a sorted list of the letters,  \\n which is already the signature.  \\n We can use it to verify say  \\n that Elvis is an anagram of lives, but not of sings.  \\n For convenience, we will collate the list  \\n of characters back into a single signature to string.  \\n The way this is achieved in Python looks a little strange,  \\n since we need to call the method join on a string  \\n that specifies the connector so to speak of the join.  \\n If it's a dash, we get a-a-n-o-r.  \\n So the connector we really want is the empty string.  \\n We're ready to make a function  \\n that performs this operation in general.  \\n Now, I remind you that our anagram finding strategy  \\n is to build a dictionary of words indexed by signature.  \\n Of course, we could also try a brute-force search  \\n that loops to the dictionary,  \\n computes the signature for every word  \\n and compares it with the signature  \\n of the word we want to anagram.  \\n That's what find anagram does.  \\n This works and seems fast enough  \\n to see just how fast we can use the IPython magic %time.  \\n So 200 milliseconds, that is not a long time to wait  \\n but we become unbearable if we need  \\n to compute long lists of anagrams.  \\n So let's do this the smart way.  \\n As we said, we will build the Python dict  \\n of words indexed by signatures.  \\n In fact, the values in the dict will be set,  \\n that indeed, contain all the words with the same signature.  \\n We call it words by SIG.  \\n If you think about it,  \\n this is the perfect application for default dict.  \\n Which we introduced in chapter two.  \\n Since the first time that we meet the signature,  \\n we have to somehow produce an empty set  \\n and add to it, perfect.  \\n Perhaps we could perform one last filtering operation  \\n by removing signatures with a single word.  \\n After all, every word is an anagram of itself,  \\n but that's not very interesting.  \\n To do the filtering, we can use a dictionary comprehension.  \\n Remember, to iterate on both key  \\n and value we use dict items.  \\n Then with the clause to select non-trivial anagram sets  \\n will length greater than one.  \\n Excellent, we can allow the simple function  \\n find anagram first that looks up a word  \\n in the dict by signature.  \\n This works fine, let's see for my name.  \\n Nothing, I didn't really expect one,  \\n But perhaps we shouldn't get an error  \\n when no anagram is found just the empty set.  \\n To fix that, we'll use a try except close.  \\n And we'll catch the key error exception with  \\n accept key error and just return the empty set in that case.  \\n If you're not familiar with exceptions in Python,  \\n I encourage you to go look them up  \\n in the Python documentation.  \\n So let's try again to anagram my name and get the empty set.  \\n This new function is much, much faster.  \\n Now that we have set this machinery up,  \\n there are many interesting investigations we could do.  \\n For instance, how about finding the sets  \\n of anagrams with the longest words?  \\n We get that by sorting the signatures,  \\n which we get from keys applied to anagrams  \\n by SIG using length.  \\n So we use the sorted built-in,  \\n given a sorting key of Len and a sync for reverse order.  \\n These are the longest signatures,  \\n but to see the actual anagrams,  \\n we can wrap it in a list comprehension.  \\n The longest anagrams have 22 letters.  \\n Looking at this list though, I must say  \\n that these are compound medical words  \\n that are not too creative in anagrammatical terms.  \\n How about the set of anagrams with the most words?  \\n For this, we will sort the dict values instead of the keys.  \\n And again use Len as the sorting key.  \\n The two longest groups have 10 elements,  \\n though some of these words are not very easily recognizable.  \\n Well done, this completes our exercise.  \\n Next, let's put what you learned to good use  \\n and take on a challenge again about wordplay.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2294377\",\"duration\":49,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Challenge: Palindromes\",\"fileName\":\"2825705_03_04_XR30_CH30_challenge1\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In the challenge, you are asked to find palindromic pairs in English, which are pairs of words that become each other when reversed. To do so, you can modify your anagram code.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1274685,\"solution\":false,\"welcomeContent\":null,\"challenge\":true,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (bright electronic music)  \\n - [Instructor] For your challenge,  \\n you should extend the anagram machinery  \\n that we built together to find all palindromic pairs  \\n of words in the English language,  \\n or at least, in our dictionary.  \\n That is, you should find pairs of words  \\n that become each other when we reverse  \\n the order of their letters.  \\n For instance, reward and drawer.  \\n That will also include true palindromes, such as radar,  \\n where the reverse of the word is the word itself.  \\n I'll give you a hint, to reverse a string,  \\n go back to what we learned  \\n about slicing sequences in Python.  \\n This challenge should take you 10 minutes.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2294378\",\"duration\":129,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Palindromes\",\"fileName\":\"2825705_03_05_XR30_SO30_solution1\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":3805977,\"solution\":true,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (upbeat music)  \\n - [Narrator] Here is my solution to the challenge.  \\n You were asked to find all palindromic  \\n pairs of words in the English dictionary.  \\n We start by loading our list of words  \\n with the one line of comprehension.  \\n We will explore the fact that if two words are palindromic,  \\n then they are also anagrams of each other.  \\n We will also need the code we wrote in this chapter  \\n to compute signatures  \\n and to associate words to signatures.  \\n In Python, there is no built-in function  \\n or method to reverse a string,  \\n but we can achieve it easily by slicing.  \\n The slicing step will need to be negative backwards.  \\n We will omit the slice start and stop  \\n to get the entire string.  \\n So for Mickela, we do a slice of colon, colon, minus one.  \\n We now look over all the word sets,  \\n one for each signature,  \\n and then overall pairs of words in the word set,  \\n checking if one of them equals the reverse of the other.  \\n It's a little annoying to write the loops,  \\n so that we are only checking the same pair twice,  \\n in reversed orders.  \\n One way is to check pairs on if they are sorted.  \\n Here's the list.  \\n It includes also the true palindromes  \\n where in order, reverse order,  \\n equals itself.  \\n But manual dis-sorts do not seem very common.  \\n I'm going to give you, also, more elegant solution.  \\n Using the stand a library module, intertools.  \\n Intertools includes an iterator combinations  \\n which return all combinations,  \\n say of two items,  \\n from a list of three.  \\n We can then simplify our solution,  \\n by again looping over word sets,  \\n and then by selecting pairs of words in the word set  \\n using intertools combinations.  \\n The code is cleaner and more expressive.  \\n But the solution is the same.  \\n \\n\\n\"}],\"name\":\"3. Wordplay: Anagrams and Palindromes\",\"size\":23010291,\"urn\":\"urn:li:learningContentChapter:2295370\"},{\"duration\":1412,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2294379\",\"duration\":195,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"NumPy overview\",\"fileName\":\"2825705_04_01_XR30_numpyoverview\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Whenever you need to manage large one-dimensional or multi-dimensional collections of homogeneous data, such as numerical arrays, you turn to the NumPy library, which provides speed and memory savings. NumPy is also a basic building block to interface with C or Fortran code. In this video, get introduced to the basic structure of NumPy arrays and the notion of dtype.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5335233,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this chapter, we introduce NumPy,  \\n a third-party package for Python  \\n that extends the language with multi-dimensional arrays  \\n that are fast, memory-efficient,  \\n and that can manage very large data sets.  \\n NumPy is an important part of the Python ecosystem.  \\n It has become a fundamental package for data analysis,  \\n and for any kind of mathematical application with Python.  \\n Let's talk about how NumPy arrays are different  \\n from Python containers, such as lists.  \\n Python variables are often described as labels.  \\n They are not little boxes in computer memory  \\n ready to receive a value.  \\n Rather, the values are independent objects  \\n with their own space in memory,  \\n and Python variables are labels or names  \\n that are attached to the values.  \\n So you can have more than one variable,  \\n referring to the same object.  \\n It's a very flexible mechanism,  \\n and it makes it possible to have lists and dictionaries  \\n with heterogenous elements.  \\n However, it's not very efficient when we need to  \\n deal with many values of the same type.  \\n In that case, you want to reserve space in memory,  \\n and store all the values side by side,  \\n and that's exactly what a NumPy array is.  \\n Organizing data in this way  \\n is both faster and more efficient in memory.  \\n It's also a necessary step if you want to  \\n interface Python with other languages,  \\n such as C or Fortran,  \\n which count on data being laid out in memory like this.  \\n In this slide, I'm showing you a schematic representation  \\n of a one dimensional and a two dimensional array.  \\n The actual data items sit side by side in memory,  \\n and they all have the same size.  \\n If there is one dimensional,  \\n we identify items by a single index,  \\n or two indices for a two dimensional array.  \\n The index ranges from 0 to one minus one,  \\n where N is the dimensional array.  \\n In the case of a two dimensional array,  \\n the dimensions can be different of course.  \\n Since, as we said, all the data items in an array  \\n need to have the same size,  \\n NumPy needs to be very precise about identifying data types.  \\n In fact, more precise than Python.  \\n While Python has just one type of integer,  \\n and one type of floating-point number,  \\n NumPY has several.  \\n NumPY identifies different types of integers,  \\n dependent on the number of bits  \\n that each of them takes up in memory,  \\n int8, int16, int32, and int64 the most common.  \\n There are also unsigned version of the integers.  \\n As for floating-point numbers,  \\n we have float16, 32, 64, and on some platforms 128.  \\n The most common is float64.  \\n There are other more special I-Types,  \\n complex numbers, booleans, true or false,  \\n bytes, unicode strings,  \\n for which you need to specify lengths,  \\n void, used for record arrays,  \\n and object, which is in effect a pointer  \\n to arbitrary Python objects.  \\n So let's see NumPY arrays in action.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2294380\",\"duration\":314,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Creating NumPy arrays\",\"fileName\":\"2825705_04_02_XR30_createarrays\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"There are various ways to create NumPy arrays, depending on your needs. In this video, learn to make empty arrays, to transform Python data structures into arrays, and to load arrays from files in various formats.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9152433,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] The easiest way to get  \\n a NumPy array is to load it from a file.  \\n NumPy recognizes several file formats,  \\n including, of course, simple text files.  \\n I have prepared one for you  \\n that describes a very well-known painting.  \\n The file is called monalisa.txt  \\n and it's included in your exercise files  \\n in the same directory as this notebook.  \\n Let's have a look at the content.  \\n We open the file with open in reading mode,  \\n and we use the readlines method  \\n to get all the lines of the file.  \\n So we see that we have 200 lines  \\n and that each line is a sequence of integers.  \\n NumPy loads the file without any trouble using loadtxt.  \\n The result is a two-dimensional array.  \\n If we display it, NumPy omits some rows and columns  \\n so it fits on the screen.  \\n We can query the object, the array,  \\n for the number of dimensions, which are two,  \\n the shape, which is 200 by 134,  \\n 200 rows by 134 columns,  \\n the total number of elements,  \\n and the type of element.  \\n In this case it's the very common 64 bit  \\n floating point number.  \\n Okay, so we have a two-dimensional array called monalisa.  \\n I wonder, is it an image that we can display?  \\n We can use the Matplotlib function imshow  \\n to display two-dimensional arrays as images.  \\n Although, we should perhaps use a better column map,  \\n such as gray.  \\n I've also prepared a colored version of the painting  \\n and I have saved it in NumPy's native binary format,  \\n which works across all platforms.  \\n The file is monalisa.mpy.  \\n This is now a three-dimensional array,  \\n where the last dimension is used to store  \\n red, green and blue components.  \\n Imshow understands this without any problem.  \\n We have lots of pixels, so we can make the image bigger  \\n by instructing Matplotlib to have a larger figure size.  \\n Five by eight refers to inches,  \\n although how that turns out in pixels  \\n depend on the resolution of your screen.  \\n We now know how to load the NumPy array.  \\n How about making one ourselves?  \\n The easiest way is to take a Python list  \\n or a nested list of lists and pass it to NumPy array.  \\n The data type is automatically set.  \\n And we can query the object as we did before.  \\n Another common way to create  \\n an array is to make an empty one.  \\n We give the shape and the data type.  \\n For instance, we can do a one-dimensional array  \\n a vector of length eight.  \\n Here d is just a shorthand for a float 64, an 8-byte float.  \\n We can do a two-dimensional array, a matrix.  \\n And we can query these objects for their metadata,  \\n and plot them on the same line.  \\n It is sometimes useful to make an array of zeros  \\n in the shape of another existing array.  \\n That's done with zeroes_like.  \\n Otherwise, we can make a really empty array.  \\n Here, the memory is allocated, but not even cleaned,  \\n so we get some nonsensical values.  \\n We can also create a regularly spaced array  \\n of number with linspace with specified extrema,  \\n for instance, zero and one,  \\n and the total number of elements, here 16.  \\n We can't show a one-dimensional array as an image,  \\n but we can certainly plot it with Matplotlib.  \\n Here, I will use a thick marker  \\n as specified by lowercase o.  \\n Instead of choosing the number of elements  \\n between two extrema as we did with linspace,  \\n we can use NumPy arange, which has the same convention  \\n as Python's built-in range.  \\n In this case, we have elements  \\n between zero and 1.5 spaced by 0.1.  \\n NumPy can also give us an array of random numbers.  \\n We just need to specify the shape.  \\n By default, we get numbers uniformly distributed  \\n between zero and one.  \\n If we plot them with color, they look suitably random.  \\n We could also use random.randint and NumPy random.randn  \\n to get either integers in a given range  \\n or normally distributed numbers.  \\n To close this video, let me show you  \\n how to save an array to a file.  \\n Np.save will create a cross-platform binary file.  \\n The file ending is conventionally .mpy,  \\n but it doesn't need to be.  \\n Numpy savetext, instead, will create a readable ASCII table.  \\n And if we load it, we see that it's all there.  \\n Now that we've created our arrays,  \\n let's see what we can do with them.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2294381\",\"duration\":320,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Indexing NumPy arrays\",\"fileName\":\"2825705_04_03_XR30_indexing\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In the analysis of large data collections, you often need to focus on subsets of data or to restructure its storage. In this video, learn how to select subarrays by specifying boundaries and strides\u2014slicing\u2014or by applying conditions to the data\u2014fancy indexing. Also, explore restructuring data\u2014for example, adding or removing axes\u2014and the distinction between views and copies.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9422227,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Let's see how we can access  \\n individual elements and ranges of elements in NumPy.  \\n We will demonstrate on our good old friend Mona Lisa.  \\n So let me load up the file.  \\n I remind you, this is a three-dimensional NumPy array  \\n with dimensions that correspond to  \\n height 1198 pixels with 804,  \\n and color three, for red, green and blue.  \\n Imgshow shows us the picture.  \\n The syntax to get that individual pixels  \\n is just an extension of Python list indexing,  \\n except that we can now include  \\n multiple indices among brackets.  \\n For instance, a point roughly in the middle  \\n would be on row 600, column 400  \\n and we grabbed the red component.  \\n If we wish to go to the bottom right corner,  \\n we may count back from the boundary of the array,  \\n just that we would do for a list.  \\n This should be the same as  \\n 1148, 754 and one.  \\n If we try to index elements beyond the boundary,  \\n we get an index error.  \\n And of course, we can use indexing to assign values  \\n to the elements.  \\n Once you get used to multi-indexing like this,  \\n you'll have the temptation of trying it  \\n on nested Python lists,  \\n but there it doesn't work.  \\n So let me demonstrate with a rather uninspired list.  \\n We cannot ask for element one comma two,  \\n rather, we need to ask for list number one,  \\n and then element two.  \\n One more reason to like NumPy arrays.  \\n Slicing also works in a very similar way to Python lists.  \\n For instance, we could grab a section  \\n in the middle of the painting  \\n from rows 400 to 800, columns 200 to 600s.  \\n Here's the detail.  \\n Often we want to grab the entire range  \\n over one or more axes, in which case,  \\n we can use the shorthand column for the full slice.  \\n There's an even shorter hand  \\n for multiple full slices, ellipses sign.  \\n We can also specify a step,  \\n which has the effect of reducing the resolution  \\n of the picture  \\n because we've taken every 20th pixel.  \\n See the black dot in the middle?  \\n It's there because earlier we assigned zero  \\n to all three color channels for pixel 600 and 400,  \\n the single pixel was invisible at higher resolution,  \\n but it's one of those selected by this slice  \\n with steps of 20.  \\n How about slicing backwards?  \\n That works too.  \\n And in this case, it inverts the rows.  \\n And if we mix slicing and indexing,  \\n we reduce the dimensionality of the array.  \\n In this case, it becomes just a vector.  \\n We can show a vector as an image or we can plot it.  \\n Note that fixing one of the indices  \\n is not the same as asking for a slice of one.  \\n In that case, the array remains two-dimensional.  \\n Slicing can also be used on the left side  \\n of an assignment statement.  \\n We can use this to modify elements in bulk,  \\n such as deleting a square in the top corner of the image.  \\n Doing so, assign the same value to all the pixels there.  \\n But we can also match slices on both sides  \\n of the assignment.  \\n So let's replace the white square  \\n with a random set of pixels.  \\n NumPy arrays also support  \\n an especially useful form of indexing  \\n that is not available with lists.  \\n This is known as fancy indexing.  \\n It means that we're using arrays to index another array.  \\n To demonstrate that,  \\n let me grab my lower resolution grayscale image.  \\n I'm going to threshold this image  \\n by first figuring out all the pixels  \\n that are darker than a certain value.  \\n The result is a two-dimensional Boolean array,  \\n the same size as monalisa_bw.  \\n I can then use this Boolean array  \\n to select the corresponding subset of pixels  \\n and modify only those.  \\n Here's the thresholded image.  \\n Finally, let me point out another very important difference  \\n between lists and NumPy arrays.  \\n Whenever you slice a list, you make a copy of it.  \\n Say I have a simple list of six elements  \\n and I take a slice of the first four.  \\n Assigning to the slice does not modify the original list.  \\n By contrast, a slice of a NumPy array  \\n is a new NumPy object  \\n that points to the same area of memory,  \\n but we modified meta data that represents  \\n the different boundaries.  \\n So if I assigned to the slides,  \\n I'm also assigning to the underlying object.  \\n If we want a true copy pointing to new memory,  \\n you have to make the copy explicitly.  \\n Acting on the copy does not affect the original.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2293500\",\"duration\":321,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Doing math with NumPy arrays\",\"fileName\":\"2825705_04_04_XR30_math\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"With NumPy, speed and agility arise from the ability to operate on entire arrays at once. In this video, learn how to perform mathematical operations that transform arrays or combine them together, while preserving or modifying their structure.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9501463,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] NumPy is extremely useful  \\n in numerical calculations.  \\n That's because in addition to packing numbers  \\n efficient in memory, NumPy makes it easy  \\n to perform mathematical operations  \\n with entire arrays.  \\n For instance, in a study of mathematical functions,  \\n we may start with a vector of equally-spaced real values  \\n between say zero and five times pi.  \\n Here it is.  \\n Note that with the list space, the extreme of zero  \\n and five pi are included.  \\n Then we may want to complete the sine  \\n of all these values.  \\n We cannot do this with a function  \\n in the standard math library.  \\n Math dot sin.  \\n But we can with the NumPy version,  \\n which is called the universal function for this reason.  \\n It can operate on any array, in element by element fashion.  \\n There is always another NumPy array  \\n with the same shape as X.  \\n Using map dot lib, I can now plot sine X against X.  \\n Specifying first the coordinates along the horizontal axis  \\n and then the coordinates along the vertical.  \\n Map dot lib takes care of setting the Y range automatically.  \\n By repeating the plot statement,  \\n I can show multiple functions together.  \\n Map dot lib will automatically cycle through colors  \\n so it can distinguish the lines.  \\n So let's try our sine together with a cosine  \\n and then logarithm.  \\n We can add labels to remind us which is which,  \\n and then collect the labels in a legend.  \\n There are many more options in map dot lib  \\n regarding the style of the lines,  \\n the formatting of the plot, and more.  \\n You can look at the documentation to learn more.  \\n We can also perform operations  \\n that involve more than one array  \\n and everything goes smoothly if we match array shapes.  \\n So let's make the cosine in addition of the sine,  \\n and let's try combining the two.  \\n By contrast, operations between arrays of different shapes  \\n generally fail.  \\n NumPy doesn't quite know what to do.  \\n There is one important exception,  \\n which is known as broadcasting.  \\n NumPy, when it can, makes sense of operations  \\n between arrays of different dimensions  \\n rather than shapes.  \\n The simplest case, which is rather intuitive,  \\n is just to add a single number to an entire array.  \\n We see that W is offset by 1.5 with respect to sine X.  \\n The plot would also be self-explanatory.  \\n Let's go up to two dimensions  \\n and then we'll straighten our friend, the Mona Lisa.  \\n The image is 200 rows by 134 columns.  \\n I can multiply every column by a different number  \\n by making a vector of length 134.  \\n In this case, NumPy matches the second dimension  \\n of the array, with a single dimension of the vector.  \\n I want to show you the result  \\n side by side with the original image.  \\n So I need to do a little work with math dot lib.  \\n I will start with a larger figure size,  \\n figure and fix size,  \\n and then I set up one row  \\n with two plots using subplot.  \\n The arguments to subplot go one row, two columns,  \\n and then the subplot that I want to make.  \\n Multiplying the array in this way  \\n had the effect of applying horizontal gradient.  \\n What about the other way around?  \\n If I make a vector of length 200,  \\n you'd think we could apply it on the left  \\n to multiply every row by a single value.  \\n That however doesn't work.  \\n What works is to add a new dimension of length one  \\n to the gradient vector, which we can do  \\n with a special indexing notation, NP dot new axis.  \\n The shape of Y grad is now 200 by one.  \\n NumPy broadcasting then matches the first dimension  \\n of the two arrays, Mona Lisa BW and Y grad,  \\n and broadcasts the second dimension of Y grad  \\n to fill up the corresponding range in Mona Lisa.  \\n The result is the vertical gradient.  \\n NumPy supports many other useful mathematical operations,  \\n including fast fully transforms, random numbers,  \\n statistics, interpolation, and linear algebra.  \\n If you need any of them,  \\n you can go read the NumPy documentation.  \\n There is one thing I want to show you here.  \\n It's that since version 3.5,  \\n Python implements a special matrix multiplication operator.  \\n The at symbol, which is put to good use by NumPy.  \\n For instance, we can use it  \\n to make the dot product of two vectors.  \\n A and B, each of three elements.  \\n This is the same as writing NumPy dot dot AB.  \\n Or we could write the products of a three by three matrix  \\n in a three vector.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2293501\",\"duration\":262,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Special arrays: Records and dates\",\"fileName\":\"2825705_04_05_XR30_special\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"NumPy offers very convenient facilities for managing data of different types together\u2014record arrays\u2014and to handle dates with the datetime64 dtype. In this video, learn how to create and use record arrays and datetime64 data.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7397157,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In the last video for this chapter,  \\n I want to show you two NumPy features  \\n that are not always covered in tutorials,  \\n but they're still very useful.  \\n One is record arrays, where we can mix different data types  \\n and give descriptive names to fields.  \\n The other is date time objects,  \\n which as the name says, can encode a date and time.  \\n Let us load up a simple example of a record array,  \\n which I have prepared in the NumPy binary format.  \\n This is a partial David Bowie discography.  \\n Each entry shows the record name, the date of release  \\n and the top rank in the UK charts.  \\n Let's look at the data type.  \\n It's a list which shows the name of each field  \\n and the actual D type.  \\n For title, it's U32, which denotes a Unicode string  \\n of maximum length 32.  \\n For release, it's M eight brackets D  \\n which denotes a date time object with granularity of days.  \\n It could be as small as a nanosecond in fact.  \\n The eight refers to the size in bytes  \\n of each date time object.  \\n Last, the top rank, is an eight byte integer data type.  \\n If you're wondering about the less symbol in each of these,  \\n those refer to the endianness of the data types,  \\n the order in which the bytes are stored in memory.  \\n Inter-processors are little endian.  \\n So what can we do with a record array?  \\n Each record looks like a Python tuple,  \\n and we can extract the elements as we would for a tuple  \\n but we can also modify them.  \\n We can also use a dict like interface  \\n using the field names in brackets.  \\n This, in fact, will also get us a full column.  \\n To create a record array,  \\n you have to be a little careful in specifying the D type.  \\n It's useful to go read about data type descriptors  \\n in the NumPy documentation.  \\n But let's try one.  \\n We specify a subset of the information  \\n we have in discography, just the title and release date.  \\n This array is empty right now,  \\n but we can copy over the two columns.  \\n Here we see that the title strings  \\n have been truncated to 16 characters.  \\n Since all the data is stored contiguously in memory,  \\n the lengths that we prescribe for the fields  \\n are very important and set the limit for the data  \\n that we can store.  \\n We see also that we specified a finer granularity  \\n for the date time object, seconds,  \\n although it's all zeros because the discography array  \\n didn't have that information.  \\n We move on to the date time object,  \\n which is called datetime64  \\n to avoid confusion with the object in the standard library,  \\n and also to remind us that each element takes 64 bits.  \\n We can initialize date time object with strings,  \\n and we can give it as much detail as we want,  \\n just the year, a full date,  \\n and date and hour minute combination, or even beyond that.  \\n Date times can be compared,  \\n so noon came before 6 p.m. on that day, like any day.  \\n Date times can also be subtracted,  \\n resulting in a time delta object,  \\n which here is specified in minutes.  \\n The nice thing about these date time objects  \\n is that they are understood across NumPy.  \\n For instance, we can use the NumPy function diff,  \\n which computes the differences between  \\n successive elements of a vector  \\n to see how long it took David Bowie  \\n to come up with a new record after each one.  \\n Ziggy Stardust was especially quick.  \\n Another example may be making a range of these.  \\n NumPy in a range understand date times.  \\n And we see that the last day is excluded  \\n consistently with the conventions of range and a range.  \\n This functionality is extended even further in Pandas.  \\n And in fact, the whole idea of record arrays  \\n has a much stronger implementation in Pandas DataFrames.  \\n We'll learn about those later in this course.  \\n \\n\\n\"}],\"name\":\"4. Arrays with NumPy\",\"size\":40808513,\"urn\":\"urn:li:learningContentChapter:2295371\"},{\"duration\":1606,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2295362\",\"duration\":64,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Overview of use case\",\"fileName\":\"2825705_05_01_XR30_weatheroverview\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this chapter, practice NumPy by loading, modifying, and plotting weather data from the National Oceanic and Atmospheric Administration. In this video, examine the files that you are going to analyze and outline your analysis goals.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":2103321,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this chapter,  \\n we are going to experiment with NumPy  \\n on a real world use case,  \\n analyzing weather data from NOAA,  \\n the National Oceanic and Atmosphere Administration.  \\n The GHCN, the Global Historical Climatology Network Daily  \\n is an integrated database of daily climate summary  \\n from land surface stations across the globe.  \\n Many in big cities for instance.  \\n Climate summaries, in this case,  \\n means variables  \\n such as the minimum and maximum temperatures,  \\n the total precipitation, and so on.  \\n The data files that we will be using  \\n can be obtained from the NOAA website.  \\n Together we will download a station list  \\n and use it to locate temperature data for cities.  \\n We will load the data files, fill missing values,  \\n and smooth time series.  \\n Finally,  \\n we will create a visualization of daily temperatures  \\n inspired by the New York Times weather plots.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2294382\",\"duration\":372,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Loading station and temperature data\",\"fileName\":\"2825705_05_02_XR30_loading\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"NumPy allows you to load data in many different formats without writing custom code. In this video, learn how to use Python to download files from the web and use NumPy to load a fixed-width table.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":14833489,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this chapter,  \\n we download several data files from the web.  \\n However, all the files that we analyze  \\n are also included in your exercise files,  \\n in case they became unavailable online,  \\n or you're unable to download them for any other reason.  \\n And before we load the data itself,  \\n it's also a good idea  \\n to start by looking at it's documentation.  \\n Browsing through the file listing at the NOAA website,  \\n we see a README file, and we start there.  \\n Instead of clicking on that link in our browser,  \\n let's use Python to download the file.  \\n There are several Python modules we could use,  \\n but for a simple download,  \\n the standard library module, urllib,  \\n is quite appropriate.  \\n urllib.request.urlretrieve needs the URL  \\n and the name of a local file.  \\n It's done already.  \\n We can use the Jupyter Notebook  \\n to look at the README file, by clicking on it.  \\n We see that it describes the contents of the directory,  \\n the format of DLY data files,  \\n which contain data for a single station,  \\n and are formatted with fixed-width columns.  \\n And the format of a file, GHCND stations,  \\n thank you, says the location, elevation, and ID  \\n for each station in the network.  \\n That's where we need to start,  \\n so we download that file with urllib.  \\n I've copied the description of the format  \\n into a text field in this Notebook,  \\n for our reference.  \\n To load a fixed-width text file, such as this,  \\n we can use NumPy genfromtxt.  \\n It needs rather precise information.  \\n We specify the width of each field  \\n in the parameter delimiter.  \\n We can derive the widths from the table above,  \\n or we need to increase them  \\n to include the spaces between the columns.  \\n Next, we provide the name,  \\n a descriptive name for each column.  \\n And we specify the dtype,  \\n the NumPy data type for each column.  \\n For the first field, for instance,  \\n we need a string of 11 characters.  \\n Then, we have three floats,  \\n and a few more strings of various lengths.  \\n And last, we'll tell NumPy  \\n to remove all the leading and trailing spaces  \\n from all the strings it parses.  \\n There result is a NumPy record array  \\n with more than a hundred thousand entries.  \\n Thankfully, Jupyter chooses to show us only a few lines  \\n at the top and the bottom.  \\n By plotting longitude against latitude,  \\n we get an idea of the impressive global coverage  \\n of the database.  \\n We need to make the dots small,  \\n so that they're not too crowded.  \\n Even so, the US and Europe are basically  \\n just solid masses of ink.  \\n How about stations in California?  \\n We can use fancy indexing with a Boolean expression,  \\n stations state equals equals CA  \\n to downselect our dataset.  \\n Coverage is still impressive.  \\n What if we need a specific station?  \\n Fancy indexing again comes to the rescue.  \\n We select all stations,  \\n for which it is true that the name field equals 'Pasadena'.  \\n We find one.  \\n If we want all stations that start with a given string,  \\n the syntax would be more esoteric.  \\n What np.char.find does,  \\n is to return the index at which a certain substring,  \\n 'Pasadena' in this case,  \\n appears in the field,  \\n or minus one if the substring is not there.  \\n If we required the index to be zero,  \\n that's the same as saying  \\n that the station name begins with 'Pasadena'.  \\n So, we see that there are several stations,  \\n a few of them in Pasadena, Texas and Pasadena, Maryland.  \\n Only one, however,  \\n is in the quality-controlled HCN network.  \\n Let's get that one.  \\n I've built this URL by looking at the structure  \\n of the directories on the website.  \\n You see that it ends in Pasadena's ID, USC00046719.dly.  \\n Locally, we'll download to the file Pasadena.dly.  \\n Let's look at that file.  \\n Again, with Jupyter Notebook.  \\n It's quite messy, but we recognize the station ID  \\n in the beginning of each line,  \\n followed by year and month.  \\n Here, we are in 1918.  \\n The name of an element, such as TMAX,  \\n and 31 data points, one for each day of the month.  \\n Each data point itself,  \\n consists of the value and three flags.  \\n We could use genfromtxt again,  \\n but it's going to take us a while,  \\n so, I prepared a small module for you, getweather.py,  \\n that takes care of parsing the file  \\n and returning consecutive daily values for a year.  \\n The module uses Pandas to clean and reformat data,  \\n but returns it as a pure NumPy array.  \\n After you've learned about Pandas later in this course,  \\n I encourage you to go look at getweather.py  \\n and see what I did there.  \\n We import the module  \\n and then we look at the help, known as docstring.  \\n This function does what I described,  \\n returning data for one year, for one station.  \\n Let's try it out on Pasadena.  \\n We request both TMIN and TMAX for year 2000.  \\n Some measurements are missing,  \\n and they are here represented as 'nan', nan, not a number.  \\n This function would be a great foundation  \\n for our work in the next few videos.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2294383\",\"duration\":310,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Filling missing values\",\"fileName\":\"2825705_05_03_XR30_filling\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Data often needs to be cleaned or otherwise edited before analyzing it. In this video, learn how to integrate missing data in the weather files you have loaded using a simple interpolation technique.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9559456,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] We pick up where we left  \\n and load temperature data for Pasadena, California  \\n using our getweather module.  \\n This is a time series, a sequence of values,  \\n organized chronologically, usually with equal cadence,  \\n that is the same time interval  \\n between every two consecutive samples.  \\n To get a sense of the data, one of them begins  \\n by computing its average value  \\n and perhaps its extreme, the minimum and maximum.  \\n With NumPy, we can use mean, min, and max.  \\n But wait, in this case, we seem to get NaNs.  \\n What's going on?  \\n It shouldn't be surprising, if we remember  \\n that the data contains missing values,  \\n which are indeed represented as NaNs.  \\n And NaNs can't really participate  \\n in any mathematical operation, NaN plus one is still NaN.  \\n In fact, how many do we have?  \\n The NumPy function isnan,  \\n creates a Boolean array of NaN-ness, so to speak.  \\n We can then count the instances of true  \\n in this array by using a neat trick.  \\n If we do arithmetics with Booleans in Python,  \\n they are converted to integers  \\n with false counting as zero and true as one.  \\n So, for instance, false plus true plus true is two.  \\n It follows that we can count the trues  \\n in a Boolean array just by summing it up with NumPy sum.  \\n So what can we do?  \\n Missing values are so common, in fact,  \\n the NumPy offers versions of its functions  \\n that simply ignore them.  \\n For instance, NumPy nanmin and nanmax.  \\n If we do need an uninterrupted series of numbers,  \\n we could just set the NaNs to the average of the column.  \\n This is yet another application of fancy indexing  \\n because we want to modify only the NaN elements.  \\n So we write something like Pasadena to mean  \\n fancy indexed to the true NaN Boolean mask  \\n is set equal to the NaN mean of the same variable.  \\n This works fine.  \\n We can tell which elements we changed  \\n because they have more digits than all the others,  \\n which were encoded with limited precision  \\n in the GHCN data.  \\n The integrated dataset can now be plotted  \\n without discontinuities.  \\n A more powerful approach to restoring missing values  \\n is to interpolate.  \\n That is, we can use neighbor values  \\n to compute a plausible number  \\n for the values that are missing.  \\n Let me demonstrate in a tall problem.  \\n Let's say we measure a function y,  \\n defined at integers x between zero and eight,  \\n but we don't have some of the values.  \\n In this case, we don't have value set x  \\n of two, three, and six.  \\n Let me show you all of this in a plot.  \\n I will now define an array of the integers  \\n at which we do want new interpolated values.  \\n I use NumPy linspace, so if I sat down  \\n and I said zero and eight, it's nine elements total.  \\n The function of NumPy interp takes as arguments  \\n the desired location, my xnew, followed by the data we have,  \\n x and y.  \\n It returns values that are interpolated linearly  \\n by fitting segments between existing data points.  \\n Here I'm plotting interpolated points as orange squares.  \\n This seems to make sense and to be rather conservative.  \\n The newx sequence, if you needed to,  \\n could well be the answer.  \\n 30 points between zero and eight.  \\n So let's use interpolation to fill missing values  \\n in the Pasadena temperature data.  \\n I need to load it again, since I fixed it already  \\n by replacing NaNs with nints.  \\n Here, now it's broken again, so to interpolate,  \\n we select the good data points, those that are not NaNs,  \\n and a tilde in this expression denotes logical notation.  \\n Then we make an array of the x-values  \\n for which we want interpolation.  \\n All days from one through 365,  \\n and then we can apply NumPy interp.  \\n This seems to work well.  \\n We celebrate by generalizing our Pasadena-centric code,  \\n so that it can fill up holes in any array by interpolation.  \\n It's just a question of replacing Pasadena  \\n with a generic array argument, and 365  \\n with the length of that array.  \\n Finally, we can plot interpolated temperature series  \\n in all their glory using our new function.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2295363\",\"duration\":386,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Smoothing time series\",\"fileName\":\"2825705_05_04_XR30_smoothing\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Many interesting data sets are organized as time series: numerical sequences sorted by date and time. In this video, learn how to use NumPy to perform basic time-series analysis tasks: computing means and standard deviations and smoothing time series.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":11602546,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Now we know how to load  \\n temperature data from any station,  \\n how to compute basic summaries  \\n such as mean, min and max,  \\n and how to integrate missing data points  \\n using interpolation.  \\n We'll continue with more data analysis in NumPy.  \\n I've copied your fill NaNs function here  \\n since we will need it.  \\n We looked at data for Pasadena in the last video,  \\n now let's move to even sunnier skies  \\n by looking at weather in the town of Hilo,  \\n big island Hawaii.  \\n We use our custom loader  \\n and again, I encourage you to go look under the hood.  \\n This is data in fact from Hilo International Airport  \\n we now fill the missing data for both T min and T max.  \\n Once more two pole unpacking is very useful.  \\n Let's look at some data summaries.  \\n The yearly average which gives us a sense  \\n of the typical value for T min, and it's min and max.  \\n Will span the range of variation of these measurements.  \\n We can plot the summaries together with the time series.  \\n The map load live function adds each line,  \\n plots a horizontal line that spans the entire graph.  \\n Also useful for reference values,  \\n and we'll make them dotted.  \\n Another common way to measure the range of variation  \\n of a time series is to compute the standard deviation  \\n defined at the square root of the values.  \\n If you don't know about this you can go to statistics,  \\n text book, or to Wikipedia.  \\n Mean and variance are computed in NumPy with NP Mean  \\n and NP Var, we can plot the time series again  \\n using the mean and the mean minus  \\n and plus the standard deviation as references.  \\n Most of the time the temperatures are included in this range  \\n and given that this is Hawaii it's also interesting  \\n to look at precipitation.  \\n We grab those values with Get Weather and just plot them.  \\n The rainy season starting in November is quite evident.  \\n Now looking at the data this way is very informative,  \\n but we also see lots of noise, rapid variations between  \\n one day and the next, which can obscure underlying trends.  \\n To remove the noise, we can smooth the data.  \\n So that we see the slower long-term behavior  \\n below those still issues and the simplest approach  \\n to smoothing is replacing each value with the average  \\n of a set of its neighbors.  \\n With NumPy we can do this with correlate.  \\n I will demonstrate first with a very simple  \\n and short data set consisting of two peaks  \\n over a background of zeroes.  \\n I then define a roughly triangular correlation mask  \\n which is highest in the middle and drops down to the sides  \\n and I have arranged the values so they sum to one,  \\n next I write the correlation.  \\n What it does is to multiply each element  \\n in the series with the mask  \\n and then sum up all the resulting short series.  \\n Sliding them so they are centered around the sample  \\n that we multiply, thus as you see in this figure,  \\n each peak generates a triangle centered  \\n on its location.  \\n I have not explained the keyword same that we gave  \\n to correlate, what it does is to request that  \\n the output of the correlation be the same length  \\n as the input.  \\n Even as this means that the points on the boundaries  \\n get sums from fewer masks.  \\n So we may see some anomaly there.  \\n To smooth our temperature series we will use  \\n an even simpler mask, uniform values normalized  \\n so that they sum to one.  \\n We're going to get that in NumPy with NumPy once,  \\n let's try this out.  \\n We plot the regional temperature series as dots,  \\n maybe a little smaller than usual,  \\n and the smoothed series has a continuous line.  \\n This works fine, we are reducing oscillations  \\n while emphasizing the underlying slower trend.  \\n We do see something strange happening  \\n at the beginning and end of the data set.  \\n The values are going way low.  \\n That has to do with the keyword same,  \\n and we detect that the values on the boundaries  \\n have fewer neighbors than everybody else.  \\n If we can do without a few points at the end  \\n and at the beginning we can change our request  \\n to amply correlate to valid and avoid this problem.  \\n We can now make a function to apply smoothing  \\n of any length to any array.  \\n The length of the smoothing mask is sometimes called window  \\n and by default we'll use valid mode.  \\n We then plot T min and T max together for Hilo.  \\n It's an interesting plot  \\n and I'd like to see it for other cities,  \\n so once again let's take a code  \\n and generalize it to arbitrary station and year.  \\n So we get the data, we fill in the NaNs  \\n and we plot both the original data and a smooth version.  \\n We need to offset the plot a bit since we lose points  \\n with valid mode, so the range if the smoothing is over  \\n 20 days would just be from day 10  \\n to day 356 of the year.  \\n Let me try this out, for instance over multiple years  \\n for Hilo to see if the Hawaii climate is stable.  \\n Quite so.  \\n How about comparing cities in different climates?  \\n Let me look over Pasadena, New York, San Diego,  \\n and Minneapolis and then create a sub-plot  \\n in two rows and two columns for each one of them.  \\n I'll focus on the year 2000.  \\n There's some downloading and then we see the plots  \\n come out together, if you can choose based on weather alone  \\n where would you live?  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2295364\",\"duration\":303,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Weather charts\",\"fileName\":\"2825705_05_05_XR30_charts\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Using NumPy and matplotlib together, you can create insightful visualizations with little effort. In this video, learn how to compute daily temperature records and plot weather charts in the style of the New York Times.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":9494132,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] We're going to conclude a NumPy practice,  \\n by making a quick but impressive weather visualization,  \\n that showcases the power  \\n and flexibility of NumPy and Matplotlib.  \\n It's inspired by the New York Times  \\n weather chart shown here.  \\n And it shows daily minima and maxima,  \\n the proper band in the context of their normal range,  \\n dark gray and of their records, light gray.  \\n We will again use Pasadena as an example,  \\n but you can do your own city,  \\n if it's included in the NOAA data set.  \\n Remember, we want to show Records,  \\n which means that we need all the data we can get.  \\n The Gateway, the module,  \\n that's a query for one year of data at a time.  \\n So, we'll call it repeatedly collecting the results  \\n in a comprehension and feeding that to NumPy vstack,  \\n which makes a two-dimensional array formally  \\n so one-dimensional arrays.  \\n The result can be visualized with matchshow.  \\n We've added also a colored bar to provide a reference  \\n of the mapping of values to color.  \\n And we have specified the extent  \\n to get more informative labels on the axis.  \\n We see some missing data, the white patches,  \\n and we can observe winter and summer nights getting warmer  \\n towards the end of the century.  \\n For simplicity, we will forego filling a nance  \\n and use NaN robust functions.  \\n We want record temperatures for every day of the year.  \\n This means that we can use NumPy nanmin on the demand data  \\n and specify axis equals zero,  \\n so that the minimum will be taken  \\n across all rows for each column.  \\n We do the same for tmax using NumPy nanmax.  \\n Let's see the records.  \\n Now for the normals.  \\n In the New York Times plot the normal temperature range  \\n for each day is defined as the average  \\n of the low and high from 1981 to 2010.  \\n So we build another stacked array with a reduced year range.  \\n And again, we take nan robust means, across rows.  \\n So that's axis equals zero.  \\n Here's the normal range.  \\n We're ready to get the plot together.  \\n We do Pasadena in 2018, just like the Times,  \\n so I'd better get that data.  \\n To plot the band,  \\n we use Micro-LIBS fill between which needs an x-axis  \\n to coordinate the array.  \\n It needs also the lower  \\n and upper lines that delimit the band.  \\n So for the x-axis,  \\n I will use the day of the year for one to 365.  \\n Here it is, I will do similar bands  \\n for the records and normal ranges.  \\n I also want to show the average temperature for the year.  \\n I have to compute that though.  \\n That would be the mean of the minimum temperature  \\n plus the mean of the maximum  \\n all across the year, divided by two.  \\n In 2018,  \\n that was 19.46 degrees Celsius.  \\n I'm going to put this average temperature in the title,  \\n so I need to build up a string for that.  \\n For that, I will use the very convenient formatted string  \\n literals introduced in Python 3.6.  \\n If I start the string with an \\\"F\\\" before the quotes,  \\n I can include variable names in braces,  \\n which are then replaced by their values.  \\n I can also specify formatting instructions as I would,  \\n using the string format interface.  \\n For instance, two decimal digits  \\n for the average temperature.  \\n Let me put everything together.  \\n I plot the three bands for record normal and current year.  \\n I have also looked up the red green blue,  \\n the composition of the New York Times colors,  \\n which Matplotlib bonds as values between zero and one.  \\n The optional step equals myth makes the band look blocky  \\n so the individual days are in evidence.  \\n And last, the alpha setting makes  \\n the current year band partially transparent.  \\n I set reasonable access limit and finally add a title.  \\n Let's fire it off, very nice.  \\n In 2018, some values are missing,  \\n we see the purple band is interrupted  \\n and those are actually the hottest days.  \\n So you can play with other cities we'll turn this example  \\n into a function that can plot any year in any station.  \\n So here's New York in 2018.  \\n NumPy is extremely powerful and flexible,  \\n so you should learn about it in depth.  \\n Coupled with Matplotlib it offers a direct route  \\n to beautiful and informative visualizations.  \\n In my course, Python Statistics Essential Training,  \\n explores statistical plots in more detail  \\n and with more examples.  \\n You are now ready for your challenge.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2293502\",\"duration\":46,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Challenge: Weather anomalies\",\"fileName\":\"2825705_05_06_XR30_CH30_challenge2\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In the challenge, you are asked to make a visualization of temperature anomalies over the historical record by computing yearly averages and comparing to midcentury averages. To do so, build on the code that you developed in this chapter.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1250849,\"solution\":false,\"welcomeContent\":null,\"challenge\":true,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (upbeat chime)  \\n - For your challenge,  \\n I'm asking you to plot the temperature anomaly for New York  \\n by computing yearly temperature averages for each year  \\n and comparing those with a mid-century average  \\n in the 1945-1955 decade.  \\n You can make yearly averages  \\n just as we did for the title  \\n of the New York Times inspired plot.  \\n TMIN plus TMAX over two  \\n averaged across the year.  \\n To make the mid-century average,  \\n just sum up results for 1945 through 1955  \\n and then take the difference.  \\n This challenge should take about 15 minutes.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2293503\",\"duration\":125,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Weather anomalies\",\"fileName\":\"2825705_05_07_XR30_SO30_solution2\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":4073114,\"solution\":true,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (upbeat music)  \\n - [Instructor] We start by importing getWeather,  \\n since we need temperature data.  \\n It will also be good to show smoothed plots,  \\n so we'll grab the smooth function that we made.  \\n We need all the available historical data for New York,  \\n say 1880 through 2019,  \\n which we collect in a stacked array.  \\n We sum TMIN and TMAX for this large array  \\n and then take the average across the columns.  \\n So x is equal one,  \\n so that we get a value for each year.  \\n The shape isn't yet what we expect.  \\n Next, the mid-century average.  \\n We need to figure out the index of 1945 and 1955,  \\n in this all avg array.  \\n For lists, we can use index  \\n to figure out the location of an element.  \\n But unfortunately,  \\n that doesn't work for NumPy arrays.  \\n However, we can turn array into lists quite easily  \\n by feeding them to the list constructor,  \\n and then index works.  \\n So now we can perform the mid-century average  \\n over the correct slice of the array.  \\n It's 12.8 degrees.  \\n And here's the plot.  \\n The anomaly is all avg  \\n minus the mid-century mean.  \\n It's quite noisy,  \\n so let's smooth it out.  \\n If we use valid mode to avoid artifacts at the edges,  \\n we need to remove some years from the x-coordinate.  \\n The solution is complete really,  \\n but we can collect this code in a more general function  \\n so we can compare a few cities.  \\n So here's the comparison,  \\n with some complaints from NumPy  \\n by way of Jupiter  \\n that there's really no data before 1910 for Pasadena,  \\n and 1940 for Minneapolis.  \\n Still, the upward trend for all these three locations  \\n is quite evident.  \\n \\n\\n\"}],\"name\":\"5. Use Case: Weather Data\",\"size\":52916907,\"urn\":\"urn:li:learningContentChapter:2295372\"},{\"duration\":1258,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2293504\",\"duration\":68,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"pandas overview\",\"fileName\":\"2825705_06_01_XR30_pandasoverview\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"pandas' powerful table objects, DataFrames, are extremely useful in the analysis of structured data that associates textual, date, and numerical information. In this video, you are introduced to the basic structure of pandas series and DataFrames, and compare them with NumPy arrays.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1758373,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] Pandas has gained broad acceptance  \\n in the Python community  \\n as the data analysis tool for Python.  \\n As of January 2020,  \\n it should reach version 1.0 very soon,  \\n signaling the stability of its API,  \\n its programming interface.  \\n Pandas is built on top of NumPy so it's very fast.  \\n And it extends NumPy in ways that are extremely useful  \\n to data analysis.  \\n For instance it attaches labels to table columns and rows.  \\n It lets us access data using indexes  \\n built from any variable.  \\n It allows us to modify table structure  \\n by adding and dropping columns  \\n and by performing other transformations.  \\n It recognizes many common data formats.  \\n It handles missing data easily.  \\n It implements database operations such as joins  \\n and it can even make plots.  \\n So if you want to do data analysis  \\n or data science with Python,  \\n I really recommend that you learn Pandas.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2294384\",\"duration\":395,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"DataFrames and Series\",\"fileName\":\"2825705_06_02_XR30_dataframes\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"To be efficient in data analysis, you need to ingest data sets in many formats, reorganize them into usable tables, and select subsets of their rows or columns. In this video, learn how to create DataFrames from Python data structures or from files; to inspect DataFrames; to extract and modify their columns; and to select data based on conditions\u2014the pandas version of fancy indexing, and the query method.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12008064,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] The two key objects in pandas  \\n are the DataFrame and the Series.  \\n A DataFrame is basically a table of data.  \\n Each column has a name and an assigned data type as a NumPy.  \\n In addition though, the DataFrame has an index,  \\n which is not necessarily the ordinal number of the row.  \\n In this example, where the columns contain name,  \\n date of birth and city, the index could be  \\n the social security number or an alphanumerical employee ID.  \\n A Series is effectively a single column  \\n from a DataFrame with its own index.  \\n Having an index makes it more powerful  \\n than a simple NumPy array.  \\n For instance, if we have two time Series  \\n that have partially overlapping indices, times,  \\n we can still combine them and pandas will figure out  \\n which entries it can actually compute.  \\n Just as for NumPy arrays the easiest way  \\n to get a pandas DataFrame is to load it from a file.  \\n And pandas can read and write  \\n an even larger variety of formats than NumPy  \\n These include ASCII tables, json, Excel,  \\n the hierarchical data format HDF  \\n using many scientific application, SAS, SAS, Strata,  \\n Big data storage formats, such as Apache Feather and Parquet  \\n SQL and even HTML tables, which is great  \\n if you want to scrape data from a website.  \\n In this table, I show you the formats  \\n with the pandas functions that read and write them.  \\n Some of them may require the assistance of another package  \\n that you need to install separately.  \\n We start with a simple text file.  \\n Nobels.CSV, which contains a list of Nobel Laureates  \\n with a year in discipline  \\n in which they were awarded their prize.  \\n We can have a look.  \\n This is quite simple, the values are separated by commas.  \\n Pandas read CSV with this without breaking a sweat.  \\n We do need to provide names for the columns  \\n since the file itself doesn't have that information.  \\n Read CSV has many other options  \\n including specifying separators other than commerce,  \\n skipping columns or rows, converting dates and more.  \\n Let's look at the DataFrame.  \\n The method Info gives us basic information.  \\n And the method Head prints the first few rows,  \\n Tail the last.  \\n We have a total of 950 records.  \\n And we see that indeed the columns are named year  \\n discipline and the Nobelist.  \\n The data types are integer for the year  \\n and Python object for discipline and Nobelist.  \\n That's an important observation while in NumPy,  \\n we represent strings as fixed with runs of characters.  \\n In panda strings are effectively the immutable strings  \\n of Python, which are more versatile.  \\n As I mentioned, the index plays a very important role  \\n for data frames, but this one in particular,  \\n is a boring Numerical index.  \\n To grab the individual columns, which become Series,  \\n we use a dict like syntax with brackets,  \\n or a class like syntax with dot.  \\n Either way, the result is a pandas series,  \\n the object there represents a column.  \\n Consequently, the series has a name, ID type,  \\n and it carries with it the index of the original DataFrame.  \\n If we need a naked NumPy array of the values,  \\n we can still get it with dot values.  \\n Here's a small slice.  \\n Sometimes it's useful to get a list or really a NumPy array  \\n of all the unique values in a column.  \\n Other times, it's useful to have counts of the times  \\n each item appears.  \\n This accounting confirms that three scientists  \\n were awarded two prizes.  \\n To select records, we can use fancy indexing,  \\n building a Boolean expression that involves the columns.  \\n For instance, select the Nobels in Physics.  \\n Or you can use the convenient and fast Query Interface  \\n which takes a logical expression given as a string.  \\n We have to mind our quotes here making sure that we use  \\n single quotes for the query  \\n and double quotes for any values inside it.  \\n Sometimes it's not evident how to write  \\n a filtering operation.  \\n For instance, if we seek all the Nobelists  \\n whose name contain Curie, we like to write  \\n something like this, Nobel's fancy indexed by Curie  \\n in Nobel's Nobelist but that fails quite spectacularly.  \\n Instead we need to dig down in the string methods  \\n supported by the series to find Contains,  \\n which does what we need.  \\n The selection confers incredible winning streak  \\n of the Curie family.  \\n Marie her husband Pierre,  \\n her daughter Irine and her son in law Frederic  \\n Be sure how to create a data frame yourself.  \\n First from a NumPy record array.  \\n For instance, the David Bowie discography  \\n that we use as an example in chapter four.  \\n This is almost like cheating because NumPy record arrays  \\n are in fact the very back end of pandas.  \\n Nevertheless, the fixed length strings  \\n are converted to Python objects, when we get a DataFrame.  \\n Starting from scratch, we may build a DataFrame  \\n from a list of dictionaries, which means  \\n that we'll be repeating the column names over and over.  \\n Or from a list of tuples by providing names for the columns  \\n here title and top rank.  \\n Name tuples would also work great here.  \\n Otherwise, we can build the DataFrame in the other direction  \\n from a dictionary of vectors or lists.  \\n Here I'm just copying information  \\n from the NumPy record array to make actual lists.  \\n And then I feed them to DataFrame.  \\n We have DataFrames, let's move on to using them.  \\n Now that we know how to load or make DataFrames,  \\n let's do something interesting with them.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2293505\",\"duration\":349,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Indexing in pandas\",\"fileName\":\"2825705_06_03_XR30_indexing\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Once you have your data organized, you may need to find the specific records you want. In this video, learn how to index DataFrames with NumPy-like indexing, or by creating indexes. Also, explore powerful but confusing MultiIndexes.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":10651500,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] We have seen how to load  \\n and create dataframes  \\n and how to select records based on boolean conditions  \\n both with fancy indexing  \\n and with a string expression-based query interface.  \\n Now we'll see how we can make selections even more directly  \\n and more efficiently using indices.  \\n So let's load up our Nobel list data set again.  \\n The index is currently the simplest possible  \\n just numbers from zero through 949.  \\n We elevate the years to serve as index.  \\n We do this with a set index method  \\n which does not work in place  \\n but other creates a new dataframe.  \\n Now the years appear as the index  \\n at the front of each row.  \\n And here's the index itself.  \\n This shows that in Pandas,  \\n indices do not need to have unique values.  \\n That's a feature, not a bug.  \\n It lets us select all records for a year, for instance,  \\n using the indexing notation  \\n and here things get a bit complicated.  \\n There are several ways to do indexing and slicing in Pandas,  \\n some equivalent to each other, some not.  \\n I'm going to show you the two interfaces  \\n that I think are the least confusing.  \\n To select all records for a given index,  \\n we use .loc followed by brackets, not parentheses,  \\n with the index value.  \\n For instance, 1901.  \\n We can also add a column name  \\n just as if we were selecting a cell in a numpy array.  \\n The result is a series.  \\n In addition to selecting individual index values  \\n .loc allows for slices.  \\n But in a break from Python new search,  \\n the range is inclusive of its end value.  \\n If we choose the years of the great war, 1914-1918,  \\n then 1918 appears in the selection.  \\n We are not limited to all micro-indices.  \\n We can set up a dataframe  \\n indexed by discipline, for instance.  \\n And it's always best to keep the index sorted  \\n which we do with sort_index.  \\n Then we can select not just individual index values,  \\n but also ranges, which again, are inclusive.  \\n So physics,  \\n or medicine through peace.  \\n Here there are 353 rows  \\n but Pandas is only showing us a few at the beginning  \\n and at the end.  \\n That's what the ellipses symbols mean in the middle.  \\n If you want numpy style indexing,  \\n looking only the progressive count of the records,  \\n you can have it with .iloc, again, brackets.  \\n Here we get the first 10 records, whatever they are,  \\n in the dataframe in its current order.  \\n But this is not the end of the story.  \\n Pandas supports multi indices.  \\n For instance, a dataframe indices nobelists by year first,  \\n and then discipline.  \\n It looks like this.  \\n The underlying index is a very complicated beast.  \\n But we can isolate the values set at two levels  \\n using, appropriately, get level values.  \\n Armed with this multi-index dataframe,  \\n we can select records by both year and discipline.  \\n Passing it two-pole to .loc.  \\n For instance, physics and 2017.  \\n Slicing however, can get complicated.  \\n Say we want chemistry prizes between 1901 and 1910.  \\n What we would like to do is to write a slice  \\n with a column in a two-pole.  \\n But Python doesn't allow that.  \\n How about we use the long-hand expression for the slice?  \\n Slice by indices start and end value.  \\n That's still confusing to Pandas  \\n because then it tries to use chemistry as a column name.  \\n What works is to request the set of columns  \\n explicitly in the .loc expression.  \\n In this case, all of them with a comma.  \\n Fancy indexing works also.  \\n Here, slice none means that we're taking all the years  \\n but we select a list of the disciplines.  \\n And again, all the fields.  \\n Finally, while multi-indexing is powerful,  \\n it can be confusing.  \\n And so you may have to resort to trial and error.  \\n Any selection that you make that way, however,  \\n you can also achieve without multi-indexing  \\n by using criteria on the values in the columns.  \\n For instance, chemistry prizes between 1901 and 1910.  \\n Where I have built a three boolean arrays,  \\n years are going to equal the 1901,  \\n years less or equal to 1910,  \\n and discipline equals equals chemistry  \\n and I have taken the logical end with the ampersand.  \\n Or again, with query,  \\n which lets me write the same selection  \\n in a more intuitive form.  \\n Note, however, that all these queries return new dataframes.  \\n So you cannot use them to modify values  \\n in the original table as you could do with the indices.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2293506\",\"duration\":446,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Plotting\",\"fileName\":\"2825705_06_04_XR30_plotting\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In data analysis, you often need to transform tables by applying operations to one or more columns. Visualizing the transformed datassets is also crucial to understanding them. In this video, learn about the basics of performing mathematical operations and of plotting with pandas.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":14191300,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] We have seen how to load  \\n and create data frames, and how to select records  \\n or ranges of records, but we have not done much  \\n with the values in the tables.  \\n In many data analysis tasks, you're interested  \\n in running computations with the columns  \\n and then making plots.  \\n Let's try that with Pandas.  \\n We'll load the data set consisting  \\n of global population health and wealth statistics,  \\n from the amazing Gapminder website.  \\n Gapminder is a Swedish foundation created  \\n by the late Hans Rosling to promote a fact-based worldview  \\n and to fight misconceptions about global development.  \\n If you want to make plots in the Gapminder style  \\n internalize their data in some depth,  \\n you can try my LinkedIn learning course,  \\n Python Statistics Essential Training.  \\n In this video we'll do simpler things  \\n but still learn a lot.  \\n So we load the comma-separated file.  \\n And we see that the data set includes a number  \\n of global statistics.  \\n Each row identifies a country, a year,  \\n the corresponding region, and then they count us  \\n population, life expectancy, the percentage  \\n of children born alive who survive to age five,  \\n the average number of babies per fertile woman  \\n and the domestic product per person in 2011 dollars.  \\n We can ask Pandas to compute single statistics  \\n on all the fields.  \\n We do that with data frame describe.  \\n We see that there are almost 15,000 records  \\n in the data set for years ranging from 1800 to 2015.  \\n We can read off the minimum, maximum, mean,  \\n and standard deviation for all the fields  \\n as well as the 25th, 50th, and 75th percentiles.  \\n If you don't know about these don't worry.  \\n They give us an idea of the typical values  \\n and typical range of variation of a quantity.  \\n One of the points that Gapminder makes to great effect  \\n is that life expectancy improves with wealth,  \\n the Gross Domestic Product per person, GDP,  \\n and that the correlation is even clear  \\n if we look at the logarithm of the GDP per person per day.  \\n We don't have a column with that information,  \\n but it's very easy to compute it and to store  \\n it in a new data frame column.  \\n So we divide GDP per capita by the average number  \\n of days in a year, apply a non-pi log 10,  \\n and store that in a new column which then appears  \\n in the data frame.  \\n To see global trends as a function of time  \\n or to examine individual countries,  \\n it makes sense to index by year and then country.  \\n We will have two versions of the data frame  \\n with those two indices.  \\n Pandas has its own plotting interface  \\n which focuses on choosing the variables with which to plot.  \\n Say for instance we want to show life expectancy  \\n is a function of log GDP.  \\n So we select data for 1960 with dot log,  \\n and then generate a scatter plot of those two variables,  \\n it's sufficient to give the column names to Pandas.  \\n If we want to compare a more recent year in the same plot,  \\n we need to grab a map of lib axis object from the first plot  \\n and then pass it to the second.  \\n This is the kind of solution you find  \\n on http://www.stackoverflow.com.  \\n You should also change colors  \\n and label the two clouds of points.  \\n We see that in going between 1960  \\n and 2015, the dots flatten towards the top,  \\n towards higher life-expectancies.  \\n Thanks to significant progress  \\n in public health policy and practice.  \\n The trend is the same for other statistical indicators  \\n such as survival by age five.  \\n The data frame index by country lets us make easy plots  \\n of the chronological evolution of an indicator  \\n such as life expectancy for a country such as Italy.  \\n But the result is jumbled  \\n if we don't first sort the values by year.  \\n I'll do it here with sort values.  \\n The style of coding where I concatenate one Pandas method  \\n after the other is in fact quite idiomatic for Pandas,  \\n if not for Python.  \\n So when we say that Pandas speaks  \\n its own Python dialect.  \\n Here's a comparative plot for three countries.  \\n Again we grab the math.lib axis and pass them  \\n to the second or third plots.  \\n We see that Italy caught up with the United States  \\n in terms of life expectancy and China is coming close  \\n after the disastrous 1960 famine.  \\n Another interesting and important correlation  \\n was between fertility rate and survival to age five.  \\n To look at this question globally we can compute the average  \\n fertility rate over all records,  \\n that however doesn't mean much,  \\n since it misses data from many years.  \\n We can use the Panda's group by functionality  \\n to segment the data frame by year  \\n before computing the average.  \\n The result is a series indexed by year  \\n which shows the average fertility rate as a function of time  \\n and we plot it against age five survival,  \\n treated in the same fashion.  \\n The Pandas plot allows us to add a second axis  \\n on the right to show the range of the second variable  \\n that we plot.  \\n This shows forcefully that high natality  \\n is a consequence of infant mortality,  \\n and that women have many fewer children  \\n when they believe they will survive.  \\n On a small scale, we see that post 1950 baby boom.  \\n To gain even more insight we can create a pivot table.  \\n This segments the fertility means by both year  \\n and geographical region.  \\n Pandas is very happy to plot the resulting timelines.  \\n The drop in fertility came after the baby boom  \\n for Africa, America, and Asia.  \\n Europe was already low and decreasing  \\n since the beginning of the 20th century.  \\n And here's the corresponding plot for age five survival.  \\n Africa is now roughly where Europe was in 1950.  \\n Using Pandas plotting functions is the quickest way  \\n to make insightful statistical illustrations.  \\n But for maximum flexibility,  \\n you can always extract the values  \\n from the frames as non-pras  \\n and pass those to standard math.lib functions,  \\n which are fully customizable.  \\n There's a lot more you can do in Pandas,  \\n and there's a lot more to learn  \\n that I can cover in this course.  \\n I try instead to give you a feel  \\n for what is possible and practical.  \\n I encourage you to start working  \\n on a data set that interests you  \\n and to pick up more techniques and knowledge  \\n using the many resources available on the web.  \\n \\n\\n\"}],\"name\":\"6. pandas\",\"size\":38609237,\"urn\":\"urn:li:learningContentChapter:2293508\"},{\"duration\":1033,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2293507\",\"duration\":44,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Overview of use case\",\"fileName\":\"2825705_07_01_XR30_babyoverview\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In this chapter, practice pandas by analyzing the popularity of baby names in the U.S. as recorded by the Social Security Administration. In this video, outline your analysis goals.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1315728,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] We are now going to apply pandas  \\n to an intriguing real world use case.  \\n We will analyze the U.S. Social Security Baby Name Catalog,  \\n which reports the names given to male and female newborns  \\n for every year since 1880.  \\n This is a very simple data set,  \\n but it's great fun to play with,  \\n and it has been mined, analyzed, and visualized  \\n in many publications and websites.  \\n Specifically, I will show you how to load it,  \\n how to track the popularity of a name across all years,  \\n and how to extract the 10 most popular names every year.  \\n Your challenge will be about finding  \\n the most common unisex names.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2295365\",\"duration\":196,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Loading data sets\",\"fileName\":\"2825705_07_02_XR30_loadingbaby\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Using Python and its libraries, you can gather and organize data very efficiently. In this video, download compressed archives from the web, use Python to open them, load their contents, concatenate them into DataFrames, and save the resulting well-organized data.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":5780382,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] You can download the Social Security  \\n name data set from their website.  \\n But I have also included the archive names.zip  \\n in your exercise files.  \\n We need to uncompress it,  \\n which we can do in Python using the ZipFile module.  \\n The interface is object oriented.  \\n You first create a ZipFile object,  \\n then called extract all in the current directory.  \\n That's the dot.  \\n Jupiter lets us browse the contents  \\n of the current directory with ls.  \\n We see that names.zip,  \\n unpacked into a directory with many text files,  \\n presumably one for every year.  \\n Let's have a look at one.  \\n We open it in read mode  \\n and print out the first few lines.  \\n It's a very simple comma separated format.  \\n Name, sex, presumably F or M,  \\n and then the number of babies born that year with that name.  \\n Pandas read CSV shouldn't have any problems.  \\n But we did do something wrong.  \\n The first record in the file, Sofia,  \\n was used to set the names of the columns.  \\n We need to provide the column names explicitly,  \\n since they're not in the file.  \\n We've already done this for the Nobel data set.  \\n Better.  \\n We will need to load all the tables  \\n and concatenate them in a single data frame.  \\n To avoid confusing data from different years,  \\n we can prepare the individual data frames  \\n by adding a new column that specifies the year.  \\n To do it on the fly, directly from the output of read CSV,  \\n by chaining a method,  \\n we can use data frame assign.  \\n In this case, a new column year appears with value 2011.  \\n Excellent.  \\n We managed to load the file in a one liner,  \\n so you can see that I'm going to use a comprehension  \\n to concatenate all the data frames.  \\n There are several things happening here.  \\n So let's look at this carefully.  \\n We loop over all the years between 1880 and 2018.  \\n We build up the file name using an f-string,  \\n and feed that to read CSV.  \\n We specify the column names,  \\n and we add the column that gives the correct year  \\n from the loop variable.  \\n Finally, we pass all the resulting data frames  \\n to pd concat, pandas concat.  \\n You see there are no brackets here,  \\n so this is in fact a generator expression,  \\n not the comprehension,  \\n which pd concat accepts quite happily.  \\n It's a very efficient way to build a data frame,  \\n and it's all there.  \\n Almost two million entries.  \\n The year range is what we expect.  \\n We can save the merged data frame using to CSV.  \\n We don't need to say the index  \\n and if we specify a file name that ends in .gz,  \\n the resulting file will be automatically compressed.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2295366\",\"duration\":260,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Comparing name popularity\",\"fileName\":\"2825705_07_03_XR30_popularity\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"Organizing pandas DataFrames with the appropriate index is important to gain easy access to the records we seek. In this video, learn how to create a MultiIndex for your data set, sort it by index value, and compare the popularity of common and similar names by plotting the corresponding time series together. Parallel and stacked plots of timelines are often insightful visualizations.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":7870708,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] We are ready to start analyzing this data.  \\n How we load and look  \\n at the combined data frame we just created.  \\n We want to examine the change in popularity of a name.  \\n So we need to reframe the data in a way,  \\n that will make this easier.  \\n We will use a multi-index.  \\n We will index the date on sex first,  \\n then name, and then year.  \\n And we will also sort the index.  \\n Getting the data for any given name  \\n is then a simple exercise  \\n of indexing with dot loc.  \\n For instance Mary,  \\n this series is ready to plot.  \\n Notice how Metro-lib automatically uses  \\n the index to set the x-axis.  \\n We see two peaks.  \\n At approximately 1920 and 1950.  \\n It probably makes sense also  \\n to consider the frequency of a name as a fraction  \\n of the number of babies born in a year.  \\n To get that, we can apply group by  \\n on the un-indexed data frame and take the sum.  \\n Then we can normalize Mary  \\n by all the newborns in every year.  \\n So as a percentage of all babies,  \\n Mary was actually more popular  \\n at the beginning of the 20th century.  \\n But there were altogether  \\n more Marys born in the 1920s and 50s.  \\n For simplicity, we continue with unnormalized counts.  \\n So let's make a generic function plot name  \\n to make a plot like this.  \\n In another function compare names  \\n to plot a few names together.  \\n You see that we pass a list of names through compare names.  \\n We look over the list called plot name for each of them  \\n and then add a legend, which is always good.  \\n Let's for instance compare Michael, John, David and Martin.  \\n Or for girls Emily, Anna, Claire and Elizabeth.  \\n It's already a popularity contest that we make in here.  \\n Another interesting investigations  \\n is to compare variance of the same name.  \\n For instance, there are two spellings of Claire.  \\n There's an older version Clara,  \\n and an Italian and Irish spelling  \\n for the pronunciation Ciara.  \\n Here's the plot.  \\n Notice how Metro-lib tries to put the legend out of the way.  \\n Claire is now dominant,  \\n but Clara is having a resurgance  \\n after having been the dominant variant  \\n at the beginning of the 20th century.  \\n We can make a slightly different cumulative  \\n or stacked plot that adds up the counts  \\n on top of each other.  \\n For that, we need a table of the frequencies  \\n for all the variance as a function of time.  \\n That would be an exercise in multi-indexing.  \\n We start by selecting all the Claires  \\n and then we can apply data frame and stack  \\n to move one of the index levels to a column name.  \\n In this case the year is level two of the multi-index.  \\n So the years become the columns.  \\n I must say that sometimes it's hard to make sense  \\n of what unstack does, so expect some trial and error.  \\n By contrast, unstacking level one  \\n would have made columns corresponding to the name variance.  \\n We can now try this stack plot.  \\n On the x-axis we will have the years  \\n just a simple range will suffice.  \\n And on the y-axis, the stacked values.  \\n This works but we see that the plot  \\n is truncated around 1974.  \\n That must be because of some of the Nans in the table,  \\n which do not lend themselves to be summed up.  \\n That's easy to fix  \\n with data frame fill and A.  \\n We'll replace the Nans with zeros.  \\n And here's the final plot.  \\n I have also added a legend,  \\n seeded by the labels given to stack plot.  \\n And I've restricted the x-axis,  \\n quite nice and informative.  \\n Except perhaps for the garish different colors  \\n chosen by map plot lib.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2295367\",\"duration\":263,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Yearly top ten names\",\"fileName\":\"2825705_07_04_XR30_toptennames\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In many cases, you need to sort and subset DataFrames based on values rather than indices. In this video, find the top ten names over a range of years, which involves several pandas operations that are broadly useful.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":8221776,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - [Instructor] In this video,  \\n we will create yearly top 10s for male and female names.  \\n We load the data, and this time,  \\n we index it slightly differently, by sex and year only  \\n since we will need to compare all the names in the database.  \\n We now build up a query by chaining pandas methods.  \\n Getting males in 2018  \\n is a simple matter of a multiindex.log.  \\n Then we get the most popular names  \\n by sorting our number in descending order.  \\n Head gives us a top 10.  \\n In 2018, Liam was king, followed closely by Noah.  \\n How about girls?  \\n We index sex with f, and the year is still 2018.  \\n For girls, it was Emma and Olivia.  \\n If we to build a table of the top 10 names  \\n over multiple years,  \\n we should get rid of the index with Reset Index,  \\n and select the name, Column Only.  \\n I will make this into a generic function.  \\n As I was saying, in pandas,  \\n one sees this operator chaining style often.  \\n And we can make the code clear  \\n by giving each method it's own line.  \\n It's a good idea, however, to add comments  \\n to explain what you're doing,  \\n either for your collaborators or your future self  \\n since pandas can be obscure.  \\n To form a table,  \\n we collect the series for different years  \\n as the columns of the data frame, labeled by the year.  \\n So in effect,  \\n we're creating a data frame from a dict comprehension.  \\n For males, you can see Liam gaining popularity  \\n and Jacob dropping.  \\n For females, we see that Emma has been dominant  \\n for a few years while Sophia dropped.  \\n Olivia is there, waiting to take the crown.  \\n How about the popularity plot for the 2018 top 10?  \\n For a change, we'll use the query interface,  \\n which conveniently lets us use the values of variables  \\n with the Add Notation.  \\n So here, we're passing sex and name to the function.  \\n And we select in All The Records  \\n where the sex column equals the sex argument,  \\n and the name column equals the name argument.  \\n This is not very pythonic,  \\n but it's nice to have once you know about it.  \\n Once we have the records, we plot number against year.  \\n So let's loop over the 2018 female top 10 and plot each.  \\n It's interesting to see  \\n that all the top names seem to have surged quite recently  \\n except perhaps for Evelyn, which was popular in the 1920s.  \\n As for the male names, two are classics, William and James.  \\n Let's look at the others then.  \\n This is the list, and I will copy  \\n a subset of it to the loop over which I plot.  \\n So now, I'm excluding William and James.  \\n And I see that, yes, the other eight  \\n have also been recent discoveries.  \\n How about all-time favorites?  \\n We get there quickly by selecting females, say,  \\n grouping by name, summing the numbers,  \\n sorting by the values, and then taking the top 10.  \\n Mary is in fact the all-time favorite among girls.  \\n If we look at the popularity over time of these names,  \\n we see that they've gained their spots  \\n in the first half of the 20th century except for Jennifer.  \\n Now that given the structure of the all-time f data frame,  \\n I'm looping over the index rather than the value.  \\n Next, you'll be asked to use what you learned  \\n in a challenge about unisex names.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2295368\",\"duration\":63,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Challenge: Unisex baby names\",\"fileName\":\"2825705_07_05_XR30_CH30_challenge3\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"In the challenge, you are asked to identify unisex names and to plot their male/female distribution, by building on the code that you developed in this chapter.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":1715937,\"solution\":false,\"welcomeContent\":null,\"challenge\":true,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (playful music)  \\n - [Narrator] For your challenge,  \\n I would like you to find a top ten unisex names  \\n and to plot their popularity throughout the years  \\n for both the male and female usage of the name.  \\n We will define unisex names as those for which  \\n the total number of boys and a total number of girls  \\n born across all years and within a factor of two.  \\n That means that you're going to compute  \\n the total number of boys,  \\n divide by the total number of girls,  \\n and verify that that's between 0.5 and two.  \\n Given the technical nature of some Pandas computations,  \\n I have some hints for you.  \\n Try using DataFrame.groupby().  \\n Take advantage of the fact that Pandas  \\n can execute a mathematical operation between two series  \\n even if they have different indexes.  \\n And finally, if you need to drop not a number,  \\n nan values, use DataFrame.dropna.  \\n \\n\\n\"},{\"urn\":\"urn:li:learningContentVideo:2295369\",\"duration\":207,\"visible\":true,\"requiredForCertificateOfCompletion\":true,\"name\":\"Solution: Unisex baby names\",\"fileName\":\"2825705_07_06_XR30_SO30_solution3\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":6047873,\"solution\":true,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" (upbeat music)  \\n - As I mentioned already, in Pandas there are often  \\n several ways to get the same result.  \\n So if your results are similar to mine,  \\n but you get them in a different way,  \\n don't worry, your solution may even be better.  \\n We'll load our data set as usual.  \\n We need to compute the total number of boys and girls  \\n for a given name.  \\n This seems a good place to use group by,  \\n which lets us segment the data before applying  \\n an aggregation, in this case, the sum  \\n of the number of babies.  \\n So we use group by over sex and name,  \\n we select the number column and we take the sum.  \\n From this list with a multi-index,  \\n we can grab the males and females respectively,  \\n using dot lock.  \\n As you see, the two indices are going to be different.  \\n Epon doesn't appear in the females.  \\n Nevertheless, we can combine the two series  \\n and pandas will align the indices for us.  \\n The results would be none where either series  \\n doesn't have an element.  \\n For instance we check where the ratio between  \\n males and females is less than two.  \\n We can certainly get rid of those nones  \\n with drop in A.  \\n Now, remember the definition of unisex names  \\n as those with a ratio between .5 and two.  \\n This is a good expression for fancy indexing,  \\n and after we apply it,  \\n we see that 1660 names pass the test.  \\n Here, I've taken the index, because we don't actually need  \\n the ratio itself, but just the names.  \\n The next thing to do is to find the ten most common  \\n unisex names, so we sum the male and female counts  \\n using the unisex array to index our two totals.  \\n We sort the resulting series,  \\n and we cut it off at the top.  \\n Jessie seems to be the winner of this particular contest,  \\n followed by Reilly, Casey, and Jackie.  \\n Now to clock popularity, it's convenient to use  \\n a fully indexed data frame.  \\n We also remember to sort that index.  \\n Now we'll loop over the most common unisex names,  \\n which remember, are the index of the common series,  \\n and we plot by selecting male or female in the name.  \\n Matplotlib type layout helps improve the spacing  \\n of the subplots, while Jessie is the absolute winner,  \\n it appears to have fallen out of favor somewhat.  \\n Reilly is ascendant, but not for boys anymore,  \\n and Casey, which peaked around 1990,  \\n may be the most unisex name of all,  \\n with the male usage of the name tracking the  \\n female usage very closely.  \\n Great, we've been through a lot in this course,  \\n and I hope you've gained an understanding  \\n of what is possible with NumPy and Pandas and matplotlib,  \\n and more generally, with Python as a language  \\n for data analysis.  \\n I hope you'll go out to discover and learn  \\n even more and that you use Python happily  \\n in your every day work.  \\n \\n\\n\"}],\"name\":\"7. Use Case: Baby Names\",\"size\":30952404,\"urn\":\"urn:li:learningContentChapter:2295373\"},{\"duration\":58,\"entries\":[{\"urn\":\"urn:li:learningContentVideo:2294385\",\"duration\":58,\"visible\":true,\"requiredForCertificateOfCompletion\":null,\"name\":\"Next steps\",\"fileName\":\"2825705_08_01_LA30_NextSteps\",\"demo\":false,\"videoCreationMetadata\":null,\"description\":\"There are many resources on the web that can help you master data analysis with Python and explore more advanced topics. This video suggests a few options.\",\"captionsStatus\":\"AVAILABLE\",\"cdnStatus\":\"AVAILABLE\",\"size\":12669699,\"solution\":false,\"welcomeContent\":null,\"challenge\":false,\"assetStatus\":\"COMPLETE\",\"transcript\":\" - Well done.  \\n Thank you for following along  \\n through some rather challenging material.  \\n You are at the start of your road to mastery.  \\n You can now move on to my more advanced courses  \\n on programming efficiently in Python  \\n and on statistics with Python.  \\n Back to the topic of this course,  \\n here are some resources that can help you learn more.  \\n You can find the answer to any question about Python  \\n or about NumPy, Matploylib and pandas  \\n on the official websites.  \\n These packages are also discussed in  \\n \\\"Python Data Science Handbook\\\" by Jake Vanderplas,  \\n a very insightful and no-nonsense textbook.  \\n If you get stuck, look for help  \\n in an internet forum such as Stack Overflow.  \\n You'll find that Python has a very helpful  \\n and supportive community.  \\n Many have said that the best thing about Python  \\n is that it's a language that makes you happy.  \\n I agree so have fun and do great things.  \\n \\n\\n\"}],\"name\":\"Conclusion\",\"size\":12669699,\"urn\":\"urn:li:learningContentChapter:2293509\"}],\"size\":310335127,\"duration\":9035,\"zeroBased\":false}],\"id\":\"65ea3ec234505e27927a3c4e\",\"product\":\"Pro Cert\",\"status\":\"Ramped\",\"description\":\"Python offers myriad possibilities for preparing, analyzing, and reporting data. If you\u2019re starting a career in data analysis or looking to improve your skills, these courses can help. Tune in, pass the final exam, and earn your certificate.<br><br>This certificate is endorsed by Anaconda, a trusted Python/R platform for data science, machine learning, and AI. Continue your Python learning journey at <a href=\\\"https://www.anaconda.com/learning?utm_source=linkedin&utm_medium=anaconda&utm_campaign=LIL-cert\\\" target=\\\"_blank\\\">Anaconda Learning</a>.\",\"outcomes\":\"Python offers myriad possibilities for preparing, analyzing, and reporting data. If you\u2019re starting a career in data analysis or looking to improve your skills, these courses can help. Tune in, pass the final exam, and earn your certificate.<br><br>This certificate is endorsed by Anaconda, a trusted Python/R platform for data science, machine learning, and AI. Continue your Python learning journey at <a href=\\\"https://www.anaconda.com/learning?utm_source=linkedin&utm_medium=anaconda&utm_campaign=LIL-cert\\\" target=\\\"_blank\\\">Anaconda Learning</a>.\"}"